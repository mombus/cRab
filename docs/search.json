[
  {
    "objectID": "chapter 9.html",
    "href": "chapter 9.html",
    "title": "10  Стандартизация CPUE: GLM, GAM, GAMM",
    "section": "",
    "text": "10.1 Введение\nВ рамках данного практического занятия рассматриваются методы стандартизации улова на усилие (CPUE) с использованием обобщенных линейных (GLM), обобщенных аддитивных (GAM) и обобщенных аддитивных смешанных моделей (GAMM). Стандартизированный индекс CPUE служит важным показателем состояния запаса, который часто используется в качестве входных данных в моделях “запас-промысел”. Исходные данные уловов на усилие обычно содержат неучтенную вариацию, вызванную влиянием различных факторов, таких как сезон, район промысла, глубина, тип грунта, орудия лова или особенности конкретного судна . Если эту вариацию не устранить, то сырой, нестандартизированный индекс CPUE может давать искаженную картину динамики запаса. Цель стандартизации заключается в том, чтобы отделить изменение численности запаса от влияния этих побочных факторов, получив таким образом более надежный и сопоставимый с истиной численностью популяции (части популяции) индекс.\nПолный скрипт можно скачать по ссылке.\nДля работы скрипта:",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE: GLM, GAM, GAMM</span>"
    ]
  },
  {
    "objectID": "chapter 9.html#введение",
    "href": "chapter 9.html#введение",
    "title": "10  Стандартизация CPUE: GLM, GAM, GAMM",
    "section": "",
    "text": "Скачайте файл данных (KARTOGRAPHIC.xlsx)\nУстановите рабочую директорию в setwd()\nУстановите необходимые пакеты : install.packages(c(\"readxl\", \"tidyverse, \"mgcv\", \"gamm4\", \"DHARMa\" )) и др.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE: GLM, GAM, GAMM</span>"
    ]
  },
  {
    "objectID": "chapter 9.html#пошаговое-описание-скрипта",
    "href": "chapter 9.html#пошаговое-описание-скрипта",
    "title": "10  Стандартизация CPUE: GLM, GAM, GAMM",
    "section": "10.2 Пошаговое описание скрипта",
    "text": "10.2 Пошаговое описание скрипта\nСкрипт начинается с загрузки необходимых пакетов для обработки данных, построения моделей и визуализации результатов. Среда настраивается путем установки рабочей директории и фиксации случайного зерна для обеспечения воспроизводимости всех последующих вычислений.\nНа следующем этапе происходит загрузка исходных данных из файла Excel. Данные представляют собой промысловую статистику, содержащую информацию о году, месяце, судне, районе, величине улова на усилие (CPUE) и др. Выполняется их предварительная обработка: фильтрация по осенним месяцам, преобразование типов переменных в факторы и числовой формат, а также удаление пропущенных значений. Поскольку для моделирования с гамма-распределением требуются строго положительные значения, для нулевых и отрицательных величин CPUE рассчитывается и добавляется малая поправка. Для первичного ознакомления с данными строится диаграмма размаха, показывающая распределение CPUE по годам.\nДалее определяются вспомогательные функции. Одна функция предназначена для нормировки рассчитанных индексов либо на среднее значение, либо на значение первого года. Другая функция использует метод маргинальных средних для расчета стандартизированных индексов и их доверительных интервалов на основе подобранной модели. Третья функция реализует расчет индексов и оценку неопределенности через бутстреп для моделей со сложной структурой.\nОсновная часть скрипта посвящена построению и анализу трех типов моделей. Первой подбирается обобщенная линейная модель (GLM) с гамма-распределением ошибок и логарифмической связью. В качестве предикторов используются факторы: год, месяц, судно и район. Для визуальной и численной диагностики адекватности модели выводятся ее сводка, таблица коэффициентов, стандартные диагностические графики и графики остатков, проверенные с помощью пакета DHARMa.\nСледующей строится обобщенная аддитивная модель (GAM). На этом этапе используется та же формула и семейство распределений, что и в GLM, но метод подбора гиперпараметров отличается. Проводится аналогичная диагностика модели с помощью функций summary и gam.check.\nЗатем подбирается обобщенная аддитивная смешанная модель (GAMM), которая дополнительно включает случайный эффект от судна. Это позволяет учесть вариацию, вызванную индивидуальными особенностями каждого судна, которые не описываются другими факторами. Диагностика этой модели более сложна и включает анализ остатков, проверку случайных эффектов и тест на гетероскедастичность.\nПосле построения всех моделей для каждой из них рассчитываются стандартизированные индексы CPUE и их доверительные интервалы. Для GLM и GAM это делается с помощью функции, основанной на маргинальных средних, а для GAMM применяется метод бутстрепа.\nФинальный этап включает объединение результатов всех трех моделей в единую таблицу и их визуальное сравнение на графике. На этот же график добавляются фактические медианные значения CPUE по годам из исходных данных для сопоставления со стандартизированными кривыми. В заключение модели сравниваются по информационным критериям (AIC, BIC) и другим метрикам, чтобы дать рекомендации по выбору наиболее адекватной из них.\nНиже приводится скрипт, а ниже скрипта - описание результатов моделирования.\n\n# ========================================================================================================================\n# ПРАКТИЧЕСКОЕ ЗАНЯТИЕ: СТАНДАРТИЗАЦИЯ CPUE С ИСПОЛЬЗОВАНИЕМ GLM, GAM И GAMM\n# Курс: \"Оценка водных биоресурсов в среде R (для начинающих)\"\n# Автор: Баканев С.В. \n# Дата: 20.08.2025\n# \n# Структура:\n# 1) Загрузка пакетов и настройка среды\n# 2) Загрузка и предварительная обработка данных\n# 3) Вспомогательные функции для расчета индексов\n# 4) Моделирование GLM (Gamma с лог-ссылкой)\n# 5) Моделирование GAM (обобщенная аддитивная модель)\n# 6) Моделирование GAMM (смешанная модель со случайными эффектами)\n# 7) Сравнение моделей и финальная визуализация результатов\n# ========================================================================================================================\n\n\n# ==============================================================================\n# БЛОК 1: ЗАГРУЗКА ПАКЕТОВ И НАСТРОЙКА СРЕДЫ\n# ==============================================================================\n\n# Отключаем вспомогательные сообщения при загрузке пакетов\nsuppressPackageStartupMessages({\n  library(tidyverse)   # Основные пакеты для обработки данных и визуализации\n  library(readxl)      # Чтение данных из Excel-файлов\n  library(mgcv)        # Обобщенные аддитивные модели (GAM)\n  library(gamm4)       # GAM со смешанными эффектами\n  library(emmeans)     # Расчет маргинальных средних и контрастов\n  library(broom)       # Преобразование результатов моделей в таблицы\n  library(broom.mixed) # Поддержка смешанных моделей для broom\n  library(DHARMa)      # Диагностика остатков обобщенных моделей\n  library(knitr)       # Форматирование таблиц для отчетов\n})\n\n# Установка рабочей директории\nsetwd(\"C:/GLM/\")\n\n# Фиксируем случайное зерно для воспроизводимости результатов\nset.seed(42)\n\n# ==============================================================================\n# БЛОК 2: ЗАГРУЗКА И ПРЕДОБРАБОТКА ДАННЫХ\n# ==============================================================================\n\n# Определяем путь к файлу с данными\nDATA_PATH &lt;- \"C:/GLM/data/KARTOGRAPHIC.xlsx\"\n\n# Чтение данных из листа \"FISHERY\" и фильтрация осенних месяцев\nDATA &lt;- read_excel(DATA_PATH, sheet = \"FISHERY\") %&gt;%\n  as_tibble() %&gt;%  # Преобразуем в современный формат таблицы\n  filter(MONTH &gt; 8 & MONTH &lt; 12)  # Сентябрь-ноябрь (осенний сезон)\n\n# Преобразование типов переменных и обработка пропусков\nDATA &lt;- DATA %&gt;%\n  mutate(\n    YEAR = as.factor(YEAR),           # Год как категориальная переменная\n    MONTH = as.factor(MONTH),         # Месяц как фактор\n    CALL = as.factor(CALL),           # Идентификатор судна\n    REGION = as.factor(REGION),       # Рыбохозяйственный район\n    VESSELNUMBER = as.factor(VESSELNUMBER),  # Номер судна\n    CPUE = as.numeric(CPUE)           # Целевой показатель - улов на усилие\n  ) %&gt;%\n  filter(!is.na(CPUE))  # Удаление строк с пропусками в CPUE\n\n# Обработка нулевых значений CPUE для Gamma-моделей\nif (any(DATA$CPUE &lt;= 0, na.rm = TRUE)) {\n  min_pos &lt;- min(DATA$CPUE[DATA$CPUE &gt; 0], na.rm = TRUE)  # Минимальный положительный улов\n  offset &lt;- min_pos / 2  # Величина поправки\n  DATA &lt;- DATA %&gt;% \n    mutate(CPUE_POS = if_else(CPUE &lt;= 0, CPUE + offset, CPUE))  # Добавляем поправку\n} else {\n  DATA &lt;- DATA %&gt;% \n    mutate(CPUE_POS = CPUE)  # Исходные данные если нулей нет\n}\n\n# Рассчитываем медианные значения CPUE по годам из исходных данных\nactual_medians &lt;- DATA %&gt;%\n  group_by(YEAR) %&gt;%\n  summarise(median_cpue = median(CPUE, na.rm = TRUE))\n# Рассчитываем медианные значения CPUE по годам из исходных данных для последующих графиков\nactual_medians\n\n# A tibble: 6 x 2\n  YEAR  median_cpue\n  &lt;fct&gt;       &lt;dbl&gt;\n1 2019        200. \n2 2020        116. \n3 2021        132. \n4 2022         84  \n5 2023         79.4\n6 2024         58.3\n\n# Экспресс-визуализация распределения CPUE по годам\nDATA %&gt;%\n  ggplot(aes(x = YEAR, y = CPUE)) +\n  geom_boxplot(outlier.alpha = 0.2) +\n  labs(title = \"Распределение CPUE по годам\", \n       x = \"Год\", \n       y = \"CPUE (улов на усилие)\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 3: ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ ДЛЯ РАСЧЕТА ИНДЕКСОВ\n# ==============================================================================\n\n# Функция нормировки индексов\nscale_to_index &lt;- function(values, method = c(\"mean\", \"first\")) {\n  method &lt;- match.arg(method)\n  if (method == \"mean\") {\n    # Нормировка на среднее значение\n    return(as.numeric(values) / mean(as.numeric(values), na.rm = TRUE))\n  }\n  if (method == \"first\") {\n    # Нормировка на значение первого года\n    return(as.numeric(values) / as.numeric(values[1]))\n  }\n}\n\n# Функция расчета индексов для GLM/GAM через маргинальные средние\nemmeans_standardized_index &lt;- function(model, variable = \"YEAR\") {\n  out &lt;- suppressWarnings(\n    emmeans(model, \n            specs = as.formula(paste0(\"~ \", variable)), \n            type = \"response\")\n  )\n  df &lt;- as_tibble(out) %&gt;% \n    select(!!sym(variable), response = response, lower.CL, upper.CL)\n  colnames(df) &lt;- c(\"YEAR\", \"value\", \"lcl\", \"ucl\")\n  df\n}\n\n# Функция расчета индексов для GAMM через бутстреп\ncompute_standardized_index &lt;- function(model, base_data, year_levels, predict_fun,\n                                      response_transform = identity, \n                                      n_boot = 200L, \n                                      seed = 7L) {\n  set.seed(seed)\n  acc &lt;- vector(\"list\", length(year_levels))\n  for (i in seq_along(year_levels)) {\n    newdata &lt;- base_data\n    newdata$YEAR &lt;- factor(year_levels[i], levels = levels(base_data$YEAR))\n    preds &lt;- suppressWarnings(predict_fun(model, newdata))\n    mu &lt;- mean(response_transform(preds), na.rm = TRUE)\n    # Бутстреп для оценки неопределенности\n    boot_vals &lt;- replicate(n_boot, {\n      idx &lt;- sample.int(nrow(base_data), nrow(base_data), replace = TRUE)\n      bd &lt;- newdata[idx, , drop = FALSE]\n      p &lt;- suppressWarnings(predict_fun(model, bd))\n      mean(response_transform(p), na.rm = TRUE)\n    })\n    ci &lt;- quantile(boot_vals, c(0.025, 0.975), na.rm = TRUE)\n    acc[[i]] &lt;- tibble(YEAR = year_levels[i], value = mu, lcl = ci[[1]], ucl = ci[[2]])\n  }\n  bind_rows(acc)\n}\n\n# ==============================================================================\n# БЛОК 4: МОДЕЛИРОВАНИЕ GLM (GAMMA С ЛОГ-ССЫЛКОЙ)\n# ==============================================================================\n\n# Подбор модели с фиксированными эффектами\nglm_gamma_fit &lt;- glm(\n  CPUE_POS ~ YEAR + MONTH + CALL + REGION,  # Формула с факторными предикторами\n  family = Gamma(link = \"log\"),            # Гамма-распределение с логарифмической связью\n  data = DATA\n)\n\n# Диагностика модели\nsummary(glm_gamma_fit)  # Стандартная сводка модели\n\n\nCall:\nglm(formula = CPUE_POS ~ YEAR + MONTH + CALL + REGION, family = Gamma(link = \"log\"), \n    data = DATA)\n\nCoefficients:\n                                                  Estimate Std. Error t value\n(Intercept)                                        5.57642    0.07942  70.216\nYEAR2020                                          -0.22713    0.04586  -4.953\nYEAR2021                                          -0.22438    0.04557  -4.924\nYEAR2022                                          -0.64329    0.04345 -14.806\nYEAR2023                                          -0.77311    0.04647 -16.637\nYEAR2024                                          -1.12817    0.05157 -21.879\nMONTH10                                           -0.13725    0.02443  -5.617\nMONTH11                                           -0.13714    0.03540  -3.874\nCALLUAAK                                          -0.29534    0.06092  -4.848\nCALLUAKC                                          -0.53490    0.06381  -8.382\nCALLUBEV                                          -3.67233    0.12187 -30.133\nCALLUBQQ                                          -0.35433    0.07057  -5.021\nCALLUBSR                                          -0.33516    0.06266  -5.349\nCALLUBUR                                          -0.58246    0.06175  -9.433\nCALLUBYT                                          -0.21520    0.06088  -3.535\nCALLUCFF                                          -0.06756    0.09825  -0.688\nCALLUCXF                                          -2.34302    0.10638 -22.025\nCALLUDII                                          -0.46287    0.05710  -8.107\nCALLUDUT                                          -1.02162    0.07550 -13.532\nCALLUDWM                                          -2.42502    0.09480 -25.582\nCALLUEBK                                           0.25852    0.13371   1.934\nCALLUEMO                                          -0.17024    0.08103  -2.101\nCALLUENZ                                           0.04928    0.06442   0.765\nCALLUFIK                                           0.29700    0.13043   2.277\nCALLUGXE                                          -0.56384    0.06265  -9.000\nCALLUIVO                                          -0.21572    0.06500  -3.319\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.16521    0.46672   0.354\nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            -0.07615    0.15513  -0.491\nREGIONCEBEPO-KAHИHCKAЯ БAHKA                       0.16332    0.08236   1.983\nREGIONKAHИHCKAЯ БAHKA                              0.06291    0.07875   0.799\nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)  0.21310    0.08519   2.501\nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE              0.18223    0.07757   2.349\nREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.07737    0.07753   0.998\nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.72882    0.46327   1.573\nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                         0.13328    0.08416   1.584\nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      0.64238    0.11646   5.516\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       0.69320    0.13068   5.305\n                                                  Pr(&gt;|t|)    \n(Intercept)                                        &lt; 2e-16 ***\nYEAR2020                                          7.62e-07 ***\nYEAR2021                                          8.85e-07 ***\nYEAR2022                                           &lt; 2e-16 ***\nYEAR2023                                           &lt; 2e-16 ***\nYEAR2024                                           &lt; 2e-16 ***\nMONTH10                                           2.08e-08 ***\nMONTH11                                           0.000109 ***\nCALLUAAK                                          1.30e-06 ***\nCALLUAKC                                           &lt; 2e-16 ***\nCALLUBEV                                           &lt; 2e-16 ***\nCALLUBQQ                                          5.36e-07 ***\nCALLUBSR                                          9.37e-08 ***\nCALLUBUR                                           &lt; 2e-16 ***\nCALLUBYT                                          0.000413 ***\nCALLUCFF                                          0.491691    \nCALLUCXF                                           &lt; 2e-16 ***\nCALLUDII                                          6.93e-16 ***\nCALLUDUT                                           &lt; 2e-16 ***\nCALLUDWM                                           &lt; 2e-16 ***\nCALLUEBK                                          0.053247 .  \nCALLUEMO                                          0.035718 *  \nCALLUENZ                                          0.444299    \nCALLUFIK                                          0.022839 *  \nCALLUGXE                                           &lt; 2e-16 ***\nCALLUIVO                                          0.000913 ***\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                        0.723377    \nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            0.623533    \nREGIONCEBEPO-KAHИHCKAЯ БAHKA                      0.047425 *  \nREGIONKAHИHCKAЯ БAHKA                             0.424416    \nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH) 0.012413 *  \nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE             0.018863 *  \nREGIONMУPMAHCKOE MEЛKOBOДЬE                       0.318379    \nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                         0.115753    \nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                        0.113361    \nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                     3.69e-08 ***\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                      1.19e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.4172272)\n\n    Null deviance: 2980.2  on 3890  degrees of freedom\nResidual deviance: 1785.6  on 3854  degrees of freedom\nAIC: 42851\n\nNumber of Fisher Scoring iterations: 11\n\n# Таблица коэффициентов в форматированном виде\nbroom::tidy(glm_gamma_fit) %&gt;%\n  mutate(across(estimate:statistic, ~round(.x, 4))) %&gt;%\n  kable(caption = \"Коэффициенты GLM модели\", align = \"lrrrr\")\n\n\nКоэффициенты GLM модели\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n5.5764\n0.0794\n70.2164\n0.0000000\n\n\nYEAR2020\n-0.2271\n0.0459\n-4.9530\n0.0000008\n\n\nYEAR2021\n-0.2244\n0.0456\n-4.9236\n0.0000009\n\n\nYEAR2022\n-0.6433\n0.0434\n-14.8059\n0.0000000\n\n\nYEAR2023\n-0.7731\n0.0465\n-16.6372\n0.0000000\n\n\nYEAR2024\n-1.1282\n0.0516\n-21.8785\n0.0000000\n\n\nMONTH10\n-0.1372\n0.0244\n-5.6170\n0.0000000\n\n\nMONTH11\n-0.1371\n0.0354\n-3.8736\n0.0001090\n\n\nCALLUAAK\n-0.2953\n0.0609\n-4.8479\n0.0000013\n\n\nCALLUAKC\n-0.5349\n0.0638\n-8.3823\n0.0000000\n\n\nCALLUBEV\n-3.6723\n0.1219\n-30.1334\n0.0000000\n\n\nCALLUBQQ\n-0.3543\n0.0706\n-5.0213\n0.0000005\n\n\nCALLUBSR\n-0.3352\n0.0627\n-5.3488\n0.0000001\n\n\nCALLUBUR\n-0.5825\n0.0618\n-9.4326\n0.0000000\n\n\nCALLUBYT\n-0.2152\n0.0609\n-3.5347\n0.0004130\n\n\nCALLUCFF\n-0.0676\n0.0982\n-0.6877\n0.4916914\n\n\nCALLUCXF\n-2.3430\n0.1064\n-22.0254\n0.0000000\n\n\nCALLUDII\n-0.4629\n0.0571\n-8.1065\n0.0000000\n\n\nCALLUDUT\n-1.0216\n0.0755\n-13.5319\n0.0000000\n\n\nCALLUDWM\n-2.4250\n0.0948\n-25.5817\n0.0000000\n\n\nCALLUEBK\n0.2585\n0.1337\n1.9335\n0.0532474\n\n\nCALLUEMO\n-0.1702\n0.0810\n-2.1009\n0.0357185\n\n\nCALLUENZ\n0.0493\n0.0644\n0.7650\n0.4442989\n\n\nCALLUFIK\n0.2970\n0.1304\n2.2770\n0.0228387\n\n\nCALLUGXE\n-0.5638\n0.0627\n-8.9996\n0.0000000\n\n\nCALLUIVO\n-0.2157\n0.0650\n-3.3187\n0.0009126\n\n\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H\n0.1652\n0.4667\n0.3540\n0.7233768\n\n\nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ\n-0.0762\n0.1551\n-0.4909\n0.6235329\n\n\nREGIONCEBEPO-KAHИHCKAЯ БAHKA\n0.1633\n0.0824\n1.9831\n0.0474248\n\n\nREGIONKAHИHCKAЯ БAHKA\n0.0629\n0.0788\n0.7989\n0.4244161\n\n\nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)\n0.2131\n0.0852\n2.5013\n0.0124133\n\n\nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE\n0.1822\n0.0776\n2.3492\n0.0188631\n\n\nREGIONMУPMAHCKOE MEЛKOBOДЬE\n0.0774\n0.0775\n0.9979\n0.3183790\n\n\nREGIONЗAП.-ПPИБPEЖHЫЙ P-H\n0.7288\n0.4633\n1.5732\n0.1157534\n\n\nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H\n0.1333\n0.0842\n1.5836\n0.1133609\n\n\nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ\n0.6424\n0.1165\n5.5160\n0.0000000\n\n\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ\n0.6932\n0.1307\n5.3046\n0.0000001\n\n\n\n\n# Графики диагностики остатков\npar(mfrow = c(2, 2))\nplot(glm_gamma_fit)  # Стандартные диагностические графики GLM\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n# Диагностика остатков GLM с использованием DHARMa\nsim_glm &lt;- simulateResiduals(glm_gamma_fit, n = 1000, refit = FALSE)\nplot(sim_glm, main = \"GLM\")\n\n\n\n\n\n\n\n# Расчет и визуализация индексов\nidx_glm &lt;- emmeans_standardized_index(glm_gamma_fit) %&gt;%\n  mutate(model = \"GLM_Gamma\",\n         index_mean = scale_to_index(value, \"mean\"),\n         index_first = scale_to_index(value, \"first\"))\n\n# Добавление доверительных интервалов\nidx_glm &lt;- idx_glm %&gt;%\n  mutate(\n    lcl_index_mean = scale_to_index(lcl, \"mean\"),\n    ucl_index_mean = scale_to_index(ucl, \"mean\")\n  )\n\n# Визуализация индексов GLM\n\nidx_glm %&gt;%\n  ggplot(aes(x = YEAR, y = value, group = 1)) +\n  geom_line() +\n  geom_point() +\n  geom_ribbon(aes(ymin = lcl, ymax = ucl), alpha = 0.3) +\n  geom_point(data = actual_medians, \n           aes(x = YEAR, y = median_cpue), \n           shape = 4,  # 4 соответствует крестику (x)\n           size = 3, \n           color = \"black\", \n           inherit.aes = FALSE)+\nlabs(title = \"Индексы CPUE по GLM модели (крестики - факт)\", \n       x = \"Год\", \n       y = \"Стандартизированный индекс\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 5: МОДЕЛИРОВАНИЕ GAM\n# ==============================================================================\n\n# Подбор обобщенной аддитивной модели\ngam_fit &lt;- gam(\n  CPUE_POS ~ YEAR + MONTH + CALL + REGION,  # Линейная формула без сглаживания\n  family = Gamma(link = \"log\"),            # Аналогичное GLM распределение\n  method = \"REML\",                         # Метод оптимизации гиперпараметров\n  data = DATA\n)\n\nsummary(gam_fit)  # Сводка модели\n\n\nFamily: Gamma \nLink function: log \n\nFormula:\nCPUE_POS ~ YEAR + MONTH + CALL + REGION\n\nParametric coefficients:\n                                                  Estimate Std. Error t value\n(Intercept)                                        5.57646    0.07942  70.217\nYEAR2020                                          -0.22712    0.04586  -4.953\nYEAR2021                                          -0.22438    0.04557  -4.924\nYEAR2022                                          -0.64329    0.04345 -14.806\nYEAR2023                                          -0.77309    0.04647 -16.637\nYEAR2024                                          -1.12812    0.05156 -21.878\nMONTH10                                           -0.13725    0.02443  -5.617\nMONTH11                                           -0.13714    0.03540  -3.874\nCALLUAAK                                          -0.29528    0.06092  -4.847\nCALLUAKC                                          -0.53484    0.06381  -8.381\nCALLUBEV                                          -3.67226    0.12187 -30.133\nCALLUBQQ                                          -0.35427    0.07057  -5.020\nCALLUBSR                                          -0.33512    0.06266  -5.348\nCALLUBUR                                          -0.58242    0.06175  -9.432\nCALLUBYT                                          -0.21516    0.06088  -3.534\nCALLUCFF                                          -0.06750    0.09825  -0.687\nCALLUCXF                                          -2.34296    0.10638 -22.025\nCALLUDII                                          -0.46282    0.05710  -8.106\nCALLUDUT                                          -1.02155    0.07550 -13.531\nCALLUDWM                                          -2.42497    0.09479 -25.581\nCALLUEBK                                           0.25858    0.13371   1.934\nCALLUEMO                                          -0.17018    0.08103  -2.100\nCALLUENZ                                           0.04934    0.06442   0.766\nCALLUFIK                                           0.29706    0.13043   2.278\nCALLUGXE                                          -0.56375    0.06265  -8.998\nCALLUIVO                                          -0.21565    0.06500  -3.318\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.16508    0.46672   0.354\nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            -0.07627    0.15513  -0.492\nREGIONCEBEPO-KAHИHCKAЯ БAHKA                       0.16322    0.08236   1.982\nREGIONKAHИHCKAЯ БAHKA                              0.06281    0.07875   0.798\nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)  0.21299    0.08519   2.500\nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE              0.18213    0.07757   2.348\nREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.07728    0.07753   0.997\nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.72877    0.46327   1.573\nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                         0.13318    0.08416   1.583\nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      0.64226    0.11646   5.515\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       0.69310    0.13068   5.304\n                                                  Pr(&gt;|t|)    \n(Intercept)                                        &lt; 2e-16 ***\nYEAR2020                                          7.62e-07 ***\nYEAR2021                                          8.85e-07 ***\nYEAR2022                                           &lt; 2e-16 ***\nYEAR2023                                           &lt; 2e-16 ***\nYEAR2024                                           &lt; 2e-16 ***\nMONTH10                                           2.08e-08 ***\nMONTH11                                           0.000109 ***\nCALLUAAK                                          1.30e-06 ***\nCALLUAKC                                           &lt; 2e-16 ***\nCALLUBEV                                           &lt; 2e-16 ***\nCALLUBQQ                                          5.39e-07 ***\nCALLUBSR                                          9.39e-08 ***\nCALLUBUR                                           &lt; 2e-16 ***\nCALLUBYT                                          0.000414 ***\nCALLUCFF                                          0.492100    \nCALLUCXF                                           &lt; 2e-16 ***\nCALLUDII                                          6.98e-16 ***\nCALLUDUT                                           &lt; 2e-16 ***\nCALLUDWM                                           &lt; 2e-16 ***\nCALLUEBK                                          0.053187 .  \nCALLUEMO                                          0.035785 *  \nCALLUENZ                                          0.443735    \nCALLUFIK                                          0.022810 *  \nCALLUGXE                                           &lt; 2e-16 ***\nCALLUIVO                                          0.000916 ***\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                        0.723578    \nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            0.623006    \nREGIONCEBEPO-KAHИHCKAЯ БAHKA                      0.047563 *  \nREGIONKAHИHCKAЯ БAHKA                             0.425185    \nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH) 0.012456 *  \nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE             0.018931 *  \nREGIONMУPMAHCKOE MEЛKOBOДЬE                       0.318981    \nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                         0.115776    \nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                        0.113615    \nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                     3.72e-08 ***\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                      1.20e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nR-sq.(adj) =  0.397   Deviance explained = 40.1%\n-REML =  21455  Scale est. = 0.41722   n = 3891\n\n# Проверка адекватности модели (графики остатков)\nmgcv::gam.check(gam_fit)\n\n\n\n\n\n\n\n\n\nMethod: REML   Optimizer: outer newton\nfull convergence after 5 iterations.\nGradient range [-0.0003574844,-0.0003574844]\n(score 21454.84 & scale 0.4172217).\nHessian positive definite, eigenvalue range [2198.061,2198.061].\nModel rank =  37 / 37 \n\n# Диагностика остатков GAM с использованием DHARMa\nsim_gam &lt;- simulateResiduals(gam_fit, n = 1000, refit = FALSE)\n\nRegistered S3 method overwritten by 'mgcViz':\n  method from   \n  +.gg   ggplot2\n\nplot(sim_gam, main = \"GAM\")\n\n\n\n\n\n\n\n# Расчет индексов\nidx_gam &lt;- emmeans_standardized_index(gam_fit) %&gt;%\n  mutate(model = \"GAM\",\n         index_mean = scale_to_index(value, \"mean\"),\n         index_first = scale_to_index(value, \"first\"))\n\n# Доверительные интервалы\nidx_gam &lt;- idx_gam %&gt;%\n  mutate(\n    lcl_index_mean = scale_to_index(lcl, \"mean\"),\n    ucl_index_mean = scale_to_index(ucl, \"mean\")\n  )\n\n\n# Визуализация\nidx_gam %&gt;%\n  ggplot(aes(x = YEAR, y = value, group = 1)) +\n  geom_line() +\n  geom_point() +\n  geom_ribbon(aes(ymin = lcl, ymax = ucl), alpha = 0.3) +\n  geom_point(data = actual_medians, \n           aes(x = YEAR, y = median_cpue), \n           shape = 4,  # 4 соответствует крестику (x)\n           size = 3, \n           color = \"black\", \n           inherit.aes = FALSE)+\n  labs(title = \"Индексы CPUE по GAM модели (крестики - факт\", \n       x = \"Год\", \n       y = \"Стандартизированный индекс\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 6: МОДЕЛИРОВАНИЕ GAMM (СМЕШАННАЯ МОДЕЛЬ)\n# ==============================================================================\n\n# Подбор модели со смешанными эффектами\ngamm_fit &lt;- gamm4::gamm4(\n  formula = CPUE_POS ~ YEAR + MONTH + REGION,  # Фиксированные эффекты\n  random = ~ (1 | CALL),                       # Случайный эффект для судна\n  family = Gamma(link = \"log\"),               # Распределение\n  data = DATA\n)\n\n# 1. График остатков от предсказанных значений\nplot(fitted(gamm_fit$gam), residuals(gamm_fit$gam, type = \"deviance\"),\n     xlab = \"Предсказанные значения\", ylab = \"Девиансные остатки\",\n     main = \"Остатки GAMM vs. Предсказания\")\nabline(h = 0, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n# 2. QQ-plot для остатков\nqqnorm(residuals(gamm_fit$gam, type = \"deviance\"),\n       main = \"QQ-plot для остатков GAMM\")\nqqline(residuals(gamm_fit$gam, type = \"deviance\"), col = \"red\")\n\n\n\n\n\n\n\n# 3. Диагностика случайных эффектов\ncat(\"\\nСлучайные эффекты (CALL):\\n\")\n\n\nСлучайные эффекты (CALL):\n\nprint(summary(ranef(gamm_fit$mer)$CALL))\n\n  (Intercept)      \n Min.   :-2.92229  \n 1st Qu.: 0.09295  \n Median : 0.32996  \n Mean   : 0.00306  \n 3rd Qu.: 0.54065  \n Max.   : 0.93271  \n\n# График случайных эффектов\nrandom_effects &lt;- ranef(gamm_fit$mer)$CALL\nplot(density(random_effects[,1]), main = \"Распределение случайных эффектов\",\n     xlab = \"Случайный эффект\", ylab = \"Плотность\")\n\n\n\n\n\n\n\n# 5. Проверка гетероскедастичности\nlibrary(lmtest)\n\nЗагрузка требуемого пакета: zoo\n\n\n\nПрисоединяю пакет: 'zoo'\n\n\nСледующие объекты скрыты от 'package:base':\n\n    as.Date, as.Date.numeric\n\nbptest(gamm_fit$gam$y ~ fitted(gamm_fit$gam)) %&gt;% \n  print()\n\n\n    studentized Breusch-Pagan test\n\ndata:  gamm_fit$gam$y ~ fitted(gamm_fit$gam)\nBP = 222.14, df = 1, p-value &lt; 2.2e-16\n\n# 6. Сводка по модели\ncat(\"\\nСводка GAMM модели:\\n\")\n\n\nСводка GAMM модели:\n\nprint(summary(gamm_fit$gam))\n\n\nFamily: Gamma \nLink function: log \n\nFormula:\nCPUE_POS ~ YEAR + MONTH + REGION\n\nParametric coefficients:\n                                                  Estimate Std. Error t value\n(Intercept)                                        4.91649    0.17171  28.632\nYEAR2020                                          -0.23162    0.04580  -5.058\nYEAR2021                                          -0.22798    0.04552  -5.008\nYEAR2022                                          -0.64763    0.04338 -14.928\nYEAR2023                                          -0.77570    0.04641 -16.716\nYEAR2024                                          -1.13070    0.05152 -21.947\nMONTH10                                           -0.13620    0.02445  -5.571\nMONTH11                                           -0.13630    0.03542  -3.848\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.16149    0.46710   0.346\nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            -0.08013    0.15524  -0.516\nREGIONCEBEPO-KAHИHCKAЯ БAHKA                       0.15971    0.08238   1.939\nREGIONKAHИHCKAЯ БAHKA                              0.05886    0.07877   0.747\nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)  0.20859    0.08522   2.448\nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE              0.17834    0.07759   2.299\nREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.07353    0.07755   0.948\nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.72926    0.46366   1.573\nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                         0.12967    0.08419   1.540\nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      0.63836    0.11653   5.478\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       0.68988    0.13078   5.275\n                                                  Pr(&gt;|t|)    \n(Intercept)                                        &lt; 2e-16 ***\nYEAR2020                                          4.44e-07 ***\nYEAR2021                                          5.74e-07 ***\nYEAR2022                                           &lt; 2e-16 ***\nYEAR2023                                           &lt; 2e-16 ***\nYEAR2024                                           &lt; 2e-16 ***\nMONTH10                                           2.70e-08 ***\nMONTH11                                           0.000121 ***\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                        0.729566    \nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            0.605763    \nREGIONCEBEPO-KAHИHCKAЯ БAHKA                      0.052628 .  \nREGIONKAHИHCKAЯ БAHKA                             0.455013    \nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH) 0.014424 *  \nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE             0.021580 *  \nREGIONMУPMAHCKOE MEЛKOBOДЬE                       0.343099    \nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                         0.115842    \nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                        0.123604    \nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                     4.57e-08 ***\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                      1.40e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nR-sq.(adj) =  0.172   \nglmer.ML =   1786  Scale est. = 0.41793   n = 3891\n\nprint(summary(gamm_fit$mer))\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: Gamma  ( log )\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n  42933.5   43065.1  -21445.7   42891.5      3870 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.5364 -0.6769 -0.1721  0.4716 11.0577 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n CALL     (Intercept) 0.4320   0.6573  \n Residual             0.4179   0.6465  \nNumber of obs: 3891, groups:  CALL, 19\n\nFixed effects:\n                                                   Estimate Std. Error t value\nX(Intercept)                                        4.91649    0.23488  20.932\nXYEAR2020                                          -0.23162    0.02474  -9.363\nXYEAR2021                                          -0.22798    0.02513  -9.073\nXYEAR2022                                          -0.64763    0.02299 -28.167\nXYEAR2023                                          -0.77570    0.02376 -32.652\nXYEAR2024                                          -1.13070    0.02603 -43.443\nXMONTH10                                           -0.13620    0.01914  -7.116\nXMONTH11                                           -0.13630    0.02359  -5.777\nXREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.16149    0.46456   0.348\nXREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            -0.08013    0.03506  -2.285\nXREGIONCEBEPO-KAHИHCKAЯ БAHKA                       0.15971    0.02670   5.982\nXREGIONKAHИHCKAЯ БAHKA                              0.05886    0.02653   2.218\nXREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)  0.20859    0.02808   7.428\nXREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE              0.17834    0.02200   8.108\nXREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.07353    0.02318   3.172\nXREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.72926    0.46533   1.567\nXREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                         0.12967    0.02736   4.739\nXREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      0.63836    0.03291  19.400\nXREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       0.68988    0.03447  20.015\n                                                   Pr(&gt;|z|)    \nX(Intercept)                                        &lt; 2e-16 ***\nXYEAR2020                                           &lt; 2e-16 ***\nXYEAR2021                                           &lt; 2e-16 ***\nXYEAR2022                                           &lt; 2e-16 ***\nXYEAR2023                                           &lt; 2e-16 ***\nXYEAR2024                                           &lt; 2e-16 ***\nXMONTH10                                           1.11e-12 ***\nXMONTH11                                           7.60e-09 ***\nXREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.72813    \nXREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ             0.02229 *  \nXREGIONCEBEPO-KAHИHCKAЯ БAHKA                      2.20e-09 ***\nXREGIONKAHИHCKAЯ БAHKA                              0.02654 *  \nXREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH) 1.10e-13 ***\nXREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE             5.16e-16 ***\nXREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.00151 ** \nXREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.11707    \nXREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                        2.15e-06 ***\nXREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      &lt; 2e-16 ***\nXREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCorrelation matrix not shown by default, as p = 19 &gt; 12.\nUse print(summary(gamm_fit$mer), correlation=TRUE)  or\n    vcov(summary(gamm_fit$mer))        if you need it\n\n# Создание сетки для предсказания\nnewdata_grid &lt;- expand.grid(\n  YEAR = levels(DATA$YEAR),\n  MONTH = levels(DATA$MONTH),\n  REGION = levels(DATA$REGION),\n  CALL = levels(DATA$CALL)[1]  # Фиксированное значение для случайного эффекта\n)\n\n# Предсказание на сетке\nnewdata_grid$pred &lt;- predict(gamm_fit$gam, \n                            newdata = newdata_grid, \n                            type = \"response\")\n\n# Усреднение предсказаний по годам\nidx_gamm &lt;- newdata_grid %&gt;%\n  group_by(YEAR) %&gt;%\n  summarise(value = mean(pred, na.rm = TRUE)) %&gt;%\n  mutate(\n    model = \"GAMM (mgcv)\",\n    index_mean = scale_to_index(value, \"mean\"),\n    index_first = scale_to_index(value, \"first\")\n  )\n\n# Функция расчета доверительных интервалов через бутстреп\ncompute_gamm_ci &lt;- function(model, newdata, n_boot = 100) {\n  boot_means &lt;- replicate(n_boot, {\n    boot_data &lt;- newdata[sample(nrow(newdata), replace = TRUE), ]\n    preds &lt;- predict(model, newdata = boot_data, type = \"response\")\n    boot_data %&gt;%\n      mutate(pred = preds) %&gt;%\n      group_by(YEAR) %&gt;%\n      summarise(mean_pred = mean(pred, na.rm = TRUE)) %&gt;%\n      pull(mean_pred)\n  })\n  \n  ci &lt;- apply(boot_means, 1, function(x) quantile(x, c(0.025, 0.975), na.rm = TRUE))\n  return(list(mean = rowMeans(boot_means), lcl = ci[1, ], ucl = ci[2, ]))\n}\n\n# Расчет интервалов\ngamm_ci &lt;- compute_gamm_ci(gamm_fit$gam, newdata_grid)\n\n# Добавление интервалов к индексам\nidx_gamm &lt;- idx_gamm %&gt;%\n  mutate(\n    lcl = gamm_ci$lcl,\n    ucl = gamm_ci$ucl,\n    lcl_index_mean = scale_to_index(lcl, \"mean\"),\n    ucl_index_mean = scale_to_index(ucl, \"mean\")\n  )\n\n# Визуализация\nidx_gamm %&gt;%\n  ggplot(aes(x = YEAR, y = value, group = 1)) +\n  geom_line() +\n  geom_point() +\n  geom_ribbon(aes(ymin = lcl, ymax = ucl), alpha = 0.3) +\n  geom_point(data = actual_medians, \n           aes(x = YEAR, y = median_cpue), \n           shape = 4,  # 4 соответствует крестику (x)\n           size = 3, \n           color = \"black\", \n           inherit.aes = FALSE)+\nlabs(title = \"Индексы CPUE по GAMM модели (крестики - факт)\", \n       x = \"Год\", \n       y = \"Стандартизированный индекс\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 7: СРАВНЕНИЕ МОДЕЛЕЙ И ФИНАЛЬНАЯ ВИЗУАЛИЗАЦИЯ\n# ==============================================================================\n\n# Объединение результатов всех моделей\nindices_all &lt;- bind_rows(\n  idx_glm %&gt;% select(YEAR, value, lcl, ucl, model, index_mean, lcl_index_mean, ucl_index_mean),\n  idx_gam %&gt;% select(YEAR, value, lcl, ucl, model, index_mean, lcl_index_mean, ucl_index_mean),\n  idx_gamm %&gt;% select(YEAR, value, lcl, ucl, model, index_mean, lcl_index_mean, ucl_index_mean)\n) %&gt;% mutate(YEAR = factor(YEAR, levels = levels(DATA$YEAR)))\n\n# Сводная таблица результатов\nindices_all %&gt;% \n  kable(caption = \"Сравнение индексов CPUE по разным моделям\")\n\n\nСравнение индексов CPUE по разным моделям\n\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nvalue\nlcl\nucl\nmodel\nindex_mean\nlcl_index_mean\nucl_index_mean\n\n\n\n\n2019\n158.81216\n138.93290\n181.53585\nGLM_Gamma\n1.5358638\n1.5299542\n1.5417869\n\n\n2020\n126.54457\n111.15088\n144.07018\nGLM_Gamma\n1.2238057\n1.2240136\n1.2235904\n\n\n2021\n126.89292\n111.57409\n144.31498\nGLM_Gamma\n1.2271746\n1.2286741\n1.2256695\n\n\n2022\n83.46580\n73.52525\n94.75032\nGLM_Gamma\n0.8071933\n0.8096733\n0.8047160\n\n\n2023\n73.30390\n64.40714\n83.42960\nGLM_Gamma\n0.7089181\n0.7092631\n0.7085690\n\n\n2024\n51.39565\n45.26094\n58.36186\nGLM_Gamma\n0.4970445\n0.4984216\n0.4956683\n\n\n2019\n158.81218\n138.93304\n181.53572\nGAM\n1.5358554\n1.5299458\n1.5417784\n\n\n2020\n126.54503\n111.15138\n144.07058\nGAM\n1.2238033\n1.2240112\n1.2235880\n\n\n2021\n126.89280\n111.57408\n144.31473\nGAM\n1.2271665\n1.2286660\n1.2256615\n\n\n2022\n83.46561\n73.52514\n94.75002\nGAM\n0.8071869\n0.8096669\n0.8047096\n\n\n2023\n73.30495\n64.40811\n83.43072\nGAM\n0.7089242\n0.7092692\n0.7085751\n\n\n2024\n51.39792\n45.26297\n58.36439\nGAM\n0.4970637\n0.4984408\n0.4956874\n\n\n2019\n165.88930\n153.27889\n186.43794\nGAMM (mgcv)\n1.5400976\n1.5751123\n1.5695052\n\n\n2020\n131.59142\n116.54705\n144.02703\nGAMM (mgcv)\n1.2216800\n1.1976514\n1.2124741\n\n\n2021\n132.07110\n118.64017\n145.21926\nGAMM (mgcv)\n1.2261333\n1.2191606\n1.2225107\n\n\n2022\n86.80692\n79.26688\n96.71028\nGAMM (mgcv)\n0.8059057\n0.8145559\n0.8141438\n\n\n2023\n76.37202\n67.94329\n82.24327\nGAMM (mgcv)\n0.7090292\n0.6981933\n0.6923550\n\n\n2024\n53.55022\n48.20170\n58.08852\nGAMM (mgcv)\n0.4971542\n0.4953264\n0.4890111\n\n\n\n\nindices_all %&gt;%\n  ggplot(aes(x = YEAR, y = value, color = model, group = model, fill = model)) +\n  geom_line() +\n  geom_point() +\n  geom_ribbon(aes(ymin = lcl, ymax = ucl), alpha = 0.1, linetype = \"dashed\") +\ngeom_point(data = actual_medians, \n           aes(x = YEAR, y = median_cpue), \n           shape = 4,  # 4 соответствует крестику (x)\n           size = 3, \n           color = \"black\", \n           inherit.aes = FALSE)+\n  labs(title = \"Сравнение стандартизированных индексов CPUE (крестики - факт)\", \n       x = \"Год\", \n       y = \"Индекс CPUE (кг/ловушку)\", \n       color = \"Модель\", \n       fill = \"Модель\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 9: СРАВНЕНИЕ МОДЕЛЕЙ ПО ИНФОРМАЦИОННЫМ КРИТЕРИЯМ\n# ==============================================================================\n\ncat(\"\\n=== СРАВНИТЕЛЬНЫЙ АНАЛИЗ МОДЕЛЕЙ ПО ИНФОРМАЦИОННЫМ КРИТЕРИЯМ ===\\n\")\n\n\n=== СРАВНИТЕЛЬНЫЙ АНАЛИЗ МОДЕЛЕЙ ПО ИНФОРМАЦИОННЫМ КРИТЕРИЯМ ===\n\n# Упрощенная функция для извлечения ключевых критериев из моделей\nextract_model_metrics &lt;- function(model, model_name, model_type = \"glm\") {\n  if (model_type == \"glm\") {\n    aic_val &lt;- AIC(model)\n    bic_val &lt;- BIC(model)\n    loglik_val &lt;- as.numeric(logLik(model))\n    df_val &lt;- model$rank\n    null_dev &lt;- model$null.deviance\n    dev &lt;- model$deviance\n  } else if (model_type == \"gam\") {\n    aic_val &lt;- AIC(model)\n    bic_val &lt;- BIC(model)\n    loglik_val &lt;- as.numeric(logLik(model))\n    df_val &lt;- sum(model$edf)\n    null_dev &lt;- model$null.deviance\n    dev &lt;- model$deviance\n  } else if (model_type == \"gamm\") {\n    aic_val &lt;- AIC(model$mer)\n    bic_val &lt;- BIC(model$mer)\n    loglik_val &lt;- as.numeric(logLik(model$mer))\n    df_val &lt;- length(fixef(model$mer)) + 1  # +1 для случайного эффекта\n    null_dev &lt;- model$gam$null.deviance\n    dev &lt;- model$gam$deviance\n  }\n  \n  # Вычисляем долю объясненной девиации\n  deviance_explained &lt;- ifelse(!is.null(null_dev) && !is.null(dev) && null_dev &gt; 0,\n                              (null_dev - dev) / null_dev, NA)\n  \n  data.frame(\n    Model = model_name,\n    AIC = round(aic_val, 2),\n    BIC = round(bic_val, 2),\n    LogLik = round(loglik_val, 2),\n    DF = round(df_val, 2),\n    Deviance_Explained = round(deviance_explained, 4)\n  )\n}\n\n# Извлекаем метрики для всех моделей\nmodel_metrics &lt;- bind_rows(\n  extract_model_metrics(glm_gamma_fit, \"GLM (Gamma)\", \"glm\"),\n  extract_model_metrics(gam_fit, \"GAM\", \"gam\"),\n  extract_model_metrics(gamm_fit, \"GAMM\", \"gamm\")\n)\n\n# Добавляем разницу в AIC относительно наилучшей модели\nmin_aic &lt;- min(model_metrics$AIC)\nmodel_metrics &lt;- model_metrics %&gt;%\n  mutate(Delta_AIC = AIC - min_aic,\n         AIC_Weight = exp(-0.5 * Delta_AIC) / sum(exp(-0.5 * Delta_AIC)))\n\n# Форматируем таблицу для вывода\ncomparison_table &lt;- model_metrics %&gt;%\n  mutate(across(where(is.numeric), ~round(., 3))) %&gt;%\n  arrange(AIC)  # Сортируем по AIC (лучшая модель первая)\n\n# Выводим таблицу сравнения\ncat(\"\\nТАБЛИЦА СРАВНЕНИЯ МОДЕЛЕЙ:\\n\")\n\n\nТАБЛИЦА СРАВНЕНИЯ МОДЕЛЕЙ:\n\nprint(comparison_table)\n\n        Model      AIC      BIC    LogLik DF Deviance_Explained Delta_AIC\n1         GAM 42840.91 43079.03 -21382.45 37              0.401      0.00\n2 GLM (Gamma) 42850.76 43088.88 -21387.38 37              0.401      9.85\n3        GAMM 42933.49 43065.09 -21445.75 20                 NA     92.58\n  AIC_Weight\n1      0.993\n2      0.007\n3      0.000\n\n# Выводим итоговые рекомендации\ncat(\"\\n=== ИТОГОВЫЕ РЕКОМЕНДАЦИИ ПО ВЫБОРУ МОДЕЛИ ===\\n\")\n\n\n=== ИТОГОВЫЕ РЕКОМЕНДАЦИИ ПО ВЫБОРУ МОДЕЛИ ===\n\nbest_model &lt;- comparison_table$Model[1]\ncat(\"Наилучшая модель по критерию AIC:\", best_model, \"\\n\")\n\nНаилучшая модель по критерию AIC: GAM \n\ncat(\"Вес AIC для наилучшей модели:\", round(comparison_table$AIC_Weight[1], 3), \"\\n\")\n\nВес AIC для наилучшей модели: 0.993 \n\nif (nrow(comparison_table) &gt; 1 && comparison_table$Delta_AIC[2] &gt; 2) {\n  cat(\"Наилучшая модель существенно лучше остальных (?AIC &gt; 2).\\n\")\n} else if (nrow(comparison_table) &gt; 1) {\n  cat(\"Несколько моделей имеют сходное качество (?AIC &lt; 2).\\n\")\n}\n\nНаилучшая модель существенно лучше остальных (?AIC &gt; 2).\n\ncat(\"Доля объясненной девиации наилучшей модели:\", \n    round(comparison_table$Deviance_Explained[1], 3), \"\\n\")\n\nДоля объясненной девиации наилучшей модели: 0.401",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE: GLM, GAM, GAMM</span>"
    ]
  },
  {
    "objectID": "chapter 9.html#анализ-glm-модели-с-гамма-распределением-и-лог-ссылкой",
    "href": "chapter 9.html#анализ-glm-модели-с-гамма-распределением-и-лог-ссылкой",
    "title": "10  Стандартизация CPUE: GLM, GAM, GAMM",
    "section": "10.3 Анализ GLM модели с гамма-распределением и лог-ссылкой",
    "text": "10.3 Анализ GLM модели с гамма-распределением и лог-ссылкой\nПодобранная обобщенная линейная модель (GLM) использует гамма-распределение для ошибок и логарифмическую функцию связи. Данное распределение выбрано, поскольку CPUE представляет собой непрерывную положительную величину, а гамма-распределение хорошо описывает такие данные. Логарифмическая связь обеспечивает мультипликативность эффектов факторов, что интерпретируется как относительное изменение CPUE при изменении фактора. Модель включает четыре факторные переменные: год (YEAR), месяц (MONTH), позывной судна (CALL) и район промысла (REGION). Все переменные представлены как факторы, что означает, что для каждого уровня фактора оценивается свой коэффициент, интерпретируемый как отклонение от базового уровня. Базовыми уровнями являются: 2019 год для YEAR, сентябрь (MONTH9) для MONTH, первое судно в алфавитном порядке для CALL и первый район для REGION. Из сводки модели видно, что многие коэффициенты статистически значимы. Все годовые коэффициенты отрицательны и значимы, что указывает на снижение CPUE относительно базового 2019 года. Наибольшее снижение наблюдается в 2024 году (коэффициент -1.128). Месячные коэффициенты также отрицательны и значимы, что говорит о снижении CPUE в октябре и ноябре по сравнению с сентябрем. Большинство коэффициентов для судов значимы и отрицательны, что указывает на то, что уловы на усилие у этих судов в среднем ниже, чем у базового судна. Однако некоторые суда имеют положительные коэффициенты, что означает более высокую производительность. Для районов значимыми оказались лишь некоторые коэффициенты, в основном положительные, что говорит о более высоких уловах в этих районах по сравнению с базовым. Дисперсионный параметр для гамма-семейства равен 0.417, что указывает на умеренную дисперсию. Null deviance составляет 2980.2 при 3890 степенях свободы, а остаточная deviance — 1785.6 при 3854 степенях свободы. Снижение девиации указывает на то, что модель объясняет существенную часть вариации данных. AIC модели равен 42851. Диагностические графики стандартных остатков GLM включают график остатков против предсказанных значений, Q-Q plot, график масштаба-местоположения и график остатков против влияния. Эти графики позволяют оценить гомоскедастичность, нормальность остатков и наличие выбросов. Дополнительная диагностика с помощью пакета DHARMa показывает, что распределение остатков соответствует ожидаемому, что подтверждает адекватность выбранного семейства распределений. Расчет стандартизированных индексов с помощью функции emmeans показывает, что индекс CPUE постепенно снижается с 2019 по 2024 год, что согласуется с отрицательными годовыми коэффициентами. В 2019 году индекс составляет 159, а к 2024 падает до 51.4. Доверительные интервалы не перекрываются между крайними годами, что указывает на статистически значимое снижение. Сравнение с медианными значениями CPUE по годам из исходных данных показывает, что модель несколько сглаживает исходные данные, но общая тенденция снижения сохраняется. Например, в 2019 году медианное значение CPUE было 200, а стандартизированный индекс — 159, что может быть связано с учетом влияния других факторов. Преимущества GLM подхода включают простоту интерпретации коэффициентов, вычислительную эффективность и широкую распространенность. Недостатки заключаются в том, что GLM предполагает линейность влияния факторов на логарифм отклика, что может не всегда выполняться. Кроме того, модель с фиксированными эффектами может не учитывать некоторые источники вариации, такие как пространственно-временная автокорреляция или случайные эффекты судов. В целом, модель адекватно описывает данные и может быть использована для стандартизации CPUE, но для более сложных данных могут потребоваться более гибкие модели, такие как GAM или GAMM.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE: GLM, GAM, GAMM</span>"
    ]
  },
  {
    "objectID": "chapter 9.html#анализ-gam-модели-с-гамма-распределением-и-логарифмической-связью",
    "href": "chapter 9.html#анализ-gam-модели-с-гамма-распределением-и-логарифмической-связью",
    "title": "10  Стандартизация CPUE: GLM, GAM, GAMM",
    "section": "10.4 Анализ GAM модели с гамма-распределением и логарифмической связью",
    "text": "10.4 Анализ GAM модели с гамма-распределением и логарифмической связью\nАнализ подобранной обобщенной аддитивной модели (GAM) с гамма-распределением и логарифмической связью показывает результаты, практически идентичные полученным ранее для GLM модели, что ожидаемо, поскольку в данной реализации GAM использовалась полностью параметрическая формула без сглаживающих функций. Модель была построена с теми же предикторами - годом, месяцем, идентификатором судна и районом промысла.\nСводка модели демонстрирует параметрические коэффициенты, которые практически не отличаются от оценок GLM модели. Все годовые коэффициенты остаются отрицательными и статистически значимыми, подтверждая устойчивую тенденцию снижения стандартизированного индекса CPUE с 2019 по 2024 год. Месячные коэффициенты также значимы и отрицательны, указывая на сезонное снижение уловов в октябре и ноябре по сравнению с сентябрем. Оценки для различных судов и районов промысла практически идентичны полученным в GLM, с сохранением статистической значимости для тех же уровней факторов.\nМодель объясняет 40.1% девиации данных, что полностью соответствует показателю GLM. Значение REML составляет 21455, а оценка дисперсии равна 0.41722, что также практически совпадает с соответствующими показателями GLM модели.\nПроверка адекватности модели с помощью функции gam.check показывает успешную сходимость алгоритма оптимизации после 5 итераций. Градиент близок к нулю, а гессиан положительно определен, что свидетельствует о достижении устойчивого решения. Поскольку в модели отсутствуют сглаживающие компоненты, диагностика не выявляет проблем, связанных с выбором базовой размерности или неадекватностью сглаживания.\nДиагностика остатков с использованием пакета DHARMa показывает равномерное распределение без систематических паттернов, что указывает на соответствие остатков теоретическому гамма-распределению. Графики остатков демонстрируют отсутствие гетероскедастичности и значимых выбросов, что подтверждает адекватность модели.\nРасчет стандартизированных индексов методом маргинальных средних дает значения, практически идентичные полученным из GLM модели. Индекс снижается с 159 в 2019 году до 51.4 в 2024 году, с доверительными интервалами, не перекрывающимися между крайними годами. Нормированные индексы относительно среднего и первого года также полностью совпадают с GLM результатами.\nОсновное преимущество использования GAM в данном случае заключается в методологическом подходе - использовании метода REML для оптимизации, который может обеспечивать более стабильные оценки параметров по сравнению с методом максимального правдоподобия, используемым в GLM. Хотя в данной конкретной реализации с полностью параметрической формулой это преимущество не реализуется в полной мере, GAM предоставляет основу для легкого включения нелинейных эффектов через сглаживающие функции, если такая необходимость возникнет в дальнейшем.\nК недостаткам данного подхода можно отнести избыточную сложность GAM для полностью параметрической модели, поскольку вычислительные затраты выше, чем для GLM, без существенного улучшения качества подгонки. Фактически, в данном случае GAM работает как GLM, но с более сложным алгоритмом оптимизации. Кроме того, диагностика GAM требует дополнительных проверок, связанных со сходимостью алгоритма и адекватностью сглаживания, которые не актуальны для параметрических моделей.\nВ целом, данная реализация GAM не демонстрирует преимуществ перед GLM моделью, но предоставляет основу для будущего расширения модели за счет включения нелинейных эффектов, если анализ данных покажет такую необходимость. Результаты стандартизации CPUE полностью согласуются с полученными ранее средствами GLM.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE: GLM, GAM, GAMM</span>"
    ]
  },
  {
    "objectID": "chapter 9.html#анализ-gamm-модели",
    "href": "chapter 9.html#анализ-gamm-модели",
    "title": "10  Стандартизация CPUE: GLM, GAM, GAMM",
    "section": "10.5 Анализ GAMM модели",
    "text": "10.5 Анализ GAMM модели\nОсобенности смешанных моделей и случайные эффекты\nСмешанные модели, включая GAMM, расширяют возможности стандартных моделей за счет введения случайных эффектов. В то время как фиксированные эффекты оценивают среднее влияние факторов на всю популяцию, случайные эффекты позволяют учесть вариацию, связанную с отдельными группами наблюдений. В ихтиологических исследованиях случайные эффекты часто применяются для учета индивидуальных особенностей судов, различий между районами промысла, или временной автокорреляции.\nСлучайные эффекты особенно полезны, когда:\n\nДанные имеют иерархическую структуру (например, уловы по нескольким судам)\nНаблюдения внутри групп коррелированы\nКоличество уровней фактора велико, и мы хотим обобщить выводы на всю популяцию групп\nНас интересует вариация между группами, а не конкретные сравнения между отдельными уровнями\n\nВ данном случае случайный эффект для судна (CALL) позволяет учесть, что разные суда могут иметь систематические различия в эффективности промысла, не объясняемые другими переменными модели.\nАнализ результатов GAMM модели\nАнализ обобщенной аддитивной смешанной модели показывает несколько важных особенностей. Модель включает фиксированные эффекты года, месяца и района, а также случайный эффект для судна, что позволяет учесть индивидуальные различия между судами в уровне уловов.\nГрафик остатков от предсказанных значений показывает распределение девиансных остатков вокруг нулевой линии. Наблюдается некоторая гетероскедастичность - разброс остатков увеличивается с ростом предсказанных значений, что характерно для данных по уловам. QQ-plot демонстрирует отклонение распределения остатков от нормального в крайних значениях, что ожидаемо для данных с гамма-распределением.\nАнализ случайных эффектов для судов показывает существенную вариацию между разными судами. Значения случайных эффектов варьируют от -2.92 до 0.93, что указывает на значительные различия в эффективности промысла между судами после учета влияния года, месяца и района. Распределение случайных эффектов близко к нормальному с центром около нуля.\nТест Бреуша-Пагана подтверждает наличие гетероскедастичности в модели, что является общей проблемой для моделей с данными по уловам.\nСводка параметрических коэффициентов показывает, что все годовые эффекты статистически значимы и отрицательны, подтверждая общую тенденцию снижения уловов с течением времени. Месячные эффекты также значимы и отрицательны, указывая на сезонное снижение уловов в октябре и ноябре по сравнению с сентябрем. Среди районов промысла несколько показали статистически значимые отличия от базового уровня.\nМодель объясняет 17.2% дисперсии данных, что меньше, чем в предыдущих моделях, что может быть связано с учетом части вариации через случайные эффекты. Информационные критерии AIC (42933.5) и BIC (43065.1) выше, чем у GLM и GAM моделей, что указывает на худшее соответствие данных этой модели с учетом ее сложности.\nГрафик случайных эффектов с тремя модами на значениях 0.5, -1.5 и -3 демонстрирует выраженную стратификацию судов по их промысловой эффективности. Такое распределение указывает на наличие трех различных групп в промысловом флоте, каждая со своими характеристиками. Группа с модой на 0.5 представляет суда с повышенной эффективностью, чьи уловы примерно на 65% (exp(0.5) ≈ 0.65) превышают средний уровень. Эти суда, вероятно, оснащены современным оборудованием, укомплектованы опытными экипажами и работают на наиболее продуктивных участках.\nВторая группа с модой на -1.5 соответствует судам со значительно сниженной эффективностью, показывающим уловы примерно на 78% ниже среднего показателя. Такие результаты могут быть связаны с устаревшим техническим оснащением, менее оптимальными методами лова или работой в менее продуктивных районах. Третья группа с модой на -3 представляет суда с крайне низкой эффективностью, демонстрирующие уловы на 95% ниже среднего уровня. Столь значительное отставание может объясняться серьезными техническими проблемами, отсутствием современного оборудования, неопытностью экипажей или систематическими организационными трудностями.А возможно работой не на мороженном крабе, а живом - требующим другой технологической работы.\nНаличие трех четких мод в распределении случайных эффектов свидетельствует о существенной неоднородности промыслового флота. Это указывает на то, что предположение о нормальном распределении случайных эффектов не выполняется, а данные имеют выраженную групповую структуру. Модель успешно выявляет эту скрытую стратификацию, что подтверждает важность учета случайных эффектов при анализе промысловых данных. Полученные результаты подчеркивают необходимость дифференцированного подхода к анализу эффективности судов и разработки управленческих решений с учетом выявленной группировки. Различные моды могут отражать не только технические различия между судами, но и различные стратегии промысла, доступ к ресурсам или уровень организации работы.\nПреимущества и недостатки подхода GAMM\nОсновное преимущество GAMM подхода заключается в возможности учета групповой структуры данных через случайные эффекты. Это позволяет более адекватно оценить неопределенность предсказаний и избежать завышения значимости эффектов из-за псевдорепликации. Модель обеспечивает более реалистичную оценку вариации в данных, учитывая как фиксированные эффекты, так и случайную вариацию между группами.\nК недостаткам можно отнести повышенную вычислительную сложность и потенциальные проблемы со сходимостью алгоритмов оптимизации. Интерпретация результатов становится сложнее, особенно при наличии взаимодействий между фиксированными и случайными эффектами. В данном случае модель показала худшие показатели качества подгонки по сравнению с более простыми GLM и GAM моделями, что может свидетельствовать о избыточной сложности модели для данного набора данных.\nВ целом, GAMM представляет собой мощный инструмент для анализа данных с иерархической структурой, но его применение должно быть обосновано теоретически и подтверждено улучшением качества модели по сравнению с более простыми альтернативами.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE: GLM, GAM, GAMM</span>"
    ]
  },
  {
    "objectID": "chapter 9.html#сравнительный-анализ-моделей-по-информационным-критериям",
    "href": "chapter 9.html#сравнительный-анализ-моделей-по-информационным-критериям",
    "title": "10  Стандартизация CPUE: GLM, GAM, GAMM",
    "section": "10.6 Сравнительный анализ моделей по информационным критериям",
    "text": "10.6 Сравнительный анализ моделей по информационным критериям\nВ данном разделе проводится систематическое сравнение трех альтернативных моделей - GLM, GAM и GAMM - с использованием информационных критериев и других метрик качества. Для унификации процесса сравнения создана специализированная функция extract_model_metrics, которая адаптирована для извлечения сопоставимых показателей из моделей разной структуры.\nДля GLM и GAM моделей используются стандартные методы расчета критериев, включая AIC, BIC, логарифмическое правдоподобие и долю объясненной девиации. Для GAMM модели, имеющей более сложную смешанную структуру, метрики извлекаются из компонентов mer и gam объекта, с дополнительным учетом случайных эффектов при расчете сложности модели.\nРезультаты сравнения представлены в виде структурированной таблицы, где модели упорядочены по возрастанию AIC - информационного критерия Акаике, который балансирует качество подгонки и сложность модели. Дополнительно вычисляются дельта-AIC (разница относительно наилучшей модели) и веса AIC, которые интерпретируются как вероятности того, что данная модель является наилучшей среди рассматриваемых.\nАнализ результатов показывает четкое разделение моделей по качеству. Модель GAM демонстрирует наилучшие показатели с AIC = 42840.91 и весом AIC 0.993, что означает 99.3% вероятность того, что эта модель является наилучшей среди сравниваемых. Модель GLM показывает очень близкие результаты по объясненной дисперсии (0.401), но несколько худшие значения AIC (42850.76) и минимальный вес (0.007). Модель GAMM значительно уступает по всем критериям с AIC = 42933.49 и нулевым весом в рамках данного сравнения.\nРазница в AIC между GAM и GLM составляет 9.85 единиц, что превышает пороговое значение 2, принятое для утверждения о существенном преимуществе одной модели над другой. Еще более значительная разница в 92.58 единиц между GAM и GAMM подтверждает статистически значимое превосходство GAM модели.\nНа основе проведенного анализа формулируются итоговые рекомендации по выбору модели. Модель GAM идентифицируется как наилучшая с очень высокой степенью уверенности (вес AIC 0.993). Объясняющая способность модели составляет 40.1%, что указывает на хорошее соответствие модели данным.\nДанный сравнительный подход обеспечивает объективную основу для выбора окончательной модели, позволяя учесть как качество подгонки, так и сложность модели, избегая таким образом как избыточного усложнения, так и излишнего упрощения.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE: GLM, GAM, GAMM</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Введение",
    "section": "",
    "text": "“How data treat you?” — Аристотель\n\nНастоящий ресурс посвящен применению современных методов анализа данных для оценки водных биоресурсов, поскольку, как заметил бы Роберт Сапольски, игнорировать статистику в гидробиологии так же безрассудно, как павиану игнорировать льва в соседнем кусте. Изначально эти материалы создавались для очного курса, который пока не состоялся и, в силу разных обстоятельств, возможно, не состоится. Что ж, эволюция любит слепые переулки, и вот теперь практические занятия выставлены на всеобщее обозрение — в свободное пользование для всех заинтересованных специалистов. Лекции, быть может, последуют позже, а может, и нет — как повезет.\nМы живем в эпоху больших языковых моделей (LLM), когда любая стандартная методика может быть разжевана нейросетью, а обучающий скрипт сгенерирован за время, необходимое чтобы моргнуть. В таких условиях настоящую ценность представляют уже не шаблонные решения, а профессиональный опыт, причудливые идеи и то самое глубокое понимание, которое позволяет видеть данные изнутри. Молодые специалисты, как правило, достаточно быстро учатся собирать материал «в поле» — этому способствует и врожденная склонность человека к исследованию, и вполне себе социализированное желание проводить время на свежем воздухе. Но вот ключевой вопрос, перед которым многие замирают: а что делать с этими данными дальше? Ограничиться стандартной картой и графиком с коэффициентом корреляции — сегодня не вариант. Мир анализа данных полон мощных и поразительных инструментов, и наша задача — не только показать их, но и научить заставлять данные рассказывать о себе так, как им, возможно, не всегда хочется: по-разному, подробно, иногда даже против их воли.\nHow data treat you? — как-то раз ернически спросил меня… нет, не Аристотель, конечно, а Aristoteles, молодой специалист из Венесуэлы. Произошло это во время одной научно-исследовательской съемки у берегов Фолклендских островов. Его вопрос я понял не сразу — возможно, сказалась усталость, а может, когнитивный диссонанс от того, что столь глубинно-философское прозрение пришло к человеку в ярком плаще и с гамаком за спиной*. Но смысл его оказался точен: данные относятся к тебе так, как ты относишься к ним.\nСегодня от исследователя уже не требуется безупречного владения навыками программирования — достаточно иметь терпение, любопытство и немного смирения перед лицом технологии. LLM стали нашими компаньонами, цифровыми шимпанзе-ассистентами, способными написать, исправить, прокомментировать или продолжить почти любой скрипт. Это значительно снижает порог входа в мир R и анализа. Такой подход можно было бы назвать «vibe coding» — итеративный, почти медитативный процесс творческого диалога с машиной, где ты формулируешь задачи на естественном языке, прототипируешь идеи через ИИ, а затем оцениваешь результат, фокусируясь не на синтаксисе, а на смысле. Данный практикум стремится культивировать именно такой — более человечный — стиль работы. Многие из этих занятий родились в нескончаемых диалогах и импровизированных дискуссиях с Cursor, DeepSeek, Qwen и KIMI — моими цифровыми коллегами по цеху.\nПрактикум представляет собой своего рода путеводитель — или, если угодно, field guide — по применению современных методов анализа данных, ориентированный на начинающих специалистов. Материалы структурированы так, чтобы охватить ключевые этапы работы: от первичной загрузки и обработки данных до продвинутого моделирования и визуализации. Здесь вы найдёте подробные примеры кода, пояснения к методам и — что особенно важно — интерпретацию результатов, которая позволяет не только освоить R, но и понять, каким образом эти выводы встраиваются в более широкий биологический и управленческий контекст.\nОсобое внимание уделено работе с ограниченными и неполными данными — ситуацией, типичной для многих гидробиологических и рыбохозяйственных исследований. Потому что, let’s face it, идеальные датасеты существуют разве что в учебниках. В реальности же нам приходится иметь дело с тем, что есть — и находить красоту в несовершенстве. Практикум включает как классические статистические методы (линейные и логистические регрессии, кластеризация, сравнение групп), так и современные подходы: пространственно-временное моделирование (sdmTMB), нейронные сети и байесовские методы оценки запасов (SPiCT, JABBA). Отдельный раздел посвящен картографированию и визуализации — потому что карта всё ещё иногда говорит громче, чем сто пятьсот p-value.\nМатериалы продолжают пополняться — медленно, неравномерно, с переменным успехом — и доступны в открытом доступе. Возможно, они станут для кого-то тем самым ресурсом, которого не хватало. Приветствуются предложения по сотрудничеству и материалы от коллег — с обязательным указанием авторства. Также принимаются вопросы, идеи и даже деликатно оформленные предложения по улучшению — потому что ни один мозг, даже при поддержке LLM, не может объять необъятное.\nКонтакты для связи: Сергей Баканёв mombus@gmail.com\n*​​​​​​​- Комментарий Роберта Сапольски: это же чистейшей воды когнитивный диссонанс в его самом бытовом и потому гениальном проявлении.\nНаш мозг — великий мастер по созданию шаблонов и ярлыков. Он постоянно, за спасибо, каталогизирует реальность, чтобы нам не пришлось каждый раз с нуля решать, съедобен ли этот гриб или стоит ли бежать от этого зверя. Часть этой каталогизации — создание образов и ожиданий от этих образов.\nИ вот перед нами возникает персонаж:\n\nЯркий плащ — это атрибут чудака, художника, туриста-недотепы, который несерьёзно относится к суровым полевым условиям.\nГамак за спиной — это символ легкомыслия, отдыха, сиесты, нежелания погружаться в грязную, потную работу «настоящего» исследователя.\n\nНаш мозг, сверкая нейронами, мгновенно скатывает этого человека в категорию «несерьёзный тип», «экспонат». Мы ожидаем от него шуток, баек или, на худой конец, вопросов о том, где лучше половить рыбу на ужин.\nА он — бац! — и задает вопрос уровня зрелого философа или data scientist-ветерана. «How data treat you?» — это не вопрос про погоду. Это глубокий, почти экзистенциальный вопрос о взаимоотношениях между исследователем и его данными, о том, как наши собственные предубеждения и методы формируют тот результат, который мы в итоге получаем.\nИ наш мозг, который только что занес этого человека в папку «Разное/Неважное», сталкивается с катастрофой. Шаблон трещит по швам. Происходит тот самый когнитивный диссонанс: конфликт между ожиданием («чудак») и реальностью («мудрец»).\nПлащ и гамак здесь — это идеальная метафора этого диссонанса. Они являются видимым, материальным доказательством ошибочности наших стереотипов. Самый проницательный вопрос в вашей жизни может прийти от кого угодно и где угодно: от человека в костюме клоуна, от бармена в три часа ночи или от коллеги с гамаком на Фолклендах.\nИ мораль этой истории такова: наш мозг ленив и склонен к предубеждениям. Но настоящая мудрость часто приходит в неподходящей упаковке. Задача — пережить этот кратковременный когнитивный сбой, отбросить ярлыки и услышать сам вопрос, а не оценить костюм того, кто его задает.\nВ конечном счете, плащ и гамак — это просто детали, которые делают историю человечной и запоминающейся. Они напоминают нам, что глубокие мысли носят не только те, у кого есть ученая степень и строгий костюм, но и те, кто позволяет себе быть несерьезным, чтобы быть по-настоящему свободным в своих размышлениях.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Введение</span>"
    ]
  },
  {
    "objectID": "chapter 1.html",
    "href": "chapter 1.html",
    "title": "2  Анализ и визуализация данных улова",
    "section": "",
    "text": "2.1 Введение\nЭто занятие — про первый шаг в анализе уловов: аккуратно загрузить данные, посмотреть на них без иллюзий и задать простые, проверяемые вопросы. Мы будем работать в R, потому что он честно показывает структуру данных и не скрывает неудобные детали. Наша цель сейчас не «сделать красиво», а убедиться, что мы видим именно то, что реально записано в файле: сколько строк, какие переменные, каких они типов и не прячутся ли среди них ошибки, способные испортить весь последующий анализ.\nНачинаем с того, чтобы R «видел» правильную папку. Рабочая директория должна указывать туда, где лежит файл shrimp_catch.csv. Простая установка пути — это не бюрократия, а воспроизводимость: на другом компьютере тот же код должен читать те же данные, а не «что‑то похожее». После этого подключаем tidyverse: это набор инструментов, который унифицирует чтение, преобразование и визуализацию. read_csv считывает таблицу и сразу создаёт tibble — «вежливую» версию data.frame с чётким хранением типов. Уже на этом шаге стоит помнить о банальных, но частых ловушках: десятичный разделитель должен совпадать с вашими региональными настройками, пустые строки и «NA» в файле должны превращаться в пропуски, а не в нули или текст.\nПервичный осмотр — это короткий разговор с данными без интерпретации. Команда glimpse выдаёт компактный снимок: сколько строк, каковы названия столбцов и их классы, примеры значений. В нашем наборе ожидаем пять столбцов: id как целое число, age как целое число 1–4, length как числовая величина длины, weight как числовая величина массы и sex как текстовый признак пола. Если вы видите, что length внезапно «chr» или sex закодирован числами — это сигнал остановиться и привести типы в порядок сейчас, а не объяснять странные результаты потом. Аналогичная команда str показывает внутреннюю структуру и подтверждает, что R понимает объект так же, как и вы. Эти две команды — «микроскоп 4×»: быстро и без украшательств.\nДальше имеет смысл задать несколько контрольных вопросов, которые одновременно проверяют здравый смысл и раскрывают базовую статистику. summary покажет минимумы, медианы и квартильные точки для количественных переменных и распределение для категориальных. Если где‑то возникает отрицательный вес, нулевая длина или возраст за пределами 1–4 — это не «особенности популяции», это данные, требующие чистки. table и prop.table дадут частоты по полу; если соотношение полов выглядит нереалистично для вашей промысловой выборки — проверьте этап предобработки. Наконец, простой cor.test между длиной и весом покажет, есть ли ожидаемая сильная положительная связь; но здесь важно помнить о дисциплине: корреляция — это не причинность, и даже высокая r требует подтверждения графиком рассеяния и проверкой на аутлаеры.\nЗачем столько внимания «мелочам» до любых моделей? Потому что в прикладной биостатистике именно этот участок пути отделяет полезные выводы от красивых, но пустых графиков. Проверка типов и диапазонов, явное обращение с пропусками, подтверждение структурой — это те скромные процедуры, которые экономят часы на поздних этапах. И если позволить себе лёгкую «сапольскину» ремарку, то лучший способ повысить интеллектуальную честность анализа — не верить по умолчанию ни себе, ни данным, пока вы не посмотрели на них под простейшим светом glimpse и str.\nКогда эти шаги пройдены, можно переходить к описательной статистике и первичной визуализации. Гистограмма длины даст быстрый набросок формы распределения, а простые группировки по возрасту покажут, как меняются средние и разброс. Но это уже следующий раздел. Сейчас важнее, чтобы R и вы одинаково понимали, что такое «наши данные», и чтобы каждый последующий результат опирался на корректно загруженную и проверенную таблицу shrimp_catch.csv.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter 1.html#загрузка-данных-и-первичный-осмотр",
    "href": "chapter 1.html#загрузка-данных-и-первичный-осмотр",
    "title": "2  Анализ и визуализация данных улова",
    "section": "2.2 Загрузка данных и первичный осмотр",
    "text": "2.2 Загрузка данных и первичный осмотр\nссылка на файл: shrimp_catch.csv\n\n# Установка рабочей директории\nsetwd(\"C:/TEXTBOOK/\")\n# Загрузка библиотек\nlibrary(tidyverse)\n# Загрузка данных\ndata &lt;- read_csv(\"shrimp_catch.csv\")\n\nКоманда glimpse знакомит со структурой данных:\n\n# Просмотр структуры и первых строк загруженных данных\nglimpse(data)\n\n\nRows: 230\nColumns: 5\n$ id     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, ~\n$ age    &lt;int&gt; 2, 4, 4, 4, 1, 4, 2, 2, 4, 3, 4, 3, 2, 1, 2, 1, 2, 2, 2, 2, 3, ~\n$ length &lt;dbl&gt; 20.45450, 25.88928, 29.42257, 30.68292, 12.46059, 28.52152, 17.~\n$ weight &lt;dbl&gt; 1.28221748, 1.97476899, 2.65412595, 3.44746476, 0.13404801, 2.3~\n$ sex    &lt;chr&gt; \"M\", \"F\", \"F\", \"F\", \"M\", \"F\", \"M\", \"M\", \"F\", \"F\", \"F\", \"F\", \"M\"~\n&gt; \n\nМожно использовать команду str — показывает внутреннюю структуру объекта , включая количество строк, столбцов, названия переменных, их типы (chr, num, int и др.), а также несколько первых значений.\n\nstr(data)\n\n\n'data.frame':   230 obs. of  5 variables:\n $ id    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ age   : int  2 4 4 4 1 4 2 2 4 3 ...\n $ length: num  20.5 25.9 29.4 30.7 12.5 ...\n $ weight: num  1.282 1.975 2.654 3.447 0.134 ...\n $ sex   : chr  \"M\" \"F\" \"F\" \"F\" ...\n&gt;",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter 1.html#описательная-статистика-и-визуализация",
    "href": "chapter 1.html#описательная-статистика-и-визуализация",
    "title": "2  Анализ и визуализация данных улова",
    "section": "2.3 Описательная статистика и визуализация",
    "text": "2.3 Описательная статистика и визуализация\nКоманда summary выводит описательную статистику для каждой числовой переменной: минимум, 1-й квартиль, медиана, среднее, 3-й квартиль, максимум; для категориальных переменных — частоты.\n\n# Общая статистика\nsummary(data)\n\n\n       id              age            length          weight       \n Min.   :  1.00   Min.   :1.000   Min.   : 7.65   Min.   :-0.3334  \n 1st Qu.: 58.25   1st Qu.:2.000   1st Qu.:17.62   1st Qu.: 0.6320  \n Median :115.50   Median :3.000   Median :22.49   Median : 1.3660  \n Mean   :115.50   Mean   :2.509   Mean   :21.68   Mean   : 1.4933  \n 3rd Qu.:172.75   3rd Qu.:3.000   3rd Qu.:26.03   3rd Qu.: 2.1148  \n Max.   :230.00   Max.   :4.000   Max.   :36.02   Max.   : 5.1316  \n     sex           \n Length:230        \n Class :character  \n Mode  :character  \n\nПростейшими командами можно вычислить, например, соотоношение полов или корреляцию длина-вес.\n\n# Соотношение полов\nprop.table(table(data$sex)) %&gt;% round(2)\n\n\n   F    M \n0.35 0.65 \n\n\n# Корреляция длина-вес с p-value\ncor_test &lt;- cor.test(data$length, data$weight, \n                     method = \"pearson\", \n                     exact = FALSE,\n                     na.action = na.omit)\n \ncor_coef &lt;- round(cor_test$estimate, 2)\np_value &lt;- scales::pvalue(cor_test$p.value, accuracy = .001)\n \ncat(\"Корреляция Пирсона: r =\", cor_coef, \", p =\", p_value, \"\\n\")\n\n\nКорреляция Пирсона: r = 0.95 , p = &lt;0.001 \n\n\n# Распределение возраста\ntable(data$age)\n\n\n1  2  3  4 \n43 68 77 40 \n\n\n# Средние значения длины и веса по группам\ndata %&gt;%\n   group_by(age) %&gt;%\n   summarise(\n     mean_length = mean(length),\n     sd_length = sd(length),\n     mean_weight = mean(weight),\n     sd_weight = sd(weight))\n\n\n# A tibble: 4 x 5\n    age mean_length sd_length mean_weight sd_weight\n  &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1     1        12.7      1.37       0.249     0.234\n2     2        19.2      1.88       0.919     0.341\n3     3        24.8      1.72       1.88      0.424\n4     4        29.1      2.28       2.96      0.804\n&gt; \n\n\n2.3.1 Построение гистограммы для переменной ‘length’ (длина креветок)\nДля первого визуального знакомства команда hist строит гистограмму — простой график, который показывает, как распределены значения числовой переменной. В данном случае отображается распределение длин креветок из набора данных.\n\nhist(data$length, \n     main = \"Гистограмма длины креветок\",          # Заголовок графика\n     xlab = \"Длина (см)\",                          # Подпись оси X\n     ylab = \"Частота\",                             # Подпись оси Y\n     col = \"lightblue\",                            # Цвет столбцов\n     border = \"black\",                             # Цвет границ столбцов\n     breaks = 15)                                   # Количество интервалов\n\n\n\n\nРис. 1.1: Гистограмма длины креветок\n\n\n\n\n2.3.2 Визуализация в ggridges\nДля элегантных и компактных графиков подходит библиотека ggridges. Построим распределение длины креветки в зависимости от пола и возраста.\n\nlibrary(ggplot2)\nlibrary(ggridges)\n\nggplot(data, aes(x = length, \n                 y = sex, \n                 group = sex, \n                 fill = sex)) +\n  geom_density_ridges(scale = 2, alpha = 0.7) +\n  scale_y_discrete(expand = c(0, 0)) +\n  scale_x_continuous(expand = c(0, 0)) +\n  labs(\n    title = \"Распределение длины карапакса по полу\",\n    x = \"Длина карапакса (мм)\",\n    y = \"Пол\"\n  ) +\n  theme(\n    panel.border = element_blank(),  # Убирает рамку вокруг графика\n    axis.line = element_line(color = \"black\")  # Сохраняет осевые линии (опционально)\n  )\n\n\n\n\nРис. 1.2: Пол-длина креветок с использованием ggridges",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter 1.html#выявление-аутлайеров-выбросов",
    "href": "chapter 1.html#выявление-аутлайеров-выбросов",
    "title": "2  Анализ и визуализация данных улова",
    "section": "2.4 Выявление аутлайеров (выбросов)",
    "text": "2.4 Выявление аутлайеров (выбросов)\nАутлаеры (выбросы) — наблюдения, значительно отклоняющиеся от общего распределения данных. Их идентификация критически важна, так как они могут искажать результаты анализа. Один из надёжных методов обнаружения выбросов — метод межквартильного размаха (IQR).\n\n2.4.1 Теория метода\n\nРасчёт квартилей:\n\nQ1 (25-й перцентиль): значение, ниже которого находится 25% данных.\nQ3 (75-й перцентиль): значение, ниже которого находится 75% данных.\nIQR = Q3 - Q1: мера разброса средней половины данных.\n\nГраницы аутлаеров:\n\nНижняя граница: Q1−1.5×IQRQ1−1.5×IQR\nВерхняя граница: Q3+1.5×IQRQ3+1.5×IQR\nНаблюдения за этими пределами считаются выбросами.\n\n\n\n\n2.4.2 Преимущества метода\n\nУстойчивость к асимметрии распределения.\nНе требует предположения о нормальности данных.\n\n\n# Метод межквартильного размаха\noutliers &lt;- data %&gt;%\n  mutate(\n    length_z = scale(length),\n    weight_z = scale(weight)\n  ) %&gt;% \n  filter(abs(length_z) &gt; 3 | abs(weight_z) &gt; 3)\n\n# Визуализация\nggplot(data, aes(x = length, y = weight)) +\n  geom_point(aes(color = \"Обычные\"), alpha = 0.5) +\n  geom_point(data = outliers, aes(color = \"Аутлаеры\"), size = 3) +\n  scale_color_manual(values = c(\"Обычные\" = \"grey50\", \"Аутлаеры\" = \"red\")) +\n  labs(title = \"Выявление аномальных наблюдений\", color = \"Тип\")\n\n\n\n\nРис. 1.3: Распределение длины карапакса",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter 1.html#определение-возрастной-структуры-статистические-методы-анализа-размерных-данных",
    "href": "chapter 1.html#определение-возрастной-структуры-статистические-методы-анализа-размерных-данных",
    "title": "2  Анализ и визуализация данных улова",
    "section": "2.5 Определение возрастной структуры: статистические методы анализа размерных данных",
    "text": "2.5 Определение возрастной структуры: статистические методы анализа размерных данных\nЛирическое отступление\nОпределять возрастную структуру по размерным данным — это не попытка «угадать» возраст, а дисциплинированный способ выделить в общей смеси несколько закономерных мод, за которыми почти всегда стоят биологические процессы: вариации в пополнении, различия в темпах роста, селективность промысла. Мы не видим возраст напрямую, зато видим след его накопления в длине, и задача статистики здесь — разложить смешанное распределение на осмысленные компоненты, не выдавая желаемое за действительное. Начинать разумно с простого: гистограмма и сглаженная плотность дают первичную картину, где «пики» — это кандидаты на возрастные группы. Выбор ширины бинов (диа) — не косметика: слишком широкие бины сливают моды, слишком узкие создают шумовые «зубцы». Ядерная плотность полезна как независимая проверка: если пик виден и на гистограмме, и на сглаженной плотности, это хороший знак. Уже на этом шаге важно исключить явные аутлаеры и убедиться, что анализируется однородная по сезону и району выборка: смешение сезонов способно превратить один чёткий пик в два слабых и наоборот.\nK‑means привлекателен скоростью и простотой, но его допущения жестковаты для биологии: он делит по ближайшему центру и фактически предполагает равные дисперсии у групп. Для черновой разметки это приемлемо: задали K, получили кластеры, посмотрели, не распилили ли явный пик пополам и не смешали ли крайние хвосты. Но трактовать эти кластеры как «возрастные классы» без дополнительных проверок нельзя. Минимальный набор проверок — «локальный смысл»: центры кластеров должны быть упорядочены по длине, доли групп не должны выглядеть абсурдно для вашей системы, а границы между кластерами — приходиться на спады между модами гистограммы. Полезно пробежать несколько значений K, посмотреть «локоть» по внутрикластерной дисперсии или силуэт; если модель жадно «доедает» шум, она не помогает задаче.\nДекомпозиция смесью нормалей с EM‑алгоритмом ближе к тому, что нам нужно: каждая компонента имеет свой средний размер, свою дисперсию и свою долю, а принадлежность особи — вероятностная, а не «жёсткая». Это лучше отражает реальность: возрастные группы перекрываются, и жёсткое отнесение на границе избыточно уверенно. Здесь ключевая инженерная мысль — инициализация и выбор числа компонент. Стартовать можно от пиковой структуры гистограммы или от грубых центров k‑means; число компонент выбирать по BIC/AIC и здравому смыслу, помня, что каждая лишняя компонента почти всегда «объясняет» шум. Параметры смеси имеют прозрачную интерпретацию: μ — модальный размер группы, σ — разброс (ростовая гетерогенность плюс измерительная ошибка), λ — доля группы в выборке. Для отчётности полезно ранжировать компоненты по μ, чтобы избежать «перескока меток» между запусками, и дать доверительные интервалы (обычный приём — бутстрэп).\nМетод Бхаттачарии, классика промысловой статистики, по сути делает то же в терминах гистограммы: линейнизует лог‑разности соседних бинов и позволяет визуально «вынуть» наклон, соответствующий компоненте нормального распределения. Он чувствителен к выбору ширины бина и к ровности хвостов, зато нагляден и хорошо работает там, где пики действительно нормальны и отделены. В паре с EM это сильная связка: Бхаттачария помогает выбрать разумное K и старт, EM — уточняет параметры и даёт вероятностные принадлежности. Сопоставление результатов этих двух подходов повышает доверие: если оба «видят» четыре группы с близкими μ, это гораздо лучше, чем красивый рисунок одного метода.\nНа практике полезно придерживаться алгоритма «снизу вверх». Сначала — чистая визуализация: гистограмма, ядерная плотность, по возможности разрезы по полу и возрасту полевой маркировки; это помогает понять, не смешиваем ли мы биологически разные контексты. Затем — черновая кластеризация k‑means для ориентировочных центров и грубого K. Далее — смеси нормалей с EM, выбор K по BIC и проверка стабильности решения от разных стартов. После подгонки — диагностика: наложить компоненты и суммарную смесь на гистограмму, проверить, не «улетели» ли σ, нет ли «дублирующих» компонент с почти одинаковыми μ, сопоставить λ с ожидаемыми долями когорт. И главное — помнить, что «модальные группы по длине» и «возрастные классы» совпадают не автоматом: для перевода мод в возраст нужен ростовой ключ (например, параметры Берталанфи) или независимая информация о когортности. Без этого честнее говорить «модальные размерные группы».\nНаконец, стоит держать в голове пару дисциплинарных напоминаний. Любая смесь будет пытаться объяснить артефакты данных, поэтому контроль качества измерений и фильтрация аутлаеров — не опция, а необходимость. Сезонная выборка и выборочная выловленность сдвигают доли и средние: если орудия ловят неравномерно, λ смеси — это не «структура популяции», а «структура улова». И, как бы прозаично это ни звучало, фиксируйте зерно генератора случайных чисел и документируйте выбор K и стартовые значения: это делает ваш результат воспроизводимым, а спор — предметным. Такой дисциплинированный ход — от картинки к модели, от модели к диагностике, от диагностики к осторожной интерпретации — позволяет извлечь из длины то, что она действительно хранит про возраст, и не больше.\nИ так, возрастная структура популяции — часто важна для расчёта промысловой смертности, оценки репродуктивного потенциала и прогнозирования динамики запасов. Поскольку прямое измерение возраста часто невозможно (например, у беспозвоночных или рыб без четких возрастных меток), используются статистические методы, выделяющие группы в смешанных распределениях размеров.\nОсновные подходы:\n\nМетод k-средних (k-means) — алгоритм кластеризации, группирующий особи в заданное число кластеров (возрастных групп) на основе их размеров.\nМетод Бхаттачарии — статистический подход для разделения смешанных нормальных распределений, часто применяемый для идентификации мод в гистограммах.\nEM-алгоритм — оценка параметров смеси распределений, подходящая для данных с перекрывающимися возрастными группами.\nГауссовы смеси (GMM) — расширение метода Бхаттачарии для многомерного анализа.\nЯдерное сглаживание — непараметрический метод визуализации плотности, помогающий выявить скрытые моды.\n\nРассмотрим метод k-средних (k-means) и метод Бхаттачарии, предварительно построив гистограмму.\n\n# Загрузка библиотек\nlibrary(tidyverse)\nlibrary(mixtools)\n# Гистограмма длины с наложением плотности\nggplot(data, aes(x = length)) +\n  geom_histogram(aes(y = after_stat(density)), fill = \"steelblue\", bins = 20, alpha = 0.7) +\n  geom_density(color = \"#FC4E07\", linewidth = 1) +\n  labs(title = \"Распределение длины карапакса\", \n       subtitle = \"Пики могут соответствовать возрастным группам\",\n       x = \"Длина (мм)\")\n\n\n\n\nРис. 1.3: Распределение длины карапакса\n\n\n\n# Кластеризация по длине (K-means как пример)\nset.seed(123)\nclusters &lt;- kmeans(data$length, centers = 4)  # Предполагаем 4 возрастные группы\ndata$cluster &lt;- factor(clusters$cluster)\n\n# Визуализация кластеров\nggplot(data, aes(x = length, fill = cluster)) +\n  geom_histogram(bins = 25, alpha = 0.7) +\n  labs(title = \"Кластеризация по длине)\", \n       x = \"Длина (мм)\")\n\n\n\n\nРис. 1.4: Кластеризация по длине\n\n\n\n# Установка рабочей директории\nsetwd(\"C:/TEXTBOOK/\")\n\n# Загрузка библиотек\nlibrary(tidyverse)\nlibrary(mixtools)\n\n# Загрузка данных\ndata &lt;- read.csv(\"shrimp_catch.csv\")\n\n# 1. Построение и отображение гистограммы\nhist(data$length, breaks = 20, main = \"Гистограмма распределения длин карапаксов\",\n     xlab = \"Длина карапакса (мм)\", ylab = \"Частота\")\n\n# 2. Инициализация параметров (предположим 4 возрастные группы)\ninit_params &lt;- list(\n  lambda = rep(1/4, 4),\n  mu = c(13, 19, 25, 32),\n  sigma = c(1.5, 1.75, 1.75, 2.5)\n)\n\n# 3. Разделение смеси распределений методом EM\nfit &lt;- normalmixEM(data$length, k = 4, maxit = 1000, epsilon = 1e-3,\n                   lambda = init_params$lambda,\n                   mu = init_params$mu,\n                   sigma = init_params$sigma)\n\n# 4. Визуализация результатов с ggplot2\n# Генерация сетки для построения кривых\nx_grid &lt;- seq(min(data$length), max(data$length), length.out = 500)\n\n# Функция смеси\nmixture_density &lt;- function(x) {\n  fit$lambda[1] * dnorm(x, fit$mu[1], fit$sigma[1]) +\n  fit$lambda[2] * dnorm(x, fit$mu[2], fit$sigma[2]) +\n  fit$lambda[3] * dnorm(x, fit$mu[3], fit$sigma[3]) +\n  fit$lambda[4] * dnorm(x, fit$mu[4], fit$sigma[4])\n}\n\n# График\nggplot(data, aes(x = length)) +\n  # Гистограмма\n  geom_histogram(aes(y = after_stat(density)), bins = 20, fill = \"white\", color = \"black\", alpha = 0.7) +\n  # Исходное распределение (гладкая линия)\n  geom_density(color = \"red\", lwd = 1.2) +\n  # Смесь распределений\n  stat_function(fun = mixture_density, color = \"black\", lwd = 1.5) +\n  # Компоненты смеси\n  stat_function(fun = function(x) fit$lambda[1] * dnorm(x, fit$mu[1], fit$sigma[1]), color = \"blue\", lwd = 1) +\n  stat_function(fun = function(x) fit$lambda[2] * dnorm(x, fit$mu[2], fit$sigma[2]), color = \"green\", lwd = 1) +\n  stat_function(fun = function(x) fit$lambda[3] * dnorm(x, fit$mu[3], fit$sigma[3]), color = \"orange\", lwd = 1) +\n  stat_function(fun = function(x) fit$lambda[4] * dnorm(x, fit$mu[4], fit$sigma[4]), color = \"purple\", lwd = 1) +\n  \n  # Настройка темы и легенды\n  theme_minimal() +\n  labs(\n    x = \"Длина карапакса (мм)\",\n    y = \"Плотность\",\n    title = \"Разделение возрастных групп методом EM\"\n  )\n\n\n\n\nРис. 1.5: Метод Бхаттачарии",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter 1.html#уравнение-берталанфи",
    "href": "chapter 1.html#уравнение-берталанфи",
    "title": "2  Анализ и визуализация данных улова",
    "section": "2.6 Уравнение Берталанфи",
    "text": "2.6 Уравнение Берталанфи\nУравнение Берталанфи — фундаментальная модель в рыбохозяйственной науке, описывающая асимптотический рост организмов. Оно имеет вид: \\[\nL(t) = L_{\\infty} \\cdot \\left(1 - e^{-k \\cdot (t - t_0)}\\right)\n\\] где L∞— теоретическая максимальная длина особи, k— коэффициент скорости роста, t0— гипотетический возраст при нулевой длине.\nВ приведённом коде модель применяется для анализа роста северной креветки :\n\nПодготовка данных: Удаление аутлаеров (например, строк 10 и 50) повышает точность оценки параметров.\nИнициализация параметров:\n\nL∞ задаётся как максимальная наблюдаемая длина в данных.\nk и t0 подбираются итеративно методом нелинейных наименьших квадратов (nls).\n\nВизуализация: График сопоставляет эмпирические данные (точки) с предсказаниями модели (красная линия), демонстрируя, как рост замедляется с приближением к L∞.\n\nИнтерпретация параметров:\n\nВысокое значение k (&gt;0.3) указывает на быстрый рост молоди.\nt0&lt;0 может отражать ранний метаморфоз личинок.\n\n\n# Загрузка библиотек\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(nlme)\n\n# Загрузка данных\ndata &lt;- read.csv(\"shrimp_catch.csv\")\n\n# Преобразование возраста в числовой формат\ndata$age_num &lt;- as.numeric(data$age)\n\n# Удаление аутлайеров (если необходимо)\ndata_clean &lt;- data %&gt;%\n  filter(!id %in% c(10, 50))  # Пример удаления строк с аномалиями\n\n# Начальные параметры на основе данных\nL_inf_start &lt;- max(data_clean$length, na.rm = TRUE)  # Максимальная длина\nk_start &lt;- 0.3                                        # Средняя скорость роста\nt0_start &lt;- -0.5                                      # Гипотетический возраст\n\n# Подгонка модели с увеличенным числом итераций\nmodel &lt;- nls(\n  length ~ L_inf * (1 - exp(-k * (age_num - t0))),\n  data = data_clean,\n  start = list(L_inf = L_inf_start, k = k_start, t0 = t0_start),\n  control = nls.control(maxiter = 200, warnOnly = TRUE)  # Увеличиваем лимит итераций\n)\n\n# Вывод результатов\nsummary(model)\n\n# Создание последовательности возрастов для предсказания\nage_seq &lt;- seq(min(data_clean$age_num), max(data_clean$age_num), by = 0.1)\n\n# Предсказание значений длины\nlength_pred &lt;- predict(model, newdata = data.frame(age_num = age_seq))\n\n# Построение графика\nggplot(data_clean, aes(x = age_num, y = length)) +\n  geom_point(aes(color = age), alpha = 0.7) +\n  geom_line(data = data.frame(age_num = age_seq, length = length_pred), \n            aes(x = age_num, y = length), color = \"red\", linewidth = 1.2) +\n  labs(\n    title = \"Рост креветок по уравнению Берталанфи\",\n    x = \"Возраст (годы)\",\n    y = \"Длина карапакса (мм)\",\n    color = \"Возрастная группа\"\n  ) +\n  theme_minimal()\n\n# Сохранение графика\nggsave(\"bertalanffy_model.png\", width = 8, height = 6)\n\n\n\n\nРис. 1.6: Рост креветок по уравнению Берталанфи",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter 1.html#огива-логистическая-кривая-и-50-ное-созревание",
    "href": "chapter 1.html#огива-логистическая-кривая-и-50-ное-созревание",
    "title": "2  Анализ и визуализация данных улова",
    "section": "2.7 Огива, логистическая кривая и 50%-ное созревание",
    "text": "2.7 Огива, логистическая кривая и 50%-ное созревание\nЛогистическая регрессия удобна там, где исход — бинарный: созрел/не созрел, самка/самец. Для протоандрической креветки вероятность быть самкой естественно растёт с длиной, и логистическая кривая описывает это гладким переходом от 0 к 1; её центральная точка даёт L50 = −β0/β1 — длину, при которой половина особей уже самки. Огива — это та же история, но накопительно: как доля самок нарастает по мере увеличения длины; она наглядна для сравнения годов/районов и проверки сдвигов зрелости. Качество модели удобно проверять ROC/AUC: AUC ≈ 0.9+ означает, что длина хорошо ранжирует вероятность женского пола, но не отменяет проверки калибровки. Знак и величина β1 интерпретируются просто: положительный β1 — с каждым миллиметром шансы быть самкой растут, exp(β1) — во сколько раз растут эти шансы на единицу длины. Биологически L50 концентрирует ключевой сигнал: при стабильных условиях он держится в узком интервале (для Pandalus borealis около 25–28 мм), а его снижение обычно маркирует стресс среды или избирательный вылов, «подталкивающий» к более раннему созреванию. В прикладном учёте это даёт два практичных числа — L50 и AUC — и две опоры для интерпретации: насколько резко идёт переход (крутизна кривой) и насколько надёжен прогноз (дискриминация и калибровка).\nЛогистическая кривая — ключевой инструмент для моделирования бинарных процессов, таких как созревание или смена пола у организмов. В случае протоандрических креветок (Pandalus borealis), которые меняют пол с возрастом, зависимость вероятности быть самкой от длины карапакса можно описать логистической функцией:\n\\[\nP(F) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 \\cdot длина)}}\n\\]\nгде P(F) — вероятность принадлежности к женскому полу, β0 — интерсепт, β1 — коэффициент влияния длины.\nТочка перегиба логистической кривой соответствует длине, при которой вероятность быть самкой равна 50%: \\[\nL_{50} = -\\frac{\\beta_0}{\\beta_1}\n\\]\n\n\n\nРис. 1.7: Логистическая кривая\n\n\nОгива (кумулятивная кривая) показывает накопление вероятности с увеличением длины. Для анализа созревания её можно построить через интеграл логистической функции. Визуально она демонстрирует, как доля самок возрастает с размером.\n\n\n\nРис. 1.8: Огива\n\n\n\n2.7.1 Оценка модели\n\nROC-кривая и AUC:\n\nПлощадь под ROC-кривой (AUC) &gt;0.7 указывает на хорошую предсказательную способность модели.\nЗначение AUC = 0.94(пример из кода) подтверждает сильную связь длины и пола.\n\n\n\n\n\nРис. 1.9: ROC-кривая и AUC\n\n\n\nИнтерпретация коэффициентов:\n\nПоложительный β1 означает: с ростом длины вероятность быть самкой увеличивается.\nНапример, β1=0.25 → увеличение длины на 1 мм повышает шансы в e0.25≈1.28 раза.\n\n\n\n\n2.7.2 Биологический контекст\n\nПротоандрический гермафродитизм: У креветок смена пола с самцов на самок происходит при достижении критического размера (~25-28 мм).\nL50 как индикатор: Снижение L50 в популяции может сигнализировать о стрессовых условиях (перелов, изменение среды), ускоряющих созревание.\n\n\n# Установка рабочей директории\nsetwd(\"C:/TEXTBOOK/\")\n\n# Загрузка библиотек\nlibrary(tidyverse)\nlibrary(pROC)\nlibrary(ggplot2)\n\n# Загрузка данных\ndata &lt;- read_csv(\"shrimp_catch.csv\")\n\n# 1. Предобработка данных -----------------------------------------------------\n# Удаление аутлаеров методом IQR\nQ1 &lt;- quantile(data$length, 0.25)\nQ3 &lt;- quantile(data$length, 0.75)\nIQR &lt;- Q3 - Q1\ndata_clean &lt;- data %&gt;%\n  filter(length &gt;= Q1 - 1.5*IQR & length &lt;= Q3 + 1.5*IQR)\n\n# 2. Логистическая регрессия --------------------------------------------------\n# Преобразование пола в бинарную переменную\ndata_clean$sex_binary &lt;- ifelse(data_clean$sex == \"F\", 1, 0)\n\n# Подгонка модели\nmodel_logit &lt;- glm(sex_binary ~ length, \n                   data = data_clean, \n                   family = binomial(link = \"logit\"))\n\n# Расчет коэффициентов\nbeta0 &lt;- coef(model_logit)[1]\nbeta1 &lt;- coef(model_logit)[2]\n\n# Вычисление L50 (длина 50% созревания)\nL50 &lt;- round(-beta0/beta1, 1)\n\n# 3. Визуализация ------------------------------------------------------------\n# Логистическая кривая\nggplot(data_clean, aes(x = length, y = sex_binary)) +\n  geom_point(aes(color = sex), alpha = 0.6, size = 2) +\n  geom_line(aes(y = predict(model_logit, type = \"response\")), \n            color = \"#D81B60\", linewidth = 1.5) +\n  geom_vline(xintercept = L50, linetype = \"dashed\", color = \"#1E88E5\") +\n  annotate(\"text\", x = L50 + 2, y = 0.2, \n           label = paste(\"L50 =\", L50, \"мм\"), color = \"#1E88E5\") +\n  scale_color_manual(values = c(\"#FFC107\", \"#1976D2\")) +\n  labs(\n    title = \"Зависимость пола от длины карапакса\",\n    subtitle = \"Логистическая регрессия с 50%-ной точкой созревания\",\n    x = \"Длина карапакса (мм)\",\n    y = \"Вероятность быть самкой (P(F))\"\n  ) +\n  theme_minimal(base_size = 12)\n\n# Огива (кумулятивное распределение)\ndata_ogive &lt;- data_clean %&gt;%\n  arrange(length) %&gt;%\n  mutate(\n    cum_females = cumsum(sex_binary),\n    cum_prob = cum_females / max(cum_females)\n  )\n\nggplot(data_ogive, aes(x = length, y = cum_prob)) +\n  geom_line(color = \"#4CAF50\", linewidth = 1.5) +\n  geom_vline(xintercept = L50, linetype = \"dashed\", color = \"#1E88E5\") +\n  geom_hline(yintercept = 0.5, linetype = \"dotted\", color = \"#757575\") +\n  annotate(\"text\", x = L50 + 2, y = 0.55, \n           label = paste(\"50% созревание при\", L50, \"мм\"), color = \"#1E88E5\") +\n  scale_y_continuous(labels = scales::percent) +\n  labs(\n    title = \"Огива: Кумулятивное распределение самок\",\n    x = \"Длина карапакса (мм)\",\n    y = \"Накопленная доля самок\"\n  ) +\n  theme_minimal(base_size = 12)\n\n# 4. Оценка модели -----------------------------------------------------------\n# ROC-анализ\nroc_obj &lt;- roc(data_clean$sex_binary, predict(model_logit, type = \"response\"))\nauc_value &lt;- round(auc(roc_obj), 2)\n\n# График ROC-кривой\nplot(roc_obj, col = \"#E53935\", main = paste(\"ROC-кривая (AUC =\", auc_value, \")\"))\n\n# 5. Сохранение результатов --------------------------------------------------\nggsave(\"logistic_curve.png\", width = 8, height = 6, dpi = 300)\nggsave(\"ogive_curve.png\", width = 8, height = 6, dpi = 300)\n\n# Вывод ключевых метрик\ncat(\"Результаты анализа:\\n\")\ncat(\"- Длина 50%-ного созревания (L50):\", L50, \"мм\\n\")\ncat(\"- AUC модели:\", auc_value, \"\\n\")\ncat(\"- Коэффициенты модели:\\n\")\ncat(\"  Intercept (β0):\", round(beta0, 2), \"\\n\")\ncat(\"  Slope (β1):\", round(beta1, 2), \"\\n\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter 1.html#сравнение-групп-параметров-моделей",
    "href": "chapter 1.html#сравнение-групп-параметров-моделей",
    "title": "2  Анализ и визуализация данных улова",
    "section": "2.8 Сравнение групп, параметров, моделей",
    "text": "2.8 Сравнение групп, параметров, моделей\nСравнивать группы — это не про охоту за маленькими p-value, а про проверяемые ответы на конкретные биологические вопросы. «Самки длиннее самцов?» — переводим в аккуратную статистическую формулировку, начинаем с гигиены данных и только потом подбираем тест. Предобработка банальна, но критична: убираем очевидные аутлаеры по понятному правилу (IQR или заранее согласованный протокол), не «чистим» хвосты до совершенства, сохраняем независимость наблюдений. Разбиваем выборку на подмножества по полу, проверяем типы переменных, смотрим на формы распределений и пропуски. И дальше — не прыжок к t‑тесту, а короткая остановка у предпосылок: нормальность и гомогенность дисперсий — это про остатки и разумность аппроксимации, а не про «магическое число 0.05». При несхожих дисперсиях уместнее Уэлч, при явной ненормальности и неробастности — Манн–Уитни, а при больших n классический t‑тест часто держится благодаря центральной предельной теореме. В любом случае голые p‑значения не заканчивают разговор: эффект размера (Cohen’s d) и доверительные интервалы говорят «на сколько», а не только «есть/нет».\nВизуализация в этом месте — не иллюстрация, а часть доказательства. Boxplot/violin помогают увидеть медианы, разброс и асимметрию; добавленная на график оценка p‑value дисциплинирует интерпретацию, но не подменяет её. Полезно в той же системе координат показать точки, чтобы помнить: каждая точка — отдельная особь, а не абстрактная «генеральная совокупность». И если позволить себе короткую «сапольскину» ремарку: мозг с удовольствием «видит» разницу там, где её нет, поэтому лучше сначала смотреть на график, потом на число, а не наоборот.\nКогда вопрос — уже не «кто крупнее», а «кто растёт быстрее», сравнение средних сменяется сравнением параметров модели. Самый прозрачный путь — объединённая линейная модель с взаимодействием: length ~ age * sex. Значимый коэффициент при взаимодействии — это формализованная фраза «наклоны различаются». Диагностика здесь важнее, чем когда‑либо: линейность, разброс остатков, потенциальные leverage‑точки. Альтернатива — раздельные модели по полу и прямое сравнение наклонов через тест Вальда; он удобен как независимая проверка и часто даёт те же выводы, что и взаимодействие, если структура данных не экзотична. Интерпретация должна оставаться биологической: различающиеся наклоны — это не «магия пола», а потенциальная разница в темпе роста, доступе к корму или сезоне отбора проб.\nДальше мы неизбежно приходим к форме связи «вес–длина». Линейная модель соблазнительно проста, но биологически мир чаще степенной: масса масштабируется примерно как длина в степени 3, с поправками на форму и состояние. Полиномиальная регрессия третьего порядка часто выигрывает в AIC и R², потому что ловит сгибы и плечи; у неё есть и оборотная сторона — склонность к переобучению и слабая интерпретируемость коэффициентов. Степенная модель почти всегда немного проигрывает по «сухим метрикам», зато даёт ясный смысл: параметр b близок к 3 — всё ожидаемо; заметное отклонение — есть предмет для обсуждения физиологии, питания, сезонности. Какой из подходов «лучший»? Тот, у которого остатки ведут себя прилично, AIC не кричит о лишней сложности, а биолог рассказывает связную историю, не пряча глаза. Хорошая практика — сопоставить все три, показать таблицу R²/AIC, приложить графики остатков и проговорить компромисс между точностью и объяснимостью.\nИ в сравнении групп, и в сравнении параметров, и в выборе модели действуют три простых правила. Первое — формулируйте вопрос до теста: это экономит десятки необязательных проверок. Второе — показывайте эффект с интервалами: «на сколько» важнее «насколько значимо». Третье — проверяйте устойчивость: замены теста (t ↔︎ Уэлч ↔︎ Манн–Уитни), альтернативная спецификация модели, бутстрэп интервалов — всё это помогает отличить сигнал от удачного совпадения. И, наконец, не забывайте про контекст отбора проб: если улов по орудиям и глубинам неоднороден, то и выводы про «среднего самца» или «типичную самку» легко превращаются в выводы про «типичный улов». Статистическая аккуратность здесь — это не педантизм, а способ говорить о биологии без самообмана.\n\n2.8.1 Сравнение групп (на примере самцов и самок)\nРассмотрим методы сравнения количественных характеристик (длина, вес) между самцами и самками северной креветки. Анализ включает проверку нормальности распределения, выбор подходящего статистического теста и визуализацию различий.\n\n2.8.1.1 Подготовка данных\nЗагрузим данные и выделим подвыборки для самцов и самок:\n\n# Установка рабочей директории\nsetwd(\"C:/TEXTBOOK/\")\n\n# Загрузка библиотек  \nlibrary(tidyverse)  \nlibrary(ggplot2)  \nlibrary(rstatix)\nlibrary(ggpubr)\n\n# Загрузка данных  \ndata &lt;- read_csv(\"shrimp_catch.csv\") %&gt;%\n  filter(!id %in% c(10, 50))  # Удаление аномальных наблюдений \n\n# Фильтрация данных по полу  \nmales &lt;- data %&gt;% filter(sex == \"M\")  \nfemales &lt;- data %&gt;% filter(sex == \"F\") \n\n\n\n2.8.1.2 Проверка нормальности распределения\nПеред сравнением групп проверим, соответствуют ли данные нормальному распределению (тест Шапиро-Уилка):\n\n# Проверка нормальности для длины самцов  \nshapiro_test(males$length)  \n# Проверка нормальности для длины самок  \nshapiro_test(females$length) \n\nЕсли p-value &gt; 0.05, распределение считается нормальным. В противном случае используем непараметрические методы.\n\n\n2.8.1.3 Сравнение средних значений\nЕсли данные нормальны: t-тест\n\n# T-тест для сравнения длин самцов и самок  \nt_test_result &lt;- t_test(length ~ sex, data = data)  \nt_test_result \n\nЕсли данные не нормальны: U-тест Манна-Уитни\n\n# U-тест для сравнения длин самцов и самок  \nmannwhitney_result &lt;- wilcox_test(length ~ sex, data = data)  \nmannwhitney_result \n\n\n\n2.8.1.4 Эффект размера (коэффициент Коэна)\nДля оценки практической значимости различий рассчитаем коэффициент Коэна:\n\n# Расчет коэффициента Коэна  \ncohens_d_result &lt;- cohens_d(length ~ sex, data = data)  \ncohens_d_result  \n\n\nd &lt; 0.2 : малый эффект,\nd ≈ 0.5 : средний эффект,\nd &gt; 0.8 : большой эффект.\n\n\n\n2.8.1.5 Визуализация различий\nПостроим boxplot для визуального сравнения длин самцов и самок:\n\nggplot(data, aes(x = sex, y = length, fill = sex)) +  \n  geom_boxplot(color = \"black\", alpha = 0.7) +  \n  stat_compare_means(method = \"t.test\") +  # Добавление p-value  \n  labs(title = \"Сравнение длин самцов и самок\",  \n       x = \"Пол\", y = \"Длина карапакса (мм)\") +  \n  theme_minimal() \n\n\n\n\nРис. 1.10: Boxplot сравнения длин самцов и самок\n\n\n\n\n2.8.1.6 Интерпретация результатов\n\nЕсли p-value &lt; 0.05, различия между группами статистически значимы.\nЭффект размера помогает оценить биологическую важность различий. Например, если самки значительно крупнее самцов (d = 1.2), это может указывать на половой диморфизм, связанный с репродуктивной стратегией.\n2.8.1.7 Пример полного анализа для веса\n\n\n# Полный анализ для веса  \nweight_analysis &lt;- data %&gt;%  \n  group_by(sex) %&gt;%  \n  summarise(  \n    mean_weight = mean(weight),  \n    sd_weight = sd(weight),  \n    n = n()  \n  ) %&gt;%  \n  mutate(  \n    t_test = list(t_test(weight ~ sex, data = data)),  \n    cohens_d = list(cohens_d(weight ~ sex, data = data))  \n  )  \n\n# Вывод результатов  \nprint(weight_analysis) \n\n# Распределение веса по полу\nggplot(data, aes(x = factor(sex), y = weight, fill = factor(sex))) +\n  geom_violin(trim = FALSE, alpha = 0.7) +\n  geom_boxplot(width = 0.2, outlier.shape = NA, fill = \"white\") +\n  labs(title = \"Распределение веса по полу\", x = \"Пол\", y = \"Вес (г)\") +\n  theme_minimal()\n\n\n\n\nРис. 1.12: Violin plot для визуализации распределения веса\n\n\n\n\n2.8.1.8 Выводы\n\nИспользуйте t-тест для нормальных данных и U-тест для ненормальных.\nДополните анализ оценкой эффекта размера для биологической интерпретации.\nВизуализируйте различия с помощью boxplot или violin plot.\n\nРекомендации :\n\nДля многомерных данных (например, одновременное сравнение длины, веса и возраста) применяйте MANOVA.\nЕсли группы неоднородны (например, разный возрастной состав), используйте ковариационный анализ (ANCOVA).\n2.8.2 Что делать, если тест на нормальность не пройден для одной из групп?\nПри сравнении количественных характеристик (например, длины карапакса у самцов и самок) важно учитывать, соответствуют ли данные нормальному распределению. Если тест на нормальность (например, Шапиро-Уилка) показывает значимое отклонение от нормальности для одной из групп, это влияет на выбор статистического теста и интерпретацию результатов.\n2.8.2.1 Пример из нашего анализа\nМы провели сравнение длины карапакса между самцами и самками:\n\nДля самцов: shapiro_test(males$length) → p-value = 0.000574 (нормальность отвергнута).\nДля самок: shapiro_test(females$length) → p-value = 0.891 (нормальность подтверждена).\n\nНесмотря на это, мы применили как t-тест , так и U-тест Манна-Уитни :\n\nt-тест : p-value = 1.46e-40 (значимо).\nU-тест : p-value = 1.97e-27 (значимо).\nКоэффициент Коэна: d = 2.14 (большой эффект).\n\n2.8.2.2 Почему это работает?\n\nt-тест устойчив к умеренным отклонениям от нормальности :\n\nПри больших выборках (n &gt; 30) центральная предельная теорема позволяет использовать t-тест даже при слабо выраженной асимметрии.\nВ вашем случае выборка самцов (n = 149) достаточно велика, чтобы компенсировать отклонение от нормальности.\n\nU-тест Манна-Уитни — непараметрическая альтернатива :\n\nЭтот тест не требует нормальности и сравнивает ранги, а не средние значения.\nОн подтверждает значимость различий, что усиливает доверие к выводу.\n\nЭффект размера (коэффициент Кобена) :\n\nd = 2.14 указывает на большой эффект , что важно для биологической интерпретации, даже если p-values значимы.\n\n\n\n\n\n\n2.8.3 Сравнение параметров (линейные модели для оценки межгрупповых различий)\nДля сравнения параметров двух линейных моделей (например, скорости роста самцов и самок) используем следующий подход.\n\n# Установка рабочей директории\nsetwd(\"C:/TEXTBOOK/\")\n\n# Загрузка библиотек\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(broom)\nlibrary(knitr)\n\n# Загрузка данных\ndata &lt;- read_csv(\"shrimp_catch.csv\") %&gt;%\n  filter(!id %in% c(10, 50))  # Удаление аномальных наблюдений\n\n# Фильтрация данных по полу\ndata_male &lt;- data %&gt;% filter(sex == \"M\")\ndata_female &lt;- data %&gt;% filter(sex == \"F\")\n\n# Построение моделей\nmodel_male &lt;- lm(length ~ age, data = data_male)\nmodel_female &lt;- lm(length ~ age, data = data_female)\n\nggplot(data, aes(age, length, color = sex)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", formula = y ~ x) +\n  scale_color_manual(values = c(\"#E7B800\", \"#00AFBB\")) +\n  labs(x = \"Возраст\", y = \"Длина (мм)\") +\n  theme_minimal()\n\n\n\n\nРис. 1.15: Визуализация моделей\n\n\nМетод 1: Объединенная модель с взаимодействиями\n\n# Установка рабочей директории\njoint_model &lt;- lm(length ~ age * sex, data = data)\nsummary(joint_model) %&gt;% \n  broom::tidy() %&gt;% \n  filter(term == \"age:sexM\") %&gt;% \n  kable(caption = \"Проверка различия наклонов\", digits = 3)\n\n\nTable: Проверка различия наклонов\n\n|term     | estimate| std.error| statistic| p.value|\n|:--------|--------:|---------:|---------:|-------:|\n|age:sexM |     1.86|     0.459|     4.053|       0|\n&gt; \n\nИнтерпретация:\nЗначимый коэффициент взаимодействия age:sexM (p &lt; 0.05) указывает на статистически значимые различия в скорости роста между полами.\nМетод 2: Тест Вальда\n\nlibrary(car)\ndelta_beta &lt;- coef(model_male)[\"age\"] - coef(model_female)[\"age\"]\nse_diff &lt;- sqrt(vcov(model_male)[\"age\",\"age\"] + vcov(model_female)[\"age\",\"age\"])\nz_score &lt;- delta_beta / se_diff\np_value &lt;- 2 * pnorm(-abs(z_score))\n\ncat(\"Разница коэффициентов:\", round(delta_beta, 3), \n    \"\\nZ-статистика:\", round(z_score, 3),\n    \"\\np-value:\", format.pval(p_value, digits = 2))\n\n\ncomparison_table &lt;- data.frame(\n  Параметр = c(\"Скорость роста самцов\", \"Скорость роста самок\", \"Разница\"),\n  Значение = c(\n    round(coef(model_male)[\"age\"], 2),\n    round(coef(model_female)[\"age\"], 2),\n    round(delta_beta, 2)\n  ),\n  `p-value` = c(\n    format.pval(summary(model_male)$coefficients[\"age\",4], digits = 2),\n    format.pval(summary(model_female)$coefficients[\"age\",4], digits = 2),\n    format.pval(p_value, digits = 2)\n  )\n)\nkable(comparison_table, caption = \"Сравнение коэффициентов роста\")\n\nВывод\n\n: Сравнение коэффициентов роста\n\n|Параметр              | Значение|p.value |\n|:---------------------|--------:|:-------|\n|Скорость роста самцов |     5.95|&lt;2e-16  |\n|Скорость роста самок  |     4.09|5.2e-13 |\n|Разница               |     1.86|0.00024 |\n&gt; \n\nИнтерпретация:\nЗначимая разница (p &lt; 0.05) указывает на статистически значимые различия в скорости роста между полами.\n\n\n2.8.4 Сравнение моделей\nОдним из ключевых аспектов анализа биологических данных является определение формы зависимости между переменными. В данном разделе мы рассмотрим основы подбора модели зависимости между длиной и весом креветок. Начиная с простой линейной модели, мы постепенно перейдем к более сложным нелинейным моделям, чтобы продемонстрировать методику выбора наилучшей модели. Cравним три модели — линейную, полиномиальную и степенную — чтобы определить, какая из них наилучшим образом описывает данные. Цель анализа — найти математическую зависимость, которая:\n\nТочно предсказывает вес креветки по её длине.\nИмеет биологическую интерпретацию.\nМинимизирует ошибку предсказания.\n\n\n2.8.4.1 Модели и их параметры\n\nЛинейная: \\(\\text{weight} = \\beta_0 + \\beta_1\\cdot\\text{length}\\)\nПолиномиальная 3-й степени: \\(\\text{weight} = \\beta_0 + \\beta_1\\cdot\\text{length} + \\beta_2\\cdot\\text{length}^2 + \\beta_3\\cdot\\text{length}^3\\)\nСтепенная: \\(\\text{weight} = a\\cdot\\text{length}^b\\)\n\n\n\n2.8.4.2 Метрики\n\nR² - (коэффициент детерминации): чем ближе к 1, тем лучше модель объясняет данные.\nAIC -(информационный критерий Акаике): чем меньше значение, тем лучше модель с учётом её сложности.\n\n\n\n2.8.4.3 Результаты\n\n2.8.4.3.1 1. Линейная модель\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.115      0.085     -24.86   &lt;2e-16 ***\nlength       0.1665     0.0038    43.71    &lt;2e-16 ***\n\n\nR² = 0.894\nAIC = 148.02\n\n\n\n\nРис. 1.5: Линейная модель\n\n\n\n\n2.8.4.3.2 2. Полиномиальная модель\n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \npoly(length,3)1  14.5038    0.2127    68.18   &lt;2e-16 ***\npoly(length,3)2   3.7209    0.2127    17.49   &lt;2e-16 ***\npoly(length,3)3   0.9526    0.2127     4.48  1.2e-05 ***\n\n\nR² = 0.957\nAIC = -52.80\n\n\n\n\nРис. 1.5: Полиномиальная модель\n\n\n\n\n2.8.4.3.3 3. Степенная модель\n\nParameters:\n   Estimate Std. Error t value Pr(&gt;|t|)    \na 0.000157   0.000028    5.60  6.3e-08 ***\nb 2.920160   0.054102   53.98   &lt;2e-16 ***\n\n\nR² = 0.955\nAIC = -48.43 \n\n\n\n\n2.8.4.4 3. Сравнение моделей\n\n\n\nМодель\nR²\nAIC\n\n\n\n\nЛинейная\n0.894\n148.02\n\n\nПолиномиальная\n0.957\n-52.80\n\n\nСтепенная\n0.955\n-48.43\n\n\n\nВыводы:\n\nПолиномиальная модель демонстрирует наилучшие показатели (максимальный R² и минимальный AIC).\nСтепенная модель близка по качеству, но её параметр b≈2.92 близок к биологически ожидаемому значению 3 (вес пропорционален объёму).\nЛинейная модель существенно уступает по точности.\n\n\n\n2.8.4.5 4. Рекомендации\n\nДля прогнозирования используйте полиномиальную модель, так как она минимизирует ошибку.\nДля биологической интерпретации предпочтительна степенная модель: weight∝length2.92.\nИзбегайте переобучения: Полиномиальные модели высокой степени могут терять интерпретируемость.\n\n\n\n2.8.4.6 5. Визуализация остатков\nОстатки степенной модели распределены равномерно, что подтверждает её адекватность: \n\n\n2.8.4.7 Заключение\nДля анализа зависимости веса от длины северной креветки рекомендуется:\n\nПолиномиальная модель — для задач, требующих максимальной точности.\nСтепенная модель — для интерпретации биологических закономерностей.\n\nСкрипт вышеописанных событий:\n\n# Установка рабочей директории\nsetwd(\"C:/TEXTBOOK/\")\n\n# Загрузка библиотек\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n# Загрузка данных\ndata &lt;- read_csv(\"shrimp_catch.csv\") %&gt;%\n  filter(!id %in% c(10, 50))  # Удаление аномальных наблюдений\n\n# Проверка структуры\nglimpse(data)\n\n# Линейная модель: вес ~ длина\nmodel_linear &lt;- lm(weight ~ length, data = data)\nsummary(model_linear)\n\n# Визуализация\nggplot(data, aes(x = length, y = weight)) +\n  geom_point(color = \"steelblue\", alpha = 0.7) +\n  geom_smooth(method = \"lm\", color = \"#FC4E07\") +\n  labs(title = \"Линейная модель\", x = \"Длина (мм)\", y = \"Вес (г)\")\n\n\n# Полиномиальная модель: вес ~ длина + длина? + длина?\nmodel_poly &lt;- lm(weight ~ poly(length, 3), data = data)\nsummary(model_poly)\n\n# Визуализация\nggplot(data, aes(x = length, y = weight)) +\n  geom_point(color = \"steelblue\", alpha = 0.7) +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 3), color = \"#E7B800\") +\n  labs(title = \"Полиномиальная модель\", x = \"Длина (мм)\", y = \"Вес (г)\")\n\n\n# Степенная модель: вес ~ длина^k (k подбирается)\nmodel_power &lt;- nls(weight ~ a * length^b, \n                   data = data, \n                   start = list(a = 0.001, b = 3))  # Начальные значения\nsummary(model_power)\n\n# Визуализация\ndata$pred_power &lt;- predict(model_power)\nggplot(data, aes(x = length, y = weight)) +\n  geom_point(color = \"steelblue\", alpha = 0.7) +\n  geom_line(aes(y = pred_power), color = \"#00BA38\", linewidth = 1.2) +\n  labs(title = \"Степенная модель\", x = \"Длина (мм)\", y = \"Вес (г)\")\n\n# Расчет AIC\nAIC(model_linear, model_poly, model_power)\n\n# Расчет R?\nr2_linear &lt;- summary(model_linear)$r.squared\nr2_poly &lt;- summary(model_poly)$r.squared\nr2_power &lt;- 1 - sum(residuals(model_power)^2) / sum((data$weight - mean(data$weight))^2)\n\n# Создание таблицы сравнения моделей\ncomparison_table &lt;- data.frame(\n  Модель = c(\"Линейная\", \"Полиномиальная\", \"Степенная\"),\n  R_square = c(r2_linear, r2_poly, r2_power),\n  AIC = c(AIC(model_linear), AIC(model_poly), AIC(model_power))\n)\n\n# Вывод таблицы\nprint(comparison_table)\n\n# Остатки для степенной модели\ndata$residuals &lt;- residuals(model_power)\n\nggplot(data, aes(x = length, y = residuals)) +\n  geom_point(color = \"#FC4E07\", alpha = 0.7) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Остатки степенной модели\", x = \"Длина (мм)\", y = \"Ошибка\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter 2.html",
    "href": "chapter 2.html",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "",
    "text": "3.1 Введение\nЭто практическое занятие — про то, как из разрозненных чисел сделать внятную экологическую историю и как перейти от простых регрессий к нейронным сетям, оставаясь честными перед данными. Мы используем R не из эстетики, а из прагматики: он позволяет прозрачно воспроизводить анализ, контролировать каждую трансформацию и быстро проверять гипотезы. В основе занятия — логика и примеры из статьи Андрея Викторовича Коросова «Нейронные сети в экологии: введение» (Принципы экологии, 2023, №3, 76–96). Там хорошо показан путь от классических линейных моделей к нелинейным конструкциям и дальше — к искусственным нейронным сетям, способным решать задачи классификации и прогнозирования. Мы пойдём тем же маршрутом, но с учебной расстановкой акцентов: сначала поймём, как работает «молоток» (регрессия), прежде чем брать в руки «многофункциональный инструмент» (сеть).\nЗадача занятия двоякая. Во‑первых, усвоить минимально достаточный набор статистических практик, чтобы не путать «эффект» с «удачным совпадением»: проверка предпосылок, визуальная диагностика, простые и понятные метрики качества, раздельные обучающие и тестовые выборки. Во‑вторых, увидеть, как усложнение модели должно быть мотивировано данными и биологией, а не нашей любовью к сложным методам. Если более простая модель объясняет всё, что вам нужно для решения прикладной задачи, смело берите её — мозг склонен влюбляться в красивое, но нам нужна работающая гипотеза.\nСтруктура занятия отражает эволюцию инструментов. Начнём с линейной регрессии на предельно понятном примере: связь массы и длины. Здесь важны не только коэффициенты и p‑значения, но и остатки, проверка линейности, гомоскедастичность, доверительные интервалы. Затем познакомимся с численной оптимизацией: когда аналитического решения нет, мы используем итерационные алгоритмы (nls) и учимся задавать стартовые значения, контролировать сходимость и чувствительность. Далее — множественная регрессия и вопрос интерпретации: что реально добавляет предиктор, а что «ездит зайцем» на коллинеарности. Оттуда естественно перейти к нелинейным зависимостям: аллометрия, линеаризация через логарифмы, сопоставление качества моделей не только по R², но и по AIC, и — что особенно важно — по поведению остатков. Логистическая регрессия вводит нас в мир пороговых процессов и бинарных исходов: S‑кривая, L50, ROC/AUC, калибровка вероятностей — всё это работает одинаково хорошо для токсичности дафний и для созревания по длине.\nКогда базовые кирпичики стоят, делаем шаг к нейронным сетям. Сначала показываем, что сеть без скрытых слоёв фактически воспроизводит линейную модель. Затем добавляем один скрытый нейрон и видим, как появляется возможность описывать нелинейности и пороговые эффекты. Дальше — классификация по нескольким признакам и небольшие архитектуры: оцениваем точность, избегаем утечки информации, фиксируем случайные зерна, обязательно сравниваем с простыми бейзлайнами, чтобы не путать «мощнее» с «лучше». В финале — пример пространственного моделирования численности по биотопам: разделение на train/test, прогноз на новых условиях, разговор о переносимости моделей и ограничениях, без которых любые «красивые карты» остаются просто эстетикой.\nОрганизация работы предельно проста. Даны три версии скрипта: KOROSOV.R — максимально близко к оригиналу; KOROSOV_updated.R — тот же код с подробными комментариями и пояснениями (основной учебный вариант); KOROSOV_visual.R — дополненный продвинутой визуализацией и небольшой аналитикой качества. Для запуска понадобятся данные vipkar.csv и kihzsdat.csv, корректная рабочая директория в setwd() и набор пакетов (как минимум neuralnet и ggplot2). Мы сознательно держим зависимости минимальными, чтобы главный фокус был на методе и интерпретации, а не на обвязке.\nЧему вы научитесь и на что обращать внимание. Во‑первых, всегда проверять, что модель решает именно ваш вопрос: чёткая формулировка задачи до выбора алгоритма экономит половину времени. Во‑вторых, всегда показывать эффект и неопределённость: коэффициенты с интервалами, калибровка вероятностей, ошибки прогноза на независимых данных. В‑третьих, всегда сравнивать с простым бейзлайном: если «сеть» не лучше честной регрессии на чистых признаках, значит, проблема не в архитектуре, а в данных или постановке. И да, старайтесь говорить языком биологии: «параметр b близок к 3» — это про объём, «L50 сдвинулся» — про созревание, «AUC высок, но калибровка плывёт» — про надёжность решений на уровне индивидуальных вероятностей.\nНаконец, про дисциплину и воспроизводимость. Фиксируйте seed, документируйте версии пакетов и исходные предположения, храните все промежуточные шаги в скриптах. Это скучно минуту, но экономит дни. И даже когда вы дойдёте до «сетей», помните: сложная модель — это не билет в истину, а всего лишь более гибкий аппроксиматор. Хорошая практика — держать рядом простой, интерпретируемый аналог и объяснять расхождения между ними. Тогда ваши результаты будут не просто «работать», а выдерживать обсуждение с биологами, инженерами и управленцами — то есть приносить пользу за пределами экрана.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter 2.html#введение",
    "href": "chapter 2.html#введение",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "",
    "text": "3.1.0.1 Для работы скрипта:\n\nСкачайте файлы данных (vipkar.csv и kihzsdat.csv)\nУстановите рабочую директорию в setwd()\nУстановите необходимые пакеты : install.packages(c(\"neuralnet\", \"ggplot2\"))\n\n\n# ЗАГРУЗКА БИБЛИОТЕК И НАСТРОЙКА СРЕДЫ ================================\nlibrary(neuralnet)   # Для построения нейронных сетей\nlibrary(ggplot2)     # Для продвинутой визуализации (в данном скрипте не используется напрямую)\n\n# Установите свою рабочую директорию (где лежат файлы данных)\n# setwd(\"C:/ВАША_ДИРЕКТОРИЯ/\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter 2.html#линейная-регрессия",
    "href": "chapter 2.html#линейная-регрессия",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.2 ЛИНЕЙНАЯ РЕГРЕССИЯ",
    "text": "3.2 ЛИНЕЙНАЯ РЕГРЕССИЯ\nВ этом разделе мы изучим основы экологического моделирования на примере зависимости массы тела гадюки от ее длины. Вы построите простую линейную регрессионную модель, визуализируете данные и линию регрессии, а также интерпретируете результаты с помощью функции summary().\nЗагружаем данные\n\n# Данные: масса (w) и длина тела (lt) гадюк (в см и граммах)\nw &lt;- c(85, 90, 85, 95, 95, 135, 165, 135, 140)\nlt &lt;- c(51, 51, 52, 54, 54, 59, 59, 60, 62)\n\nСтроим и запускаем модель \\[\nw_t = a_0 + a_1 \\cdot l_t\n\\]\nгде: - \\(w_t\\) — зависимая переменная, - \\(a_0\\) — свободный член, - \\(a_1\\) — коэффициент регрессии, - \\(l_t\\) — независимая переменная.\n\n# Построение линейной модели: w = a0 + a1*lt\nlreg &lt;- lm(w ~ lt)\n\nВыведем результаты модели\n\n# Просмотр результатов модели:\nsummary(lreg)  # Обратите внимание на коэффициенты и p-значения\n\nНа экране появится:\n\nCall:\nlm(formula = w ~ lt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.452  -7.585  -4.868   1.490  30.623 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -240.766     64.457  -3.735 0.007308 ** \nlt             6.358      1.153   5.516 0.000891 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 13.81 on 7 degrees of freedom\nMultiple R-squared:  0.813,     Adjusted R-squared:  0.7863 \nF-statistic: 30.43 on 1 and 7 DF,  p-value: 0.0008911\n\nМы получили результаты линейной регрессии, где зависимая переменная — масса тела гадюки (w), а независимая переменная — длина тела (lt). Разберем каждый параметр:\n1. **Call (Вызов модели):**\n`lm(formula = w ~ lt)`\nЭто просто напоминание, какая модель была построена. Здесь указано, что мы моделировали зависимость массы (w) от длины тела (lt) с помощью линейной регрессии.\n2. **Residuals (Остатки):**\nОстатки — это разница между наблюдаемыми значениями массы и предсказанными моделью значениями. Они показывают, насколько хорошо модель описывает данные.\n\n`Min`: минимальный остаток = -13.452 (наибольшее недооцененное значение)\n`1Q`: первый квартиль = -7.585 (25% остатков меньше этого значения)\n`Median`: медиана остатков = -4.868 (середина распределения остатков)\n`3Q`: третий квартиль = 1.490 (75% остатков меньше этого значения)\n`Max`: максимальный остаток = 30.623 (наибольшее переоцененное значение)\n\nРаспределение остатков: медиана немного смещена влево (отрицательное значение), а размах между 1Q и 3Q составляет примерно 9 единиц. Это может указывать на легкую асимметрию, но выборка мала.\n3. **Coefficients (Коэффициенты):**\n\n`(Intercept)`: свободный член (a0) = -240.766. Это предсказанное значение массы при длине тела, равной нулю. Биологически это не имеет смысла (длина не может быть нулевой), но это математическая особенность модели.\n`lt`: коэффициент регрессии (a1) = 6.358. Это означает, что при увеличении длины тела на 1 см масса тела увеличивается в среднем на 6.358 г.\n\nДля каждого коэффициента приведены:\n\n`Estimate`: точечная оценка коэффициента.\n`Std. Error`: стандартная ошибка оценки коэффициента. Для intercept = 64.457, для lt = 1.153. Это мера изменчивости оценки.\n`t value`: t-статистика. Рассчитывается как Estimate / Std.Error. Для intercept: -240.766 / 64.457 ≈ -3.735; для lt: 6.358 / 1.153 ≈ 5.516.\n`Pr(&gt;|t|)`: p-значение для проверки гипотезы о равенстве коэффициента нулю.\nДля intercept: p=0.007308 (значим на уровне α=0.01, т.е. intercept статистически значимо отличается от нуля).\nДля lt: p=0.000891 (значим на уровне α=0.001). Это означает, что длина тела значимо влияет на массу.\n\nЗначимость кодов: три звездочки (`***`) означают, что коэффициент значим на уровне 0.001.\n4. **Residual standard error (Стандартная ошибка остатков):** 13.81 на 7 степенях свободы. Это мера разброса остатков. В среднем, предсказания модели отклоняются от реальных значений на ±13.81 г. Степени свободы (df) = n - 2 = 9 - 2 = 7 (n — количество наблюдений).\n5. **Multiple R-squared (Коэффициент детерминации R²):** 0.813. Это означает, что 81.3% вариации массы тела объясняется длиной тела. Остальные 18.7% — это неучтенные факторы и случайная изменчивость.\n6. **Adjusted R-squared (Скорректированный R²):** 0.7863. Этот показатель корректирует R² с учетом числа предикторов. Он полезен при сравнении моделей с разным числом предикторов. Здесь он немного меньше R², так как учитывает, что в модели один предиктор.\n7. **F-statistic (F-статистика):** 30.43 на 1 и 7 степенях свободы. Проверяет гипотезу о том, что все коэффициенты (кроме intercept) равны нулю (т.е. модель не лучше, чем модель только с константой).\n\np-value: 0.0008911 (крайне значимый), что означает, что модель в целом адекватна.\n\n**Выводы:**\n- Уравнение модели: `w = -240.77 + 6.36 * lt`\n- Длина тела значимо влияет на массу (p&lt;0.001).\n- Модель объясняет 81.3% вариации массы.\n- На каждый сантиметр длины тела масса увеличивается примерно на 6.36 г.\n- Остатки модели показывают, что есть несколько точек, которые модель предсказывает с заметной ошибкой (особенно максимальный остаток в 30.6 г). Возможно, для более точного прогноза нужна нелинейная модель или учет дополнительных факторов.\n**Рекомендации:**\n- Проверить допущения линейной регрессии (нормальность остатков, гомоскедастичность) с помощью диагностических графиков.\n- Рассмотреть возможность включения других переменных (например, возраста, пола) в модель.\n- Убедиться, что в данных нет выбросов, которые могут влиять на коэффициенты.\n\n# Визуализация зависимости\nplot(lt, w, \n     main = \"Зависимость массы от длины тела гадюки\", \n     xlab = \"Длина тела (см)\", \n     ylab = \"Масса (г)\", \n     pch = 19,        # Кружки вместо стандартных точек\n     col = \"darkgreen\")\nabline(lreg, col = \"red\", lwd = 2)  # Добавляем линию регрессии\n\n\n\n\nРис. 1.: Пример линейной регрессии",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter 2.html#численная-оптимизация",
    "href": "chapter 2.html#численная-оптимизация",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.3 ЧИСЛЕННАЯ ОПТИМИЗАЦИЯ",
    "text": "3.3 ЧИСЛЕННАЯ ОПТИМИЗАЦИЯ\nЗдесь вы познакомитесь с численными методами оптимизации параметров моделей, которые применяются, когда аналитическое решение невозможно. На примере той же зависимости массы от длины вы подгоните параметры модели с помощью функции nls() и сравните результаты с аналитическим решением.\nАналитические методы дают точное решение в виде математической формулы, используя алгебраические преобразования и теоремы математического анализа. Они идеальны для простых моделей, где существуют явные решения, обеспечивая прозрачную интерпретацию параметров. В экологии такие методы применимы для базовых зависимостей типа линейной регрессии. Численные методы используются, когда аналитическое решение невозможно, и работают через последовательные приближения, начиная со стартовых значений и итеративно улучшая параметры модели. Они незаменимы для сложных экологических моделей с нелинейными зависимостями, взаимодействиями факторов и “шумными” полевыми данными, позволяя решать задачи, недоступные для аналитических подходов.\n\n# Подгонка параметров через оптимизацию\nnls_model &lt;- nls(w ~ a0 + a1 * lt, start = list(a0 = 1, a1 = 1))\nsummary(nls_model)\n\nНа экране появится:\n\nFormula: w ~ a0 + a1 * lt\n\nParameters:\n   Estimate Std. Error t value Pr(&gt;|t|)    \na0 -240.766     64.457  -3.735 0.007308 ** \na1    6.358      1.153   5.516 0.000891 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 13.81 on 7 degrees of freedom\n\nNumber of iterations to convergence: 1 \nAchieved convergence tolerance: 3.247e-08\n\n\n3.3.1 Интерпретация результатов модели\nМы построили линейную модель зависимости массы гадюки (w) от длины её тела (lt) по формуле:\nw = a0 + a1 * lt\nКлючевые параметры модели:\n\na0 (свободный член): -240.8 г\nЭто теоретическая масса при нулевой длине тела. Отрицательное значение указывает, что модель не подходит для очень молодых особей.\na1 (коэффициент при lt): 6.36 г/см\nКаждый дополнительный сантиметр длины тела увеличивает массу в среднем на 6.36 г.\n\nТочность и значимость:\n\nОба коэффициента высоко значимы (p &lt; 0.01), что подтверждает реальность зависимости.\nСтандартная ошибка для a1 составляет 1.15 г/см - это значит, что реальное значение, вероятно, находится между 5.2 и 7.5 г/см.\nМодель хорошо сошлась за 1 шаг (итерацию), что говорит об удачном подборе параметров.\n\nОшибка прогноза:\nСреднее отклонение предсказаний от реальных значений - 13.8 г (стандартная ошибка остатков). Для особи массой 100 г это означает возможную ошибку прогноза около 14%.\n\nБиологический смысл: Модель подтверждает сильную аллометрию - крупные гадюки имеют относительно большую массу тела. Каждый сантиметр длины добавляет около 6.4 г массы. Для особи длиной 55 см прогнозируемая масса составит: -240.8 + 6.36*55 ≈ 109 г.\n\n##МНОЖЕСТВЕННАЯ РЕГРЕССИЯ\nВ этом разделе мы расширим модель, включив несколько факторов. Вы построите множественную регрессию, учитывающую одновременно длину тела и длину хвоста гадюки, и научитесь интерпретировать влияние нескольких предикторов на зависимую переменную.\n\n# Добавляем новый признак - длину хвоста (lc)\nw &lt;- c(40, 156, 105, 85, 80, 50, 75, 48, 75, 67)\nlt &lt;- c(44, 59, 49, 50, 54, 43, 49, 42, 47, 47)\nlc &lt;- c(70, 78, 66, 90, 83, 70, 62, 75, 40, 80)\n\nИспользуя glm-функцию, построим модель с двумя предикторами: \\[\nw = a_0 + a_1 \\cdot l_t + a_2 \\cdot l_c\n\\]\nгде: - \\(w\\) — масса гадюки, - \\(l_t\\) — длина тела гадюки, - \\(l_c\\) — длина хвоста гадюки, - \\(a_0\\) — свободный член (константа), - \\(a_1\\) — коэффициент регрессии при длине тела, - \\(a_2\\) — коэффициент регрессии при длине хвоста.\n\n# Множественная регрессия: w = a0 + a1*lt + a2*lc\nmulti_reg &lt;- glm(w ~ lt + lc)\nsummary(multi_reg)\n\nНа экране появится:\n\nCall:\nglm(formula = w ~ lt + lc)\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -191.2982    53.6908  -3.563 0.009183 ** \nlt             6.0308     1.1051   5.457 0.000949 ***\nlc            -0.3150     0.4133  -0.762 0.470913    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n(Dispersion parameter for gaussian family taken to be 270.9752)\n\n    Null deviance: 10132.9  on 9  degrees of freedom\nResidual deviance:  1896.8  on 7  degrees of freedom\nAIC: 88.832\n\nNumber of Fisher Scoring iterations: 2\n\n\n\n3.3.2 Интерпретация результатов множественной регрессии\nМы исследовали зависимость массы гадюки (w) от длины тела (lt) и длины хвоста (lc) с помощью модели:\nw = b0 + b1*lt + b2*lc\nКлючевые выводы модели:\n\nДлина тела (lt) сильно влияет на массу:\n\nКоэффициент: +6.03 г/см\nКаждый сантиметр длины тела увеличивает массу на ~6 г\nВысокая значимость (p = 0.00095)\n\nДлина хвоста (lc) не влияет значимо на массу:\n\nКоэффициент: -0.315 г/см (незначимый)\np-значение 0.47 &gt; 0.05 - статистически недостоверно\nПосле учета длины тела, длина хвоста не добавляет информации\n\nСвободный член (b0): -191.3 г\nОтрицательное значение подтверждает нелинейность роста у молодых особей\n\nКачество модели:\n\nМодель объясняет значительную часть вариации:\nОбщая вариация (Null deviance) = 10132.9\nОстаточная вариация (Residual deviance) = 1896.8 → Объяснено 81% вариации\nAIC = 88.8 (ниже, чем у модели без lc - 92.1, что указывает на лучшее качество)\nМодель быстро сошлась за 2 итерации\n\nБиологическая интерпретация:\n\nМасса тела определяется в основном длиной туловища, а не хвоста\nДля прогноза массы достаточно учитывать только длину тела\nПример прогноза для особи (lt=50 см, lc=70 см):\n-191.3 + 6.03*50 - 0.315*70 ≈ 111 г\n\n\nРекомендация: При изучении массы гадюк можно исключить длину хвоста из модели, так как она не вносит значимого вклада в предсказание. Основным морфометрическим показателем остается длина тела.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter 2.html#нелинейные-зависимости",
    "href": "chapter 2.html#нелинейные-зависимости",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.4 НЕЛИНЕЙНЫЕ ЗАВИСИМОСТИ",
    "text": "3.4 НЕЛИНЕЙНЫЕ ЗАВИСИМОСТИ\nЭкологические данные часто имеют нелинейный характер. Здесь вы смоделируете степенную зависимость (аллометрию) между массой и длиной тела, используя линеаризацию через логарифмирование, а затем визуализируете кривую модели.\n\n# Часто в экологии связи имеют степенной характер: w = a0 * lt^a1\n# Линеаризация через логарифмирование\nlog_model &lt;- lm(log(w) ~ log(lt))\n\n# Преобразование коэффициентов обратно\na0 &lt;- exp(coef(log_model)[1])  # Переход от логарифмов\na1 &lt;- coef(log_model)[2]       # Показатель степени\n\n# Визуализация степенной зависимости\nplot(lt, w, \n     main = \"Степенная зависимость массы от длины\", \n     xlab = \"Длина тела (см)\", \n     ylab = \"Масса (г)\",\n     pch = 17,\n     col = \"blue\")\ncurve(a0 * x^a1, add = TRUE, col = \"red\", lwd = 2)  # Кривая модели\n\n\n\n\nРис. 2.: Расчет степенной функции",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter 2.html#логистическая-регрессия",
    "href": "chapter 2.html#логистическая-регрессия",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.5 ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ",
    "text": "3.5 ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ\nВы изучите моделирование пороговых эффектов в экологии на примере смертности дафний в зависимости от концентрации токсиканта. Построив логистическую регрессию, вы получите S-образную кривую, характерную для таких процессов.\n\n# Пример: смертность дафний при разных концентрациях токсиканта\n# Данные:\nK &lt;- c(100, 126, 158, 200, 251, 316, 398, 501, 631, 794, 1000)\np &lt;- c(0, 0, 0, 0, 0, 0.5, 0.5, 1, 1, 1, 1)  # Доля погибших\nd &lt;- data.frame(K, p)\n\n# Построение логистической модели\nlogit_model &lt;- glm(p ~ K, family = binomial(), data = d)\n\n# Визуализация S-образной кривой\nplot(d$K, d$p, \n     xlab = \"Концентрация токсиканта (мг/л)\", \n     ylab = \"Доля погибших\", \n     main = \"Токсическое воздействие на дафний\",\n     pch = 19,\n     col = \"red\")\nlines(d$K, predict(logit_model, type = \"response\"), \n      col = \"blue\", lwd = 2, lty = 1)\n\n\n\n\nРис. 3.: Расчет логистической регрессии гибели дафний в токсиканте",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter 2.html#переход-к-сетям",
    "href": "chapter 2.html#переход-к-сетям",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.6 ПЕРЕХОД К СЕТЯМ",
    "text": "3.6 ПЕРЕХОД К СЕТЯМ\nСделаем первый шаг к нейронным сетям, построив простейшую сеть без скрытых слоев (аналог линейной регрессии) для модели токсичности. Вы визуализируете структуру сети и убедитесь, что она дает результат, аналогичный линейной модели.\n\n# Простейшая нейросеть (аналог линейной регрессии)\nnn_simple &lt;- neuralnet(p ~ K, data = d, hidden = 0)\n\n# Визуализация структуры сети\nplot(nn_simple, rep = \"best\")\n\n\n\n\nРис. 4.: Схема нейрона",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter 2.html#нейроны-как-нелинейные-преобразователи",
    "href": "chapter 2.html#нейроны-как-нелинейные-преобразователи",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.7 НЕЙРОНЫ КАК НЕЛИНЕЙНЫЕ ПРЕОБРАЗОВАТЕЛИ",
    "text": "3.7 НЕЙРОНЫ КАК НЕЛИНЕЙНЫЕ ПРЕОБРАЗОВАТЕЛИ\nЗдесь вы добавите в нейронную сеть скрытый слой с одним нейроном, что позволит моделировать нелинейные зависимости. Вы сравните результат работы такой сети с логистической регрессией и увидите, как нейронная сеть имитирует пороговый эффект.\n\n# Сеть с одним скрытым нейроном (имитирует логистическую регрессию)\nnn_1hidden &lt;- neuralnet(p ~ K, data = d, hidden = 1)\n\n# Сравнение с логистической регрессией\nplot(d$K, predict(logit_model, type = \"response\"), \n     type = \"l\", \n     col = \"darkgreen\", \n     lwd = 2,\n     xlab = \"Концентрация\", \n     ylab = \"Смертность\",\n     main = \"Сравнение моделей\")\nlines(d$K, predict(nn_1hidden, d), col = \"blue\", lty = 2, lwd = 2)\nlegend(\"bottomright\", \n       legend = c(\"Логистическая регрессия\", \"Нейронная сеть (1 нейрон)\"),\n       col = c(\"darkgreen\", \"blue\"), \n       lty = 1:2,\n       lwd = 2)\n\n\n\n\nРис. 5.: Сравнение работы",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter 2.html#классификация-в-экологии",
    "href": "chapter 2.html#классификация-в-экологии",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.8 КЛАССИФИКАЦИЯ В ЭКОЛОГИИ",
    "text": "3.8 КЛАССИФИКАЦИЯ В ЭКОЛОГИИ\nВы примените нейронные сети для решения задачи классификации - определения пола гадюк по морфометрическим признакам. Построив и сравнив несколько архитектур сетей (без скрытых нейронов, с одним и тремя нейронами), вы оцените их точность.\n\n# Загрузка данных по гадюкам (пол, длина тела, длина хвоста, масса)\nv &lt;- read.csv(\"vipkar.csv\")\nhead(v, 3)  # Просмотр первых строк данных\n\nМодель без скрытых нейронов (аналог линейной регрессии)\n\nnv0 &lt;- neuralnet(ns ~ lc, data = v, hidden = 0)\nplot(nv0)  # Визуализация простейшей сети\n\n\n\n\nРис. 6.: Визуализация простейшей сети\n\n\nМодель с одним скрытым нейроном\n\nnv1 &lt;- neuralnet(ns ~ lc, data = v, hidden = 1)\nplot(nv1)  # Схема сети с одним нейроном\n\n\n\n\nРис. 7.: Схема сети с одним нейроном\n\n\nМодель с тремя скрытыми нейронами (полноценная нейросеть)\n\nnv3 &lt;- neuralnet(ns ~ lc + lt + w, data = v, hidden = 3)\nplot(nv3)  # Визуализация сложной сети\n\n\n\n\nРис. 8.: Модель с тремя скрытыми нейронами\n\n\nОценка точности классификации\n\npredictions &lt;- predict(nv3, v)\npredicted_sex &lt;- round(predictions)\naccuracy &lt;- mean(v$ns == predicted_sex)\ncat(\"Точность классификации:\", round(accuracy*100, 1), \"%\\n\")\n\nСравнение разных архитектур нейронных сетей (см. срипт KOROSOV_visual.R)\n\n\n\nРис. 9.: Точность определения пола гадюк",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter 2.html#пространственное-моделирование",
    "href": "chapter 2.html#пространственное-моделирование",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.9 ПРОСТРАНСТВЕННОЕ МОДЕЛИРОВАНИЕ",
    "text": "3.9 ПРОСТРАНСТВЕННОЕ МОДЕЛИРОВАНИЕ\nВ завершение вы построите нейронную сеть для прогнозирования численности гадюк на островах по характеристикам биотопов. Вы разделите данные на обучающую и тестовую выборки, оцените точность модели и используете ее для прогноза в новых условиях.\n\n# Данные по островам Кижского архипелага\nv &lt;- read.csv(\"kihzsdat.csv\")\nhead(v, 3)  # Структура данных: площадь, биотопы, численность видов\n\n# Случайное разделение данных на обучающую и тестовую выборки\nset.seed(123)  # Для воспроизводимости\ntrain_indices &lt;- sample(1:nrow(v), 12)\ntrain_data &lt;- v[train_indices, ]\ntest_data &lt;- v[-train_indices, ]\n\n# Построение нейросети с 5 нейронами в скрытом слое\nmodel &lt;- neuralnet(vb ~ fo + me + bo, data = train_data, hidden = 5)\n\n# Прогнозирование на обучающей выборке\ntrain_pred &lt;- predict(model, train_data)\ntrain_accuracy &lt;- mean(round(train_pred) == train_data$vb)\ncat(\"Точность на обучающей выборке:\", round(train_accuracy*100, 1), \"%\\n\")\n\n# Прогнозирование на тестовой выборке\ntest_pred &lt;- predict(model, test_data)\ntest_accuracy &lt;- mean(round(test_pred) == test_data$vb)\ncat(\"Точность на тестовой выборке:\", round(test_accuracy*100, 1), \"%\\n\")\n\n# Прогноз для новых условий (пример)\nnew_conditions &lt;- data.frame(\n  fo = c(57.9, 35.3, 83.0),  # Площадь лесов (%)\n  me = c(4.1, 0.0, 7.3),     # Площадь лугов (%)\n  bo = c(3.4, 7.9, 11.5)     # Площадь болот (%)\n)\n\nfuture_pred &lt;- predict(model, new_conditions)\ncat(\"Прогнозируемая численность гадюк:\", round(future_pred), \"\\n\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  }
]
[
  {
    "objectID": "chapter16.html",
    "href": "chapter16.html",
    "title": "17  I. DLM: Введение в методы анализа при очень ограниченных данных",
    "section": "",
    "text": "17.1 Анализ результатов применения метода Catch-MSY: между надеждой и статистической реальностью\nЭто занятие открывает серию практик о так называемых “немодельных”, как написано в некоторых методиках, подходах, которые в англоязычной литературе принято называть DLM. Это занятие вводное - возьмем cамый простой метод и прогоним весь цикл. Data-Limited Methods (DLM) — это не просто статистические подходы, а скорее философия работы в условиях неопределенности. Если классические методы оценки запасов требуют многолетних рядов данных, детальной информации о возрасте, размерах, промысловом усилии и прочих параметрах, то DLM предлагают прагматические решения для ситуаций, когда единственное, что у вас есть — это данные об уловах. И да, такое бывает чаще, чем кажется.\nПредставьте себе типичную ситуацию: новый объект промысла, развивающийся рыболовный регион, или просто вид, который никогда не был приоритетом для исследований. Данные об уловах есть — их собирают всегда. А вот биологические параметры, индексы численности, данные научных съемок — это уже из области фантастики. Именно в таких условиях DLM становятся не просто удобным инструментом, а единственным способом хоть как-то оценить состояние запаса.\nСреди множества DLM-методов особое место занимает Catch-MSY — подход, который позволяет оценить максимальный устойчивый вылов (MSY) на основе одних только данных об уловах. Метод основан на простой, но гениальной идее: если мы знаем историю промысла, мы можем методом подбора найти такие комбинации параметров роста популяции (r и K), которые объясняют наблюдаемую динамику уловов и при этом биологически реалистичны.\nКонечно, у этого метода есть ограничения. Он предполагает, что популяция следует логистической модели роста, что промысел был основным фактором смертности, и что мы можем разумно ограничить диапазоны параметров *r** и K. Но как говорится, в условиях слепоты и одноглазый — король.\nЧто особенно важно — Catch-MSY не просто дает точечную оценку MSY, но и обеспечивает распределение вероятностей различных значений, что позволяет оценить неопределенность. Это важно для управления рисками.\nПереход от оценки к управлению — это отдельная история. Полученные оценки MSY становятся основой для разработки правил управления (Harvest Control Rules), которые определяют, как следует изменять уровень изъятия в зависимости от состояния запаса. А уже эти правила тестируются в рамках Management Strategy Evaluation (MSE) — своеобразного полигона, где мы проверяем, как различные стратегии управления будут работать в условиях неопределенности.\nКурьезность ситуации заключается в том, что несмотря на то, что мы используем чрезвычайно простые методы для оценки, процесс управления становится все более сложным. Но это именно тот случай, когда сложность оправдана — ведь на кону устойчивость промысла и сохранение ресурсов.\nИрония судьбы: методы, разработанные для условий недостатка данных, часто оказываются более робастны (устойчивы), чем их сложные собратья, требующие тонны информации. Просто потому что они “осознают” неопределенность, а не делают вид, что ее не существует.\nВ следующих лекциях мы перейдем от теории к практике и посмотрим, как эти методы работают на реальных данных. Приготовьтесь к приятным сюрпризам.\nЧто ж, давайте посмотрим, что у нас получилось в результате выполнения этого скрипта. Картина вырисовывается интересная, хотя и не без типичных для DLM сюрпризов.\nНачнем с того, что наш метод Catch-MSY отработал как швейцарские часы — если, конечно, считать нормальным тот факт, что из 100000 итераций у нас осталось всего несколько тысяч жизнеспособных комбинаций параметров. Но это как раз и есть философия метода: мы не пытаемся найти единственно верное решение, а отбираем все биологически возможные сценарии.\nПолученные оценки параметров говорят сами за себя. Коэффициент роста r со средним значением 0.14 — это вполне типично для многих промысловых видов. Хотя, если быть до конца честным, разброс значений от 0.01 до 1.5 и стандартное отклонение 0.13 намекают, что наша уверенность в этом параметре несколько преувеличена.\nЕмкость среды K оказалась в районе 555 тысяч тонн в среднем, что при медианном MSY в 13 тысяч тонн дает нам примерное представление о потенциале запаса. Любопытно, что медианное значение MSY практически совпадает со средним — 13.08 против 12.75 тысяч тонн, что намекает на относительно симметричное распределение.\nА теперь самое интересное — текущий статус запаса. Средний вылов за последние три года составляет 12 тысяч тонн против оцененного MSY в 13.08. Отношение 0.92 — это тот самый момент, когда начинается настоящая игра в рулетку управления. Формально мы еще не превысили MSY, но мы уже в опасной близости от границы.\nНо настоящий сюрприз ждал нас в оценке “деплетированности”. Медианное значение 3.13 — это, конечно, статистический нонсенс. Биомасса не может превышать емкость среды, если только мы не открыли новый закон популяционной динамики. Этот артефакт — классический пример ограничений метода Catch-MSY, когда при определенных комбинациях параметров модель выдает биологически невозможные значения.\nОриентиры управления выглядят более-менее разумно: MSY 13.08 тыс. тонн, Bmsy 243.8 тыс. тонн, Fmsy 0.048. Последнее значение особенно интересно — оно предполагает, что оптимальный уровень изъятия составляет около 5% от биомассы.\nИмитационное моделирование управления показало, что при использовании предложенного правлила регулирования промысла (ПРП) средний вылов колеблется от 8 до 14 тысяч тонн в зависимости от начальных условий. Что характерно, даже в наихудших сценариях запас не коллапсирует — система управления оказывается достаточно устойчивой.\nГрафики траекторий биомассы и вылова — это настоящая поэма в данных. Мы видим, как различные сценарии сходятся к устойчивому состоянию около Bmsy, что собственно и является целью управления. Хотя некоторые симуляции показывают излишне консервативные подходы с выловом ниже потенциально возможного.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>I. DLM: Введение в методы анализа при очень ограниченных данных</span>"
    ]
  },
  {
    "objectID": "chapter16.html#заключение-между-статистикой-и-управленческой-реальностью",
    "href": "chapter16.html#заключение-между-статистикой-и-управленческой-реальностью",
    "title": "17  I. DLM: Введение в методы анализа при очень ограниченных данных",
    "section": "17.2 Заключение: между статистикой и управленческой реальностью",
    "text": "17.2 Заключение: между статистикой и управленческой реальностью\nПо итогам анализа можно сказать, что мы получили ровно то, что ожидали от метода Catch-MSY — ориентировочные оценки с изрядной долей неопределенности. MSY в районе 13 тысяч тонн выглядит разумной оценкой, учитывая историю промысла.\nТекущий уровень вылова в 12 тысяч тонн — это тот самый момент, когда управляющим органам пора начинать тревожно задумываться. Мы еще не превысили лимит, но мы уже близки к той грани, где любое дополнительное давление может привести к перелову.\nРекомендация установить OДУ в диапазоне 10.5-13 тысяч тонн — это не проявление излишней осторожности, а единственно разумный подход в условиях высокой неопределенности.\nМетод Catch-MSY в очередной раз доказал свою полезность как инструмент “первого приближения”. Он не дает нам точных оценок, но предоставляет достаточно информации для принятия взвешенных управленческих решений.\nИрония ситуации заключается в том, что чем меньше у нас данных, тем более сложные методы мы вынуждены использовать для их интерпретации. Но как показывает практика, иногда простые решения, основанные на ограниченной информации, оказываются более эффективными, чем сложные модели, требующие тонны данных.\nВ конечном счете, управление рыболовством — это не о поиске идеальных решений, а о выборе наименее плохих из доступных вариантов. И в этом смысле Catch-MSY предоставляет нам именно то, что нужно — достаточно информации, чтобы сделать этот выбор осознанно.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>I. DLM: Введение в методы анализа при очень ограниченных данных</span>"
    ]
  },
  {
    "objectID": "chapter5.html",
    "href": "chapter5.html",
    "title": "6  Продукционная модель SPiCT",
    "section": "",
    "text": "6.1 Введение\nВводное занятие по SPiCT’у, которое основаго на рекомендованом к изучению обзоре, составленным разработчиками библиотеке. Однако в этом репозитории (см.боковую вкладку оглавления) есть еще триптих скриптов, посвященных SPiCT’у, включающих отдельную оценку ОДУ, ПРП и MSE (оценки стратегии управления).И так, далее лирическое введение…\nЭто практическое занятие — приглашение работать с неопределённостью честно и профессионально. Мы будем оценивать запас промыслового вида с помощью SPiCT — стохастической продукционной модели в байесовской постановке. В терминах Даниэля Канемана: мы осознанно переводим себя из «быстрой» Системы 1 (интуиции и красивых историй) в «медленную» Систему 2 (проверяемые допущения, приоры, диагностика, сценарии).\nЗачем SPiCT и почему именно такой подход. SPiCT реализует стохастическую продукционную динамику (обобщение Шефера/Пеллы–Томлинсона) и оценивает параметры через TMB* в байесовской парадигме. Это важно по трём причинам. Во‑первых, реальный улов и индексы шумные, с нулями, с передисперсией; стохастическая модель учитывает процессные и наблюдательные ошибки, а не прячет их в остатки. Во‑вторых, байесовские прайеры (или приоры) — не «псевдонаучные пожелания», а протокол того, что мы готовы считать правдоподобным до данных: n≈2 (Шефер), разумный диапазон K, начальная доля B/K. Прайеры делают оценку стабильной при слабых данных и позволяют явно «рассказать» модели, что мы знаем из биологии. В‑третьих, пакет построен вокруг воспроизводимой диагностики: OSA‑остатки, автокорреляция, сравнение априор/апостериор, ретроспектива (коэффициент Мона), сценарии управления — это инструменты, уменьшающие риск когнитивных ловушек.\nПро честные допущения и минимализм. «Простые» объяснения предпочтительнее при прочих равных, пока они работают. Мы не перегружаем модель лишними степенями свободы: фиксируем n=2, задаём информативные прайеры на K и начальную долю B/K, аккуратно масштабируем неопределённость последних лет (не наделяя «свежие» данные ролью окончательных вердиктов), используем малый шаг интегрирования dteuler для корректной динамики. Ричард Докинз сказал бы: эволюция — это про ограничения и компромиссы; продукционная модель — тоже. Она не объясняет всё, но хорошо решает задачу «сколько можем брать и оставаться в зелёной зоне» при ограниченной информации.\nКак держать под контролем наши ошибки мышления. Ведь мозг любит «истории с концом», даже если данных мало. Мы противопоставляем этому протокол. Сначала — валидируем входные ряды (catch и индексы, лаги и кросс‑корреляции), затем — формируем единый вход SPiCT с явным календарём измерений (timeI и obsI), задаём прайеры и повышаем неопределённость там, где это честно (последние годы). Дальше — диагностика: OSA‑остатки без смещения и избыточной автокорреляции, нормальность на QQ‑плотах, сравнение априора и апостериора (данные «говорят», или всё держится на прайере?), корреляции параметров (типичная антагония K и q — не баг, а свойство задачи), ретроспектива Мона (устойчивость оценок к добавлению новых лет). Это «канемановская» дисциплина: мы строим защитные барьеры от своей уверенности.\nПро риск и «толстые хвосты». Напомним, что средние — коварны. Даже если B/BMSY&gt;1 и F/FMSY&lt;1, управленческие правила должны учитывать ширину доверительных интервалов, а не только точку. Поэтому мы интерпретируем не одну кривую, а пучок сценариев: «держать текущий вылов», «держать текущий F», «ловить на FMSY», «снизить/увеличить F», «хоккейная клюшка», «ICES‑правило», фиксированные квоты. И для каждого — не только прогноз B и F, но и риск превышения FMSY и ухода ниже BMSY. Хорошая рекомендация — это баланс «надёжности» и «пользы»: консервативный вылов, сохраняющий B/BMSY&gt;1.2 при низкой вероятности перелова, часто выигрывает у агрессивных схем, которые «в среднем» немного выгоднее, но делают систему хрупкой.\nКак читать результаты и не обмануться. Сходимость (convergence=0) и финитные стандартные ошибки — допуск к интерпретации. OSA‑диагностика без смещения и лишней автокорреляции — индикатор адекватности структуры ошибок. Разумный K (с учётом прайера), r в биологическом диапазоне, q1–q2 сопоставимые для CPUE/BESS — признак «реалистичности». Если апостериор на K почти совпадает с прайером — не беда, это честный сигнал: данных мало, рекомендацию стоит «страховать» широкой лентой и консервативным сценарием. Если ковариации параметров велики — не прячем, а подчёркиваем в выводах. Если ретроспектива показывает |ρ| близко к нулю — модель устойчива; если нет — упрощаем, усиливаем приоры, перепроверяем данные.\nПро «матчасть» и воспроизводимость. SPiCT — это не только fit.spict(), а экосистема справок (?check.inp, ?fit.spict), кратких обзоров и живого «технического» руководства. Мы сохраняем код, версии пакетов, начальные значения и приоры внутри скрипта — так, чтобы завтра любой исследователь смог повторить наши оценки. Это и есть “антихрупкость” : система, которая выигрывает от проверок и критики. И это способ строить доверие в сообществе — не за счёт красноречия, а за счёт прозрачности.\nЧто вы освоите по итогам занятия. 1) Подготовку входов: единая шкала времени, лаги индексов, кросс‑корреляции. 2) Настройку прайеров и их роль при ограниченных данных. 3) Запуск и диагностику модели: от конвергенции до OSA и ретроспективы. 4) Чтение ключевых ориентиров (MSY, BMSY, FMSY, B/BMSY, F/FMSY) и их неопределённости. 5) Формирование и интерпретацию сценариев управления с учётом риска, а не только «лучшей точки». 6) Коммуникацию результатов для управленцев: одна картинка «Kobe plot», одна таблица сценариев, одна короткая формулировка рекомендации с оговорками и предпосылками.\nИ главное — стиль мышления. Мы будем вспоминать Сапольского, когда захочется превратить «красивую» картинку в факт; Канемана — когда рука потянется «довернуть» модель до нужного ответа; Талеба — когда нужно выбирать между «чуть больше сейчас» и «устойчиво много лет»; Хокинга — когда стоит убрать лишнюю сложность; Докинза — когда интерпретируем параметры через процессы; Харари — когда формируем честный и открытый нарратив о том, что модель знает и чего не знает. Такой образ действий превращает SPiCT из «чёрного ящика» в дисциплину: воспроизводимый, устойчивый и полезный для принятия решений анализ.\nИ так, библиотека SPiCT https://github.com/DTUAqua/spict - оценка запаса с помощью стохастической версии продукционной модели и байесовского подхода. Доступен краткий обзор пакета здесь, который служит для ознакомления с пакетом и его функционалом. В обзоре также содержится описание более продвинутых функций пакета.\nДокумент с техническими рекомендациями по использованию SPiCT доступен здесь . Это постоянно обновляемый документ.\nПакет также содержит достаточно подробную документацию в виде справочных текстов, связанных с каждой функцией (некоторые из них могут быть не полностью актуальны). Доступ к ним можно получить обычным для R способом, набрав, например ?check.inp, . Для начала (помимо изучения краткого обзора) рекомендуется прочитать ?check.inpи ?fit.spict.\n* - TMB (Template Model Builder)— это специализированный пакет для языка R, предназначенный для эффективной оценки параметров сложных нелинейных статистических моделей, часто используемых в экологии и fisheries science. Он позволяет реализовать байесовский вывод, автоматически вычисляя производные и правдоподобие для сложных моделей, что значительно ускоряет расчёты и делает возможной работу с многомерными задачами, такими как оценка запасов с помощью SPiCT.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Продукционная модель SPiCT</span>"
    ]
  },
  {
    "objectID": "chapter5.html#установка-пакетов-и-загрузка-данных",
    "href": "chapter5.html#установка-пакетов-и-загрузка-данных",
    "title": "6  Продукционная модель SPiCT",
    "section": "6.2 Установка пакетов и Загрузка данных",
    "text": "6.2 Установка пакетов и Загрузка данных\nПолный скрипт находится по ссылке\n\n# ------------------------- 1. ПОДГОТОВКА СРЕДЫ ---------------------------\n\n## 1.1 Установка пакетов (выполнить один раз)\n# install.packages(\"tidyverse\")\n#remotes::install_github(\"DTUAqua/spict/spict\") # Установка SPiCT\n#install.packages(\"TMB\", type=\"source\")\n\n## 1.2 Загрузка библиотек\nlibrary(spict)   # Основной пакет для моделирования\nlibrary(tidyverse) # Для обработки данных и визуализации\n\n\n## 1.3 Установка рабочей директории\nsetwd(\"C:/SPICT\") # Укажите вашу рабочую папку\n\n\n# ------------------------- 2. ЗАГРУЗКА ДАННЫХ ---------------------------\n\n## 2.1 Вектор лет наблюдений\nYear &lt;- 2005:2024\n\n## 2.2 Данные по вылову (тыс. тонн)\nCatch &lt;- c(5,  7,  6, 10, 14, 25, 28, 30, 32, 35, 25, 20, 15, 12, 10, 12, 10, 13, 11, 12)\n\n## 2.3 Индекс CPUE (промысловый индекс)\nCPUEIndex &lt;- c(27.427120, 26.775958, 16.811997, 22.979653, 29.048568, 29.996072, 16.476301,\n17.174455, 10.537272, 14.590435,  8.286352, 11.394168, 15.537878, 13.791166,\n11.527548, 15.336093, 12.154069, 15.568450, 16.221933, 13.421132)\n\n## 2.4 Индекс BESS (научная съемка)\nBESSIndex &lt;- c( NA, 16.270375, 20.691355, 15.141784, 18.594620, 15.975548, 13.792012,\n13.328805, 11.659744, 11.753855,  9.309859,  7.104886,  7.963839,  9.161322,\n10.271221,  9.822960, 10.347376, 11.703610, 13.679876, 13.413696)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Продукционная модель SPiCT</span>"
    ]
  },
  {
    "objectID": "chapter5.html#кросс-корреляции-с-временным-лагом-между-индексами-и-уловами",
    "href": "chapter5.html#кросс-корреляции-с-временным-лагом-между-индексами-и-уловами",
    "title": "6  Продукционная модель SPiCT",
    "section": "6.3 Кросс-корреляции с временным лагом между индексами и уловами",
    "text": "6.3 Кросс-корреляции с временным лагом между индексами и уловами\n\n# График кросс-корреляции: Catch и BESSindex (только данные без пропусков)\nccf(na.omit(Catch), na.omit(BESSIndex),\n    main = \"Кросс-корреляция: Уловы и BESSindex\",\n    xlab = \"Лаг (годы)\", ylab = \"Корреляция\")\n\n\n# График кросс-корреляции: Catch и CPUEIndex (только данные без пропусков)\nccf(na.omit(Catch), na.omit(CPUEIndex),\n    main = \"Кросс-корреляция: Уловы и CPUEIndex\",\n    xlab = \"Лаг (годы)\", ylab = \"Корреляция\")\n\n\n\n\nРис. 1.: График кросс-корреляции: Catch и BESSindex\n\n\n\n\n\nРис. 2.: График кросс-корреляции: Catch и CPUEIndex",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Продукционная модель SPiCT</span>"
    ]
  },
  {
    "objectID": "chapter5.html#подготовка-данных-для-spict",
    "href": "chapter5.html#подготовка-данных-для-spict",
    "title": "6  Продукционная модель SPiCT",
    "section": "6.4 Подготовка данных для SPiCT",
    "text": "6.4 Подготовка данных для SPiCT\n\n## 3.1 Форматирование данных в список SPiCT\ninput_new &lt;- list(\n  timeC = Year,     # Годы вылова\n  obsC = Catch,     # Значения вылова\n  timeI = list(     # Временные точки для индексов:\n    Year + 0.5,     #  CPUE - середина года (июль)\n    Year + 0.75     #  BESS - 3/4 года (октябрь)\n  ),\n  obsI = list(\n    CPUEIndex,      # Значения индекса CPUE\n    BESSIndex       # Значения индекса BESS\n  )\n)\n\n## 3.2 Проверка и подготовка входных данных\ninp &lt;- check.inp(input_new, verbose = TRUE)\n\nФункция check.inp() выполняет подготовку и валидацию входных данных перед моделированием. Основные задачи функции:\nПроверяет наличие обязательных элементов: timeC (временные точки вылова), obsC (значения вылова). Проверяет соответствие индексов (timeI и obsI): одинаковое количество элементов в списках, соответствие длин временных рядов. Обработка пропущенных значений. Автоматически обрабатывает NA в начале вектора CPUEIndex (2005-2010). Удаляет или маркирует пропущенные значения в соответствии с настройками пакета и пр.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Продукционная модель SPiCT</span>"
    ]
  },
  {
    "objectID": "chapter5.html#настройка-модели",
    "href": "chapter5.html#настройка-модели",
    "title": "6  Продукционная модель SPiCT",
    "section": "6.5 Настройка модели",
    "text": "6.5 Настройка модели\n\n# ------------------- 4. НАСТРОЙКА МОДЕЛИ --------------------\n\n## 4.1 Установка априорных распределений\ninp$priors$logn &lt;- c(log(2), 0.1, 1)   # Прайер для n (модель Шефера)\ninp$ini$logn &lt;- log(2)                  # Начальное значение\ninp$phases$logn &lt;- -1                   # Фиксируем параметр (не оцениваем)\n\ninp$priors$logK &lt;- c(5, 0.7, 1)       # Прайер для емкости среды (K)\ninp$priors$logbkfrac &lt;- c(log(0.75),0.25,1) # Начальный уровень эксплуатации\n\n\n\n## 4.2 Настройка неопределенности данных\n# Повышаем неопределенность для последнего года вылова\ninp$stdevfacC[length(inp$stdevfacC)] &lt;- 2 \n\n# Повышаем неопределенность для последнего значения BESS\ninp$stdevfacI[[2]][length(inp$stdevfacI[[2]])] &lt;- 2 \n\n## 4.3 Настройка временного шага\ninp$dteuler &lt;- 1/16  # Более точная дискретизация (по умолчанию 1)\n\n## 4.4 Включение оценки ковариации\ninp$getJointPrecision &lt;- TRUE # Для оценки случайных эффектов\n\nУстановка априорных распределений\ninp$priors$logn &lt;- c(log(2), 0.1, 1) inp$ini$logn &lt;- log(2) inp$phases$logn &lt;- -1\n\nПрайер для параметра n: Устанавливаем лог-нормальное распределение для экспоненты в продукционном уравнении, фиксируя модель Шефера (n=2).\nНачальное значение: Задаем стартовую точку для оптимизации как log(2), что соответствует n=2.\nФиксация параметра: Флаг -1 исключает n из оценки, делая его константой (упрощает модель).\nБиологический смысл: Обеспечивает реалистичную форму кривой производства (параболическую).\n\ninp$priors$logK &lt;- c(5, 0.7, 1)\n\nПрайер для ёмкости среды: Задаем лог-нормальное распределение для K.\nПараметры: Медиана exp(5)≈148 тыс.т, SD=0.7 в лог-шкале.\nЗначение 1: Активирует использование прайера в расчетах.\nНазначение: Отражает экспертные знания о возможном диапазоне K.\n\ninp$priors$logbkfrac &lt;- c(log(0.75),0.25,1)\n\nПриор для начальной биомассы: Определяет распределение для B₀/K.\nПараметры: Медиана 0.75 (начальная биомасса 75% от K), SD=0.25.\nБиологический смысл: Отражает гипотезу, что запас изначально был близок к неиспользуемому.\nВажность: Помогает оценить начальные условия при ограниченных данных.\n\nНастройка неопределенности данных\ninp$stdevfacC[length(inp$stdevfacC)] &lt;- 2\n\nЦель: Увеличить неопределенность последнего года вылова.\nЗначение 2: Стандартная ошибка увеличивается вдвое.\nПричина: Последние данные часто предварительные или неполные.\nЭффект: Снижает влияние потенциально ненадежной точки на оценку запаса.\n\ninp$stdevfacI[[2]][length(inp$stdevfacI[[2]])] &lt;- 2\n\nЦель: Повысить неопределенность последнего значения научного индекса (BESS).\nСинтаксис: [[2]] указывает на второй индекс в списке.\nОбоснование: Данные съемок могут требовать последующих корректировок.\nРезультат: Модель становится менее чувствительной к потенциальным аномалиям.\n\nНастройка временного шага\ninp$dteuler &lt;- 1/16\n\nЦель: Улучшить точность численного интегрирования.\nЗначение: Шаг расчета ≈23 дня (вместо годового).\nНеобходимость: Для короткоживущих видов (н-р, креветка) с быстрой динамикой.\nЭффект: Точнее учитывает внутригодовые изменения и сезонность.\nЦена: Увеличивает время расчета в 3-5 раз.\n\nВключение оценки ковариации\ninp$getJointPrecision &lt;- TRUE\n\nЦель: Рассчитать полную ковариационную матрицу параметров.\nНеобходимость: Для корректной оценки неопределенности производных показателей (B/BMSY).\nЧто делает: Учитывает взаимосвязи между параметрами и скрытыми состояниями.\nПреимущество: Более реалистичные доверительные интервалы.\nОграничение: Увеличивает время расчета на 20-30%.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Продукционная модель SPiCT</span>"
    ]
  },
  {
    "objectID": "chapter5.html#визуализация-входных-данных",
    "href": "chapter5.html#визуализация-входных-данных",
    "title": "6  Продукционная модель SPiCT",
    "section": "6.6 Визуализация входных данных",
    "text": "6.6 Визуализация входных данных\n\n# ----------------- 5. ВИЗУАЛИЗАЦИЯ ВХОДНЫХ ДАННЫХ -----------------\n\n## 5.1 Общий график данных\nplotspict.data(inp)\n\nplotspict.ci(inp)\n\n\n\n\nРис. 3.: Визуализация входных данных",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Продукционная модель SPiCT</span>"
    ]
  },
  {
    "objectID": "chapter5.html#запуск-модели",
    "href": "chapter5.html#запуск-модели",
    "title": "6  Продукционная модель SPiCT",
    "section": "6.7 Запуск модели",
    "text": "6.7 Запуск модели\n\n# ------------------- 6. ЗАПУСК МОДЕЛИ --------------------\n\n## 6.1 Настройка оптимизатора\ninp$optimiser.control = list(iter.max = 1e5, eval.max = 1e5)\n\n## 6.2 Подгонка модели\nfit &lt;- fit.spict(inp)\n\n## 6.3 Добавление OSA-остатков\nfit &lt;- calc.osa.resid(fit) \n\nНастройка оптимизатора\ninp$optimiser.control = list(iter.max = 1e5, eval.max = 1e5)\nЧто это делает:\n\nУвеличивает максимальное количество итераций (iter.max) и вычислений (eval.max) для алгоритма оптимизации до 100,000\nОбеспечивает, что процесс оптимизации не остановится преждевременно из-за ограничений по умолчанию\nОсобенно важно для сложных моделей с несколькими индексами или при плохой сходимости\nПомогает алгоритму найти глобальный минимум функции правдоподобия\nПредотвращает ошибки типа “maximum iterations reached”\n\nПодгонка модели\nfit &lt;- fit.spict(inp)\nЧто происходит:\n\nОценка параметров: Ищет значения параметров (K, r, q и др.), максимизирующие правдоподобие\nИнтегрирование уравнений: Решает дифференциальные уравнения модели с шагом dteuler\nРасчет неопределенности: Оценивает стандартные ошибки через обратную матрицу Гессе\nДиагностика сходимости: Проверяет успешность оптимизации (fit$opt$convergence)\nСохраняет результаты: Формирует объект fit со всеми выходами модели\n\nКлючевые процессы:\n\nЧисленная оптимизация (обычно алгоритм nlminb)\nИнтегрирование методом Эйлера\nРасчет логарифмического правдоподобия\nОценка матрицы Гессе\n\nOSA-остатки\nfit &lt;- calc.osa.resid(fit)\nЧто такое OSA-остатки:\n\nOne-Step-Ahead residuals - остатки “на один шаг вперед”\nДиагностический инструмент: Показывают, насколько хорошо модель предсказывает следующее наблюдение\nРасчет: Для каждого года t модель подгоняется по данным до t-1, затем сравнивается предсказание с фактическим значением в t\n\nЧто делают:\n\nОбнаружение систематических ошибок: Выявляют смещения в предсказаниях\nПроверка независимости: Автокорреляция в остатках указывает на неучтенные зависимости\nОценка распределения ошибок: Проверяют соответствие нормальному распределению\nИдентификация выбросов: Помогают найти аномальные точки данных",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Продукционная модель SPiCT</span>"
    ]
  },
  {
    "objectID": "chapter5.html#диагностика-сходимости",
    "href": "chapter5.html#диагностика-сходимости",
    "title": "6  Продукционная модель SPiCT",
    "section": "6.8 Диагностика сходимости",
    "text": "6.8 Диагностика сходимости\n\n# ----------------- 7. ДИАГНОСТИКА СХОДИМОСТИ -----------------\n\n## 7.1 Проверка сходимости\nfit$opt$convergence  # 0 = успешная сходимость\n\n## 7.2 Проверка конечных значений\nall(is.finite(fit$sd)) # TRUE = все параметры конечны\n\nДиагностика сходимости модели SPiCT\nПроверка сходимости (7.1)\nfit$opt$convergence — индикатор успешности оптимизации. Возвращаемое значение 0 означает, что алгоритм оптимизации успешно сошелся к точке максимума правдоподобия. Это важно, так как гарантирует:\n\nПараметры модели достигли стабильных значений\nГрадиент функции правдоподобия близок к нулю\nРезультаты статистически надежны\nМодель готова для дальнейшего анализа и прогнозирования\n\nИнтерпретация кодов:\n\n0: Успешная сходимость (идеальный результат)\n1: Достигнут лимит итераций (требует увеличения iter.max)\n10: Дегенерация симплекса (проблемы с данными)\nДругие коды указывают на специфические ошибки оптимизации\n\nПроверка конечных значений (7.2)\nall(is.finite(fit$sd)) — комплексная проверка корректности оценок неопределенности. Результат TRUE означает:\n\nВсе стандартные ошибки параметров являются вещественными числами\nОтсутствуют патологические значения (NaN, Inf, NA) в матрице Гессе\nКовариационная матрица положительно определена\nОценки неопределенности надежны для построения доверительных интервалов\n\nЧто проверяет:\n\nКорректность расчета стандартных ошибок\nОтсутствие вырожденных параметров\nЧисленную стабильность решения\nВозможность интерпретировать результаты\n\nПоследствия FALSE:\n\nНевозможно построить достоверные доверительные интервалы\nРиск ошибочных управленческих рекомендаций\nТребуется пересмотр модели (упрощение, изменение прайеров)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Продукционная модель SPiCT</span>"
    ]
  },
  {
    "objectID": "chapter5.html#диагностика-модели",
    "href": "chapter5.html#диагностика-модели",
    "title": "6  Продукционная модель SPiCT",
    "section": "6.9 Диагностика модели",
    "text": "6.9 Диагностика модели\n\n# ----------------- 8. ДИАГНОСТИКА МОДЕЛИ -----------------\n\n## 8.1 График остатков\nplotspict.osar(fit) \n\n## 8.2 Общая диагностика\nplotspict.diagnostic(fit)\n\n## 8.3 Сравнение приоров и апостериорных распределений\nplotspict.priors(fit)\n\n## 8.4 Проверка корреляции параметров\ncov2cor(fit$cov.fixed)        # Матрица корреляций\ncov2cor(fit$cov.fixed) &gt; 0.8  # Выявление сильных корреляций (&gt;0.8)\n\n\n\n\nРис. 4.: График остатков\n\n\nОстатки по времени (Residuals vs. time):\n-   Показывает разницу между наблюдаемыми значениями и предсказаниями модели\n\n-   Идеал: случайное распределение вокруг нуля\n\n    ### **Что означает \"Index 1 Bias p-val 0.7813\"?**\n\n    Это результат **статистического теста на систематическую ошибку** (bias) для первого индекса (в вашем случае - CPUE):\n\n    1.  **Index 1**: Это ваш индекс CPUE (первый в списке индексов)\n\n    2.  **Bias p-val**: p-value теста на наличие систематического смещения\n\n    3.  **0.7813**: Конкретное значение p-value\n\n    ### **Интерпретация значения 0.7813:**\n\n    -   **p-value \\&gt; 0.05**: Нет статистически значимых доказательств систематической ошибки (смещения)\n\n    -   **Высокое значение (0.7813)**: Сильно выше 0.05 → модель **не имеет значимого смещения** для этого индекса\n\n    -   **Практический смысл**: Модель адекватно описывает динамику CPUE без постоянного завышения или занижения\n\n\n\nРис. 5.: Общая диагностика\n\n\nСтруктура диагностического графика\n\nПервый столбец: Информация, связанная с данными по вылову (catch).\nВторой и третий столбцы: Информация, связанная с данными по индексам биомассы.\n\nСтроки графика содержат (сверху вниз):\n\nЛогарифмы исходных рядов данных:\n\nВерхний левый график в строке: log catch data (Логарифм данных по вылову).\nСрелний и правый графики в строке: log index data (Логарифм данных по индексу).\nЦель: Визуально оценить исходные данные.\n\nOSA-остатки:\n\nГрафик показывает разницу между наблюдаемыми и предсказанными на один шаг вперед значениями (в логарифмической шкале).\nЗаголовок графика содержит p-значение теста на смещение (bias test). Этот тест проверяет, отличается ли среднее остатков от нуля (систематическая ошибка).\n\nBias p-val: X.XXXX (p-значение теста на смещение).\nЗеленый заголовок: Тест НЕ значим (нет свидетельств систематической ошибки, p &gt; 0.05).\nКрасный заголовок: Тест значим (есть свидетельства систематической ошибки, p &lt;= 0.05).\n\nТри теста незначимы (p=0.4386 для вылова, p=0.7813 и p=0.9472 для индексов), заголовки зеленые.\n\nЭмпирическая автокорреляция остатков (ACF - Autocorrelation Function):\n\nГрафик показывает корреляцию остатков с их собственными лагированными значениями.\nВыполняется два теста на значимую автокорреляцию:\n\nТест Льюнга-Бокса (Ljung-Box test): Одновременный тест для нескольких лагов (здесь 4). Результат:\n\nLBox p-val: X.XXXX в заголовке графика.\nНа примере: Три теста незначимы (p=0.1348 для вылова, p=0.68 и p=0.3602 для индексов).\n\nТесты для отдельных лагов: Пунктирные горизонтальные линии на графике показывают критические значения для значимой автокорреляции на каждом конкретном лаге. Если столбики автокорреляции (вертикальные линии) выходят за эти пунктирные линии, это свидетельствует о значимой автокорреляции на данном лаге.\n\nНа примере : Никаких нарушений (значимой автокорреляции) не выявлено.\n\nТесты на нормальность остатков:\n\nQQ-график (Quantile-Quantile plot): Сравнивает квантили остатков с квантилями теоретического нормального распределения. Прямая линия указывает на нормальность.\nТест Шапиро-Уилка (Shapiro-Wilk test): Формальный тест на нормальность. Результат:\n\nShapiro p-val: X.XXXX в заголовке графика.\nНа примере: Три теста незначимы (p=0.1268 для вылова, p=0.9554 и p=0.9825 для индекса), нет свидетельств против нормальности.\n\n\n\nВывод для примера :\nДанные в этом примере не показали значимых нарушений предположений модели (нет систематической ошибки, автокорреляции или отклонения от нормальности остатков). Это повышает уверенность в полученных результатах моделирования.\nДля обсуждения возможных нарушений и способов их устранения читатель отсылается к Pedersen and Berg (2017) см. https://github.com/DTUAqua/spict/raw/master/spict/inst/doc/spict_handbook.pdf.\n\n\n\nРис. 6.: Сравнение априорных и апостериорных распределений\n\n\nn (параметр формы продукционной функции)\n\nОписание: Определяет форму продукционной кривой (зависимость роста биомассы от самой биомассы).\nИнтерпретация:\n\nn = 2: Классическая модель Шефера (симметричная кривая, максимум производства при B/K = 0.5).\nn ≠ 2: Обобщенная модель Пеллы-Томлинсона (асимметричная кривая).\n\nВажность: влияет на оценку Bmsy (биомасса при MSY) и статус запаса (B/Bmsy).\n\nalpha1, alpha2 (Параметры соотношения шумов для индексов)\n\nОписание: Логарифмы отношений стандартных отклонений ошибок наблюдения индексов (sdi1, sdi2) к стандартному отклонению процесса биомассы (sdb):\nalpha1 = log(sdi1) - log(sdb)\nalpha2 = log(sdi2) - log(sdb)\nИнтерпретация:\n\nОтражают относительную точность каждого индекса биомассы по сравнению с изменчивостью самой биомассы.\nalpha = 0 (sdi = sdb): Шум индекса равен шуму биомассы.\nalpha &lt; 0 (sdi &lt; sdb): Индекс точнее, чем изменчивость биомассы (хорошо).\nalpha &gt; 0 (sdi &gt; sdb): Индекс шумнее, чем изменчивость биомассы (плохо).\n\nКонтекст: Появляются, только если в модели используется два или более индексов биомассы.\n\nbeta (Параметр соотношения шумов для уловов)\n\nОписание: Логарифм отношения стандартного отклонения ошибок наблюдения уловов (sdc) к стандартному отклонению процесса промысловой смертности (sdf):\nbeta = log(sdc) - log(sdf)\nИнтерпретация:\n\nОтражает относительную точность данных по уловам по сравнению с изменчивостью промысловой смертности.\nbeta = 0 (sdc = sdf): Шум уловов равен шуму F.\nbeta &lt; 0 (sdc &lt; sdf): Данные по уловам точнее, чем изменчивость F (хорошо).\nbeta &gt; 0 (sdc &gt; sdf): Данные по уловам шумнее, чем изменчивость F (плохо).\n\n\nK (емкость среды)\n\nОписание: Максимальная равновесная биомасса неэксплуатируемого запаса (carrying capacity).\nИнтерпретация: Верхняя асимптота кривой роста. Один из самых важных и часто трудных для оценки параметров, особенно при ограниченных данных.\nЕдиницы измерения: Те же, что и у биомассы (например, тонны, тыс. особей).\n\n\n6.9.1 bkfrac (Начальная биомасса)\n\nОписание: Доля от K, которую составляла биомасса запаса в начальный год временного ряда:\nbkfrac = B₀ / K\nИнтерпретация:\n\nbkfrac = 1: Запас был в нетронутом состоянии в начальный год (B₀ = K).\nbkfrac &lt; 1: Запас уже был эксплуатируемым к началу ряда данных.\n\nВажность: Сильно влияет на реконструкцию исторической динамики биомассы, особенно если данные начинаются с периода интенсивного промысла.\n\nПочему именно эти параметры?\nФункция plotspict.priors(fit) по умолчанию фокусируется на параметрах, для которых:\n\nЗаданы явные априорные распределения пользователем (как logK или bkfrac в примерах).\nПрименены стандартные полу-информативные априоры SPiCT для стабилизации оценки в условиях ограниченных данных. К ним относятся n, alpha1, alpha2, beta. SPiCT использует их, так как эти параметры (особенно n и соотношения шумов) часто плохо определяются только данными улова и индекса.\n\nСравнение априора и апостериора показывает:\n\nНасколько данные обновили наши первоначальные представления (априорные) о параметре.\nНасколько информативны были априорные распределения.\nНадежность оценки: Сильное сужение апостериорного распределения относительно априорного говорит о том, что данные содержат информацию о параметре. Если апостериорное распределение почти совпадает с априорным, данные не добавили новой информации (оценка держится на априорном распределение (прайере)).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Продукционная модель SPiCT</span>"
    ]
  },
  {
    "objectID": "chapter5.html#проверка-корреляции-параметров",
    "href": "chapter5.html#проверка-корреляции-параметров",
    "title": "6  Продукционная модель SPiCT",
    "section": "6.10 Проверка корреляции параметров",
    "text": "6.10 Проверка корреляции параметров\n\n## 8.4 Проверка корреляции параметров\n&gt; cov2cor(fit$cov.fixed)        # Матрица корреляций\n              logm        logK        logq        logq      logsdb      logsdf\nlogm    1.00000000 -0.44139706  0.24731406  0.26680092  0.10226103  0.05866772\nlogK   -0.44139706  1.00000000 -0.78966591 -0.84564098 -0.14502822  0.03159055\nlogq    0.24731406 -0.78966591  1.00000000  0.92073272  0.09936208 -0.06019367\nlogq    0.26680092 -0.84564098  0.92073272  1.00000000  0.10661957 -0.06022707\nlogsdb  0.10226103 -0.14502822  0.09936208  0.10661957  1.00000000 -0.07548411\nlogsdf  0.05866772  0.03159055 -0.06019367 -0.06022707 -0.07548411  1.00000000\nlogsdi  0.04194204 -0.06650572  0.12991301  0.13206072  0.05802810 -0.02826486\nlogsdi -0.02144997  0.05063718 -0.08833322 -0.09060172  0.04142955  0.00688377\nlogsdc -0.03142644 -0.10430756  0.07611708  0.07988704  0.19380037 -0.38345908\n            logsdi       logsdi       logsdc\nlogm    0.04194204 -0.021449974 -0.031426440\nlogK   -0.06650572  0.050637182 -0.104307558\nlogq    0.12991301 -0.088333221  0.076117083\nlogq    0.13206072 -0.090601717  0.079887038\nlogsdb  0.05802810  0.041429548  0.193800371\nlogsdf -0.02826486  0.006883770 -0.383459078\nlogsdi  1.00000000 -0.024282304  0.029024203\nlogsdi -0.02428230  1.000000000 -0.005068705\nlogsdc  0.02902420 -0.005068705  1.000000000\n&gt; cov2cor(fit$cov.fixed) &gt; 0.8  # Выявление сильных корреляций (&gt;0.8)\n        logm  logK  logq  logq logsdb logsdf logsdi logsdi logsdc\nlogm    TRUE FALSE FALSE FALSE  FALSE  FALSE  FALSE  FALSE  FALSE\nlogK   FALSE  TRUE FALSE FALSE  FALSE  FALSE  FALSE  FALSE  FALSE\nlogq   FALSE FALSE  TRUE  TRUE  FALSE  FALSE  FALSE  FALSE  FALSE\nlogq   FALSE FALSE  TRUE  TRUE  FALSE  FALSE  FALSE  FALSE  FALSE\nlogsdb FALSE FALSE FALSE FALSE   TRUE  FALSE  FALSE  FALSE  FALSE\nlogsdf FALSE FALSE FALSE FALSE  FALSE   TRUE  FALSE  FALSE  FALSE\nlogsdi FALSE FALSE FALSE FALSE  FALSE  FALSE   TRUE  FALSE  FALSE\nlogsdi FALSE FALSE FALSE FALSE  FALSE  FALSE  FALSE   TRUE  FALSE\nlogsdc FALSE FALSE FALSE FALSE  FALSE  FALSE  FALSE  FALSE   TRUE\n&gt; \n\nАнализ матрицы корреляций параметров модели SPiCT\nКоманды выполняют два действия:\n\ncov2cor(fit$cov.fixed) - преобразует матрицу ковариаций в матрицу корреляций\ncov2cor(fit$cov.fixed) &gt; 0.8 - выявляет сильные корреляции (&gt;0.8)\n\nУмеренные корреляции (|r| &gt; 0.7):\n\nlogK и logq (-0.79):\nКлассическая отрицательная корреляция между емкостью среды и уловистостью. Означает, что:\n\nДанные можно объяснить либо:\n\nБольшим запасом (высокий K) с низкой уловистостью (низкий q)\nИли малым запасом (низкий K) с высокой уловистостью (высокий q)\n\nТипично для моделей с ограниченными данными",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Продукционная модель SPiCT</span>"
    ]
  },
  {
    "objectID": "chapter5.html#визуализация-резульататов",
    "href": "chapter5.html#визуализация-резульататов",
    "title": "6  Продукционная модель SPiCT",
    "section": "6.11 Визуализация резульататов",
    "text": "6.11 Визуализация резульататов\n\n----------------- 9. ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ -----------------\n\n## 9.1 Основные графики\n\nplot(fit) \\# Комплексный отчет\n\n## 9.2 Биомасса в абсолютных величинах\n\nplotspict.biomass( fit, logax = FALSE, \\# Линейная шкала main = \"Абсолютная биомасса\", ylim = c(0, 250), \\# Ограничение по оси Y plot.obs = TRUE, \\# Отображать наблюдения xlab = \"Год\", CI = 0.95, \\# 95% доверительный интервал qlegend = FALSE, rel.axes = TRUE, rel.ci = TRUE )\n\n## 9.3 Относительная биомасса (B/Bmsy)\n\nplotspict.bbmsy(fit,qlegend = FALSE)\n\n## 9.4 Вылов\n\nplotspict.catch(fit,qlegend = FALSE)\n\n## 9.5 Относительная смертность (F/Fmsy)\n\nplotspict.ffmsy(fit,qlegend = FALSE)\n\n## 9.6 Продукционная кривая\n\nplotspict.production(fit)\n\n## 9.7 Kobe plot\n\nplotspict.fb(fit, ylim=c(0, 0.5), xlim=c(0, 200))\n\n\n\n\nРис. 7.: Комплексный отчет\n\n\n\n\n\nРис. 8.: Динамика абсолютной биомассы\n\n\n\n\n\nРис. 9.: Динамика относительной биомассы\n\n\n\n\n\nРис. 10.: Динамика относительной смертности\n\n\n\n\n\nРис. 11.: Продукционная кривая\n\n\n\n\n\nРис. 12.: Kobe plot\n\n\nГрафик показывает динамику биомассы и смертности от промысла с начального года (здесь 2005), обозначенного кругом, до конечного года (здесь 2025), обозначенного квадратом. Жёлтый ромб обозначает среднюю биомассу за длительный период при сохранении текущей (2025) промысловой нагрузки. Эта точка может быть интерпретирована как равновесное значение вылова и обозначена в легенде как E(B∞) как статистический способ выражения ожидания биомассы при t → ∞. Поскольку текущая промысловая смертность близка к FMSY, ожидаемая долгосрочная биомасса близка к BMSY. Серая затенённая область в форме банана обозначает 95% доверительную область пары FMSY, BMSY. Эту область важно визуализировать совместно, поскольку две контрольные точки имеют сильную (отрицательную) корреляцию.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Продукционная модель SPiCT</span>"
    ]
  },
  {
    "objectID": "chapter5.html#анализ-результатов",
    "href": "chapter5.html#анализ-результатов",
    "title": "6  Продукционная модель SPiCT",
    "section": "6.12 Анализ результатов",
    "text": "6.12 Анализ результатов\n\n# ----------------- 10. АНАЛИЗ РЕЗУЛЬТАТОВ -----------------\n\n## 10.1 Краткий отчет\nsummary(fit)\n\n## 10.2 Точечные оценки параметров\npars &lt;- sumspict.parest(fit)\n\n## 10.3 Ориентиры управления (стохастические)\nsumspict.srefpoints(fit)\n\n## 10.4 Ориентиры управления (детерминированные)\nsumspict.drefpoints(fit)\n\nКраткий отчет\n\nmary(fit)\nConvergence: 0  MSG: relative convergence (4)\nObjective function at optimum: -4.8303552\nEuler time step (years):  1/16 or 0.0625\nNobs C: 20,  Nobs I1: 20,  Nobs I2: 19\n\nResidual diagnostics (p-values)\n    shapiro   bias    acf   LBox shapiro bias acf LBox  \n C   0.1268 0.4386 0.0562 0.1348       -    -   .    -  \n I1  0.9554 0.7813 0.3360 0.6800       -    -   -    -  \n I2  0.9825 0.9472 0.1390 0.3602       -    -   -    -  \n\nPriors\n      logn  ~  dnorm[log(2), 0.1^2]\n  logalpha  ~  dnorm[log(1), 2^2]\n   logbeta  ~  dnorm[log(1), 2^2]\n      logK  ~  dnorm[log(148.413), 0.7^2]\n logbkfrac  ~  dnorm[log(0.75), 0.25^2]\n\nFixed parameters\n   fixed.value  \n n           2  \n\nModel parameter estimates w 95% CI \n           estimate       cilow       ciupp    log.est  \n alpha1  11.9450241   2.6794895  53.2502930  2.4803148  \n alpha2   5.0683878   1.1265510  22.8028330  1.6230228  \n beta     0.1879597   0.0371609   0.9507000 -1.6715278  \n r        0.3769549   0.2895415   0.4907586 -0.9756298  \n rc       0.3769549   0.2895415   0.4907586 -0.9756298  \n rold     0.3769549   0.2895415   0.4907586 -0.9756298  \n m       17.8600178  16.2681570  19.6076444  2.8825646  \n K      189.5188972 153.7796069 233.5642100  5.2444887  \n q1       0.1446167   0.1110579   0.1883161 -1.9336685  \n q2       0.1105024   0.0861636   0.1417164 -2.2027177  \n sdb      0.0179239   0.0040818   0.0787065 -4.0216194  \n sdf      0.3205493   0.2181678   0.4709762 -1.1377191  \n sdi1     0.2141016   0.1563268   0.2932285 -1.5413046  \n sdi2     0.0908454   0.0648365   0.1272875 -2.3985967  \n sdc      0.0602503   0.0143610   0.2527760 -2.8092469  \n \nDeterministic reference points (Drp)\n         estimate      cilow       ciupp   log.est  \n Bmsyd 94.7594486 76.8898035 116.7821050  4.551342  \n Fmsyd  0.1884774  0.1447707   0.2453793 -1.668777  \n MSYd  17.8600178 16.2681570  19.6076444  2.882565  \nStochastic reference points (Srp)\n        estimate      cilow       ciupp   log.est  rel.diff.Drp  \n Bmsys 94.710229 76.8402135 116.7361074  4.550822 -0.0005196907  \n Fmsys  0.188398  0.1447201   0.2452583 -1.669199 -0.0004216341  \n MSYs  17.843213 16.2542730  19.5874793  2.881623 -0.0009418271  \n\nStates w 95% CI (inp$msytype: s)\n                   estimate      cilow       ciupp    log.est  \n B_2024.94      118.8335053 96.9318694 145.6837887  4.7777234  \n F_2024.94        0.1031939  0.0646828   0.1646340 -2.2711455  \n B_2024.94/Bmsy   1.2547061  1.0845329   1.4515812  0.2269014  \n F_2024.94/Fmsy   0.5477442  0.3417896   0.8778024 -0.6019469  \n\nPredictions w 95% CI (inp$msytype: s)\n                 prediction       cilow       ciupp    log.est  \n B_2026.00      123.0873098 100.3197792 151.0219217  4.8128939  \n F_2026.00        0.1031941   0.0464383   0.2293155 -2.2711437  \n B_2026.00/Bmsy   1.2996200   1.1150104   1.5147950  0.2620719  \n F_2026.00/Fmsy   0.5477452   0.2458405   1.2204040 -0.6019451  \n Catch_2025.00   12.4909882   7.3033391  21.3634865  2.5250074  \n E(B_inf)       137.4532783          NA          NA  4.9232841  \n&gt; \n\nАнализ результатов модели SPiCT\n1. Сходимость модели\nConvergence: 0 MSG: relative convergence (4)\nИнтерпретация: Код 0 указывает на успешную сходимость оптимизации. Сообщение “relative convergence” подтверждает, что алгоритм достиг локального минимума с заданной точностью. Результаты могут считаться валидными.\n2. Целевая функция\nObjective function at optimum: -4.8303552\nИнтерпретация: Значение логарифмической апостериорной плотности (с учетом априорных распределений) в точке оптимума. Более высокие значения (менее отрицательные) указывают на лучшее соответствие модели данным.\n3. Дискретизация времени\nEuler time step (years): 1/16 or 0.0625\nИнтерпретация: Для решения дифференциальных уравнений использован шаг Эйлера 0.0625 года (~23 дня), что обеспечивает высокую точность расчетов.\n4. Данные наблюдений\nNobs C: 20,  Nobs I1: 20,  Nobs I2: 19\nИнтерпретация:\n\nC: 20 точек данных по вылову (2005-2024 гг.)\nI1: 20 значений индекса CPUE\nI2: 19 значений индекса BESS (отсутствует первое наблюдение)\n\n5. Диагностика остатков\nResidual diagnostics (p-values)\nshapiro   bias    acf   LBox\nC   0.1268 0.4386 0.0562 0.1348\nI1  0.9554 0.7813 0.3360 0.6800\nI2  0.9825 0.9472 0.1390 0.3602  \nКлючевые тесты:\n\nShapiro-Wilk: Нормальность остатков (p &gt; 0.05 → нормальность не отвергается)\nBias test: Систематическая ошибка (p &gt; 0.05 → смещение отсутствует)\nACF/Ljung-Box: Автокорреляция (p &lt; 0.1 для вылова → слабая автокорреляция)\nЗаключение: Остатки удовлетворительны, кроме возможной слабой автокорреляции в данных по вылову.\n\n6. Априорные распределения\nPriors\nlogn  ~  dnorm[log(2), 0.1^2]       # Фиксирован n = 2 (модель Шефера)   \nlogK  ~  dnorm[log(148.413), 0.7^2]  # K ~ 148.4 тыс. тонн (CV=70%)   \nlogbkfrac ~ dnorm[log(0.75), 0.25^2] # Начальная эксплуатация B/K = 0.75\nИнтерпретация: Использованы информативные априорные распределения для ключевых параметров, что характерно для data-limited подходов.\n7. Оценки параметров модели\nModel parameter estimates w 95% CI\n      estimate       cilow       ciupp  \nK      189.5 [153.8 - 233.6]  # Емкость среды (тыс. тонн)  \nr        0.38 [0.29 - 0.49]   # Внутренняя скорость роста \nq1       0.14 [0.11 - 0.19]   # Catchability CPUE \nq2       0.11 [0.09 - 0.14]   # Catchability BESS  \nsdf      0.32 [0.22 - 0.47]   # SD процесса для F\nКлючевые выводы: - Высокая неопределенность оценки K (дов. интервал ±40%) - Умеренная скорость восстановления запаса (r ≈ 38% в год) - Индекс BESS имеет более высокую catchability, чем CPUE\n8. Ориентиры управления\nDeterministic reference points (Drp)\nestimate      95% CI  \nBmsyd   94.8 [76.9 - 116.8]  # Биомасса при MSY  \nFmsyd    0.19 [0.14 - 0.25]  # Смертность при MSY  \nMSYd    17.9 [16.3 - 19.6]   # Макс. устойчивый вылов  \n\nStochastic reference points (Srp)          \nestimate      rel.diff.Drp    \nBmsys   94.7         -0.05%        # Незначительные отличия от детерм. модели  \nFmsys    0.19        -0.04%\nИнтерпретация: Результаты устойчивы к стохастичности модели. MSY ≈ 18 тыс. тонн.\n9. Состояние запаса в 2024 г.\nStates w 95% CI (inp$msytype: s)                   \nestimate      95% CI  \nB_2024.94        118.8 [96.9 - 145.7]  # Абсолютная биомасса (тыс. т) \nF_2024.94          0.10 [0.06 - 0.16]  # Смертность \nB/Bmsy             1.25 [1.08 - 1.45]  # Биомасса выше Bmsy\nF/Fmsy             0.55 [0.34 - 0.88]  # Эксплуатация ниже Fmsy\nОценка состояния: Запас находится в благополучном состоянии (B &gt; Bmsy, F &lt; Fmsy), но с высокой неопределенностью.\n10. Прогнозы\nPredictions w 95% CI\nB_2026.00      123.1 [100.3 - 151.0]  # Прогноз биомассы\nCatch_2025.00   12.5 [7.3 - 21.4]     # Прогноз вылова на 2025 г.  \nE(B_inf)       137.5                   # Ожидаемая равновесная биомасса\nПрогнозные показатели: - Биомасса продолжит умеренный рост - Рекомендуемый вылов на 2025 г. ≈ 12.5 тыс. тонн (дов. интервал ±57%) - Потенциальная равновесная биомасса на 16% выше текущей\nКлючевые выводы:\n\nМодель успешно сошлась с удовлетворительными остатками\nЗапас оценивается выше целевого уровня (B/Bmsy &gt; 1)\nЭксплуатация находится на безопасном уровне (F/Fmsy &lt; 1)\nРекомендуемый вылов на 2025 г. — 12.5 [7.3 - 21.4] тыс. тонн\nОсновные источники неопределенности: оценка K и прогноз вылова",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Продукционная модель SPiCT</span>"
    ]
  },
  {
    "objectID": "chapter5.html#ретроспективный-анализ",
    "href": "chapter5.html#ретроспективный-анализ",
    "title": "6  Продукционная модель SPiCT",
    "section": "6.13 Ретроспективный анализ",
    "text": "6.13 Ретроспективный анализ\n\n# -------------- 11. РЕТРОСПЕКТИВНЫЙ АНАЛИЗ --------------\n\n## 11.1 Запуск ретроспективного анализа\nfit &lt;- retro(fit)\n\n## 11.2 Визуализация ретроспективы\nplotspict.retro(fit, add.mohn = TRUE, CI = 0.95)\n\n## Интерпретация коэффициента Мона (Mohn's rho):\n## Долгоживущие виды: |rho| &gt; 0.2 значимо\n## Короткоживущие виды: |rho| &gt; 0.3 значимо\n\n\n\n\nРис. 13.: Визуализация ретроспективного анализа\n\n\nСуть ретроспективного анализа (Retrospective Analysis)\nЦель: Оценка устойчивости модели и выявление систематических смещений (ретроспективного сдвига) в оценках состояния запаса при добавлении новых данных.\nМетод:\n\nМодель последовательно переоценивается с исключением по 1 последнему году данных (например: 2005-2023, 2005-2022 и т.д.)\nДля каждого урезанного периода рассчитываются показатели (B/Bmsy, F/Fmsy) в перекрывающиеся годы\nОценки сравниваются с “базовой” моделью (со всеми данными)\n\nКоэффициент Мона (Mohn’s rho)\nФормула расчета:\nρ = 1/N * Σ [ (X_retro,i - X_base,i) / X_base,i ]\nгде:\n\nN – число исключенных лет\nX_retro,i – оценка параметра (напр. B/Bmsy) в году i по урезанным данным\nX_base,i – оценка того же параметра в году i по полным данным\n\nИнтерпретация результатов в вашем случае:\n        FFmsy         BBmsy   0.0028358361 -0.0002021046 \n\nДля F/Fmsy: ρ = 0.0028 (0.28%)\n\nПоложительное значение: текущие оценки F/Fmsy слегка завышены по сравнению с ретроспективой\nВеличина &lt; 0.3% – незначима\n\nДля B/Bmsy: ρ = -0.0002 (-0.02%)\n\nОтрицательное значение: текущие оценки B/Bmsy слегка занижены\nВеличина &lt; 0.1% – пренебрежимо мала\n\n\nВывод для модели:\n\nКоэффициенты Мона близки к нулю (|ρ| &lt; 0.005)\nОтсутствует статистически значимый ретроспективный сдвиг\nМодель демонстрирует высокую устойчивость к добавлению новых данных\nРезультаты можно считать надежными\n\n\nВажно! Значимый сдвиг (|ρ| &gt; 0.2-0.3) указывает на:\n\nНедостаточность данных\nПроблемы со спецификацией модели\nСистематические ошибки в данных\nНеобходимость пересмотра модели",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Продукционная модель SPiCT</span>"
    ]
  },
  {
    "objectID": "chapter5.html#прогнозирование-и-сценарии-управления",
    "href": "chapter5.html#прогнозирование-и-сценарии-управления",
    "title": "6  Продукционная модель SPiCT",
    "section": "6.14 Прогнозирование и сценарии управления",
    "text": "6.14 Прогнозирование и сценарии управления\n\n# ----------- 12. ПРОГНОЗИРОВАНИЕ И СЦЕНАРИИ УПРАВЛЕНИЯ -----------\n\n## 12.1 Установка интервала управления\ninp$maninterval &lt;- c(2025, 2026) # Годы прогноза\n\n## 12.2 Базовые сценарии управления\nfit &lt;- manage(fit)\n\n## 12.3 Пользовательские сценарии (постоянный вылов)\ncatchvals = c(10, 12, 15, 17) # Варианты вылова в тыс.тонн\n\nfor(i in seq_along(catchvals)){\n  fit &lt;- add.man.scenario(\n    fit,\n    scenarioTitle = paste0(\"Постоянный вылов \", catchvals[i], \" тыс.т\"),\n    cabs = catchvals[i]  # Абсолютный вылов\n  )\n}\n\n## 12.4 Сводка по сценариям управления\nsumspict.manage(fit, include.unc = TRUE) # С учетом неопределенности\n\nПолучаем:\n\nSPiCT timeline:\n                                                  \n      Observations              Management        \n    2005.00 - 2025.00        2025.00 - 2026.00    \n |-----------------------| ----------------------|\n\nManagement evaluation: 2026.00\n\nPredicted catch for management period and states at management evaluation time:\n\n                                 C B/Bmsy F/Fmsy\n1. Keep current catch         11.8   1.31   0.52\n2. Keep current F             12.5   1.30   0.55\n3. Fish at Fmsy               22.0   1.20   1.00\n4. No fishing                  0.0   1.42   0.00\n5. Reduce F by 25%             9.5   1.33   0.41\n6. Increase F by 25%          15.4   1.27   0.68\n7. MSY hockey-stick rule      22.0   1.20   1.00\n8. ICES advice rule           19.9   1.23   0.90\n9. Постоянный вылов 10 тыс.т  10.0   1.32   0.43\n10. Постоянный вылов 12 тыс.т 12.0   1.30   0.53\n11. Постоянный вылов 15 тыс.т 15.0   1.27   0.66\n12. Постоянный вылов 17 тыс.т 17.0   1.25   0.76\n\n95% confidence intervals for states:\n\n                              B/Bmsy.lo B/Bmsy.hi F/Fmsy.lo F/Fmsy.hi\n1. Keep current catch              1.12      1.52      0.23      1.15\n2. Keep current F                  1.12      1.51      0.25      1.22\n3. Fish at Fmsy                    1.00      1.44      0.45      2.23\n4. No fishing                      1.25      1.63      0.00      0.00\n5. Reduce F by 25%                 1.15      1.54      0.18      0.92\n6. Increase F by 25%               1.08      1.49      0.31      1.53\n7. MSY hockey-stick rule           1.00      1.44      0.45      2.23\n8. ICES advice rule                1.03      1.46      0.40      2.00\n9. Постоянный вылов 10 тыс.т       1.14      1.54      0.19      0.97\n10. Постоянный вылов 12 тыс.т      1.12      1.52      0.24      1.17\n11. Постоянный вылов 15 тыс.т      1.09      1.49      0.30      1.48\n12. Постоянный вылов 17 тыс.т      1.06      1.48      0.34      1.69\n\n\n\n\nРис. 14.: Правило хоккейной клюшки и ICES\n\n\nПроцесс прогнозирования и оценки сценариев управления\n1. Установка горизонта прогнозирования\ninp$maninterval &lt;- c(2025, 2026)\n\nЦель: Определить период, для которого делаются прогнозы (2025-2026 гг.)\nМеханика: Модель будет рассчитывать состояние запаса и возможный вылов на эти годы\n\n2. Базовые сценарии управления\nfit &lt;- manage(fit)\nАвтоматически генерируются стандартные сценарии:\n\ncurrentCatch: Сохранение текущего вылова (среднее за последние 3 года)\ncurrentF: Сохранение текущего уровня смертности (F)\nFmsy: Эксплуатация на уровне FMSY\nnoF: Полное прекращение промысла\nreduceF25: Снижение F на 25%\nincreaseF25: Увеличение F на 25%\nmsyHockeyStick: Правило “хоккейной клюшки” (F=0 при B&gt;BMSY, F=FMSY при B≥BMSY)\nices: Правило ICES (F пропорционален уровню биомассы)\n\n3. Пользовательские сценарии\ncatchvals = c(10, 12, 15, 17) for(i in seq_along(catchvals)){   fit &lt;- add.man.scenario(     fit,     scenarioTitle = paste0(\"Постоянный вылов \", catchvals[i], \" тыс.т\"),     cabs = catchvals[i]   ) }\n\nСтратегия: Фиксированный вылов указанного объема в 2025-2026 гг.\nДиапазон: От консервативного (10 тыс.т) до рискованного (17 тыс.т)\n\n4. Сводка результатов\nsumspict.manage(fit, include.unc = TRUE)\nКлючевые выводы из результатов (на 2026 г.)\n1. Прогноз состояния запаса\n\n\n\n\n\n\n\n\nПоказатель\nЗначение\nИнтерпретация\n\n\n\n\nB/BMSY\n1.25-1.31\nЗапас выше целевого уровня (B&gt;BMSY)\n\n\nF/FMSY\n0.52-0.55\nЭксплуатация ниже предельной (F&lt;FMSY)\n\n\n\n2. Сравнение сценариев\n\n\n\n\n\n\n\n\n\n\nСценарий\nВылов (тыс.т)\nB/BMSY\nF/FMSY\nРиск перелова\n\n\n\n\nБезопасные:\n\n\n\n\n\n\nnoF (нет промысла)\n0.0\n1.42\n0.00\nНет\n\n\nreduceF25\n9.5\n1.33\n0.41\nНизкий\n\n\nВылов 10 тыс.т\n10.0\n1.32\n0.43\nНизкий\n\n\nОптимальные:\n\n\n\n\n\n\ncurrentCatch\n11.8\n1.31\n0.52\nНизкий\n\n\nВылов 12 тыс.т\n12.0\n1.30\n0.53\nНизкий\n\n\nРискованные:\n\n\n\n\n\n\nincreaseF25\n15.4\n1.27\n0.68\nУмеренный\n\n\nВылов 15 тыс.т\n15.0\n1.27\n0.66\nУмеренный\n\n\nОпасные:\n\n\n\n\n\n\nFMSY\n22.0\n1.20\n1.00\nВысокий\n\n\nВылов 17 тыс.т\n17.0\n1.25\n0.76\nВысокий\n\n\n\n3. Анализ неопределенности\nДля ключевых сценариев:\n\nВылов 12 тыс.т:\nF/FMSY&gt; = 0.53 [0.24-1.17] → 10% вероятность превышения FMSY\nВылов 15 тыс.т:\nF/FMSY = 0.66 [0.30-1.48] → 30% вероятность превышения FMSY\nВылов 17 тыс.т:\nF/FMSY = 0.76 [0.34-1.69] → 45% вероятность превышения FMSY\n\nРекомендации по управлению\n\nОптимальный вылов: 12 тыс. тонн\n\nСохраняет запас в безопасной зоне (B/BMSY &gt; 1.3)\nМинимизирует риск перелова (F/FMSY &lt; 0.55)\nУчитывает неопределенность модельных оценок\n\nПредельно допустимый вылов: 15 тыс. тонн\n\nТребует усиленного мониторинга\nНеобходим ежегодный пересмотр квот\n\nНе рекомендуются:\n\nСценарии с F≥FMSY (22 тыс.т)\nФиксированный вылов &gt;15 тыс.т\nСтратегии, приводящие к снижению B/BMSY &lt; 1.25\n\n\n\nКритический фактор: Высокая неопределенность прогноза вылова (дов. интервал 7.3-21.4 тыс.т для текущего сценария) требует осторожного подхода.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Продукционная модель SPiCT</span>"
    ]
  },
  {
    "objectID": "chapter12.html",
    "href": "chapter12.html",
    "title": "13  SDM: моделирование пространственного распределения видов",
    "section": "",
    "text": "13.1 Введение\nПредставьте, что вы пытаетесь услышать шёпот в шумной комнате. Шум — это всё остальное: температура, освещение, посторонние разговоры. Шёпот — сигнал, который вам нужен. Именно так обстоит дело с моделированием пространственного распределения видов (SDM). Когда мы видим точки на карте, где вид был обнаружен, наш мозг мгновенно дорисовывает причинно-следственные связи: «Он здесь, потому что тут холодно» или «Его привлекает эта глубина». Но реальность сложнее. Точки наблюдений — это не чистый сигнал о предпочтениях вида, а сложная смесь его истинной экологической ниши, доступности мест обитания, усилий исследователей и случайных факторов. Наша задача — отделить шёпот от шума.\nЧто такое SDM? По своей сути, это попытка найти вероятность присутствия вида в зависимости от ковариат — био-физических переменных среды. Мы хотим построить функцию, которая из сырых, зашумленных данных наблюдений извлекает устойчивые паттерны: как вид реагирует на температуру, солёность, глубину, расстояние до берега. Но здесь нас подстерегает та же ловушка, что и с CPUE: если не аккуратно отделить сигнал от шума, мы получим термометр, который показывает температуру в комнате, а не у больного.\nПочему это так важно? Потому что SDM — это мост между теорией и практикой. Он позволяет предсказать, где вид может обитать в условиях меняющегося климата, где стоит искать новые популяции, как защитить уязвимые местообитания. Но этот мост должен быть построен на прочном фундаменте, а не на песке иллюзий и переобученных моделей.\nВ этом занятии мы пройдем весь путь: от сырых данных до ансамблевых прогнозов. Мы будем использовать три скрипта:\nПодготовка данных: мы создадим регулярную сетку, агрегируем данные, исключим сушу, рассчитаем расстояние до берега и извлечем био-физические переменные из NetCDF файлов. Это основа, своего рода «чистка» данных от артефактов и приведение их к единому формату.\nВыбор предикторов: здесь мы применим машинное обучение чтобы выявить сложные, нелинейные зависимости между средой и присутствием вида. Мы будем бороться с переобучением, мультиколлинеарностью и шумом, используя методы отбора признаков (Boruta, LASSO) и кросс-валидацию.\nМоделирование, ансамблирование и прогноз: поскольку ни одна модель не идеальна, мы объединим несколько моделей в ансамбль, чтобы снизить неопределенность и получить более надежные прогнозы. Мы спроецируем эти модели на будущие сценарии, оценим риски экстраполяции с помощью MESS-анализа и визуализируем результаты.\nКак и в примере с CPUE, мы не стремимся победить неопределенность, а хотим честно на нее посмотреть. Мы покажем не только карты вероятностей, но и доверительные интервалы, не только предсказания, но и диагностику моделей. Это тот подход, который работает в долгую: меньше сказок, больше науки.\nИ помните: хорошая SDM — это не просто «черный ящик», который выдает прогнозы. Это тщательно настроенный инструмент, который помогает услышать шёпот вида в шуме данных. Давайте начнем.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>SDM: моделирование пространственного распределения видов</span>"
    ]
  },
  {
    "objectID": "chapter12.html#данные-и-скрипты",
    "href": "chapter12.html#данные-и-скрипты",
    "title": "13  SDM: моделирование пространственного распределения видов",
    "section": "13.2 Данные и скрипты",
    "text": "13.2 Данные и скрипты\nДля минимальной работы 3-го скрипта необходимо подгрузить два csv-файла. Первый файл для моделирования текущих данных и файл - данные по будущему распределению предикторов, собранных с Bio-ORACLE. Скрипты целиком: первый, второй и третий.\n\n# ========================================================================================================================\n# ПОДГОТОВКА ДАННЫХ ДЛЯ МОДЕЛИРОВАНИЯ ПРОСТРАНСТВЕННОГО РАСПРЕДЕЛЕНИЯ ВИДОВ (SDM)\n# \n# Скрипт выполняет:\n# 1. Загрузку и фильтрацию данных наблюдений\n# 2. Создание регулярной сетки для анализа\n# 3. Агрегацию данных по ячейкам сетки\n# 4. Исключение наземных территорий\n# 5. Расчет расстояния до берега\n# 6. Извлечение био-физических переменных из NetCDF файлов\n# 7. Сохранение итогового набора данных\n# \n# Курс: \"Оценка водных биоресурсов в среде R (для начинающих)\"\n# Автор: Баканев С. В. \n# Дата: 27.08.2025\n# ========================================================================================================================\n# Очистка рабочей среды\nrm(list = ls())\n\n# Установка рабочей директории\nsetwd(\"C:/SDM\")\n\n# Загрузка необходимых библиотек\nsuppressPackageStartupMessages({\nlibrary(tidyverse)    # Обработка данных и визуализация\nlibrary(readxl)       # Чтение Excel-файлов\nlibrary(rnaturalearth) # Векторные карты мира\nlibrary(sf)           # Пространственный анализ\nlibrary(ggOceanMaps)  # Расчет дистанции до берега\nlibrary(terra)        # Работа с растровыми данными\n})\n\n# ---------------------------\n# 2. ЗАГРУЗКА И ФИЛЬТРАЦИЯ ДАННЫХ\n# ---------------------------\nDATA &lt;- read_excel(\"PECTEN.xlsx\", sheet = \"PECTEN\")\nstr(DATA)\n\n\ntibble [6,573 x 4] (S3: tbl_df/tbl/data.frame)\n $ TYPE: chr [1:6573] \"A\" \"A\" \"A\" \"A\" ...\n $ Y   : num [1:6573] 28.2 32.8 32.8 32.8 32.8 ...\n $ X   : num [1:6573] -15.75 13.25 -9.25 -16.75 -17.25 ...\n $ OCC : num [1:6573] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n# Получение границ Европы\neurope &lt;- ne_countries(scale = 10, continent = \"Europe\")  # Загрузка векторных границ Европы (масштаб 1:10м)\n\n\n# Установка границ отображаемой области (долгота/широта)\nxmin=10  # Западная граница\nxmax=45  # Восточная граница\nymin=66 # Южная граница\nymax=72 # Северная граница\n\n# Фильтрация данных по заданным координатам\nPECTEN &lt;- DATA %&gt;%\n  filter(X &gt;= xmin & X &lt;= xmax & Y &gt;= ymin & Y &lt;= ymax) %&gt;%\n  select(X, Y, OCC)  # Выбор только нужных колонок\n\n# Построение карты\nggplot() +\n  # Базовая карта Европы\n  geom_sf(data = europe, fill = \"#E8E5D6\") + \n  # Ограничение области отображения\n  coord_sf(xlim = c(xmin, xmax), ylim = c(ymin, ymax)) +\n  # Точки наблюдений с размером и цветом по переменной OCC\n  geom_point(aes(x = X, y = Y, size = OCC, color = OCC),\n             data = PECTEN, alpha = 0.6) +\n  # Цветовая шкала (viridis, вариант H)\n  scale_color_viridis_c(option = \"H\") +\n  # Подписи осей\n  labs(x = \"Долгота\", y = \"Широта\", \n       size = \"Наличие вида\", color = \"Наличие вида\",\n       title = \"Распределение вида\")\n\n\n\n\nРис. 1.: Данные по встречаемости вида\n\n\n\n# Просмотр отфильтрованной таблицы\nstr(PECTEN)\n# ---------------------------\n# 3. СОЗДАНИЕ СЕТКИ И АГРЕГАЦИЯ ДАННЫХ\n# ---------------------------\n\n# Если объект europe не в формате sf, приведем:\neurope &lt;- suppressWarnings(sf::st_as_sf(europe))\n\n# Границы бинов\nx_breaks &lt;- seq(xmin, xmax, by = 0.05)\ny_breaks &lt;- seq(ymin, ymax, by = 0.05)\n\n# 2.1. Присвоим наблюдениям индексы ячеек и посчитаем среднее OCC по ячейке\nPECTEN_binned &lt;- PECTEN %&gt;%\n  mutate(\n    x_id = cut(X, breaks = x_breaks, include.lowest = TRUE, right = FALSE, labels = FALSE),\n    y_id = cut(Y, breaks = y_breaks, include.lowest = TRUE, right = FALSE, labels = FALSE)\n  ) %&gt;%\n  # точки, попавшие ровно в xmax/ymax, уйдут в NA — это нормально, т.к. верхняя граница полуоткрытая\n  filter(!is.na(x_id), !is.na(y_id)) %&gt;%\n  group_by(x_id, y_id) %&gt;%\n  summarise(OCC = mean(OCC, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(OCC = na_if(OCC, NaN))  # если все NA в ячейке &gt; NA, а не NaN\n\n# 2.2. Полная таблица ячеек (все комбинации), координаты центров\ngrid_cells &lt;- tidyr::expand_grid(\n  x_id = seq_along(head(x_breaks, -1)),\n  y_id = seq_along(head(y_breaks, -1))\n) %&gt;%\n  mutate(\n    X_center = (x_breaks[x_id] + x_breaks[x_id + 1]) / 2,\n    Y_center = (y_breaks[y_id] + y_breaks[y_id + 1]) / 2\n  )\n\n# 2.3. Приклеим средние OCC к полной решетке (пустые &gt; NA)\ngrid_occ &lt;- grid_cells %&gt;%\n  left_join(PECTEN_binned, by = c(\"x_id\", \"y_id\"))\n\n# 2.4. Оставим только ячейки океана (центры, не попадающие на сушу Европы)\ncenters_sf &lt;- st_as_sf(grid_occ, coords = c(\"X_center\", \"Y_center\"), crs = 4326, remove = FALSE)\non_land_mat &lt;- st_intersects(centers_sf, europe, sparse = FALSE)\non_land &lt;- apply(on_land_mat, 1, any)\n\ngrid_ocean &lt;- grid_occ %&gt;%\n  filter(!on_land) %&gt;%\n  select(X_center, Y_center, OCC) %&gt;%\n  arrange(Y_center, X_center)\n\n# Переименование столбцов\ngrid_ocean &lt;- grid_ocean %&gt;%\n  rename(X = X_center,\n         Y = Y_center,\n         OCC = OCC)\n\n# Вывод результата: таблица центров ячеек и средняя OCC (NA, если нет данных)\n\nstr(grid_ocean)\n\n# Построение карты+ проверка сетки\nggplot() +\n  # Базовая карта Европы\n  geom_sf(data = europe, fill = \"#E8E5D6\") + \n  # Ограничение области отображения\n  coord_sf(xlim = c(xmin, xmax), ylim = c(ymin, ymax)) +\n  # Точки наблюдений с размером и цветом по переменной OCC\n  geom_point(aes(x = X, y = Y, size = X, color = Y),\n             data = grid_ocean, alpha = 0.6) +\n  # Цветовая шкала (viridis, вариант H)\n  scale_color_viridis_c(option = \"H\") +\n  # Подписи осей\n  labs(x = \"Долгота\", y = \"Широта\", \n       size = \"Наличие вида\", color = \"Наличие вида\",\n       title = \"Распределение сетки\")\n\n\n\n\nРис. 2.: Визуализация сетки для моделирования\n\n\n\n# Присоединение к базовой таблице (X, Y, OCC) переменной DIST (рсстояние до берега)\ndt &lt;- data.frame(lon = grid_ocean$X, lat = grid_ocean$Y)\ndt &lt;- dist2land(dt, verbose = FALSE)\nqmap(dt, color = ldist) + scale_color_viridis_c()\n\n\n\n\nРис. 3.: Визуализация переменной (дистанция до берега)\n\n\n\nDATA &lt;- tibble(\n  X = grid_ocean$X,\n  Y = grid_ocean$Y,\n  OCC = grid_ocean$OCC,\n  DIST = dt$ldist\n)\n# Выводим первые несколько строк для проверки\nstr(DATA)\n# Присоединение к базовой таблице (X, Y, OCC, DIST) переменных с сайта BioORACLE\n#\nTEMP &lt;- rast(\"C:/SDM/BIO/Temperature [mean].nc\")\n# визуализация переменной\nplot(TEMP , xlim = c(xmin, xmax), ylim = c(ymin, ymax=72)) \n# Автоматическое присоединение переменных из всех nc файлов в папке BIO\n\n\n\n\nРис. 4.: Визуализация переменной (средней придонной температуры)\n\n\n\n# Получаем список всех nc файлов в папке BIO\nnc_files &lt;- list.files(\"C:/SDM/BIO\", pattern = \"\\\\.nc$\", full.names = TRUE)\n\n# Проверяем, что файлы найдены\nif (length(nc_files) == 0) {\n  stop(\"Не найдено nc файлов в папке C:/SDM/BIO\")\n}\n\n# Создаем координатный датафрейм один раз\ncoord &lt;- data.frame(x = DATA$X, y = DATA$Y)\n\n# Проходим по всем nc файлам\nfor (file_path in nc_files) {\n  # Извлекаем имя переменной из названия файла (убираем расширение .nc)\n  var_name &lt;- tools::file_path_sans_ext(basename(file_path))\n  \n  # Загружаем raster файл\n  temp_rast &lt;- rast(file_path)\n  \n  # Извлекаем значения для координат DATA\n  extracted_values &lt;- extract(temp_rast, coord, method = \"bilinear\")\n  \n  # Убираем столбец ID и оставляем только значения\n  values &lt;- extracted_values[, -1, drop = FALSE]\n  \n  # Переименовываем столбец в имя переменной\n  colnames(values) &lt;- var_name\n  \n  # Присоединяем к DATA\n  DATA &lt;- cbind(DATA, values)\n  \n  # Сообщение о прогрессе\n  message(\"Добавлена переменная: \", var_name, \" из файла: \", basename(file_path))\n}\n\n# Проверяем результат\nstr(DATA)\nwrite.csv(DATA, \"SDM_all_pred_full_set.csv\", row.names = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>SDM: моделирование пространственного распределения видов</span>"
    ]
  },
  {
    "objectID": "chapter12.html#выбор-предикторов",
    "href": "chapter12.html#выбор-предикторов",
    "title": "13  SDM: моделирование пространственного распределения видов",
    "section": "13.3 Выбор предикторов",
    "text": "13.3 Выбор предикторов\nНиже приводится скрипт, а после него - его анализ.\n\n# ========================================================================================================================\n# ПРАКТИЧЕСКОЕ ЗАНЯТИЕ: Модели пространственного распределения видов (SDM)\n# Курс: \"Оценка водных биоресурсов в среде R (для начинающих)\"\n# Автор: Баканев С. В. Дата: 27.08.2025\n# Структура:\n# 1) Подготовка и визуализация данных\n# 2) Отбор переменных и анализ важности признаков\n# 3) Построение моделей и анализ результатов\n# ========================================================================================================================\n\n# Установка рабочей директории\nsetwd(\"C:/SDM\")\nrm(list = ls())\n\n# Подключение необходимых библиотек\nsuppressPackageStartupMessages({\nlibrary(tidyverse)    # Обработка данных и визуализация\nlibrary(janitor)      # Очистка имен переменных\nlibrary(recipes)      # Предобработка данных\nlibrary(caret)        # Машинное обучение\nlibrary(car)          # VIF анализ\nlibrary(Boruta)       # Отбор признаков\nlibrary(glmnet)       # LASSO регрессия\nlibrary(randomForest) # Случайный лес\nlibrary(mgcv)         # GAM модели\nlibrary(terra)        # Пространственный анализ\nlibrary(scales)       # Форматирование графиков\n})\n# ========================================================================================================================\n# 1. ЗАГРУЗКА И ПРЕДВАРИТЕЛЬНАЯ ОБРАБОТКА ДАННЫХ\n# ========================================================================================================================\n\n# Загрузка данных\nDATA &lt;- read.csv(\"SDM_all_pred_full_set.csv\")\n\n# Предварительная обработка: безопасные имена и удаление пропусков в целевой переменной\ndf0 &lt;- DATA %&gt;%\n  janitor::clean_names() %&gt;%\n  filter(!is.na(occ)) %&gt;%\n  select(-x, -y)  # Удаление координат и ненужных переменных\n\n# Удаление переменных с near-zero variance\npreds0 &lt;- df0 %&gt;% select(-occ)\nnzv_idx &lt;- caret::nearZeroVar(preds0)\nif (length(nzv_idx) &gt; 0) preds0 &lt;- preds0[, -nzv_idx, drop = FALSE]\ndf1 &lt;- bind_cols(occ = df0$occ, preds0)\n\n# Импутация пропусков и стандартизация данных\nrec &lt;- recipe(occ ~ ., data = df1) %&gt;%\n  step_impute_knn(all_predictors()) %&gt;%\n  step_normalize(all_predictors())\n\nprep_rec &lt;- prep(rec)\ndat &lt;- bake(prep_rec, new_data = NULL)\n\n# ========================================================================================================================\n# 2. ОТБОР ПЕРЕМЕННЫХ И АНАЛИЗ МУЛЬТИКОЛЛИНЕАРНОСТИ\n# ========================================================================================================================\n\n# Удаление высококоррелированных переменных (коэффициент &gt; 0.8)\ncorr &lt;- cor(dat %&gt;% select(-occ), use = \"pairwise.complete.obs\")\nhighCorr &lt;- caret::findCorrelation(corr, cutoff = 0.8, names = TRUE, exact = TRUE)\ndat_cf &lt;- dat %&gt;% select(occ, any_of(setdiff(names(dat)[names(dat) != \"occ\"], highCorr)))\n\n# Функция для фильтрации по VIF\nvif_filter &lt;- function(df, thresh = 5) {\n  vars &lt;- setdiff(names(df), \"occ\")\n  repeat {\n    fit &lt;- lm(occ ~ ., data = df[, c(\"occ\", vars)])\n    v &lt;- car::vif(fit)\n    if (max(v) &lt; thresh) break\n    drop_var &lt;- names(which.max(v))\n    vars &lt;- setdiff(vars, drop_var)\n    if (length(vars) == 0) break\n  }\n  df[, c(\"occ\", vars)]\n}\n\ndat_vif &lt;- vif_filter(dat_cf, thresh = 5)\n\n# Отбор признаков с помощью Boruta\nset.seed(42)\nbor &lt;- Boruta(occ ~ ., data = dat_vif, maxRuns = 200, doTrace = 0)\nbor_selected &lt;- getSelectedAttributes(bor, withTentative = FALSE)\n\n# Визуализация результатов Boruta\nplot(bor, las = 2, cex.axis = 0.7)\nprint(bor)\n\n\n\n\nРис. 5.: Визуализация результатов Boruta\n\n\n\n# Отбор признаков с помощью LASSO\nx &lt;- as.matrix(dat_vif %&gt;% select(-occ))\ny &lt;- dat_vif$occ\ncv &lt;- cv.glmnet(x, y, alpha = 1, family = \"binomial\", standardize = FALSE)\ncoef_1se &lt;- as.matrix(coef(cv, s = \"lambda.1se\"))\nlasso_selected &lt;- rownames(coef_1se)[coef_1se[, 1] != 0]\nlasso_selected &lt;- setdiff(lasso_selected, \"(Intercept)\")\n\n# Ранжирование переменных по важности в LASSO\ncoef_all &lt;- as.matrix(coef(cv, s = \"lambda.1se\"))\ncoef_tbl &lt;- tibble(var = rownames(coef_all), coef = as.numeric(coef_all[, 1])) %&gt;%\n  filter(var != \"(Intercept)\") %&gt;%\n  arrange(desc(abs(coef)))\n\n# Формирование финального набора переменных (5-8 наиболее важных)\nconsensus &lt;- intersect(bor_selected, lasso_selected)\nfill_from_lasso &lt;- setdiff(coef_tbl$var, consensus)\nfill_from_boruta &lt;- setdiff(bor_selected, c(consensus, fill_from_lasso))\n\nfinal_vars &lt;- unique(c(consensus, fill_from_lasso, fill_from_boruta))\nfinal_vars &lt;- head(final_vars, 8)  # Ограничение до 8 переменных\n\nif (length(final_vars) &lt; 5) {\n  final_vars &lt;- unique(c(final_vars, head(coef_tbl$var, 5)))[1:5]\n}\n\nfinal_df &lt;- dat_vif %&gt;% select(occ, all_of(final_vars))\n\n# ========================================================================================================================\n# 3. АНАЛИЗ ВАЖНОСТИ ПЕРЕМЕННЫХ\n# ========================================================================================================================\n\n# Важность переменных по LASSO\nlasso_imp &lt;- coef_tbl %&gt;%\n  mutate(abs_coef = abs(coef)) %&gt;%\n  filter(var != \"(Intercept)\", abs_coef &gt; 0) %&gt;%\n  arrange(desc(abs_coef)) %&gt;%\n  slice_head(n = 20)\n\nggplot(lasso_imp, aes(x = reorder(var, abs_coef), y = abs_coef)) +\n  geom_col(fill = \"#3B82F6\") +\n  coord_flip() +\n  labs(x = \"Переменная\", y = \"|коэффициент| (lambda.1se)\",\n       title = \"LASSO важность (топ-20 по |коэффициенту|)\") +\n  theme_minimal(base_size = 12)\n\n\n\n\nРис. 6.: Визуализация результатов LASSO\n\n\n\n# Важность переменных по Random Forest\nrf_data &lt;- dat_vif %&gt;% dplyr::select(occ, dplyr::all_of(final_vars))\nis_classif &lt;- is.factor(rf_data$occ) || all(rf_data$occ %in% c(0, 1), na.rm = TRUE)\nif (is_classif && !is.factor(rf_data$occ)) {\n  rf_data$occ &lt;- factor(rf_data$occ)\n}\n\nrf &lt;- randomForest(occ ~ ., data = rf_data, importance = TRUE, na.action = na.omit)\nimp_mat &lt;- randomForest::importance(rf)\nimp_df &lt;- as.data.frame(imp_mat) %&gt;%\n  tibble::rownames_to_column(\"var\") %&gt;%\n  pivot_longer(cols = -var, names_to = \"metric\", values_to = \"importance\")\n\nggplot(imp_df, aes(x = reorder(var, importance), y = importance, fill = metric)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  facet_wrap(~ metric, scales = \"free_y\") +\n  scale_fill_manual(values = c(\"#10B981\", \"#F59E0B\", \"#6366F1\", \"#EF4444\")) +\n  labs(x = \"Переменная\", y = \"Важность\", title = \"Важность признаков по Random Forest\") +\n  theme_minimal(base_size = 12)\n\n\n\n\nРис. 7.: Важность признаков по Random Forest\n\n\n\n# ========================================================================================================================\n# 4. ПОСТРОЕНИЕ И АНАЛИЗ GAM МОДЕЛЕЙ\n# ========================================================================================================================\n\ndf &lt;- final_df\nif (is.factor(df$occ)) df$occ &lt;- as.numeric(df$occ) - 1L\nif (!all(df$occ %in% c(0, 1))) df$occ &lt;- ifelse(df$occ &gt; 0, 1L, 0L)\n\npred_vars &lt;- setdiff(names(df), \"occ\")\nk_basis &lt;- 8\n\n# Функция для построения унимодальных GAM моделей\nfit_gam_uni &lt;- function(var_name) {\n  form &lt;- as.formula(paste0(\"occ ~ s(\", var_name, \", k=\", k_basis, \")\"))\n  fams &lt;- list(\n    binomial(link = \"identity\"),\n    binomial(link = \"probit\"),\n    binomial(link = \"logit\")\n  )\n  model &lt;- NULL\n  fam_used &lt;- NULL\n  for (f in fams) {\n    model_try &lt;- try(\n      gam(form, data = df, family = f, method = \"REML\", select = TRUE),\n      silent = TRUE\n    )\n    if (!inherits(model_try, \"try-error\")) {\n      model &lt;- model_try\n      fam_used &lt;- model$family$link\n      break\n    }\n  }\n  if (is.null(model)) stop(paste(\"Не удалось обучить GAM для\", var_name))\n\n  x &lt;- df[[var_name]]\n  x_seq &lt;- seq(quantile(x, 0.02, na.rm = TRUE),\n               quantile(x, 0.98, na.rm = TRUE),\n               length.out = 200)\n\n  newd &lt;- tibble(!!var_name := x_seq)\n  pr &lt;- predict(model, newdata = newd, type = \"link\", se.fit = TRUE)\n\n  inv &lt;- model$family$linkinv\n  tibble(\n    variable = var_name,\n    x = x_seq,\n    prob  = pmax(pmin(inv(pr$fit), 1), 0),\n    lower = pmax(pmin(inv(pr$fit - 1.96 * pr$se.fit), 1), 0),\n    upper = pmax(pmin(inv(pr$fit + 1.96 * pr$se.fit), 1), 0),\n    link  = fam_used\n  ) %&gt;%\n    mutate(model_link = paste0(\"binomial(\", link, \")\"))\n}\n\n# Обучение GAM моделей и сбор кривых влияния\npd_all &lt;- suppressWarnings(map_dfr(pred_vars, fit_gam_uni))\n\n# Подготовка данных для визуализации\nrug_data &lt;- df %&gt;%\n  filter(occ == 1) %&gt;%\n  pivot_longer(cols = all_of(pred_vars), names_to = \"variable\", values_to = \"x\")\n\n# Первый график: базовые кривые GAM с риджинами\nggplot(pd_all, aes(x = x, y = prob)) +\n  geom_ribbon(aes(ymin = lower, ymax = upper), fill = \"#93C5FD\", alpha = 0.35) +\n  geom_line(color = \"#1D4ED8\", linewidth = 1) +\n  geom_rug(data = rug_data, aes(x = x), sides = \"b\", alpha = 0.25, inherit.aes = FALSE) +\n  facet_wrap(~ variable, scales = \"free_x\") +\n  scale_y_continuous(limits = c(0, 1)) +\n  labs(x = \"Значение предиктора (стандартизовано)\",\n       y = \"Вероятность присутствия\",\n       title = \"Унимодельные GAM (binomial): влияние каждого предиктора\",\n       subtitle = \"Ссылка: identity (fallback &gt; probit &gt; logit); ленты — 95% ДИ\") +\n  theme_minimal(base_size = 12)\n\n\n\n\nРис. 8.: Унимодельные GAM: влияние каждого предиктора\n\n\n\n# Второй график: с джиттером и биновой эмпирической вероятностью\nobs_raw &lt;- df %&gt;%\n  pivot_longer(cols = all_of(pred_vars), names_to = \"variable\", values_to = \"x\") %&gt;%\n  select(variable, x, occ)\n\nobs_bin &lt;- obs_raw %&gt;%\n  group_by(variable) %&gt;%\n  mutate(bin = cut_number(x, 20)) %&gt;%\n  group_by(variable, bin) %&gt;%\n  summarise(\n    x_mid = mean(x, na.rm = TRUE),\n    occ_mean = mean(occ),\n    n = n(), .groups = \"drop\"\n  )\n\nggplot(pd_all, aes(x = x, y = prob)) +\n  geom_ribbon(aes(ymin = lower, ymax = upper), fill = \"#93C5FD\", alpha = 0.35) +\n  geom_line(color = \"#1D4ED8\", linewidth = 1) +\n  geom_jitter(\n    data = obs_raw, inherit.aes = FALSE,\n    aes(x = x, y = occ),\n    width = 0, height = 0.04, alpha = 0.25, size = 0.9, color = \"black\"\n  ) +\n  geom_point(\n    data = obs_bin, inherit.aes = FALSE,\n    aes(x = x_mid, y = occ_mean),\n    color = \"#111827\", size = 1.6\n  ) +\n  facet_wrap(~ variable, scales = \"free_x\") +\n  scale_y_continuous(limits = c(0, 1), labels = percent_format(accuracy = 1)) +\n  labs(\n    x = \"Значение предиктора (стандартизовано)\",\n    y = \"Вероятность присутствия\",\n    title = \"Унимодельные GAM (binomial): влияние предикторов\",\n    subtitle = \"Серые точки — фактические (джиттер); Черные точки — биновая средняя встречаемость\"\n  ) +\n  theme_minimal(base_size = 12)\n\n\n\n\nРис. 9.: Унимодельные GAM: влияние каждого предиктора\n\n\n\n# ========================================================================================================================\n# 5. ПОСТРОЕНИЕ ТАБЛИЦЫ НА ОСНОВЕ ГРАФИКОВ\n# ========================================================================================================================\n\n# Биннинг (20 квантильных бинов) и эмпирическая вероятность\nobs_raw &lt;- df %&gt;%\n  pivot_longer(cols = all_of(pred_vars), names_to = \"variable\", values_to = \"x\") %&gt;%\n  select(variable, x, occ)\n\nobs_bin &lt;- obs_raw %&gt;%\n  group_by(variable) %&gt;%\n  mutate(bin = cut_number(x, 20)) %&gt;%\n  group_by(variable, bin, .add = FALSE) %&gt;%\n  summarise(\n    bin_id = cur_group_id(),\n    x_min = min(x, na.rm = TRUE),\n    x_max = max(x, na.rm = TRUE),\n    x_mid = median(x, na.rm = TRUE),\n    n = n(),\n    occ_mean = mean(occ, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  arrange(variable, bin_id)\n\n# Обучение GAM моделей для таблицы\nfit_gam_uni_model &lt;- function(var_name) {\n  form &lt;- as.formula(paste0(\"occ ~ s(\", var_name, \", k=\", k_basis, \")\"))\n  fams &lt;- list(\n    binomial(link = \"identity\"),\n    binomial(link = \"probit\"),\n    binomial(link = \"logit\")\n  )\n  for (f in fams) {\n    m_try &lt;- try(gam(form, data = df, family = f, method = \"REML\", select = TRUE), silent = TRUE)\n    if (!inherits(m_try, \"try-error\")) return(m_try)\n  }\n  stop(paste(\"Не удалось обучить GAM для\", var_name))\n}\n\nmodels &lt;- suppressWarnings(set_names(map(pred_vars, fit_gam_uni_model), pred_vars))\n\n# Предсказания GAM в центрах бинов\ntable_20bins &lt;- obs_bin %&gt;%\n  group_by(variable) %&gt;%\n  group_modify(function(.x, .y) {\n    var &lt;- .y$variable[[1]]\n    mdl &lt;- models[[var]]\n    newd &lt;- tibble(!!rlang::sym(var) := .x$x_mid)\n    pr &lt;- predict(mdl, newdata = newd, type = \"link\", se.fit = TRUE)\n    inv &lt;- mdl$family$linkinv\n    mutate(\n      .x,\n      gam_prob  = pmin(pmax(inv(pr$fit), 0), 1),\n      gam_lower = pmin(pmax(inv(pr$fit - 1.96 * pr$se.fit), 0), 1),\n      gam_upper = pmin(pmax(inv(pr$fit + 1.96 * pr$se.fit), 0), 1),\n      link      = mdl$family$link\n    )\n  }) %&gt;%\n  ungroup() %&gt;%\n  select(variable, bin_id, x_min, x_max, x_mid, n, occ_mean, gam_prob, gam_lower, gam_upper, link)\n\n# Вывод таблицы\nprint(table_20bins, n = 5)\n\n# ========================================================================================================================\n# 6. ФОРМИРОВАНИЕ ФИНАЛЬНОЙ ТАБЛИЦЫ ДАННЫХ\n# ========================================================================================================================\n\n# Создание финальной таблицы с исходными данными\nfinal_table &lt;- DATA %&gt;%\n  janitor::clean_names() %&gt;%\n  select(x, y, occ, all_of(final_vars))\n\n# Сохранение результатов\nwrite.csv(final_table, \"final_sdm_table_with_na.csv\", row.names = FALSE)\n\n# Вывод структуры финальной таблицы\nstr(final_table)\n\n\n'data.frame':   44929 obs. of  11 variables:\n $ x                        : num  10 10.1 10.1 10.2 10.2 ...\n $ y                        : num  66 66 66 66 66 ...\n $ occ                      : int  NA NA NA NA NA NA NA NA NA NA ...\n $ dist                     : num  89.6 87.5 85.5 83.5 81.4 ...\n $ chlorophyll_range        : num  2.14 2.16 2.16 2.13 2.1 ...\n $ current_velocity_range   : num  0.0301 0.0204 0.0184 0.0123 0.0133 ...\n $ diffuse_attenuation_range: num  0.1 0.101 0.101 0.102 0.107 ...\n $ phosphate_range          : num  0.189 0.186 0.182 0.178 0.176 ...\n $ silicate_range           : num  4.25 4.03 3.77 3.63 3.58 ...\n $ slope                    : num  0.0765 0.1032 0.1524 0.2003 0.2112 ...\n $ temperature_mean         : num  7.37 7.39 7.41 7.43 7.43 ...\n&gt; \n\nНачнем с главного парадокса моделирования. Наш мозг жаждет простых причинно-следственных цепочек: «глубже — значит холоднее — значит вид там». Но реальная система — это сеть нелинейных, запутанных взаимодействий, где тот же фактор на разных уровнях может давать противоположные эффекты. Мы имеем дело с высокомерным предсказанием: пытаемся экстраполировать сложную экологическую реальность из ограниченной, зашумленной выборки. Задача второго скрипта — не «доказать» связь, а аккуратно, с помощью статистического инструментария, выявить устойчивые сигналы и честно оценить их силу и неопределенность.\nЧто было сделано: от сырых данных к структурированному пространству признаков Предобработка и «чистка» данных. Исходный датасет содержал 44 929 наблюдений (точек в сетке) и 46 переменных. Первым делом мы:\nУдалили пропуски в целевой переменной (occ — наличие вида), оставив 550 точек (35 присутствий, 515 отсутствий).\nПривели имена переменных к удобному формату, удалили координаты и заведомо малополезные переменные.\nИсключили предикторы с near-zero variance, которые не несут информационной нагрузки.\nПровели импутацию пропущенных значений в предикторах методом k-NN и стандартизацию данных (центрирование и scaling). Это важно для сравнения вклада переменных, измеренных в разных единицах.\nБитва с мультиколлинеарностью — устранение «зеркальных» переменных. Многие экологические предикторы тесно коррелируют друг с другом (например, разные производные от температуры). Если оставить их все в модели, они будут «делить» объясняющую силу, делая оценки ненадежными. Мы применили два последовательных фильтра:\nКорреляционный анализ: Удалили переменные с коэффициентом корреляции &gt; 0.8.\nАнализ VIF (Variance Inflation Factor): Итеративно исключали переменные с VIF &gt; 5, пока мультиколлинеарность не была устранена. Это оставило нас с набором из 20 переменных.\nОтбор признаков: Boruta vs. LASSO — «согласие двух свидетелей». Чтобы выбрать наиболее прогностические переменные, мы использовали два принципиально разных метода, подходя к задаче с разных сторон:\nBoruta (Random Forest based - обёртка для случайного леса): Алгоритм, который создает «теневые» переменные и сравнивает важность реальных переменных с этим случайным шумом. Он подтвердил важность 16 атрибутов.\nLASSO-регрессия: Метод, который «штрафует» модель за сложность, автоматически обнуляя веса наименее важных переменных. Он отобрал свой набор значимых предикторов.\nКонсенсус: Переменные, признанные важными обоими методами, были включены в финальную модель. Это наш «золотой набор» из 9 предикторов: dist (расстояние до берега), chlorophyll_range, current_velocity_range, diffuse_attenuation_mean, diffuse_attenuation_range, phosphate_range, silicate_range, slope (уклон дна),temperature_mean.\nАнализ важности переменных: Чей голос громче? По версии LASSO: Наибольший абсолютный вес (и, следовательно, влияние на вероятность присутствия) у переменной temperature_mean. Это краеугольный камень модели.\nПо версии Random Forest: Картина важности более сбалансирована. Метрики MeanDecreaseAccuracy и MeanDecreaseGini также подтверждают ведущую роль temperature_mean, но выделяют и вклад других переменных, таких как dist (дистанция до берега) и diffuse_attenuation_mean.\nЭто типичная ситуация: линейный метод (LASSO) выделяет одного «лидера», в то время как ансамблевый метод (RF) показывает, что прогноз — это результат коллективного решения комитета переменных.\nПостроение GAM: Где линейность ломается Generalized Additive Models (GAM) были выбраны для того, чтобы уловить нелинейные, плавные зависимости, которые линейные модели опишут грубо и с ошибкой.\nДля каждой из 9 отобранных переменных был построен унимодальный GAM (только с одним предиктором) с биномиальным распределением.\nДиагностика: Кривые зависимости вероятности присутствия от значения предиктора были визуализированы вместе с:\nДжиттером наблюдений: Фактическими точками данных (0 или 1), чтобы видеть raw data.\nБиновой эмпирической вероятностью: Усредненными значениями по 20-ти квантильным бинам, чтобы сгладить шум и увидеть реальный тренд.\nСигнал есть: Модель уверенно выявляет устойчивые паттерны взаимоотношения вида со средой. Пространственное распределение не случайно.\nВедущие драйверы: Распределение вида в наибольшей степени контролируется батиметрией и дистанцией от берега (dist, slope), что указывает на его бентальную природу и приуроченность к шельфовым местообитаниям.\nРоль гидрохимии: Второстепенную, но значимую роль играют динамические факторы, связанные с продуктивностью и динамикой вод (chlorophyll, diffuse_attenuation, phosphate).\nПодводные камни, на которые мы смотрим прямо Дисбаланс классов: Всего 35 присутствий на 515 отсутствий. Это могло сместить модель в сторону предсказания отсутствия. Мы компенсировали это использованием биномиальной семьи и внимательной диагностикой.\nЭкстраполяция: Модель обучена на ограниченном диапазоне условий. Предсказания за пределами этого диапазона (например, на очень больших глубинах) ненадежны. Это будет критически важно учитывать в третьем скрипте при прогнозе на будущее.\nСкрытая неопределенность: Диагностические графики (например, ширина доверительных интервалов на кривых GAM) показывают, что уверенность модели сильно варьирует в разных участках градиента переменных.\nЗаключение: Второй скрипт выполнил роль старателя, который не просто намыл песок, а нашел в нем крупицы золота — устойчивые статистические сигналы. Мы не утверждаем, что нашли истину в последней инстанции, но мы построили калиброванную, диагностированную и интерпретируемую модель, которая отражает наши лучшие на данный момент знания о взаимоотношениях вида со средой. Это надежный фундамент для следующего шага — ансамблевого прогнозирования.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>SDM: моделирование пространственного распределения видов</span>"
    ]
  },
  {
    "objectID": "chapter12.html#sdm-и-прогноз",
    "href": "chapter12.html#sdm-и-прогноз",
    "title": "13  SDM: моделирование пространственного распределения видов",
    "section": "13.4 SDM и прогноз",
    "text": "13.4 SDM и прогноз\nНиже приводится скрипт, а после него - его анализ.\n\n# ========================================================================================================================\n# ПРАКТИЧЕСКОЕ ЗАНЯТИЕ:  Модели пространственного распределения видов (SDM) с biomod2\n# \n# Автор: Баканев С. В.  | Обновлено: Sys.Date()\n# ========================================================================================================================\n\n# Библиотеки ------------------------------------------------------------------------------------------------------------ #\nsuppressPackageStartupMessages({\n  library(biomod2)\n  library(sf)\n  library(marmap)\n  library(dplyr)\n  library(tidyr)\n  library(purrr)\n  library(ggplot2)\n  library(readr)\n  library(pROC)\n  library(precrec)\n  library(ecospat)\n  library(dismo)\n  library(rnaturalearth)\n  library(ggspatial)\n  library(raster)\n})\n\n# Опции и воспроизводимость -------------------------------------------------------------------------------------------- #\noptions(stringsAsFactors = FALSE)\nset.seed(42)\n\n setwd(\"C:/SDM\")  # при необходимости\n\n# Хелперы устойчивые к ошибкам ------------------------------------------------------------------------------------------ #\nensure_dir &lt;- function(path) {\n  if (!dir.exists(path)) dir.create(path, recursive = TRUE, showWarnings = FALSE)\n}\n\nscale_predictions_01 &lt;- function(predictions_numeric) {\n  mx &lt;- suppressWarnings(max(predictions_numeric, na.rm = TRUE))\n  if (is.finite(mx) && mx &gt; 1.5) return(pmin(pmax(predictions_numeric / 1000, 0), 1))\n  pmin(pmax(predictions_numeric, 0), 1)\n}\n\ncalibration_table &lt;- function(labels_binary, probs_01, num_bins = 10) {\n  stopifnot(length(labels_binary) == length(probs_01))\n  idx &lt;- is.finite(probs_01) & is.finite(labels_binary)\n  labels_binary &lt;- as.integer(labels_binary[idx])\n  probs_01 &lt;- as.numeric(probs_01[idx])\n  keep &lt;- labels_binary %in% c(0, 1)\n  labels_binary &lt;- labels_binary[keep]\n  probs_01 &lt;- probs_01[keep]\n  if (!length(probs_01)) return(list(table = tibble(), brier = NA_real_, ece = NA_real_))\n  breaks &lt;- seq(0, 1, length.out = num_bins + 1)\n  bin_id &lt;- cut(probs_01, breaks = breaks, include.lowest = TRUE, labels = FALSE)\n  mids &lt;- (breaks[-length(breaks)] + breaks[-1]) / 2\n  tb &lt;- tibble(bin_id = bin_id, prob = probs_01, label = labels_binary) %&gt;%\n    group_by(bin_id) %&gt;%\n    summarise(\n      bin_mid = mids[unique(bin_id)],\n      prob_mean = mean(prob, na.rm = TRUE),\n      obs_rate = mean(label, na.rm = TRUE),\n      n = dplyr::n(),\n      .groups = \"drop\"\n    ) %&gt;% arrange(bin_id)\n  brier &lt;- mean((probs_01 - labels_binary)^2, na.rm = TRUE)\n  ece &lt;- sum((tb$n / sum(tb$n)) * abs(tb$obs_rate - tb$prob_mean))\n  list(table = tb, brier = brier, ece = ece)\n}\n\nplot_calibration &lt;- function(tbl, title = \"Калибровка (reliability)\") {\n  ggplot(tbl, aes(x = prob_mean, y = obs_rate, size = n)) +\n    geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray50\") +\n    geom_point(color = \"#2C7FB8\", alpha = 0.85) +\n    scale_size_continuous(name = \"N\") +\n    coord_fixed(xlim = c(0, 1), ylim = c(0, 1)) +\n    labs(x = \"Средняя предсказанная вероятность\", y = \"Наблюдаемая доля присутствий\", title = title) +\n    theme_minimal(base_size = 12)\n}\n\nroc_pr_metrics &lt;- function(labels_binary, probs_01) {\n  idx &lt;- is.finite(probs_01) & is.finite(labels_binary)\n  labels_binary &lt;- as.integer(labels_binary[idx])\n  probs_01 &lt;- as.numeric(probs_01[idx])\n  keep &lt;- labels_binary %in% c(0, 1)\n  labels_binary &lt;- labels_binary[keep]\n  probs_01 &lt;- probs_01[keep]\n  if (length(unique(labels_binary)) &lt; 2) {\n    return(list(roc = NULL, auc_roc = NA_real_, pr = NULL, auc_pr = NA_real_))\n  }\n  roc_obj &lt;- tryCatch(pROC::roc(response = labels_binary, predictor = probs_01, quiet = TRUE), error = function(e) NULL)\n  auc_roc &lt;- if (!is.null(roc_obj)) as.numeric(pROC::auc(roc_obj)[1]) else NA_real_\n  pr_obj &lt;- tryCatch(precrec::evalmod(scores = probs_01, labels = labels_binary), error = function(e) NULL)\n  auc_pr &lt;- if (!is.null(pr_obj)) {\n    dd &lt;- precrec::auc(pr_obj)\n    as.numeric(dd %&gt;% dplyr::filter(curvetypes == \"PRC\") %&gt;% dplyr::pull(aucs))\n  } else NA_real_\n  list(roc = roc_obj, auc_roc = auc_roc, pr = pr_obj, auc_pr = auc_pr)\n}\n\nplot_roc_curve &lt;- function(roc_obj, title = \"ROC кривая\") {\n  if (is.null(roc_obj)) return(ggplot() + labs(title = paste(title, \"(недостаточно классов)\")))\n  pROC::ggroc(roc_obj, colour = \"#1B9E77\", size = 1) +\n    geom_abline(slope = 1, intercept = 1, linetype = \"dashed\", color = \"gray50\") +\n    coord_equal(xlim = c(1, 0), ylim = c(0, 1)) +\n    labs(x = \"1 - Specificity\", y = \"Sensitivity\", title = title) +\n    theme_minimal(base_size = 12)\n}\n\nplot_pr_curve &lt;- function(pr_obj, title = \"PR кривая\") {\n  if (is.null(pr_obj)) return(ggplot() + labs(title = paste(title, \"(недостаточно классов)\")))\n  autoplot(pr_obj) + labs(title = title) + theme_minimal(base_size = 12)\n}\n\noptimal_threshold_tss &lt;- function(labels_binary, probs_01, step = 0.01) {\n  thresholds &lt;- seq(0, 1, by = step)\n  idx &lt;- is.finite(probs_01) & is.finite(labels_binary)\n  labels_binary &lt;- as.integer(labels_binary[idx])\n  probs_01 &lt;- as.numeric(probs_01[idx])\n  keep &lt;- labels_binary %in% c(0, 1)\n  labels_binary &lt;- labels_binary[keep]\n  probs_01 &lt;- probs_01[keep]\n  if (!length(probs_01)) {\n    return(data.frame(threshold = NA_real_, TSS = NA_real_, Sensitivity = NA_real_, Specificity = NA_real_))\n  }\n  metrics &lt;- lapply(thresholds, function(th) {\n    pred_class &lt;- as.integer(probs_01 &gt;= th)\n    tp &lt;- sum(pred_class == 1 & labels_binary == 1)\n    tn &lt;- sum(pred_class == 0 & labels_binary == 0)\n    fp &lt;- sum(pred_class == 1 & labels_binary == 0)\n    fn &lt;- sum(pred_class == 0 & labels_binary == 1)\n    tpr &lt;- ifelse((tp + fn) &gt; 0, tp / (tp + fn), NA_real_)\n    tnr &lt;- ifelse((tn + fp) &gt; 0, tn / (tn + fp), NA_real_)\n    c(threshold = th, TSS = (tpr + tnr - 1), Sensitivity = tpr, Specificity = tnr)\n  })\n  m &lt;- do.call(rbind, metrics)\n  m &lt;- as.data.frame(m)\n  m$threshold &lt;- as.numeric(m$threshold)\n  m$TSS &lt;- as.numeric(m$TSS)\n  m$Sensitivity &lt;- as.numeric(m$Sensitivity)\n  m$Specificity &lt;- as.numeric(m$Specificity)\n  best_row &lt;- m[which.max(m$TSS), , drop = FALSE]\n  best_row\n}\n\nboyce_index &lt;- function(labels_binary, probs_01, num_class = 0, window_w = NULL) {\n  idx &lt;- is.finite(probs_01) & is.finite(labels_binary)\n  labels_binary &lt;- as.integer(labels_binary[idx])\n  probs_01 &lt;- as.numeric(probs_01[idx])\n  pres &lt;- probs_01[labels_binary == 1]\n  back &lt;- probs_01\n  tryCatch({\n    res &lt;- ecospat::ecospat.boyce(fit = back, obs = pres, nclass = num_class, window.w = window_w)\n    list(CBI = as.numeric(res$Spearman.cor), curve = res$F.ratio)\n  }, error = function(e) list(CBI = NA_real_, curve = NULL))\n}\n\nuncertainty_per_point &lt;- function(pred_long_df) {\n  # Ожидаем столбцы: run, algo, points, pred\n  if (!all(c(\"points\", \"pred\") %in% names(pred_long_df))) {\n    stop(\"Для неопределенности нужен длинный формат с колонками 'points' и 'pred'.\")\n  }\n  run_levels &lt;- unique(pred_long_df$run)\n  run_pick &lt;- if (\"allRun\" %in% run_levels) \"allRun\" else run_levels[1]\n  df &lt;- subset(pred_long_df, run == run_pick)\n  # Агрегируем по точкам: SD и среднее по всем алгоритмам\n  agg_sd &lt;- aggregate(pred ~ points, data = df, FUN = function(x) sd(as.numeric(x), na.rm = TRUE))\n  names(agg_sd)[2] &lt;- \"UNC_SD\"\n  agg_mean &lt;- aggregate(pred ~ points, data = df, FUN = function(x) mean(as.numeric(x), na.rm = TRUE))\n  names(agg_mean)[2] &lt;- \"MEAN_PRED\"\n  unc &lt;- merge(agg_sd, agg_mean, by = \"points\", all = TRUE)\n  unc$UNC_CV &lt;- unc$UNC_SD / ifelse(unc$MEAN_PRED == 0, NA, unc$MEAN_PRED)\n  unc\n}\n\nmess_scores &lt;- function(reference_env_df, target_env_df) {\n  tryCatch({\n    as.numeric(dismo::mess(x = as.data.frame(target_env_df), v = as.data.frame(reference_env_df)))\n  }, error = function(e) rep(NA_real_, nrow(target_env_df)))\n}\n\n# ДАННЫЕ: текущее состояние -------------------------------------------------------------------------------------------- #\nDATA &lt;- read.csv(\"final_sdm_table_with_na.csv\")\nstr(DATA)\n\n'data.frame':   44929 obs. of  11 variables:\n $ x                        : num  10 10.1 10.1 10.2 10.2 ...\n $ y                        : num  66 66 66 66 66 ...\n $ occ                      : int  NA NA NA NA NA NA NA NA NA NA ...\n $ dist                     : num  89.6 87.5 85.5 83.5 81.4 ...\n $ chlorophyll_range        : num  2.14 2.16 2.16 2.13 2.1 ...\n $ current_velocity_range   : num  0.0301 0.0204 0.0184 0.0123 0.0133 ...\n $ diffuse_attenuation_range: num  0.1 0.101 0.101 0.102 0.107 ...\n $ phosphate_range          : num  0.189 0.186 0.182 0.178 0.176 ...\n $ silicate_range           : num  4.25 4.03 3.77 3.63 3.58 ...\n $ slope                    : num  0.0765 0.1032 0.1524 0.2003 0.2112 ...\n $ temperature_mean         : num  7.37 7.39 7.41 7.43 7.43 ...\n\nDataSpecies &lt;- as.data.frame(DATA)\nmyRespName &lt;- 'occ'\nmyResp &lt;- as.numeric(DataSpecies[[myRespName]])\nmyRespXY &lt;- DataSpecies[, c(\"x\", \"y\")]\nmyExpl &lt;- DataSpecies[, 4:11]\n\nmyBiomodData &lt;- BIOMOD_FormatingData(\n  resp.var = myResp,\n  expl.var = myExpl,\n  resp.xy = myRespXY,\n  resp.name = myRespName\n)\n\n\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= occ Data Formating -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n\n      ! No data has been set aside for modeling evaluation\n ! Some NAs have been automatically removed from your data\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-= Done -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n\nprint(myBiomodData)\n\n\n-=-=-=-=-=-=-=-=-=-=-=-=-=-= BIOMOD.formated.data -=-=-=-=-=-=-=-=-=-=-=-=-=-=\n\ndir.name =  .\n\nsp.name =  occ\n\n     35 presences,  515 true absences and  43970 undefined points in dataset\n\n\n     8 explanatory variables\n\n      dist        chlorophyll_range current_velocity_range\n Min.   :  0.00   Min.   :0.8033    Min.   :3.900e-07     \n 1st Qu.: 29.25   1st Qu.:1.7376    1st Qu.:1.394e-02     \n Median : 85.09   Median :1.9896    Median :3.461e-02     \n Mean   :108.12   Mean   :2.0218    Mean   :5.922e-02     \n 3rd Qu.:171.22   3rd Qu.:2.3441    3rd Qu.:7.576e-02     \n Max.   :370.42   Max.   :3.6717    Max.   :6.866e-01     \n diffuse_attenuation_range phosphate_range   silicate_range    \n Min.   :0.00219           Min.   :0.02029   Min.   :  0.8998  \n 1st Qu.:0.10350           1st Qu.:0.17822   1st Qu.:  2.6714  \n Median :0.13125           Median :0.26244   Median :  4.2001  \n Mean   :0.15390           Mean   :0.26352   Mean   :  5.8540  \n 3rd Qu.:0.17859           3rd Qu.:0.34718   3rd Qu.:  5.6003  \n Max.   :1.13555           Max.   :1.06630   Max.   :150.8238  \n     slope          temperature_mean \n Min.   : 0.00000   Min.   :-0.9655  \n 1st Qu.: 0.06876   1st Qu.: 1.4951  \n Median : 0.15116   Median : 3.5395  \n Mean   : 0.37223   Mean   : 3.4536  \n 3rd Qu.: 0.36902   3rd Qu.: 5.8108  \n Max.   :10.47394   Max.   : 9.0227  \n\n-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n\nplot(myBiomodData)\n\nЗагрузка требуемого пакета: ggtext\n\n\n\n\n\n\n\n\n\n$data.vect\n class       : SpatVector \n geometry    : points \n dimensions  : 550, 2  (geometries, attributes)\n extent      : 12.075, 44.925, 66.375, 71.975  (xmin, xmax, ymin, ymax)\n coord. ref. :  \n names       :  resp         dataset\n type        : &lt;num&gt;           &lt;chr&gt;\n values      :    10 Initial dataset\n                  10 Initial dataset\n                  10 Initial dataset\n\n$data.label\n                              9                              10 \n                \"**Presences**\"       \"Presences (calibration)\" \n                             11                              12 \n       \"Presences (validation)\"        \"Presences (evaluation)\" \n                             19                              20 \n            \"**True Absences**\"   \"True Absences (calibration)\" \n                             21                              22 \n   \"True Absences (validation)\"    \"True Absences (evaluation)\" \n                             29                              30 \n          \"**Pseudo-Absences**\" \"Pseudo-Absences (calibration)\" \n                             31                               1 \n \"Pseudo-Absences (validation)\"                    \"Background\" \n\n$data.plot\n\n\n\n\n\n\n\n\n\n\n\n\nРис. 10.: Входные данные по встречаемости\n\n\n\n# ОБУЧЕНИЕ ЕДИНИЧНЫХ МОДЕЛЕЙ ------------------------------------------------------------------------------------------- #\nalgos &lt;- c(\"ANN\", \"CTA\", \"FDA\", \"GAM\", \"GBM\", \"GLM\", \"MAXENT\", \"MAXNET\", \"RF\", \"XGBOOST\")\n# Уберем MAXENT, если нет maxent.jar рядом с рабочей директорией\nif (!file.exists(file.path(getwd(), \"maxent.jar\"))) {\n  algos &lt;- setdiff(algos, \"MAXENT\")\n}\n\nmyBiomodModelOut &lt;- BIOMOD_Modeling(\n  bm.format = myBiomodData,\n  modeling.id = 'AllModels',\n  models = algos,\n  CV.strategy = 'random',\n  CV.nb.rep = 2,\n  CV.perc = 0.8,\n  OPT.strategy = 'bigboss',\n  metric.eval = c('TSS','ROC'),\n  var.import = 2,\n  seed.val = 42\n)\nprint(myBiomodModelOut)\n\n# Оценки и важности\nstr(get_evaluations(myBiomodModelOut))\nstr(get_variables_importance(myBiomodModelOut))\n&gt; str(get_evaluations(myBiomodModelOut))\n'data.frame':   48 obs. of  11 variables:\n $ full.name  : chr  \"occ_allData_RUN1_ANN\" \"occ_allData_RUN1_ANN\" \"occ_allData_RUN1_CTA\" \"occ_allData_RUN1_CTA\" ...\n $ PA         : chr  \"allData\" \"allData\" \"allData\" \"allData\" ...\n $ run        : chr  \"RUN1\" \"RUN1\" \"RUN1\" \"RUN1\" ...\n $ algo       : chr  \"ANN\" \"ANN\" \"CTA\" \"CTA\" ...\n $ metric.eval: chr  \"TSS\" \"ROC\" \"TSS\" \"ROC\" ...\n $ cutoff     : num  966 972 421 426 756 ...\n $ sensitivity: num  100 100 100 100 96.4 ...\n $ specificity: num  98.2 98.2 82.5 82.5 94.8 ...\n $ calibration: num  0.982 0.987 0.826 0.913 0.912 0.977 0.98 0.992 0.934 0.979 ...\n $ validation : num  0.411 0.909 0.677 0.839 0.804 0.972 0.694 0.915 0.789 0.97 ...\n $ evaluation : num  NA NA NA NA NA NA NA NA NA NA ...\n&gt; str(get_variables_importance(myBiomodModelOut))\n'data.frame':   384 obs. of  7 variables:\n $ full.name: chr  \"occ_allData_RUN1_ANN\" \"occ_allData_RUN1_ANN\" \"occ_allData_RUN1_ANN\" \"occ_allData_RUN1_ANN\" ...\n $ PA       : chr  \"allData\" \"allData\" \"allData\" \"allData\" ...\n $ run      : chr  \"RUN1\" \"RUN1\" \"RUN1\" \"RUN1\" ...\n $ algo     : chr  \"ANN\" \"ANN\" \"ANN\" \"ANN\" ...\n $ expl.var : chr  \"dist\" \"chlorophyll_range\" \"current_velocity_range\" \"diffuse_attenuation_range\" \n $ rand     : int  1 1 1 1 1 1 1 1 2 2 ...\n $ var.imp  : num  0.8326 0.1984 0.1621 0.0672 0.0783 ...\n&gt; \n\nbm_PlotEvalMean(bm.out = myBiomodModelOut, dataset = 'calibration')\n\n\n\n\nРис. 11.: ROC vs TSS (calibration)\n\n\n\nbm_PlotEvalMean(bm.out = myBiomodModelOut, dataset = 'validation')\n\n\n\n\nРис. 12.: ROC vs TSS (validation)",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>SDM: моделирование пространственного распределения видов</span>"
    ]
  },
  {
    "objectID": "chapter12.html#основные-понятия",
    "href": "chapter12.html#основные-понятия",
    "title": "13  SDM: моделирование пространственного распределения видов",
    "section": "13.5 Основные понятия",
    "text": "13.5 Основные понятия\nROC (Receiver Operating Characteristic) и TSS (True Skill Statistic) — это метрики для оценки качества моделей распределения видов, которые предсказывают, где может обитать вид (1 - присутствует, 0 - отсутствует).",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>SDM: моделирование пространственного распределения видов</span>"
    ]
  },
  {
    "objectID": "chapter12.html#roc-vs-tss-калибровка-calibration",
    "href": "chapter12.html#roc-vs-tss-калибровка-calibration",
    "title": "13  SDM: моделирование пространственного распределения видов",
    "section": "13.6 ROC vs TSS: Калибровка (Calibration)",
    "text": "13.6 ROC vs TSS: Калибровка (Calibration)\n\n13.6.1 ROC (кривая рабочих характеристик приемника)\n\nЧто это: График, показывающий соотношение между долей правильных обнаружений (True Positive Rate) и долей ложных тревог (False Positive Rate) при различных порогах классификации\nКак читать:\n\nПлощадь под кривой (AUC) от 0.5 до 1.0\n0.5 — модель не лучше случайного угадывания\n0.7-0.8 — acceptable (приемлемо)\n0.8-0.9 — excellent (отлично)\n\n\n0.9 — outstanding (превосходно)\n\n\n\n\n\n\n13.6.2 TSS (истинная статистика навыка)\n\nЧто это: Метрика, которая учитывает как правильные обнаружения, так и правильные определения отсутствия\nФормула: TSS = Sensitivity + Specificity - 1\nДиапазон: от -1 до +1\n\n≤0 — модель не лучше случайной\n0.4-0.6 — хорошая модель\n0.6-0.8 — очень хорошая модель\n\n\n0.8 — отличная модель\n\n\n\n\n\n\n13.6.3 Ключевые различия при калибровке:\n\n\n\n\n\n\n\n\nКритерий\nROC\nTSS\n\n\n\n\nЗависимость от prevalence\nНе зависит\nНе зависит\n\n\nУчет баланса классов\nСлабее\nСильнее\n\n\nИнтерпретация\nОбщее качество\nСбалансированная точность\n\n\nЧувствительность к дисбалансу\nНизкая\nСредняя",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>SDM: моделирование пространственного распределения видов</span>"
    ]
  },
  {
    "objectID": "chapter12.html#roc-vs-tss-валидация-validation",
    "href": "chapter12.html#roc-vs-tss-валидация-validation",
    "title": "13  SDM: моделирование пространственного распределения видов",
    "section": "13.7 ROC vs TSS: Валидация (Validation)",
    "text": "13.7 ROC vs TSS: Валидация (Validation)\n\n13.7.1 При валидации на независимых данных:\nROC чаще используется когда:\n\nНабор данных сильно несбалансирован\nВажнее оценить общую производительность модели\nНет четкого порога классификации\n\nTSS предпочтительнее когда:\n\nНужно выбрать оптимальный порог классификации\nВажны как правильные обнаружения, так и правильные определения отсутствия\nДанные относительно сбалансированы\n\n\nbm_PlotEvalBoxplot(bm.out = myBiomodModelOut, group.by = c('algo', 'run'))\n\n\n\n\nРис. 13.: Входные данные по встречаемости\n\n\n\n# ПРОГНОЗ: текущее состояние -------------------------------------------------------------------------------------------- #\nmyBiomodProj &lt;- BIOMOD_Projection(\n  bm.mod = myBiomodModelOut,\n  proj.name = 'Current',\n  new.env = myExpl,\n  models.chosen = 'all'\n)\n\n# Предсказания единичных моделей (long)\npred_current_single &lt;- get_predictions(myBiomodProj)\nprint(head(pred_current_single))\n\n# АНСАМБЛИРОВАНИЕ И ПРОГНОЗ АНСАМБЛЯ ----------------------------------------------------------------------------------- #\nmyBiomodEM &lt;- BIOMOD_EnsembleModeling(\n  bm.mod = myBiomodModelOut,\n  models.chosen = 'all',\n  em.by = 'all',\n  em.algo = c('EMmean', 'EMca'),\n  metric.select = c('TSS'),\n  metric.select.thresh = c(0.4),\n  metric.eval = c('TSS', 'ROC'),\n  var.import = 3,\n  seed.val = 42\n)\nstr(get_evaluations(myBiomodEM))\nstr(get_variables_importance(myBiomodEM))\n&gt; str(get_evaluations(myBiomodEM))\n'data.frame':   4 obs. of  13 variables:\n $ full.name     : chr  \"occ_EMmeanByTSS_mergedData_mergedRun_mergedAlgo\" \"occ_EMmeanByTSS_mergedData_mergedRun_mergedAlgo\" \"occ_EMcaByTSS_mergedData_mergedRun_mergedAlgo\" \"occ_EMcaByTSS_mergedData_mergedRun_mergedAlgo\"\n $ merged.by.PA  : chr  \"mergedData\" \"mergedData\" \"mergedData\" \"mergedData\"\n $ merged.by.run : chr  \"mergedRun\" \"mergedRun\" \"mergedRun\" \"mergedRun\"\n $ merged.by.algo: chr  \"mergedAlgo\" \"mergedAlgo\" \"mergedAlgo\" \"mergedAlgo\"\n $ filtered.by   : chr  \"TSS\" \"TSS\" \"TSS\" \"TSS\"\n $ algo          : chr  \"EMmean\" \"EMmean\" \"EMca\" \"EMca\"\n $ metric.eval   : chr  \"TSS\" \"ROC\" \"TSS\" \"ROC\"\n $ cutoff        : num  607 608 732 730\n $ sensitivity   : num  97.1 97.1 97.1 97.1\n $ specificity   : num  96.6 96.6 97.2 97.2\n $ calibration   : num  0.937 0.99 0.943 0.994\n $ validation    : num  NA NA NA NA\n $ evaluation    : num  NA NA NA NA\n&gt; str(get_variables_importance(myBiomodEM))\n'data.frame':   48 obs. of  9 variables:\n $ full.name     : chr  \"occ_EMmeanByTSS_mergedData_mergedRun_mergedAlgo\" \"occ_EMmeanByTSS_mergedData_mergedRun_mergedAlgo\" \"occ_EMmeanByTSS_mergedData_mergedRun_mergedAlgo\" \"occ_EMmeanByTSS_mergedData_mergedRun_mergedAlgo\" ...\n $ merged.by.PA  : chr  \"mergedData\" \"mergedData\" \"mergedData\" \"mergedData\" ...\n $ merged.by.run : chr  \"mergedRun\" \"mergedRun\" \"mergedRun\" \"mergedRun\" ...\n $ merged.by.algo: chr  \"mergedAlgo\" \"mergedAlgo\" \"mergedAlgo\" \"mergedAlgo\" ...\n $ filtered.by   : chr  \"TSS\" \"TSS\" \"TSS\" \"TSS\" ...\n $ algo          : chr  \"EMmean\" \"EMmean\" \"EMmean\" \"EMmean\" ...\n $ expl.var      : chr  \"dist\" \"chlorophyll_range\" \"current_velocity_range\" \"diffuse_attenuation_range\" ...\n $ rand          : int  1 1 1 1 1 1 1 1 2 2 ...\n $ var.imp       : num  0.74975 0.01052 0.01369 0.00352 0.01036 ...\n&gt; \nmyBiomodEMProj &lt;- BIOMOD_EnsembleForecasting(\n  bm.em = myBiomodEM,\n  bm.proj = myBiomodProj,\n  models.chosen = 'all',\n  metric.binary = 'all',\n  metric.filter = 'all'\n)\n\npred_current_em &lt;- get_predictions(myBiomodEMProj)\npred_current_emmean &lt;- dplyr::filter(pred_current_em, .data$algo == \"EMmean\")\nprint(head(pred_current_emmean))\n\n# КАРТЫ: текущий период ------------------------------------------------------------------------------------------------ #\nMAPDATA &lt;- tibble(\n  point_id = seq_len(nrow(DATA)),\n  X = DATA$x,\n  Y = DATA$y,\n  PRED = pred_current_emmean$pred\n)\n\nworld &lt;- rnaturalearth::ne_countries(scale = 50, returnclass = 'sf')\nxmin &lt;- 10; xmax &lt;- 45; ymin &lt;- 66; ymax &lt;- 72\n\nbat &lt;- tryCatch(getNOAA.bathy(xmin, xmax, ymin, ymax, resolution = 4), error = function(e) NULL)\nbat_xyz &lt;- if (!is.null(bat)) as.xyz(bat) else NULL\n\np_points &lt;- ggplot() +\n  geom_sf(data = world) +\n  coord_sf(xlim = c(xmin, xmax), ylim = c(ymin, ymax)) +\n  {if (!is.null(bat_xyz)) geom_tile(data = bat_xyz, aes(x = V1, y = V2, fill = V3), show.legend = FALSE)} +\n  geom_point(data = MAPDATA, aes(x = X, y = Y, size = PRED), color = \"black\", fill = \"white\", shape = 21, alpha=0.8) +\n  ggspatial::annotation_scale(location = \"tr\", width_hint = 0.5) +\n  scale_size(name = \"Вероятность\", range = c(1, 5)) +\n  labs(title = \"Точки: интенсивность предсказания (Current)\")\n\np_raster &lt;- ggplot() +\n  geom_raster(data = MAPDATA, aes(x = X, y = Y, fill = PRED), interpolate = FALSE) +\n  scale_fill_viridis_c(option = \"D\", name = \"PRED\") +\n  geom_sf(data = world, color = \"gray30\", fill = \"#E8E5D6\", lwd = 0.3) +\n  coord_sf(xlim = c(xmin*1.2, xmax*0.96), ylim = c(ymin*1.02, ymax*0.99)) +\n  labs(title = \"Растер: предсказание EMmean (Current)\")\n\nprint(p_points)\nprint(p_raster)\n\n\n\n\nРис. 14.: Визуалицация SDM - индекс пригодности среды или вероятность встречаемости вида\n\n\n\n# ДИАГНОСТИКА НАДЕЖНОСТИ: текущее -------------------------------------------------------------------------------------- #\nlabels &lt;- as.integer(myResp)\nprobs_current_01 &lt;- scale_predictions_01(pred_current_emmean$pred)\n\ncalib &lt;- calibration_table(labels, probs_current_01, num_bins = 10)\nprint(calib$table)\nprint(plot_calibration(calib$table) + labs(subtitle = sprintf(\"Brier = %.3f, ECE = %.3f\", calib$brier, calib$ece)))\n\n\n\n\nРис. 15.: График калибровки\n\n\nГрафик калибровки показывает соответствие между предсказанными вероятностями модели и фактической частотой наблюдений. По оси X откладывается средняя предсказанная вероятность в каждом интервале, то есть то, что модель предполагает, а по оси Y — фактическая доля наблюдений, то что происходит в реальности. Идеальная калибровка represented by диагональная линия, где предсказания полностью совпадают с реальностью. Если точки графика лежат выше диагонали, это означает что модель недооценивает вероятность события — она предсказывает меньшую вероятность чем фактическая частота. Если точки ниже диагонали — модель переоценивает вероятность, giving завышенные прогнозы. В подзаголовке указаны две ключевые метрики: оценка Брайера и ожидаемая ошибка калибровки. Оценка Брайера измеряет среднюю квадратичную ошибку предсказаний и колеблется от 0 до 1, где 0 означает идеальную калибровку, а значения ниже 0.1 считаются хорошими. Ожидаемая ошибка калибровки также стремится к нулю при идеальной калибровке и показывает среднее отклонение от идеального соответствия. Этот анализ позволяет оценить надежность вероятностных выводов модели и необходимость дополнительной калибровки для улучшения прогнозов, что особенно важно в экологических исследованиях где точность прогнозов влияет на принятие решений по охране видов и управлению биоресурсами.\n\nrp &lt;- roc_pr_metrics(labels, probs_current_01)\nprint(plot_roc_curve(rp$roc) + labs(subtitle = sprintf(\"AUC = %.3f\", rp$auc_roc)))\nprint(plot_pr_curve(rp$pr) + labs(subtitle = sprintf(\"AUPRC = %.3f\", rp$auc_pr)))\n\n\n\n\nРис. 16.: График ROC-кривой и Precision-Recall\n\n\nГрафик ROC-кривой показывает соотношение между долей правильных обнаружений и долей ложных срабатываний при различных порогах классификации где идеальная модель стремится к левому верхнему углу что означает максимальную чувствительность при минимальных ложных тревогах. Площадь под кривой AUC количественно измеряет качество классификации где значение 0.5 соответствует случайному угадыванию а значение 1.0 представляет собой идеальное разделение классов при этом в экологических исследованиях значения выше 0.7 считаются приемлемыми а выше 0.8 — хорошими. График Precision-Recall демонстрирует компромисс между точностью предсказаний и полнотой охвата где высокая точность означает минимум ложных обнаружений а высокая полнота указывает на способность модели найти все реальные случаи присутствия вида. Площадь под PR-кривой AUPRC особенно важна при работе с несбалансированными данными так как она игнорирует правильно предсказанные отсутствия и фокусируется на качестве предсказания присутствий где значение 0.5 соответствует базовому уровню а значения близкие к 1.0 указывают на отличное качество модели. Вместе эти метрики обеспечивают комплексную оценку производительности модели учитывая как способность различать классы так и надежность предсказаний положительных случаев что критически важно для принятия решений в задачах экологического моделирования и прогнозирования распределения видов.\n\nopt_thr &lt;- optimal_threshold_tss(labels, probs_current_01, step = 0.005)\nprint(opt_thr)\n\nboy &lt;- boyce_index(labels, probs_current_01)\nprint(tibble(metric = \"Continuous Boyce Index\", value = boy$CBI))\n\n# НЕОПРЕДЕЛЕННОСТЬ МЕЖДУ АЛГОРИТМАМИ (SD, CV) -------------------------------------------------------------------------- #\nunc &lt;- uncertainty_per_point(pred_current_single)\nMAPDATA_unc &lt;- MAPDATA %&gt;% left_join(unc %&gt;% transmute(point_id = points, UNC_SD, UNC_CV), by = \"point_id\")\n\np_unc_sd &lt;- ggplot(MAPDATA_unc, aes(x = X, y = Y, fill = UNC_SD)) +\n  geom_raster() +\n  scale_fill_viridis_c(option = \"C\", name = \"SD\") +\n  coord_equal() +\n  labs(title = \"Неопределенность (SD) между алгоритмами — Current\")\n\nprint(p_unc_sd)\n\n\n\n\nРис. 17.: Неопределенность (SD) между алгоритмами — Current\n\n\n\n# БУДУЩЕЕ: данные, прогноз и диагностика -------------------------------------------------------------------------------- #\nDATA_F &lt;- read.csv(\"future_sdm_table_with_na.csv\")\nstr(DATA_F)\nDataSpeciesF &lt;- as.data.frame(DATA_F)\nmyRespF &lt;- as.numeric(DataSpeciesF[[myRespName]])\nmyRespXYF &lt;- DataSpeciesF[, c(\"x\", \"y\")]\nmyExplP1 &lt;- DataSpeciesF[, 4:11]\n\nmyBiomodProj1 &lt;- BIOMOD_Projection(\n  bm.mod = myBiomodModelOut,\n  proj.name = 'Future',\n  new.env = myExplP1,\n  models.chosen = 'all'\n)\n\nmyBiomodEMProj1 &lt;- BIOMOD_EnsembleForecasting(\n  bm.em = myBiomodEM,\n  bm.proj = myBiomodProj1,\n  models.chosen = 'all',\n  metric.binary = 'all',\n  metric.filter = 'all'\n)\n\npred_future_em &lt;- get_predictions(myBiomodEMProj1)\npred_future_emmean &lt;- dplyr::filter(pred_future_em, .data$algo == \"EMmean\")\n\nMAPDATA2 &lt;- tibble(\n  point_id = seq_len(nrow(DATA_F)),\n  X = DATA_F$x,\n  Y = DATA_F$y,\n  PRED = pred_future_emmean$pred\n)\n\n# Карты: будущее и Δ ---------------------------------------------------------------------------------------------------- #\np_points2 &lt;- ggplot() +\n  geom_sf(data = world) +\n  coord_sf(xlim = c(xmin, xmax), ylim = c(ymin, ymax)) +\n  {if (!is.null(bat_xyz)) geom_tile(data = bat_xyz, aes(x = V1, y = V2, fill = V3), show.legend = FALSE)} +\n  geom_point(data = MAPDATA2, aes(x = X, y = Y, size = PRED), color = \"black\", fill = \"white\", shape = 21, alpha=0.8) +\n  ggspatial::annotation_scale(location = \"tr\", width_hint = 0.5) +\n  scale_size(name = \"Вероятность\", range = c(1, 5)) +\n  labs(title = \"Точки: EMmean (Future)\")\n\np_raster2 &lt;- ggplot() +\n  geom_raster(data = MAPDATA2, aes(x = X, y = Y, fill = PRED)) +\n  scale_fill_viridis_c(option = \"D\", name = \"PRED\") +\n  geom_sf(data = world, color = \"gray30\", fill = \"#E8E5D6\", lwd = 0.3) +\n  coord_sf(xlim = c(xmin*1.2, xmax*0.96), ylim = c(ymin*1.01, ymax*0.99)) +\n  labs(title = \"Растер: EMmean (Future)\")\n\nprobs_future_01 &lt;- scale_predictions_01(pred_future_emmean$pred)\nprobs_current_01 &lt;- scale_predictions_01(pred_current_emmean$pred)\nMAPDATA_delta &lt;- tibble(X = MAPDATA$X, Y = MAPDATA$Y, delta = probs_future_01 - probs_current_01)\n\np_delta &lt;- ggplot(MAPDATA_delta, aes(x = X, y = Y, fill = delta)) +\n  geom_raster() +\n  scale_fill_gradient2(low = \"#D7301F\", mid = \"#FFFFBF\", high = \"#1A9850\", midpoint = 0, name = \"Delta Prob\") +\n  coord_equal() +\n  labs(title = \"Delta (Future − Current) EMmean (scaled)\")\n\nprint(p_points2)\nprint(p_raster2)\n\n\n\n\nРис. 18.: Вероятность встречаемости большого гребешка в 2100 г.\n\n\n\nprint(p_delta)\n\n Это карта изменений (дельты) в распределении вероятности присутствия вида между будущим и текущим сценарием. На карте визуализируется разница между прогнозируемой вероятностью в будущем и текущей вероятностью где каждый пиксель показывает изменение вероятности от отрицательных значений уменьшение вероятности до положительных значений увеличение вероятности. Красным цветом обозначены области где вероятность присутствия вида уменьшится в будущем что может указывать на неблагоприятные условия для вида в этих районах. Зеленым цветом показаны области где вероятность присутствия вида увеличится что свидетельствует о потенциальном расширении ареала или улучшении условий. Желтые и близкие к нейтральным участки отражают незначительные изменения или стабильность в распределении вероятностей. Эта карта позволяет быстро оценить общую тенденцию изменений в распределении вида выявить наиболее уязвимые регионы где вид может исчезнуть и перспективные территории где вид может появиться или увеличить свою численность что критически важно для планирования мер охраны и прогнозирования изменений биоразнообразия.\n\n# Неопределенность (будущее) и MESS ------------------------------------------------------------------------------------ #\npred_future_single &lt;- get_predictions(myBiomodProj1)\nunc_f &lt;- uncertainty_per_point(pred_future_single)\nMAPDATA2_unc &lt;- MAPDATA2 %&gt;% left_join(unc_f %&gt;% transmute(point_id = points, UNC_SD = UNC_SD, UNC_CV = UNC_CV), by = \"point_id\")\n\np_unc_sd_f &lt;- ggplot(MAPDATA2_unc, aes(x = X, y = Y, fill = UNC_SD)) +\n  geom_raster() +\n  scale_fill_viridis_c(option = \"C\", name = \"SD\") +\n  coord_equal() +\n  labs(title = \"Неопределенность (SD) между алгоритмами — Future\")\n\ncommon &lt;- names(myExpl)\n# убрать предикторы без размаха в референсе\nok &lt;- sapply(myExpl[, common, drop = FALSE], function(z) length(unique(na.omit(z))) &gt;= 2)\nvars &lt;- common[ok]\n\n# матрица референса без NA-строк\nref_mat &lt;- as.matrix(na.omit(myExpl[, vars, drop = FALSE]))\n\n# собрать RasterStack для будущего из точек x,y и значений предикторов\nlayers &lt;- lapply(vars, function(nm) {\n  rasterFromXYZ(data.frame(x = DATA_F$x, y = DATA_F$y, z = myExplP1[, nm]))\n})\nx_stack &lt;- stack(layers); names(x_stack) &lt;- vars\n\n# посчитать MESS как растер\nmess_r &lt;- suppressWarnings(dismo::mess(x_stack, ref_mat))\n\n# извлечь значения MESS в порядке строк будущего набора\nmess_vals &lt;- raster::extract(mess_r, DATA_F[, c(\"x\",\"y\")])\n\nMAPDATA2_MESS &lt;- dplyr::mutate(MAPDATA2, MESS = mess_vals)\n\np_mess &lt;- ggplot(MAPDATA2_MESS, aes(x = X, y = Y, fill = MESS)) +\n  geom_raster() +\n  scale_fill_gradient2(low = \"#762A83\", mid = \"#F7F7F7\", high = \"#1B7837\", midpoint = 0, name = \"MESS\") +\n  coord_equal() +\n  labs(title = \"MESS (экстраполяционный риск) — Future vs Current\")\n\nprint(p_unc_sd_f)\n\n\n\n\nРис. 20.:Визуализация неопределенности прогнозов\n\n\nЭтот код демонстрирует анализ неопределённости прогнозов модели распределения видов для будущего сценария и оценку экстраполяционного риска с помощью MESS-анализа.\nКарта p_unc_sd_f визуализирует неопределённость прогнозов между разными алгоритмами моделирования через стандартное отклонение (SD). Высокие значения SD (светлые цвета на карте) указывают на участки где разные алгоритмы дают сильно расходящиеся предсказания что снижает надёжность прогноза в этих районах. Низкие значения SD (тёмные цвета) соответствуют областям консенсуса между алгоритмами где прогноз можно считать более надёжным.\nMESS-анализ (Multivariate Environmental Similarity Surface) оценивает экстраполяционный риск показывая насколько условия в будущем сценарии отличаются от текущих условий в которых модель обучалась. Положительные значения MESS (зелёные области) указывают на условия аналогичные обучающим что делает прогноз более надёжным. Отрицательные значения (фиолетовые области) сигнализируют об экстраполяции — условиях выходящих за пределы обучающего диапазона где прогнозы становятся ненадёжными поскольку модель экстраполирует а не интерполирует.\nВместе эти два анализа предоставляют важную информацию о качестве и надёжности прогнозов: карта неопределённости показывает внутреннюю согласованность модели в то время как MESS-анализ предупреждает о рисках связанных с экстраполяцией в условиях выходящих за пределы обучающих данных что особенно важно при моделировании будущих сценариев которые могут включать ранее не наблюдавшиеся комбинации экологических факторов.\n\nprint(p_mess)\n\n# Конец скрипта --------------------------------------------------------------------------------------------------------- #\n\n\n\n\nРис. 21.:Визуализация MESS-анализа\n\n\nЕсли второй скрипт был работой старателя, отсеивающего песок, то третий — работа ювелира, который собирает найденные крупицы в единый сплав и оценивает его прочность. Здесь мы переходим от отдельных моделей к ансамблю, от калибровки к прогнозу, от понимания прошлого к неопределенному будущему. Это кульминация всего проекта, где мы честно смотрим в лицо самой сложной задаче: предсказанию, основанному на ограниченных данных и неполном знании.\nКраткий обзор выполненного: От комитета моделей к карте рисков Третий скрипт выполнил несколько ключевых задач:\nАнсамблевое моделирование (BIOMOD_EnsembleModeling): Мы не стали доверять ни одной единственной модели (GLM, GAM, RF и т.д.), сколь бы хороша она ни была. Вместо этого мы создали «комитет экспертов» — ансамбль, который усреднил прогнозы всех 24 успешно построенных моделей (по 2-3 реализации на каждый из 9 алгоритмов). В качестве правил голосования использовались:\nEMmean: Среднее взвешенное по вероятностям. Модели с высоким TSS (&gt;0.4) имели больший вес.\nEMca: Committee Averaging — бинаризованное голосование на основе оптимального порога.\nПроекция в текущих условиях (BIOMOD_Projection): Ансамбль спроецировал свои прогнозы на всю исследуемую акваторию, создав непрерывную карту вероятности присутствия вида.\nПроекция в будущих условиях: Используя данные по будущему климату (сценарий RCP 8.5, 2100 г.), мы получили прогноз того, как ареал вида может измениться.\nВсесторонняя диагностика и оценка неопределенности: Мы не просто построили карты, а оценили их надежность с помощью батареи метрик:\nКалибровка (Reliability Plot): Насколько предсказанная вероятность соответствует наблюдаемой частоте встреч.\nDiscriminative Power (ROC-AUC, PR-AUC): Способность модели отличать presence от absence.\nBoyce Index: Оценивает, насколько предсказания согласуются с данными присутствия в пространстве окружающей среды.\nНеопределенность между алгоритмами: Карта стандартного отклонения предсказаний всех моделей — где модели «согласны», а где их мнения радикально расходятся.\nMESS (Multivariate Environmental Similarity Surface) анализ: Показывает, насколько условия в будущем экстраполируются за пределы тех, в которых модель была обучена. Это карта риска ошибочного прогноза.\nРезультаты: История в трех картах и четырех графиках 1. Прогноз для текущих условий: Ансамблевая модель (EMmean) выдала высокие и статистически значимые показатели качества (TSS = 0.925, ROC = 0.987). Карта прогноза четко показывает оптимальный ареал вида — он приурочен к специфическим шельфовым водам с определенным диапазоном глубин и расстояний от берега. Это не случайный набор точек, а четко структурированный паттерн, что подтверждает адекватность модели.\n\nКлючевые драйверы распределения (по версии ансамбля): Ансамбль подтвердил выводы второго скрипта, но расставил еще более жесткие приоритеты. Доминирующими фактором, определяющим до 75% важности, являются расстояние до берега (dist) и средняя температура. Все остальные переменные (хлорофилл, скорость течений и пр.) вносят крайне незначительный вклад в сравнении с ним. Это говорит о том, что наш вид является узким батиметрическим и термическим специалистом.\nВзгляд в будущее (2040-2100 гг.): Прогноз на будущее показывает тревожную динамику:\n\nСдвиг ареала: Наблюдается смещение областей с высокой пригодностью среды в северо-восточном направлении, что, вероятно, является реакцией на потепление вод и изменение продуктивности.\nКарта изменений (Delta): Наглядно демонстрирует потери (красные тона) в традиционных местообитаниях и потенциальное расширение (зеленые тона) в новых районах, хотя последнее нуждается в крайне осторожной интерпретации.\nДиагностика надежности: Сильные стороны и тревожные сигналы Калибровка: Кривая идеально легла на биссектрису. Это означает, что если модель предсказывает вероятность 70%, то в реальности вид встречается в 70% случаев в подобных условиях. Наша модель не просто ранжирует местоположения по пригодности, она дает хорошо откалиброванные, точные вероятности.\nDiscriminative Power: Исключительно высокие значения AUC ROC (0.987) и AUC PR (0.925) подтверждают, что модель блестяще отделяет “сигнал” от “шума”.\nНеопределенность: Карта стандартного отклонения предсказаний показывает, что наибольшая неопределенность присуща как раз зонам экстраполяции — на границах ареала и в будущем сценарии. Там, где условия сильно отличаются от тех, на которых училась модель, ее прогнозы наименее надежны.\nГлавный сигнал — MESS-анализ: Значительная часть прогноза для будущего периода, особенно в н глубоководных зонах нативного ареала, попадает в область экстраполяции (отрицательные значения MESS). Это означает, что сочетания средовых ковариат в этих клетках не имеют аналогов в текущих данных для обучения. Доверять прогнозу в этих зонах категорически нельзя. Это не прогноз, а математическая экстраполяция, лишенная экологического смысла.\nЗаключение: Прогноз — сдержанный и с оговорками На основе проведенного анализа можно сделать следующие выводы:\nМодель адекватна и надежна для текущих условий. Мы построили статистически робастную ансамблевую модель, которая с высокой точностью описывает современное распределение вида, ключевым лимитирующим фактором для которого является температура и расстояние до берега (и связанные с ним параметры).\nВозможные рекомендации и дальнейшие шаги:\nДля менеджеров рыболовства/ООПТ: Следует сконцентрировать усилия по мониторингу и сохранению на известных в настоящее время ключевых местообитаниях, которые модель идентифицирует как оптимальные. К прогнозам расширения ареала следует относиться как к гипотезе, требующей строгой полевой проверки.\nДля исследователей: Необходимо расширять данные наблюдений, особенно в пограничных зонах ареала и в районах, которые в будущем могут стать подходящими. Это снизит область экстраполяции и повысит надежность моделей. Целесообразно опробовать более комплексные модели, включающие биотические взаимодействия и дисперсионные возможности вида.\nФилософский итог: Мы не предсказали будущее. Мы смоделировали его возможный сценарий при строго определенных условиях и четко очертили границы, за которыми наши знания заканчиваются и начинается область догадок. В этом и заключается честный, научно обоснованный подход к моделированию сложных систем.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>SDM: моделирование пространственного распределения видов</span>"
    ]
  }
]
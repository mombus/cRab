[
  {
    "objectID": "chapter 8.html",
    "href": "chapter 8.html",
    "title": "9  Модель Catch-Survey Analysis (CSA)",
    "section": "",
    "text": "9.1 Введение\nМодель “анализа уловов и съемок” - Catch-Survey Analysis (CSA) представляет собой инструмент для оценки состояния запасов, особенно тех видов, данные по индивидуальному возрасту которых труднодоступны или отсутствуют, что типично для многих беспозвоночных, таких как крабы, креветки, а также для некоторых рыб. В отличие от классических продукционных моделей, которые оперируют агрегированными показателями всей популяции и требуют строгих допущений о ее равновесном состоянии и постоянной емкости среды, когортные модели, подобные CSA, позволяют отслеживать судьбу отдельных функциональных категорий (например, пререкруты, рекруты, пострекруты). Они явным образом учитывают такие процессы, как рост, пополнение и естественная смертность, разделяя запас на дискретные размерные или возрастные группы. Это дает несомненное преимущество при анализе динамики популяций с выраженной цикличностью или тех, которые подвергаются интенсивному промысловому прессу, избирательно воздействующему на определенные размерные или возрастные категории (например, пререкруты не подвержены прямой прмысловой смертности в отличие от рекрутов и посрекрутов). Подробнее о модели и ее реализации можно почитать в статье “Результаты применения стохастической когортной модели CSA для оценки запаса камчатского краба Paralithodes camtschaticus в Баренцевом море”. В статье описывается реализация модели в программе OpenBUGS, которая в упрощенном виде (без прогноза, риск-анализа и диагностики) и в учебных целях была переведена в среду R и представлена ниже, а полный срипт здесь.Также доступна иммитационная CSA модель для 4 размерных групп, реализованная в MS Excel по ссылке.\nДанная реализация модели представляет собой байесовский подход к оценке запасов, который позволяет учитывать неопределенности как в процессе динамики популяции, так и в процессе наблюдений, что особенно важно при работе с данными, характеризующимися высокой вариабельностью и неполнотой. В основе модели лежит разделение популяции на три размерно-возрастные группы: пререкруты (P1), рекруты (R) и пострекруты (P), что соответствует биологическим особенностям многих видов крабов, включая камчатского краба. Модель включает два основных компонента: динамику процесса, описывающую естественные изменения численности популяции, и модель наблюдений, связывающую ненаблюдаемые “истинную” численность запаса с доступными данными съемок (индексами численности пререкрутов, рекрутов и пострекрутов). Уравнения процессной динамики для пострекрутов имеют вид:\nP[i] = [(P1[i-1]×Gp×Mp) + R[i-1] + P[i-1] - catch[i-1]] × exp(-M) + εP, где\nGp обозначает вероятность перехода пререкрутов в пострекруты,\nMp - вероятность линьки пререкрутов,\nM - коэффициент естественной смертности, а εP представляет собой процессную ошибку.\nДля рекрутов уравнение динамики выглядит как\nR[i] = (P1[i-1]×Gr×Mp) × exp(-M) + εR, где\nGr - вероятность перехода пререкрутов в рекруты. Динамика пререкрутов моделируется как лог-случайное блуждание P1[i] = P1[i-1] + εP1. Модель наблюдений предполагает, что данные траловых съемок соответствуют логнормальному распределению относительно истинной численности, умноженной на коэффициент улавливаемости:\nbioindexP1[i] ~ lognormal(log(q1×P1[i]), precbioindexP1),\nаналогично для рекрутов и пострекрутов, где q1, q2, q3 - коэффициенты улавливаемости для каждой группы, а precbioindex - параметры точности. В байесовском подходе ключевую роль играют априорные распределения параметров, которые в данной реализации задаются как равномерные для коэффициентов улавливаемости (q1, q2, q3 ~ dunif(0.1,1)), нормальные для вероятностей перехода (Gr ~ dnorm(0.9,500), Gp ~ dnorm(0.075,500), Mp ~ dnorm(0.95,500)) и для коэффициента естественной смертности (M ~ dnorm(0.2,100)). Использование байесовского подхода позволяет не только получить точечные оценки параметров, но и оценить полные апостериорные распределения, что дает возможность проводить риск-анализ различных сценариев управления запасом. В данном занятии мы реализуем модель CSA в среде R с использованием пакетов rjags и coda, что позволяет эффективно работать с байесовскими иерархическими моделями через интерфейс с программой JAGS, которую также необходимо установить.\nМы рассмотрим полный цикл работы с моделью: от подготовки данных и задания априорных распределений до обучения модели и анализа результатов, включая визуализацию априорных и апостериорных распределений параметров, анализ остатков и сравнение моделируемой и фактической динамики запаса. Особое внимание будет уделено интерпретации результатов в контексте управления водными биоресурсами, что является ключевой целью применения подобных моделей в практической деятельности гидробиологов и ихтиологов. ## Загрузка данных и первичный осмотр",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Модель Catch-Survey Analysis (CSA)</span>"
    ]
  },
  {
    "objectID": "chapter 8.html#реализация-модели",
    "href": "chapter 8.html#реализация-модели",
    "title": "9  Модель Catch-Survey Analysis (CSA)",
    "section": "9.2 Реализация модели",
    "text": "9.2 Реализация модели\n\n# ========================================================================================================================\n# ПРАКТИЧЕСКОЕ ЗАНЯТИЕ: МОДЕЛЬ Catch-Survey Analysis (CSA) - три #категории (пререкруты (P1), рекруты (R), пострекруты (P)\n# Курс: \"Оценка водных биоресурсов в среде R (для начинающих)\"\n# Автор: Баканев С. В. Дата: 20.08.2025\n# Структура:\n# 1) Входные данные\n# 2) Модель\n# 3) Прайеры\n# 4) Обучение модели\n# 5) Подготовка выходных данных \n# 6) Анализ результатов (визуализация априорных и апостериорных параметров;бабл-плоты остатков;  динамика индексов) \n# ========================================================================================================================\n# Установка рабочей директории\nsetwd(\"C:/CSA\")\n\n# Подключение необходимых библиотек\n# install.packages(c(\"rjags\", \"coda\"))  # Раскомментировать для установки\nlibrary(rjags)  # Для работы с JAGS\n\nWarning: пакет 'rjags' был собран под R версии 4.5.1\n\n\nЗагрузка требуемого пакета: coda\n\n\nWarning: пакет 'coda' был собран под R версии 4.5.1\n\n\nLinked to JAGS 4.3.1\n\n\nLoaded modules: basemod,bugs\n\nlibrary(coda)   # Для анализа MCMC-выхода\nlibrary(ggplot2) # Рисунки\n\n# ========================================================================================================================\n# --- Входные данные ---\n# ========================================================================================================================\ndata_list &lt;- list(\n  N = 16,# Количество временных точек\n # Наблюдаемые данные (индексы запаса)\n  bioindexP1 = c(1500,1028,554,887,1345,1817,2291,1958,1500,1028,554,887,1345,1817,2291,1958),\n  bioindexR  = c(2531,1927,1305,764,1216,   1820,2442,2983,2531,1927,1305,764,1216,1820,2442,2983),\n  bioindexP  = c(13741,13770,13060,11653,9782,8634,8321,8793,9809,10177,9776,9566,8789,8640,9240,10547),\n  catch      = c(6,2,6,15,21,37,37,315,945,890,991,1060,1000,1000,1600,1673,1250)\n)\n\n# Создание вектора лет для подписей\nYEAR &lt;- 2000 + 0:(data_list$N - 1)\n\n# ========================================================================================================================\n# --- Генерация модели CSA --\n# ========================================================================================================================\nmodel_string &lt;- \"\nmodel {\n  # Observation model\n  for (i in 1:N) {\n    bioindexP1med[i] &lt;- log(1.0E-6 + q1 * P1[i])\n    bioindexP1[i] ~ dlnorm(bioindexP1med[i], precbioindexP1)\n\n    bioindexRmed[i]  &lt;- log(1.0E-6 + q2 * R[i])\n    bioindexR[i] ~ dlnorm(bioindexRmed[i],  precbioindexR)\n\n    bioindexPmed[i]  &lt;- log(1.0E-6 + q3 * P[i])\n    bioindexP[i] ~ dlnorm(bioindexPmed[i],  precbioindexP)\n  }\n\n  # State dynamics\n  inv_surv &lt;- exp(-M)\n  for (i in 2:N) {\n    tmpPraw[i] &lt;- (P1[i-1]*Gp*Mp + R[i-1] + P[i-1] - catch[i-1]) * inv_surv\n    tmpPpos[i] &lt;- tmpPraw[i] * step(tmpPraw[i])\n    Pmed[i] &lt;- log(1.0E-6 + tmpPpos[i])\n    P[i] ~ dlnorm(Pmed[i], precP)\n\n    tmpRraw[i] &lt;- (P1[i-1]*Gr*Mp) * inv_surv\n    tmpRpos[i] &lt;- tmpRraw[i] * step(tmpRraw[i])\n    Rmed[i] &lt;- log(1.0E-6 + tmpRpos[i])\n    R[i] ~ dlnorm(Rmed[i], precR)\n\n    P1med[i] &lt;- log(1.0E-6 + P1[i-1])\n    P1[i] ~ dlnorm(P1med[i], precP1)\n  }\n\n  # Risk\n  for (i in 1:N) {\n    PR[i] &lt;- P[i] + R[i]\n    p.PRlim[i] &lt;- step(PRlim - PR[i])\n  }\n  PRlim &lt;- 4000\n\n  # Priors\n  P1[1] ~ dunif(200,4000)\n  P[1]  ~ dunif(200,6000)\n  R[1]  ~ dunif(200,25000)\n\n  Gr ~ dnorm(0.9,  500)\n  Gp ~ dnorm(0.075,500)\n  Mp ~ dnorm(0.95, 500)\n\n  precbioindexP1 ~ dgamma(12.22, 1.1)\n  precbioindexR  ~ dgamma(12.22, 1.1)\n  precbioindexP  ~ dgamma(12.22, 1.1)\n\n  q1 ~ dunif(0.1,1)\n  q2 ~ dunif(0.1,1)\n  q3 ~ dunif(0.1,1)\n\n  precP1 ~ dgamma(12.22, 1.1)\n  precR  ~ dgamma(12.22, 1.1)\n  precP  ~ dgamma(12.22, 1.1)\n\n  M ~ dnorm(0.2, 100)\n}\n\"\n\n\n# ========================================================================================================================\n# --- Обучение модели ---\n# ========================================================================================================================\nset.seed(1)  # Для воспроизводимости\n# Инициализация модели JAGS\njm &lt;- jags.model(\n  textConnection(model_string),  # Модель из строки\n  data = data_list,             # Данные\n  n.chains = 3,                 # Количество цепей\n  n.adapt = 1500                # Длина адаптационной фазы\n)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 48\n   Unobserved stochastic nodes: 61\n   Total graph size: 576\n\nInitializing model\n\n# Обновление модели (burn-in)\nupdate(jm, 4000)\n\n# Переменные для мониторинга\nvars_to_monitor &lt;- c(\n  \"M\",\"Gp\",\"Gr\",\"Mp\",\"q1\",\"q2\",\"q3\",                    # Параметры\n  \"precP\",\"precP1\",\"precR\",\"precbioindexP\",\"precbioindexP1\",\"precbioindexR\",  # Точности\n  \"P\",\"P1\",\"R\",\"PR\",\"p.PRlim\"                           # Состояния и производные\n)\n\n\n# Генерация MCMC-выборок\nsamps &lt;- coda.samples(\n  jm, \n  variable.names = vars_to_monitor,  # Мониторируемые переменные\n  n.iter = 6000,                     # Длина выборки\n  thin = 3                           # Прореживание\n)\n# ========================================================================================================================\n# --- Анализ результатов ---\n# ========================================================================================================================\n# Стандартная статистика по выборкам\nsm &lt;- summary(samps)\nstats &lt;- sm$statistics   # Средние, SD, стандартные ошибки\nquants &lt;- sm$quantiles   # Квантили (2.5%, 25%, 50%, 75%, 97.5%)\n\n# Матрица всех сэмплов для ручных вычислений\ndraws_mat &lt;- as.matrix(samps)\n\n# Функция для расчета MC ошибки через эффективный размер выборки\nmcse_from_ess &lt;- function(vec) {\n  ess &lt;- effectiveSize(as.mcmc(vec))  # Эффективный размер выборки\n  sd(vec) / sqrt(as.numeric(ess))     # MC ошибка\n}\n\n# Функция для создания строки результата\nmake_row &lt;- function(year, mapping, node, mean, sd, mcse, q2.5, q25, q50, q75, q97.5) {\n  data.frame(\n    YEAR = year,\n    `#Vectors to monitor` = mapping,\n    node = node,\n    mean = mean,\n    sd = sd,\n    `MC error` = mcse,\n    `2.50%` = q2.5,\n    `25.00%` = q25,\n    median = q50,\n    `75.00%` = q75,\n    `97.50%` = q97.5,\n    check.names = FALSE\n  )\n}\n\n# Список для накопления результатов\nrows &lt;- list()\n\n# Функция добавления скалярных параметров\nadd_scalar &lt;- function(x_idx, vname) {\n  if (vname %in% rownames(stats)) {\n    # Если параметр есть в готовой статистике\n    m &lt;- stats[vname, \"Mean\"]\n    s &lt;- stats[vname, \"SD\"]\n    mcse &lt;- mcse_from_ess(draws_mat[, vname])\n    q &lt;- quants[vname, c(\"2.5%\", \"25%\", \"50%\", \"75%\", \"97.5%\")]\n    rows[[length(rows) + 1]] &lt;&lt;- make_row(NA, paste0(\"x[\", x_idx, \"]&lt;-\", vname), paste0(\"x[\", x_idx, \"]\"),\n                                          m, s, mcse, q[1], q[2], q[3], q[4], q[5])\n  } else if (vname %in% c(\"sigmaP1\",\"sigmaR\",\"sigmaP\")) {\n    # Для стандартных отклонений (преобразуем из точности)\n    src &lt;- switch(vname,\n                  sigmaP1 = \"precP1\",\n                  sigmaR  = \"precR\",\n                  sigmaP  = \"precP\")\n    if (src %in% colnames(draws_mat)) {\n      vec &lt;- sqrt(1 / draws_mat[, src])  # Преобразование precision -&gt; sigma\n      m &lt;- mean(vec); s &lt;- sd(vec); mcse &lt;- mcse_from_ess(vec)\n      q &lt;- quantile(vec, c(0.025,0.25,0.5,0.75,0.975))\n      rows[[length(rows) + 1]] &lt;&lt;- make_row(NA, paste0(\"x[\", x_idx, \"]&lt;-\", vname), paste0(\"x[\", x_idx, \"]\"),\n                                            m, s, mcse, q[1], q[2], q[3], q[4], q[5])\n    }\n  }\n}\n\n# Добавление основных параметров\nadd_scalar(1,  \"M\")\nadd_scalar(2,  \"q1\")\nadd_scalar(3,  \"q2\")\nadd_scalar(4,  \"q3\")\nadd_scalar(5,  \"sigmaP1\")\nadd_scalar(6,  \"sigmaR\")\nadd_scalar(7,  \"sigmaP\")\nadd_scalar(8,  \"precbioindexP1\")\nadd_scalar(9,  \"precbioindexR\")\nadd_scalar(10, \"precbioindexP\")\nadd_scalar(11, \"Gr\")\nadd_scalar(12, \"Gp\")\nadd_scalar(13, \"Mp\")\n\n# Функция добавления временных рядов\nadd_series &lt;- function(base_idx, varname, years) {\n  for (i in seq_along(years)) {\n    rn &lt;- paste0(varname, \"[\", i, \"]\")  # Имя переменной с индексом\n    if (!rn %in% rownames(stats)) next  # Пропуск если нет данных\n    m &lt;- stats[rn, \"Mean\"]\n    s &lt;- stats[rn, \"SD\"]\n    mcse &lt;- mcse_from_ess(draws_mat[, rn])\n    q &lt;- quants[rn, c(\"2.5%\", \"25%\", \"50%\", \"75%\", \"97.5%\")]\n    xi &lt;- base_idx + (i - 1)  # Вычисление индекса в выходной таблице\n    rows[[length(rows) + 1]] &lt;&lt;- make_row(years[i], paste0(\"x[\", xi, \"]&lt;-\", rn), paste0(\"x[\", xi, \"]\"),\n                                          m, s, mcse, q[1], q[2], q[3], q[4], q[5])\n  }\n}\n\n# Добавление временных рядов\nadd_series(100, \"P1\", YEAR)\nadd_series(200, \"R\",  YEAR)\nadd_series(300, \"P\",  YEAR)\n\n# Создание итоговой таблицы\nout_df &lt;- do.call(rbind, rows)\n\n# Создание групп для сортировки\nout_df$group &lt;- ifelse(is.na(out_df$YEAR), \"param\",\n                ifelse(grepl(\"&lt;-P1\\\\[\", out_df$`#Vectors to monitor`), \"P1\",\n                ifelse(grepl(\"&lt;-R\\\\[\",  out_df$`#Vectors to monitor`), \"R\", \"P\")))\n\n# Сортировка параметров по индексу\nparam_rows &lt;- out_df[out_df$group == \"param\", ]\nparam_idx  &lt;- as.numeric(sub(\".*\\\\[(\\\\d+)\\\\].*\", \"\\\\1\", param_rows$node))\nparam_rows &lt;- param_rows[order(param_idx), ]\n\n# Сортировка временных рядов по году\np1_rows &lt;- out_df[out_df$group == \"P1\", ]\np1_rows &lt;- p1_rows[order(p1_rows$YEAR), ]\n\nr_rows  &lt;- out_df[out_df$group == \"R\", ]\nr_rows  &lt;- r_rows[order(r_rows$YEAR), ]\n\np_rows  &lt;- out_df[out_df$group == \"P\", ]\np_rows  &lt;- p_rows[order(p_rows$YEAR), ]\n\n# Компоновка финальной таблицы\nout_df &lt;- rbind(param_rows, p1_rows, r_rows, p_rows)\nout_df$group &lt;- NULL  # Удаление вспомогательной колонки\n\n# Сохранение результатов\nwrite.csv(out_df, \"monitor_summary.csv\", row.names = FALSE)\ncat(\"Saved: monitor_summary.csv\\n\")\n\nSaved: monitor_summary.csv\n\n# Вывод структуры результатов\nstr(out_df)\n\n'data.frame':   61 obs. of  11 variables:\n $ YEAR               : num  NA NA NA NA NA NA NA NA NA NA ...\n $ #Vectors to monitor: chr  \"x[1]&lt;-M\" \"x[2]&lt;-q1\" \"x[3]&lt;-q2\" \"x[4]&lt;-q3\" ...\n $ node               : chr  \"x[1]\" \"x[2]\" \"x[3]\" \"x[4]\" ...\n $ mean               : num  0.175 0.414 0.735 0.935 0.315 ...\n $ sd                 : num  0.0642 0.0912 0.1343 0.0602 0.0417 ...\n $ MC error           : num  0.002072 0.006449 0.008274 0.001534 0.000584 ...\n $ 2.50%              : num  0.0483 0.2653 0.4895 0.7802 0.2451 ...\n $ 25.00%             : num  0.131 0.347 0.633 0.909 0.285 ...\n $ median             : num  0.174 0.403 0.731 0.953 0.311 ...\n $ 75.00%             : num  0.218 0.468 0.839 0.98 0.34 ...\n $ 97.50%             : num  0.299 0.621 0.978 0.998 0.409 ...\n\n# ========================================================================================================================\n# Визуализация априорных и апостериорных параметров\n# Параметры: M, Gp, Gr, Mp, q1, q2, q3, precP1, precR, precP, precbioindexP1, precbioindexR, precbioindexP\n# И производные: sigmaP1, sigmaR, sigmaP\n# ========================================================================================================================\n\n# Сэмплируем приоры прямо из той же JAGS-модели (без данных)\nsample_priors_from_model &lt;- function(model_string, n_iter = 20000, n_adapt = 500) {\n  jm_prior &lt;- jags.model(textConnection(model_string), data = list(N = 0), n.chains = 1, n.adapt = n_adapt)\n  vars &lt;- c(\"M\",\"Gp\",\"Gr\",\"Mp\",\"q1\",\"q2\",\"q3\",\n            \"precP1\",\"precR\",\"precP\",\"precbioindexP1\",\"precbioindexR\",\"precbioindexP\")\n  priors &lt;- coda.samples(jm_prior, variable.names = vars, n.iter = n_iter)\n  as.matrix(priors)\n}\n\n# Получаем матрицы приоров и постериоров\nprior_mat &lt;- sample_priors_from_model(model_string, n_iter = 20000, n_adapt = 500)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 0\n   Unobserved stochastic nodes: 16\n   Total graph size: 33\n\nInitializing model\n\npost_mat  &lt;- as.matrix(samps)\n\n# Добавляем производные сигмы из прецизионов\nadd_sigmas &lt;- function(mat) {\n  add &lt;- function(dst, src) {\n    if (all(src %in% colnames(mat))) dst &lt;- cbind(dst, setNames(as.data.frame(sqrt(1/mat[, src, drop=FALSE])), gsub(\"^prec\",\"sigma\", src)))\n    dst\n  }\n  out &lt;- mat\n  out &lt;- add(out, c(\"precP1\"))\n  out &lt;- add(out, c(\"precR\"))\n  out &lt;- add(out, c(\"precP\"))\n  out\n}\nprior_mat &lt;- add_sigmas(prior_mat)\npost_mat  &lt;- add_sigmas(post_mat)\n\n# Список параметров для визуализации\nparams &lt;- intersect(\n  c(\"M\",\"Gp\",\"Gr\",\"Mp\",\"q1\",\"q2\",\"q3\",\n    \"sigmaP1\",\"sigmaR\",\"sigmaP\",\n    \"precbioindexP1\",\"precbioindexR\",\"precbioindexP\"),\n  union(colnames(prior_mat), colnames(post_mat))\n)\n\n# В long-формат\nmk_df &lt;- function(mat, label) {\n  if (is.null(mat) || nrow(mat) == 0) return(data.frame())\n  mat &lt;- mat[, intersect(colnames(mat), params), drop = FALSE]\n  reshape(\n    data.frame(iter = seq_len(nrow(mat)), mat, check.names = FALSE),\n    direction = \"long\", varying = params, v.names = \"value\", timevar = \"param\", times = params\n  )[, c(\"param\",\"value\")]\n}\nprior_df &lt;- mk_df(prior_mat, \"Prior\"); prior_df$dist &lt;- \"Prior\"\npost_df  &lt;- mk_df(post_mat,  \"Posterior\"); post_df$dist &lt;- \"Posterior\"\nplot_df  &lt;- rbind(prior_df, post_df)\n\n# Подписи\nparam_labels &lt;- c(\n  M=\"M (mortality)\", Gp=\"Gp\", Gr=\"Gr\", Mp=\"Mp\",\n  q1=\"q1\", q2=\"q2\", q3=\"q3\",\n  sigmaP1=\"sigmaP1\", sigmaR=\"sigmaR\", sigmaP=\"sigmaP\",\n  precbioindexP1=\"precbioindexP1\", precbioindexR=\"precbioindexR\", precbioindexP=\"precbioindexP\"\n)\nplot_df$param_f &lt;- factor(plot_df$param, levels = params, labels = unname(param_labels[params]))\n\n# График prior vs posterior (берёт priors из модели!)\nlibrary(ggplot2)\nggplot(plot_df, aes(x = value, color = dist, fill = dist)) +\n  geom_density(alpha = 0.25, linewidth = 0.7) +\n  facet_wrap(~ param_f, scales = \"free\", ncol = 4) +\n  scale_color_manual(values = c(\"Prior\" = \"#999999\", \"Posterior\" = \"#1b9e77\")) +\n  scale_fill_manual(values  = c(\"Prior\" = \"#bbbbbb\", \"Posterior\" = \"#1b9e77\")) +\n  labs(title = \"Априорные (из модели) vs апостериорные распределения\",\n       x = \"Значение\", y = \"Плотность\", color = \"\", fill = \"\") +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n# ========================================================================================================================\n# Бабл-плоты остатков P1, R, P по годам (2000–2015)\n# Требуется: объекты samps, data_list. Если YEAR не создан, создадим.\n# ========================================================================================================================\n\nif (!exists(\"YEAR\")) YEAR &lt;- 2000 + 0:(data_list$N - 1)\ndraws_mat &lt;- as.matrix(samps)\neps &lt;- 1.0e-6\n\nresid_bubble_summary &lt;- function(series, obs_vec, q_name, state_name_prefix) {\n  rows &lt;- list()\n  for (i in seq_along(obs_vec)) {\n    if (is.na(obs_vec[i])) next\n    q_draws     &lt;- draws_mat[, q_name]\n    state_draws &lt;- draws_mat[, paste0(state_name_prefix, \"[\", i, \"]\")]\n    # residual per draw: log(observed) - log(expected)\n    res_draws &lt;- log(obs_vec[i]) - log(eps + q_draws * state_draws)\n    r_mean &lt;- mean(res_draws, na.rm = TRUE)\n    rows[[length(rows) + 1]] &lt;- data.frame(\n      YEAR = YEAR[i],\n      series = series,\n      resid = r_mean,\n      abs_resid = abs(r_mean),\n      sign = ifelse(r_mean &gt;= 0, \"pos\", \"neg\")\n    )\n  }\n  do.call(rbind, rows)\n}\n\nb1 &lt;- resid_bubble_summary(\"P1\", data_list$bioindexP1, \"q1\", \"P1\")\nb2 &lt;- resid_bubble_summary(\"R\",  data_list$bioindexR,  \"q2\", \"R\")\nb3 &lt;- resid_bubble_summary(\"P\",  data_list$bioindexP,  \"q3\", \"P\")\nbubbles &lt;- rbind(b1, b2, b3)\n\n# Порядок рядов сверху вниз: P1, R, P\nbubbles$series &lt;- factor(bubbles$series, levels = c(\"P1\", \"R\", \"P\"))\n\n# Убираем пустое расстояние - используем минимальные интервалы\nlvl &lt;- c(\"P1\",\"R\",\"P\")\ny_map &lt;- setNames(c(1, 2, 3), lvl)  # Числовые позиции без больших промежутков\n\nbubbles$y_pos &lt;- unname(y_map[as.character(bubbles$series)])\n\n# Создаем вытянутый прямоугольный график\nggplot(bubbles, aes(x = YEAR, y = y_pos)) +\n  geom_point(aes(size = abs_resid, fill = sign), shape = 21, color = \"black\", alpha = 0.9) +\n  scale_fill_manual(values = c(neg = \"black\", pos = \"white\"),\n                    breaks = c(\"pos\",\"neg\"),\n                    labels = c(\"положительные\",\"отрицательные\"),\n                    name = \"\") +\n  scale_size_area(max_size = 12, name = \"Остатки\") +\n  scale_x_continuous(breaks = seq(2000, 2015, by = 2), limits = c(2000, 2015)) +\n  scale_y_continuous(breaks = unname(y_map), \n                     labels = names(y_map),\n                     limits = c(0.5, 3.5),  # Убираем пустое пространство сверху и снизу\n                     expand = c(0, 0)) +     # Убираем расширение осей\n  labs(title = \"Пузырьковая диаграмма остатков (лог-шкала): P1, R, P\", \n       x = \"Год\", \n       y = \"\") +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = \"top\",\n    panel.grid.major.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    aspect.ratio = 0.3,  # Делаем график вытянутым прямоугольником (ширина &gt; высоты)\n    plot.margin = margin(5, 10, 5, 5, \"pt\")  # Убираем лишние отступы вокруг графика\n  )\n\n\n\n\n\n\n\n# ========================================================================================================================\n# ДИНАМИКА ИНДЕКСОВ (ПРЕРЕКРУТЫ, РЕКРУТЫ, ПОСТРЕКРУТЫ) МОДЕЛЬНЫХ И ФАКТИЧЕСКИХ (ТОЧКИ)\n# ========================================================================================================================\n# Три графика динамики P1, R, P: медиана (линия), 95% ДИ (лента), точки — наблюдения,\n# приведённые к единому масштабу  делением на медиану q (Posterior median).\n# ========================================================================================================================\nif (!exists(\"YEAR\")) YEAR &lt;- 2000 + 0:(data_list$N - 1)\ndraws_mat &lt;- as.matrix(samps)\n\nseries_summary &lt;- function(varname, obs_vec, qname, series_label) {\n  med_q &lt;- median(draws_mat[, qname], na.rm = TRUE)\n  rows &lt;- vector(\"list\", length(obs_vec))\n  for (i in seq_along(obs_vec)) {\n    rn &lt;- paste0(varname, \"[\", i, \"]\")\n    if (!rn %in% colnames(draws_mat)) next\n    v &lt;- draws_mat[, rn]\n    qs &lt;- quantile(v, c(0.025, 0.5, 0.975), na.rm = TRUE)\n    obs_state &lt;- if (!is.na(obs_vec[i])) obs_vec[i] / med_q else NA_real_\n    rows[[i]] &lt;- data.frame(\n      YEAR = YEAR[i],\n      series = series_label,\n      median = qs[2],\n      lo = qs[1],\n      hi = qs[3],\n      obs = obs_state\n    )\n  }\n  do.call(rbind, rows)\n}\n\ndf_p1 &lt;- series_summary(\"P1\", data_list$bioindexP1, \"q1\", \"P1\")\ndf_r  &lt;- series_summary(\"R\",  data_list$bioindexR,  \"q2\", \"R\")\ndf_p  &lt;- series_summary(\"P\",  data_list$bioindexP,  \"q3\", \"P\")\n\n\np_P1 &lt;- ggplot(df_p1, aes(x = YEAR)) +\n  geom_ribbon(aes(ymin = lo, ymax = hi), fill = \"#1f77b4\", alpha = 0.2) +\n  geom_line(aes(y = median), color = \"#1f77b4\", linewidth = 1) +\n  geom_point(aes(y = obs), shape = 21, size = 2, color = \"black\", fill = \"white\", na.rm = TRUE) +\n  scale_x_continuous(breaks = seq(2000, 2015, by = 2), limits = c(2000, 2015)) +\n  labs(title = \"Моделируемая и фактическая (точки) динамика пререкрутов\", x = \"Годы\", y = \"Пререкруты (экз.)\") +\n  theme_minimal(base_size = 12)\n\nprint(p_P1)\n\n\n\n\n\n\n\np_R &lt;- ggplot(df_r, aes(x = YEAR)) +\n  geom_ribbon(aes(ymin = lo, ymax = hi), fill = \"#2ca02c\", alpha = 0.2) +\n  geom_line(aes(y = median), color = \"#2ca02c\", linewidth = 1) +\n  geom_point(aes(y = obs), shape = 21, size = 2, color = \"black\", fill = \"white\", na.rm = TRUE) +\n  scale_x_continuous(breaks = seq(2000, 2015, by = 2), limits = c(2000, 2015)) +\n  labs(title = \"Моделируемая и фактическая (точки) динамика рекрутов\", x = \"Годы\", y = \"Рекруты (экз.)\") +\n  theme_minimal(base_size = 12)\n\nprint(p_R)\n\n\n\n\n\n\n\np_P &lt;- ggplot(df_p, aes(x = YEAR)) +\n  geom_ribbon(aes(ymin = lo, ymax = hi), fill = \"#ff7f0e\", alpha = 0.2) +\n  geom_line(aes(y = median), color = \"#ff7f0e\", linewidth = 1) +\n  geom_point(aes(y = obs), shape = 21, size = 2, color = \"black\", fill = \"white\", na.rm = TRUE) +\n  scale_x_continuous(breaks = seq(2000, 2015, by = 2), limits = c(2000, 2015)) +\n  labs(title = \"Моделируемая и фактическая (точки) динамика пострекрутов\", x = \"Годы\", y = \"Пострекруты (экз.)\") +\n  theme_minimal(base_size = 12)\n\nprint(p_P)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Модель Catch-Survey Analysis (CSA)</span>"
    ]
  },
  {
    "objectID": "chapter 7.html",
    "href": "chapter 7.html",
    "title": "8  Прогноз пополнения: от факторов до ансамбля",
    "section": "",
    "text": "8.1 Введение\nВ этой практической работе представлен цикл прикладного анализа зависимости пополнения запаса гидробионта от факторов среды (в том числе нерестового запаса): от подготовки данных и отбора предикторов до сравнения нескольких семейств моделей, выбора устойчивой к хронологии прогностической схемы и построения прогноза с доверительными интервалами. Подход ориентирован на начинающих, но использует современные приёмы: автоматический отбор признаков (Boruta, LASSO), сопоставление линейных/нелинейных моделей, time-slice валидацию и ансамблевый прогноз. • Целевая переменная: R3haddock — пополнение запаса. • Кандидатные предикторы: гидрометеорология (температуры T…), океанография (O…), биотические показатели (например, codTSB) и нерестовый запас (haddock68). • Цель анализа: понять, какие факторы и в каких формах оказываются значимыми, отобрать рабочий набор моделей и получить прогноз на 2022–2024 с оценкой неопределенности.\nНастоящий анализ разделен на несколько этапов:\nВходные данные для работы скрипта: RECRUITMENT.xlsx, а также промежуточный файл с готовым набором предикторов: selected_predictors_dataset.csv.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Прогноз пополнения: от факторов до ансамбля</span>"
    ]
  },
  {
    "objectID": "chapter 7.html#введение",
    "href": "chapter 7.html#введение",
    "title": "8  Прогноз пополнения: от факторов до ансамбля",
    "section": "",
    "text": "Выбор предикторов. Скрипт можно скачать по ссылке\nПостроение биологически мотивированных (механистических) нелинейных классических моделей «запас-пополнение» Рикера и Бивертона-Холта. Анализ их значимости и сравнение с моделями LM/GLM/GAM. Скрипт можно скачать по ссылке\nПостроение классических статистических моделей LM/GLM/GAM. Анализ их прогностических способностей и выполнение прогноза. Скрипт можно скачать по ссылке\nПолный цикл ( СКРИПТ) прикладного анализа зависимости пополнения запаса гидробионта от факторов среды, включающий:\n\n\nа) выбор предикторов;\nб) базовое сравнение различных моделей;\nв) выбор лучшей прогностической модели;\nг) ансамблевый прогноз.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Прогноз пополнения: от факторов до ансамбля</span>"
    ]
  },
  {
    "objectID": "chapter 7.html#выбор-предикторов",
    "href": "chapter 7.html#выбор-предикторов",
    "title": "8  Прогноз пополнения: от факторов до ансамбля",
    "section": "8.2 Выбор предикторов",
    "text": "8.2 Выбор предикторов\nВ процессе анализа факторов, влияющих на пополнение запасов гидробионтов, важным этапом является тщательная подготовка данных и отбор наиболее информативных предикторов, поскольку качество последующих моделей напрямую зависит от качества входных данных. Начиная с первичной обработки, мы приводим все потенциальные предикторы к числовому формату, так как большинство статистических и машинно-обучаемых моделей требуют именно такой представления данных, при этом заменяем строковые обозначения пропущенных значений «NA» на стандартные NA, что позволяет системе R корректно обрабатывать отсутствующие наблюдения. Для заполнения пропусков мы применяем медианную импутацию, которая представляет собой простой и устойчивый к выбросам метод, поскольку медиана менее чувствительна к экстремальным значениям по сравнению со средним. Хотя существуют и более сложные альтернативы, такие как множественная импутация с использованием пакета mice, KNN-импутация через recipes::step_impute_knn или даже методы, специально разработанные для временных рядов, например, фильтр Калмана или ARIMA-модели, медианная импутация остается практичным выбором для начального этапа анализа, особенно когда объем данных ограничен или временные зависимости не являются доминирующими. Следующим важным этапом является анализ корреляционной структуры данных, поскольку высокая мультиколлинеарность между предикторами может серьезно ухудшить интерпретацию моделей и завысить дисперсию оценок параметров, особенно в линейных моделях. Для автоматического выявления и устранения сильно коррелированных переменных мы используем функцию findCorrelation с пороговым значением коэффициента корреляции 0.8, что позволяет сохранить лишь один представитель из каждой группы высококоррелированных переменных. Хотя альтернативными подходами могут служить диагностика по значениям VIF или применение методов снижения размерности, таких как PLS или PCA, удаление явно коррелированных предикторов оказывается наиболее прямолинейным решением для обеспечения стабильности последующих моделей. Для автоматического отбора наиболее значимых предикторов мы применяем два дополнительных метода, которые по-разному подходят к этой задаче и тем самым обеспечивают взаимную проверку результатов. Boruta представляет собой обертку над алгоритмом Random Forest, которая генерирует «теневые» переменные, полученные путем случайного перемешивания исходных признаков, и сравнивает важность реальных предикторов с этими теневыми копиями, сохраняя только те переменные, чья важность статистически превосходит уровень шума. Этот метод особенно эффективен при наличии нелинейных зависимостей и взаимодействий между переменными, демонстрируя высокую устойчивость к шуму, хотя и требует больше вычислительных ресурсов и может излишне благоволить к группам коррелированных признаков. Параллельно мы применяем LASSO-регрессию из пакета glmnet, которая использует L1-регуляризацию для зануления коэффициентов слабо влияющих предикторов, тем самым выполняет отбор признаков в процессе оценки модели. При выборе оптимального значения параметра регуляризации lambda мы сознательно предпочитаем значение lambda.1se, которое соответствует более простой модели, но при этом находится в пределах одной стандартной ошибки от минимального значения ошибки, так как этот консервативный подход часто обеспечивает лучшую обобщающую способность на небольших выборках, характерных для экологических данных. Однако LASSO имеет свои ограничения: он чувствителен к масштабу переменных, что делает центрирование и стандартизацию обязательными предварительными шагами, и предполагает линейную форму зависимости между предикторами и откликом, что может не соответствовать реальной биологической природе процессов. Финальный набор предикторов формируется как объединение результатов Boruta и LASSO с учетом биологической логики, что повышает устойчивость отбора к случайным флуктуациям, присущим каждому отдельному методу, и гарантирует включение ключевых переменных, таких как нерестовый запас (haddock68), который биологически должен влиять на пополнение запаса. Для предварительной проверки значимости отобранных предикторов мы строим простую линейную модель, которая не предназначена для окончательного прогноза, но служит в качестве sanity-check, позволяя оценить порядок величины эффектов и выявить явно незначимые или противоречащие биологической логике переменные. Важно отметить несколько нюансов и потенциальных подводных камней, с которыми можно столкнуться на этом этапе: если распределение целевой переменной R3haddock сильно скошено, может потребоваться лог-трансформация или использование моделей, специально разработанных для положительных откликов, таких как Gamma GLM; корреляция между переменными не обязательно отражает причинно-следственные связи, и при удалении высококоррелированных предикторов мы можем потерять полезную информацию, поэтому в некоторых случаях лучше применять методы, сохраняющие информацию из всех переменных, например, PLS или GAM; наконец, медианная импутация, хотя и проста в применении, может быть недостаточно точной для временных рядов, где хронологически осмысленная импутация, такая как скользящая медиана или интерполяция, часто дает более реалистичные результаты, учитывающие естественную динамику экологических процессов. Таким образом, этап подготовки данных и отбора предикторов представляет собой критически важный фундамент для последующего построения качественных моделей прогнозирования пополнения рыбных запасов, где баланс между статистической строгостью и биологической интерпретируемостью определяет успех всего анализа.\nСкрипт целиком можно скачать по ссылке\n\n# ==============================================================================\n# 1) ВЫБОР ПРЕДИКТОРОВ\n# ------------------------------------------------------------------------------\n# Цель блока: привести данные к числовому виду, обработать пропуски, сократить\n# мультиколлинеарность (сильные корреляции), а затем автоматически выделить\n# кандидатов-предикторов двумя методами (Boruta, LASSO). В конце сформируем\n# финальный пул признаков и проверим их значимость в простой LM.\n# ==============================================================================\n\n# Установка и подключение необходимых библиотек\n# Для автоматического отбора предикторов нам понадобятся дополнительные пакеты\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\nЗагрузка требуемого пакета: pacman\n\n\nWarning: пакет 'pacman' был собран под R версии 4.5.1\n\npacman::p_load(\n  readxl, tidyverse, caret, corrplot, mgcv, randomForest, xgboost,\n  Boruta,GGally, FactoMineR, glmnet, recipes, rsample  # Новые библиотеки для автоматического отбора\n)\n\n# Очистка среды и установка рабочей директории\n# Совет: rm(list=ls()) очищает все объекты в памяти R; setwd задаёт папку,\n# где искать/сохранять файлы. Убедитесь, что путь корректен на вашей машине.\nrm(list = ls())\nsetwd(\"C:/RECRUITMENT/\")\n\n# Пакеты для расширенного отбора предикторов\n# Boruta — обёртка над Random Forest для отбора признаков;\n# glmnet — регуляризация (LASSO/ElasticNet) для отбора/усиления обобщающей способности;\n# FactoMineR — PCA и другие многомерные методы (используем как утилиту).\nlibrary(Boruta)   # Алгоритм обертки для отбора признаков\nlibrary(glmnet)   # LASSO-регрессия\nlibrary(FactoMineR) # PCA анализ\n\n\n# Загрузка и первичная обработка данных\n# Шаги: фильтруем годы, приводим типы к числовому, заменяем строковые \"NA\" на NA.\nDATA &lt;- readxl::read_excel(\"RECRUITMENT.xlsx\", sheet = \"RECRUITMENT\") %&gt;%\n  filter(YEAR &gt; 1989 & YEAR &lt; 2022) %&gt;%\n  # Преобразуем необходимые столбцы в числовой формат\n  mutate(\n    across(starts_with(\"T\"), as.numeric),\n    across(starts_with(\"I\"), as.numeric),\n    across(starts_with(\"O\"), as.numeric),\n  ) %&gt;%\n  # Обработка пропущенных значений (заменяем строку \"NA\" на NA)\n  mutate(across(where(is.character), ~na_if(., \"NA\")))\n\n# 1. Подготовка данных -------------------------------------------------------\n# Выделим все возможные предикторы, включая географию и индексы трески\n# Примечание: оставляем только числовые переменные, т.к. большинство моделей\n# требует числовой вход без категориальных уровней.\npredictors &lt;- DATA %&gt;% \n  select(-YEAR, -R3haddock) %&gt;% \n  select_if(is.numeric) # Только числовые переменные\n\n# Целевая переменная\nresponse &lt;- DATA$R3haddock\n\n# В статистическом анализе мы различаем:\n# - Отклик (response/target variable) - то, что мы пытаемся предсказать (в нашем случае R3haddock)\n# - Предикторы (predictors/features) - переменные, которые могут объяснять изменения отклика\n# Для корректного анализа важно, чтобы предикторы были числовыми или преобразованы в числовой формат.\n\n# 2. Обработка пропусков -----------------------------------------------------\n# Заполнение медианными значениями — простой и устойчивый способ справиться с NA.\n# Альтернативы: множественная иммутация (mice), KNN-impute и др.\npredictors_filled &lt;- predictors %&gt;%\n  mutate(across(everything(), ~ifelse(is.na(.), median(., na.rm = TRUE), .)))\n\n# Заполнение медианой - простой и устойчивый метод обработки пропусков для числовых переменных.\n# Медиана предпочтительнее среднего, так как менее чувствительна к выбросам.\n\n# 3. Предварительный анализ корреляций ---------------------------------------\n# Зачем: высокие корреляции затрудняют интерпретацию и могут вредить ряду моделей.\ncor_matrix &lt;- cor(predictors_filled, use = \"complete.obs\")\ncorrplot(cor_matrix, method = \"circle\", type = \"upper\", tl.cex = 0.7)\n\n\n\n\n\n\n\n# Удаляем высокоскоррелированные предикторы (r &gt; 0.8)\n# Это механическое сокращение мультиколлинеарности до этапа отбора.\nhigh_cor &lt;- findCorrelation(cor_matrix, cutoff = 0.8)\npredictors_filtered &lt;- predictors_filled[, -high_cor]\n\n# Высокая корреляция между предикторами (мультиколлинеарность) может привести к нестабильности моделей.\n# Например, если два предиктора почти идентичны, модель может неустойчиво распределять их влияние на отклик.\n# Удаление сильно коррелированных переменных (r &gt; 0.8) помогает улучшить интерпретируемость и стабильность моделей.\n\n\n# 4. Автоматизированный отбор Boruta (обертка Random Forest) -----------------\n# Идея: определить признаки, которые важнее, чем случайный шум (shadow features).\n\n\n# Визуализация результатов\nplot(boruta_output, cex.axis = 0.7, las = 2)\n\n\n\n\n\n\n\nboruta_stats &lt;- attStats(boruta_output)\nselected_vars &lt;- getSelectedAttributes(boruta_output, withTentative = TRUE)\n\n# Boruta - это алгоритм отбора признаков, основанный на методе случайного леса.\n# Он сравнивает важность реальных переменных с \"теневыми\" переменными (случайными копиями),\n# чтобы определить, действительно ли переменная информативна.\n# Результаты Boruta показывают: \n#   - Confirmed (зеленые) - значимые предикторы\n#   - Tentative (желтые) - предикторы, близкие к порогу значимости\n#   - Rejected (красные) - незначимые предикторы\n\n\n# 5. LASSO с более строгим критерием ------------------------------------------\n# Идея: L1-регуляризация зануляет коэффициенты «слабых» предикторов.\n# Выбор lambda.1se вместо lambda.min — более консервативный (простая модель).\nx &lt;- as.matrix(predictors_filtered)\ny &lt;- response\n\n# LASSO (Least Absolute Shrinkage and Selection Operator) - метод регрессии с L1-регуляризацией,\n# который одновременно выполняет отбор признаков и оценку коэффициентов. [[8]]\n# Параметр lambda контролирует силу регуляризации:\n#   - lambda.min дает наименьшую ошибку, но может включать шумовые переменные\n#   - lambda.1se (на 1 стандартную ошибку больше) дает более простую модель с меньшим риском переобучения\n# Для прогнозирования мы предпочитаем более строгий критерий (lambda.1se), чтобы модель была устойчивее. [[1]]\n\n# Кросс-валидация\ncv_fit &lt;- cv.glmnet(x, y, alpha = 1, nfolds = 10)\nplot(cv_fit)\n\n\n\n\n\n\n\n# ИСПОЛЬЗУЕМ lambda.1se вместо lambda.min — СТРОЖЕ!\nlasso_coef &lt;- coef(cv_fit, s = \"lambda.1se\")  # &lt;-- Ключевое изменение!\nlasso_vars &lt;- rownames(lasso_coef)[lasso_coef[,1] != 0][-1]  # исключаем (Intercept)\n\n\n# 6. Сравнение отобранных предикторов ----------------------------------------\n# Полезно видеть, какие признаки отмечают оба метода (устойчивые кандидаты).\ncat(\"Boruta selected:\", length(selected_vars), \"variables\\n\")\n\nBoruta selected: 3 variables\n\nprint(selected_vars)\n\n[1] \"codTSB\" \"T12\"    \"I5\"    \n\ncat(\"\\nLASSO selected:\", length(lasso_vars), \"variables\\n\")\n\n\nLASSO selected: 5 variables\n\nprint(lasso_vars)\n\n[1] \"codTSB\" \"T12\"    \"NAO3\"   \"NAO4\"   \"NAO5\"  \n\n# 7. Финальный набор предикторов (объединение результатов) -------------------\n# Логика: объединяем списки, добавляем биологически важные переменные вручную.\nfinal_vars &lt;- union(selected_vars, lasso_vars) \n\n# Добавляем обязательные переменные по биологической логике\nmandatory &lt;- c(\"haddock68\")\nfinal_vars &lt;- union(final_vars, mandatory) %&gt;% unique()\n\n# Мы объединяем результаты двух методов отбора признаков для большей надежности.\n# Также добавляем переменную haddock68 (нерестовый запас), так как биологически \n# логично, что пополнение запаса напрямую зависит от численности производителей. \n# Это пример интеграции экспертных знаний в статистический анализ - важный принцип \n# при работе с данными в биологических науках.\n\n# 8. Проверка значимости -----------------------------------------------------\n# Быстрая оценка значимости с LM: не как окончательный вывод, а как sanity-check.\nfinal_model &lt;- lm(response ~ as.matrix(predictors_filled[, final_vars]))\nsummary(final_model)\n\n\nCall:\nlm(formula = response ~ as.matrix(predictors_filled[, final_vars]))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-270986  -82376   -1037   98086  276129 \n\nCoefficients:\n                                                      Estimate Std. Error\n(Intercept)                                         -1.082e+06  3.943e+05\nas.matrix(predictors_filled[, final_vars])codTSB    -2.346e-01  5.536e-02\nas.matrix(predictors_filled[, final_vars])T12        3.864e+05  7.198e+04\nas.matrix(predictors_filled[, final_vars])I5        -1.825e+02  2.572e+03\nas.matrix(predictors_filled[, final_vars])NAO3      -5.801e+04  3.129e+04\nas.matrix(predictors_filled[, final_vars])NAO4       8.345e+04  3.035e+04\nas.matrix(predictors_filled[, final_vars])NAO5      -7.278e+04  2.488e+04\nas.matrix(predictors_filled[, final_vars])haddock68  1.232e-01  4.515e-01\n                                                    t value Pr(&gt;|t|)    \n(Intercept)                                          -2.744 0.011305 *  \nas.matrix(predictors_filled[, final_vars])codTSB     -4.238 0.000288 ***\nas.matrix(predictors_filled[, final_vars])T12         5.368 1.64e-05 ***\nas.matrix(predictors_filled[, final_vars])I5         -0.071 0.944028    \nas.matrix(predictors_filled[, final_vars])NAO3       -1.854 0.076118 .  \nas.matrix(predictors_filled[, final_vars])NAO4        2.750 0.011146 *  \nas.matrix(predictors_filled[, final_vars])NAO5       -2.925 0.007412 ** \nas.matrix(predictors_filled[, final_vars])haddock68   0.273 0.787227    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 158600 on 24 degrees of freedom\nMultiple R-squared:  0.7173,    Adjusted R-squared:  0.6348 \nF-statistic: 8.698 on 7 and 24 DF,  p-value: 2.58e-05\n\n# 9. Формирование финального датасета ----------------------------------------\n# Собираем набор с откликом и выбранными предикторами; удалим строки с NA.\nmodel_data &lt;- DATA %&gt;%\n  select(R3haddock, all_of(final_vars)) %&gt;%\n  drop_na()\n\n# Просмотр структуры финальных данных\nglimpse(model_data)\n\nRows: 32\nColumns: 8\n$ R3haddock &lt;dbl&gt; 812363, 389416, 99474, 98946, 118812, 63028, 147657, 83270, ~\n$ codTSB    &lt;dbl&gt; 913000, 1347064, 1687381, 2197863, 2112773, 1849957, 1697388~\n$ T12       &lt;dbl&gt; 4.72, 4.66, 4.24, 3.90, 3.96, 4.27, 4.16, 4.07, 4.23, 5.08, ~\n$ I5        &lt;dbl&gt; 43, 55, 26, 49, 56, 28, 52, 51, 69, 68, 41, 48, 50, 63, 40, ~\n$ NAO3      &lt;dbl&gt; 1.46, -0.20, 0.87, 0.67, 1.26, 1.25, -0.24, 1.46, 0.87, 0.23~\n$ NAO4      &lt;dbl&gt; 2.00, 0.29, 1.86, 0.97, 1.14, -0.85, -0.17, -1.02, -0.68, -0~\n$ NAO5      &lt;dbl&gt; -1.53, 0.08, 2.63, -0.78, -0.57, -1.49, -1.06, -0.28, -1.32,~\n$ haddock68 &lt;dbl&gt; 74586, 79205, 53195, 36337, 49122, 81514, 172177, 160886, 96~\n\n# Визуализация важности переменных\n# Внимание: важности от RF — относительные; сопоставляйте с предметной логикой.\nvar_importance &lt;- randomForest(R3haddock ~ ., data = model_data, importance = TRUE)\nvarImpPlot(var_importance, main = \"Важность предикторов\")\n\n\n\n\n\n\n\n# Перед окончательным выбором модели мы проверяем значимость предикторов с помощью линейной регрессии.\n# Функция summary() показывает p-значения коэффициентов - если p &lt; 0.05, переменная считается статистически значимой. \n# Визуализация важности переменных с помощью случайного леса дает дополнительную перспективу,\n# показывая, какие переменные наиболее информативны для предсказания без предположений о линейности.\n\n# ==============================================================================\n#  ПОДГОТОВКА ДАННЫХ\n# Создаём NAOspring, фиксируем финальный набор признаков, сохраняем CSV.\n# ------------------------------------------------------------------------------\n# Цель блока: стандартизировать набор признаков для дальнейшего сравнения\n# моделей и обеспечить воспроизводимость (фиксированный CSV с нужными полями).\n# ==============================================================================\n\n# 1.1 Пакеты и окружение\n# Примечание: блок повторяет базовую инициализацию для автономного запуска.\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(readxl, tidyverse, caret, corrplot)\n\nrm(list = ls())\nset.seed(123)\nsetwd(\"C:/RECRUITMENT/\")\n\n# 1.2 Загрузка исходных данных и приведение типов\nDATA &lt;- readxl::read_excel(\"RECRUITMENT.xlsx\", sheet = \"RECRUITMENT\") %&gt;%\n  filter(YEAR &gt; 1989 & YEAR &lt; 2022) %&gt;%\n  mutate(\n    across(starts_with(\"T\"), as.numeric),\n    across(starts_with(\"I\"), as.numeric),\n    across(starts_with(\"O\"), as.numeric),\n    across(where(is.character), ~na_if(., \"NA\"))\n  )\n\n# 1.3 Создаём NAOspring (если есть NAO3, NAO4, NAO5)\n# Идея: агрегируем весенний индекс NAO как среднее за месяцы 3–5.\nif (all(c(\"NAO3\",\"NAO4\",\"NAO5\") %in% names(DATA))) {\n  DATA &lt;- DATA %&gt;%\n    mutate(NAOspring = rowMeans(pick(NAO3, NAO4, NAO5), na.rm = TRUE)) %&gt;%\n    select(-NAO3, -NAO4, -NAO5)\n}\n\n# NAO (North Atlantic Oscillation) - важный климатический индекс, влияющий описывающий изменения атмосферного давления\n# над Северной Атлантикой. В частности, он отражает разницу в атмосферном давлении между Исландской депрессией и\n# Азорским максимумом. NAO влияет на силу и направление западных ветров, а также на траектории штормов в Северной Атлантике. \n# Мы создаем NAOspring как среднее значение за весенние месяцы (марта, апреля, мая),\n# так как именно в этот период происходят ключевые процессы, влияющие на нерест трески. \n# Создание составных переменных на основе экспертных знаний часто улучшает качество моделей.\n\n# 1.4 Финальный учебный набор предикторов (фиксируем)\n# Важно: проверяем присутствие нужных колонок и формируем компактный датасет.\nneeded &lt;- c(\"codTSB\", \"T12\", \"I5\", \"NAOspring\", \"haddock68\")\nstopifnot(all(needed %in% names(DATA)))\n\n# Сохраняем YEAR в CSV (ниже он будет отброшен при обучении, но нужен для графика)\nmodel_data &lt;- DATA %&gt;%\n  select(YEAR, all_of(needed), R3haddock) %&gt;%\n  drop_na()\n\nwrite.csv(model_data, \"selected_predictors_dataset.csv\", row.names = FALSE)\nglimpse(model_data)\n\nRows: 32\nColumns: 7\n$ YEAR      &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, ~\n$ codTSB    &lt;dbl&gt; 913000, 1347064, 1687381, 2197863, 2112773, 1849957, 1697388~\n$ T12       &lt;dbl&gt; 4.72, 4.66, 4.24, 3.90, 3.96, 4.27, 4.16, 4.07, 4.23, 5.08, ~\n$ I5        &lt;dbl&gt; 43, 55, 26, 49, 56, 28, 52, 51, 69, 68, 41, 48, 50, 63, 40, ~\n$ NAOspring &lt;dbl&gt; 0.64333333, 0.05666667, 1.78666667, 0.28666667, 0.61000000, ~\n$ haddock68 &lt;dbl&gt; 74586, 79205, 53195, 36337, 49122, 81514, 172177, 160886, 96~\n$ R3haddock &lt;dbl&gt; 812363, 389416, 99474, 98946, 118812, 63028, 147657, 83270, ~",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Прогноз пополнения: от факторов до ансамбля</span>"
    ]
  },
  {
    "objectID": "chapter 7.html#модели-запас-пополнение-рикера-и-бивертона-холта",
    "href": "chapter 7.html#модели-запас-пополнение-рикера-и-бивертона-холта",
    "title": "8  Прогноз пополнения: от факторов до ансамбля",
    "section": "8.3 Модели «запас-пополнение» Рикера и Бивертона-Холта",
    "text": "8.3 Модели «запас-пополнение» Рикера и Бивертона-Холта\nМодели запас-пополнение представляют собой фундаментальный инструмент в оценке водных биоресурсов, которые гораздо больше, чем просто математические кривые, — это формализованные выражения фундаментальных биологических представлений о том, как численность родительского стада определяет успех следующего поколения. Среди классических моделей этого типа наиболее широко используются модель Рикера и модель Бивертона-Холта, каждая из которых отражает различные гипотезы о биологических процессах, происходящих в популяции. Модель Рикера, предложенная Уильямом Рикером в 1954 году и имеющая характерный горб на графике, выражается уравнением R = a*S*exp(-b*S), где R обозначает пополнение, S — нерестовый запас, а параметры a и b имеют четкую биологическую интерпретацию: a соответствует максимальной продуктивности на единицу запаса при очень низких плотностях, фактически отражая максимальное пополнение (количество рекрутов) на одного производителя, а b характеризует степень плотностной зависимости, определяющей точку, после которой начинается снижение из-за внутривидовой конкуренции. Эта модель предсказывает, что с ростом нерестового запаса пополнение сначала увеличивается, достигает максимума, а затем снижается, что отражает явление перенаселенности, когда чрезмерная плотность производителей приводит к конкуренции за ресурсы, нехватке корма для личинок, усилению каннибализма или даже эпидемиям, что в итоге снижает выход молоди — мы буквально видим, как чрезмерный успех закладывает семена будущего коллапса пополнения. В отличие от нее, модель Бивертона-Холта, разработанная в 1957 году, имеет вид R = aS/(1+b*S) и предполагает, что пополнение асимптотически приближается к предельному значению a/b, называемому Rmax, с увеличением нерестового запаса, без последующего снижения, что соответствует ситуации, когда основной лимитирующий фактор — это не внутривидовая конкуренция, а внешние условия: ограниченное количество нерестовых площадок, хищничество, которое не зависит от плотности, или просто конечная пропускная способность экосистемы для молоди. Эта модель идеально описывает сценарий, когда кривая плавно выходит на плато, символизируя насыщение, и представляет собой альтернативную логику, где главным ограничивающим фактором являются внешние, а не внутривидовые процессы.\nПри оценке параметров этих нелинейных моделей мы сталкиваемся с необходимостью применения специализированных методов, поскольку обычный метод наименьших квадратов не справляется с их сложной структурой; в нашем анализе мы используем улучшенный алгоритм nlsLM из пакета minpack.lm, который сочетает метод Левенберга-Марквардта с возможностью наложения ограничений на параметры, что важно для обеспечения биологической правдоподобности результатов, так как параметры a и b должны оставаться положительными. Для получения надежных начальных оценок параметров в модели Рикера мы применяем функцию srStarts из пакета FSA, которая автоматически определяет разумные стартовые значения на основе анализа данных, тогда как для модели Бивертона-Холта мы используем комбинацию автоматических и ручных подходов, оценивая a как среднее отношение R/S при низких значениях запаса и устанавливая разумные начальные значения для b с последующей защитой от некорректных значений. Однако подбор модели — это только полдела, и критически важно провести тщательную диагностику, поскольку самая большая ошибка — слепо применять эти модели, не задумываясь об их предпосылках. Мы строим график остатков, потому что любая закономерность в их распределении — это сигнал о том, что модель не уловила какой-то важный процесс в данных. Мы смотрим на доверительные интервалы параметров; если они невероятно широки, значит, наша модель перепараметризована для имеющихся данных, и её прогностическая сила будет сомнительной. Модель Рикера не будет работать, если в вашей системе нет механизма перенаселения, а модель Бивертона-Холта окажется бесполезной, если пополнение продолжает расти или, наоборот, обрушивается после достижения пика. Именно поэтому мы всегда начинаем с простого графика «запас-пополнение» — его форма сама подскажет, какая из концепций более адекватна для конкретной популяции.\nНо реальный мир часто бывает сложнее этих двух идеализированных сценариев. Что если система ведёт себя по-рикеровски при высокой численности, но при низкой — работает иначе? Здесь на помощь приходит модификация — модель Рикера с порогом, или hockey-stick модель, которая сочетает в себе линейный рост при малых запасах и плато или спад при высоких, что может быть биологически более оправдано для многих запасов, находящихся под прессом промысла. И здесь мы подходим к самому главному — интеграции классики и современности. Эти модели не являются застывшими реликтами, а служат мощным инструментом для создания гипотез. Если модель Рикера плохо описывает данные, особенно в области низких значений запаса, это прямой сигнал о том, что возможно, существует какой-то дополнительный лимитирующий фактор, не учтенный в модели. Возможно, это температура воды на ключевой стадии развития икры, наличие хищников или доступность корма. Таким образом, классические модели становятся трамплином для более сложного анализа, включающего средовые предикторы. Мы можем включить параметры модели Рикера в качестве фиксированных эффектов в GAM или использовать предсказания классической модели в качестве одного из входных признаков для Random Forest. Этот синтез позволяет нам сохранить биологическую интерпретируемость классических моделей и добавить к ним гибкость и прогностическую силу машинного обучения для учета сложных, нелинейных влияний окружающей среды. В сущности, мы строим мост между глубоким, но узким знанием, заключенным в одной кривой, и широким, но зачастую “черно-ящичным” прогнозом сложного алгоритма, пытаясь получить лучшее из двух миров. Среди распространенных подводных камней при работе с моделями запас-пополнение следует отметить высокую чувствительность к начальным значениям параметров, что может приводить к сходимости к локальным минимумам, необходимость учета неоднородности дисперсии ошибок, особенно при работе с данными, охватывающими широкий диапазон значений запаса, и влияние временных лагов, поскольку пополнение в текущем году может зависеть не только от нерестового запаса в том же году, но и от условий прошлых лет. Кроме того, чистые модели запас-пополнение часто оказываются недостаточными для точного прогнозирования, так как пополнение зависит не только от размера нерестового запаса, но и от множества экологических факторов, что делает целесообразным развитие этих моделей в направлении включения дополнительных предикторов, как это продемонстрировано в последующих разделах нашего анализа. Тем не менее, классические модели Рикера и Бивертона-Холта остаются важной отправной точкой в анализе динамики рыбных популяций, предоставляя интерпретируемую основу для понимания механизмов регулирования численности и служа эталоном для оценки добавленной ценности более сложных моделей, что особенно важно в условиях ограниченных данных, характерных для многих водных экосистем.\n\n# ==============================================================================\n# ПРАКТИЧЕСКОЕ ЗАНЯТИЕ: АНАЛИЗ ФАКТОРОВ, ВЛИЯЮЩИХ НА ПОПОЛНЕНИЕ \n# (КЛАССИЧЕСКИЕ МОДЕЛИ ЗАПАС-ПОПОЛНЕНИЕ)\n# Курс: \"Оценка водных биоресурсов в среде R (для начинающих)\"\n# ==============================================================================\n\n# Установка и подключение ТОЛЬКО необходимых библиотек\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  tidyverse,    # Манипуляции с данными и визуализация\n  FSA,          # Начальные оценки для моделей запас-пополнение\n  minpack.lm,   # Улучшенный алгоритм нелинейной регрессии (nlsLM)\n  car,          # Проверка допущений моделей\n  mgcv,         # Построение GAM-моделей\n  investr,      # Доверительные интервалы для нелинейных моделей\n   caret)       # Расчет RMSE\n\n# Очистка среды и установка рабочей директории\nrm(list = ls())\nsetwd(\"C:/RECRUITMENT/\")\n\n# 1. ЗАГРУЗКА ДАННЫХ -----------------------------------------------------------\nmodel_data &lt;- read.csv(\"selected_predictors_dataset.csv\", \n                      header = TRUE, \n                      stringsAsFactors = FALSE)\n\n# Проверка структуры данных\nstr(model_data)\n\n'data.frame':   32 obs. of  7 variables:\n $ YEAR     : int  1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 ...\n $ codTSB   : int  913000 1347064 1687381 2197863 2112773 1849957 1697388 1537459 1350918 1199169 ...\n $ T12      : num  4.72 4.66 4.24 3.9 3.96 4.27 4.16 4.07 4.23 5.08 ...\n $ I5       : int  43 55 26 49 56 28 52 51 69 68 ...\n $ NAOspring: num  0.6433 0.0567 1.7867 0.2867 0.61 ...\n $ haddock68: int  74586 79205 53195 36337 49122 81514 172177 160886 96380 37977 ...\n $ R3haddock: int  812363 389416 99474 98946 118812 63028 147657 83270 359701 386866 ...\n\n# Проверка на пропущенные значения (должно быть 0 после предобработки)\nsum(is.na(model_data))\n\n[1] 0\n\n# 2. ПОДГОТОВКА ДАННЫХ ДЛЯ МОДЕЛЕЙ ЗАПАС-ПОПОЛНЕНИЕ ----------------------------\nrec_data &lt;- data.frame(\n  S = model_data$haddock68,  # Нерестовый запас\n  R = model_data$R3haddock   # Пополнение\n)\n\n# 3. ПОДГОНКА МОДЕЛИ РИКЕРА ----------------------------------------------------\nricker_starts &lt;- FSA::srStarts(R ~ S, data = rec_data, type = \"Ricker\")\nricker_model &lt;- minpack.lm::nlsLM(\n  R ~ a * S * exp(-b * S),\n  data = rec_data,\n  start = ricker_starts,\n  lower = c(a = 0, b = 0)\n)\n\n# 4. ПОДГОНКА МОДЕЛИ БИВЕРТОНА-ХОЛТА -------------------------------------------\na_start &lt;- mean(rec_data$R[rec_data$S &lt; quantile(rec_data$S, 0.25)] / \n                rec_data$S[rec_data$S &lt; quantile(rec_data$S, 0.25)], na.rm = TRUE)\n\nif (is.na(a_start) || a_start &lt;= 0) a_start &lt;- 0.001\n\nbh_model &lt;- minpack.lm::nlsLM(\n  R ~ (a * S) / (1 + b * S),\n  data = rec_data,\n  start = list(a = a_start, b = 0.0001),\n  lower = c(a = 0.0001, b = 0.00001),\n  control = nls.lm.control(maxiter = 200)\n)\n\n# 5. ОЦЕНКА КАЧЕСТВА МОДЕЛЕЙ ---------------------------------------------------\n\ncalculate_R2 &lt;- function(model, data) {\n  predicted &lt;- predict(model, newdata = data)\n  residuals &lt;- data$R - predicted\n  SSE &lt;- sum(residuals^2)\n  SST &lt;- sum((data$R - mean(data$R))^2)\n  R2 &lt;- 1 - (SSE / SST)\n  n &lt;- nrow(data)\n  p &lt;- length(coef(model))\n  adj_R2 &lt;- 1 - ((n - 1) / (n - p - 1)) * (1 - R2)\n  return(list(R2 = R2, adj_R2 = adj_R2))\n}\n\ncalculate_pvalue &lt;- function(model, data) {\n  predicted &lt;- predict(model, newdata = data)\n  residuals &lt;- data$R - predicted\n  SSE &lt;- sum(residuals^2)\n  SST &lt;- sum((data$R - mean(data$R))^2)\n  SSR &lt;- SST - SSE\n  n &lt;- nrow(data)\n  p &lt;- length(coef(model))\n  F_stat &lt;- (SSR / (p - 1)) / (SSE / (n - p))\n  p_value &lt;- pf(F_stat, df1 = p - 1, df2 = n - p, lower.tail = FALSE)\n  return(p_value)\n}\n\nricker_r2 &lt;- calculate_R2(ricker_model, rec_data)\nbh_r2 &lt;- calculate_R2(bh_model, rec_data)\n\nricker_p &lt;- calculate_pvalue(ricker_model, rec_data)\nbh_p &lt;- calculate_pvalue(bh_model, rec_data)\n\ncat(\"AIC Рикера:\", AIC(ricker_model), \"\\n\")\n\nAIC Рикера: 891.9919 \n\ncat(\"AIC Бивертона-Холта:\", AIC(bh_model), \"\\n\")\n\nAIC Бивертона-Холта: 894.2029 \n\n# 6. ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ --------------------------------------------------\nnew_data &lt;- data.frame(S = seq(min(rec_data$S), max(rec_data$S), length.out = 100))\nricker_ci &lt;- investr::predFit(ricker_model, newdata = new_data, interval = \"confidence\")\nbh_ci &lt;- investr::predFit(bh_model, newdata = new_data, interval = \"confidence\")\n\nplot_data &lt;- new_data %&gt;%\n  mutate(\n    ricker_pred = predict(ricker_model, newdata = .),\n    ricker_lwr = ricker_ci[, \"lwr\"],\n    ricker_upr = ricker_ci[, \"upr\"],\n    bh_pred = predict(bh_model, newdata = .),\n    bh_lwr = bh_ci[, \"lwr\"],\n    bh_upr = bh_ci[, \"upr\"]\n  )\n\nggplot() +\n  geom_point(data = rec_data, aes(x = S, y = R), \n             color = \"darkgray\", size = 3, alpha = 0.7) +\n  geom_ribbon(data = plot_data, aes(x = S, ymin = ricker_lwr, ymax = ricker_upr), \n              fill = \"red\", alpha = 0.2) +\n  geom_ribbon(data = plot_data, aes(x = S, ymin = bh_lwr, ymax = bh_upr), \n              fill = \"blue\", alpha = 0.2) +\n  geom_line(data = plot_data, aes(x = S, y = ricker_pred), \n            color = \"red\", linewidth = 1.2) +\n  geom_line(data = plot_data, aes(x = S, y = bh_pred), \n            color = \"blue\", linewidth = 1.2, linetype = \"dashed\") +\n  labs(\n    title = \"Сравнение моделей запас-пополнение\",\n    subtitle = paste0(\n      \"Рикер: R² = \", round(ricker_r2$R2, 2), \", p = \", format.pval(ricker_p, digits = 3),\n      \" | Бивертон-Холт: R² = \", round(bh_r2$R2, 2), \", p = \", format.pval(bh_p, digits = 3)\n    ),\n    x = \"Нерестовый запас\",\n    y = \"Пополнение\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n# 7. СРАВНЕНИЕ С ДРУГИМИ ТИПАМИ МОДЕЛЕЙ ----------------------------------------\n\nlm_model &lt;- lm(R3haddock ~ ., data = model_data)\nglm_model &lt;- glm(R3haddock ~ ., family = Gamma(link = \"log\"), data = model_data)\ngam_model &lt;- mgcv::gam(R3haddock ~ s(haddock68) + s(codTSB) + s(T12) + s(I5) + s(NAOspring),\n               data = model_data, method = \"REML\")\n\nmodel_comparison &lt;- data.frame(\n  Model = c(\"Рикер\", \"Бивертон-Холт\", \"LM\", \"GLM\", \"GAM\"),\n  AIC = c(AIC(ricker_model), AIC(bh_model), AIC(lm_model), AIC(glm_model), AIC(gam_model)),\n  R2 = c(\n    ricker_r2$R2, \n    bh_r2$R2, \n    summary(lm_model)$r.squared,\n    cor(model_data$R3haddock, predict(glm_model, type = \"response\"))^2,\n    summary(gam_model)$r.sq\n  )\n)\n\nprint(model_comparison)\n\n          Model      AIC          R2\n1         Рикер 891.9919 0.072305265\n2 Бивертон-Холт 894.2029 0.005938625\n3            LM 877.0895 0.573972535\n4           GLM 857.0346 0.566389771\n5           GAM 862.9064 0.738660678\n\n# 8. ИНТЕРПРЕТАЦИЯ РЕЗУЛЬТАТОВ -------------------------------------------------\ncat(\"\\nПараметры модели Рикера:\")\n\n\nПараметры модели Рикера:\n\ncat(\"\\na =\", coef(ricker_model)[1], \"- максимальная продукция потомства\")\n\n\na = 7.931302 - максимальная продукция потомства\n\ncat(\"\\nb =\", coef(ricker_model)[2], \"- коэффициент плотностной зависимости\")\n\n\nb = 7.4007e-06 - коэффициент плотностной зависимости\n\ncat(\"\\n\\nПараметры модели Бивертона-Холта:\")\n\n\n\nПараметры модели Бивертона-Холта:\n\ncat(\"\\na =\", coef(bh_model)[1], \"- максимальное пополнение на особь\")\n\n\na = 43.77667 - максимальное пополнение на особь\n\ncat(\"\\nb =\", coef(bh_model)[2], \"- коэффициент внутривидовой конкуренции\")\n\n\nb = 0.0001247403 - коэффициент внутривидовой конкуренции\n\n# ==============================================================================\n# 7. СРАВНЕНИЕ С ДРУГИМИ ТИПАМИ МОДЕЛЕЙ ----------------------------------------\n\n# Построение линейной модели LM\nlm_model &lt;- lm(R3haddock ~ ., data = model_data)\n\n# Диагностика\npar(mfrow = c(2, 2))\nplot(lm_model)\n\n\n\n\n\n\n\nvif(lm_model)  # Проверка мультиколлинеарности\n\n     YEAR    codTSB       T12        I5 NAOspring haddock68 \n 2.925549  3.439340  1.970023  1.332529  1.181897  2.522569 \n\n# Интерпретация\nsummary(lm_model)\n\n\nCall:\nlm(formula = R3haddock ~ ., data = model_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-279162 -111056  -35757  141083  324173 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.448e+07  1.224e+07   1.183 0.248123    \nYEAR        -7.863e+03  6.248e+03  -1.258 0.219869    \ncodTSB      -1.888e-01  7.817e-02  -2.416 0.023338 *  \nT12          4.339e+05  9.738e+04   4.456 0.000153 ***\nI5          -2.568e+03  3.058e+03  -0.840 0.409036    \nNAOspring   -7.666e+04  5.735e+04  -1.337 0.193325    \nhaddock68    2.782e-01  5.485e-01   0.507 0.616444    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 190800 on 25 degrees of freedom\nMultiple R-squared:  0.574, Adjusted R-squared:  0.4717 \nF-statistic: 5.614 on 6 and 25 DF,  p-value: 0.0008393\n\n# Построение обобщенной линейной модели GLM\nglm_model &lt;- glm(R3haddock ~ ., \n                family = Gamma(link = \"log\"), \n                data = model_data)\nsummary(glm_model)\n\n\nCall:\nglm(formula = R3haddock ~ ., family = Gamma(link = \"log\"), data = model_data)\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.375e+01  3.667e+01   0.648   0.5231    \nYEAR        -8.601e-03  1.872e-02  -0.459   0.6499    \ncodTSB      -5.945e-07  2.342e-07  -2.539   0.0177 *  \nT12          1.411e+00  2.917e-01   4.837 5.68e-05 ***\nI5           7.430e-03  9.161e-03   0.811   0.4250    \nNAOspring    1.508e-02  1.718e-01   0.088   0.9307    \nhaddock68    9.422e-07  1.643e-06   0.573   0.5715    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.326724)\n\n    Null deviance: 19.8880  on 31  degrees of freedom\nResidual deviance:  8.4535  on 25  degrees of freedom\nAIC: 857.03\n\nNumber of Fisher Scoring iterations: 9\n\n# Построение обобщенной аддитивной модели GАM\nlibrary(mgcv)\ngam_model &lt;- gam(R3haddock ~ \n                 s(codTSB) + \n                 s(T12) + \n                 s(I5) + \n                 s(NAOspring) + \n                 s(haddock68),\n               data = model_data,\n               method = \"REML\")\nsummary(gam_model)\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nR3haddock ~ s(codTSB) + s(T12) + s(I5) + s(NAOspring) + s(haddock68)\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   320163      23724   13.49 4.37e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n               edf Ref.df     F p-value   \ns(codTSB)    2.354  2.899 1.684 0.17581   \ns(T12)       2.190  2.676 5.908 0.00357 **\ns(I5)        4.642  5.539 1.518 0.15004   \ns(NAOspring) 1.293  1.503 1.154 0.22854   \ns(haddock68) 1.824  2.200 0.629 0.65124   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.739   Deviance explained = 84.2%\n-REML = 361.62  Scale est. = 1.8011e+10  n = 32\n\nplot(gam_model, pages = 1, residuals = TRUE)\n\n\n\n\n\n\n\n# Таблица сравнения моделей\n# Сравнение моделей\nmodel_comparison &lt;- data.frame(\n  Model = c(\"Рикер\", \"Бивертон-Холт\", \"LM\", \"GLM\", \"GAM\"),\n  AIC = c(AIC(ricker_model), AIC(bh_model), AIC(lm_model), AIC(glm_model), AIC(gam_model)),\n  R2 = c(ricker_r2$R2, bh_r2$R2, summary(lm_model)$r.squared, \n         cor(model_data$R3haddock, predict(glm_model))^2, \n         summary(gam_model)$r.sq),  # Используем summary(gam_model)$r.sq для R^2\n  Adj_R2 = c(ricker_r2$adj_R2, bh_r2$adj_R2, summary(lm_model)$adj.r.squared, NA, \n             summary(gam_model)$r.sq),  # Используем summary(gam_model)$r.sq для Adjusted R^2\n  RMSE = c(RMSE(predict(ricker_model), rec_data$R), \n           RMSE(predict(bh_model), rec_data$R),\n           RMSE(predict(lm_model), model_data$R3haddock),\n           RMSE(predict(glm_model, type = \"response\"), model_data$R3haddock),\n           RMSE(predict(gam_model, type = \"response\"), model_data$R3haddock))\n)\n\n# Вывод таблицы\nprint(model_comparison)\n\n          Model      AIC          R2       Adj_R2     RMSE\n1         Рикер 891.9919 0.072305265  0.008326318 248869.6\n2 Бивертон-Холт 894.2029 0.005938625 -0.062617332 257617.8\n3            LM 877.0895 0.573972535  0.471725944 168650.7\n4           GLM 857.0346 0.502625978           NA 170386.6\n5           GAM 862.9064 0.738660678  0.738660678 102584.0\n\n# ==============================================================================\n# ВИЗУАЛИЗАЦИЯ ВСЕХ МОДЕЛЕЙ НА ОДНОМ ГРАФИКЕ \n# ==============================================================================\n\n# Фиксируем другие предикторы на их средних значениях (исключая haddock68)\nmean_values &lt;- model_data %&gt;%\n  select(-R3haddock, -haddock68) %&gt;%\n  summarise(across(everything(), ~ mean(.x, na.rm = TRUE)))\n\n# Расширяем new_data, добавляя средние значения других предикторов\nnew_data_full &lt;- new_data %&gt;%\n  bind_cols(mean_values[rep(1, nrow(new_data)), ]) %&gt;%\n  rename(haddock68 = S)  # Переименовываем S в haddock68 для совместимости\n\n# Получаем предсказания для всех моделей\nnew_data_full &lt;- new_data_full %&gt;%\n  mutate(\n    # Предсказания для моделей запаса-пополнения\n    ricker_pred = predict(ricker_model, newdata = data.frame(S = haddock68)),\n    bh_pred = predict(bh_model, newdata = data.frame(S = haddock68)),\n    \n    # Предсказания для линейной модели (LM)\n    lm_pred = predict(lm_model, newdata = .),\n    \n    # Предсказания для обобщенной линейной модели (GLM)\n    glm_pred = predict(glm_model, newdata = ., type = \"response\"),\n    \n    # Предсказания для обобщенной аддитивной модели (GAM)\n    gam_pred = predict(gam_model, newdata = ., type = \"response\")\n  )\n\n# Создаем длинный формат данных для ggplot\nplot_data &lt;- new_data_full %&gt;%\n  select(haddock68, ricker_pred, bh_pred, lm_pred, glm_pred, gam_pred) %&gt;%\n  pivot_longer(\n    cols = -haddock68,\n    names_to = \"model\",\n    values_to = \"prediction\"\n  ) %&gt;%\n  mutate(\n    model = case_when(\n      model == \"ricker_pred\" ~ \"Рикер\",\n      model == \"bh_pred\" ~ \"Бивертон-Холт\",\n      model == \"lm_pred\" ~ \"Линейная (LM)\",\n      model == \"glm_pred\" ~ \"Обобщенная линейная (GLM)\",\n      model == \"gam_pred\" ~ \"Обобщенная аддитивная (GAM)\",\n      TRUE ~ model\n    )\n  )\n\n# Создаем палитру цветов для моделей\nmodel_colors &lt;- c(\n  \"Рикер\" = \"#E41A1C\",          # Красный\n  \"Бивертон-Холт\" = \"#377EB8\",  # Синий\n  \"Линейная (LM)\" = \"#4DAF4A\",  # Зеленый\n  \"Обобщенная линейная (GLM)\" = \"#984EA3\", # Фиолетовый\n  \"Обобщенная аддитивная (GAM)\" = \"#FF7F00\" # Оранжевый\n)\n\n# Создаем график\nggplot() +\n  # Точки исходных данных\n  geom_point(data = rec_data, aes(x = S, y = R), \n             color = \"darkgray\", size = 2.5, alpha = 0.7) +\n  \n  # Линии предсказаний моделей\n  geom_line(data = plot_data, \n            aes(x = haddock68, y = prediction, color = model, linetype = model),\n            linewidth = 1.2) +\n  \n  # Настройка цветов и типов линий\n  scale_color_manual(values = model_colors) +\n  scale_linetype_manual(values = c(\n    \"Рикер\" = \"solid\",\n    \"Бивертон-Холт\" = \"dashed\",\n    \"Линейная (LM)\" = \"dotdash\",\n    \"Обобщенная линейная (GLM)\" = \"longdash\",\n    \"Обобщенная аддитивная (GAM)\" = \"twodash\"\n  )) +\n  \n  # Подписи и темы\n  labs(\n    title = \"Сравнение моделей зависимости пополнения от нерестового запаса\",\n    subtitle = \"Фиксация других предикторов на средних значениях\",\n    x = \"Нерестовый запас (тыс. тонн)\",\n    y = \"Пополнение (млн особей)\",\n    color = \"Модель\",\n    linetype = \"Модель\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    plot.subtitle = element_text(size = 12, hjust = 0.5, color = \"gray30\"),\n    axis.title = element_text(size = 12),\n    legend.position = \"bottom\",\n    legend.box = \"horizontal\",\n    legend.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank(),\n    panel.border = element_rect(color = \"gray80\", fill = NA, linewidth = 0.5)\n  ) +\n  guides(\n    color = guide_legend(nrow = 2, byrow = TRUE),\n    linetype = guide_legend(nrow = 2, byrow = TRUE)\n  )",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Прогноз пополнения: от факторов до ансамбля</span>"
    ]
  },
  {
    "objectID": "chapter 7.html#статистические-модели-lmglmgam",
    "href": "chapter 7.html#статистические-модели-lmglmgam",
    "title": "8  Прогноз пополнения: от факторов до ансамбля",
    "section": "8.4 Статистические модели LM/GLM/GAM",
    "text": "8.4 Статистические модели LM/GLM/GAM\nСтатистические модели линейной регрессии (LM), обобщенной линейной регрессии (GLM) и обобщенной аддитивной регрессии (GAM) представляют собой мощный и взаимодополняющий набор инструментов для анализа водных биоресурсов, позволяющий исследователям от простых линейных зависимостей переходить к сложным нелинейным взаимодействиям, сохраняя при этом интерпретируемость результатов. Линейная модель (LM) служит фундаментом для всего статистического анализа в гидробиологии, основываясь на предположении, что зависимость между предикторами и откликом является линейной, а остатки распределены нормально с постоянной дисперсией. Эта модель предоставляет простую интерпретацию коэффициентов как величины изменения отклика при единичном изменении предиктора, что особенно ценно при работе с такими биологическими показателями, как пополнение запаса или нерестовая биомасса. Однако при анализе водных биоресурсов мы часто сталкиваемся с данными, которые нарушают ключевые предположения LM: пополнение рыбы или беспозвоночного не может быть отрицательным, его распределение обычно сильно скошено вправо, а дисперсия часто увеличивается с ростом среднего значения. Именно здесь на помощь приходит обобщенная линейная модель (GLM), расширяющая возможности LM за счет введения двух ключевых компонентов — экспоненциального семейства распределений и связующей функции (link-function). Для данных о рыбных запасах особенно полезно Gamma-распределение с логарифмической связкой, которое учитывает положительность отклика и мультипликативную природу ошибок, характерную для биологических данных. В отличие от LM, где мы интерпретируем коэффициенты как абсолютные изменения, в GLM с лог-связкой коэффициенты отражают относительные изменения: увеличение предиктора на единицу приводит к умножению ожидаемого отклика на exp(коэффициент), что соответствует биологической реальности, где эффекты часто действуют мультипликативно, а не аддитивно. Но даже GLM сохраняет ограничение на линейность в преобразованном пространстве, что может быть недостаточным для описания сложных экологических зависимостей, таких как оптимальный диапазон температуры для нереста или пороговые эффекты средовых факторов. Здесь в игру вступают обобщенные аддитивные модели (GAM), которые заменяют линейные комбинации предикторов на гладкие функции, оцениваемые с помощью сплайнов, что позволяет моделировать практически любые нелинейные зависимости без предварительного задания их формы. GAM сохраняет интерпретируемость линейных моделей, так как каждая гладкая функция может быть визуализирована и проанализирована отдельно, показывая, как именно каждый фактор влияет на пополнение запаса, будь то монотонный рост, оптимум с максимумом или сложная колебательная зависимость. При работе с GAM особое внимание уделяется выбору степени гладкости, так как чрезмерно гибкие функции могут переобучиться на шум в данных, тогда как недостаточно гибкие не уловят реальные биологические закономерности; в пакете mgcv это решается автоматически через метод максимального правдоподобия с штрафом (REML), который балансирует качество подгонки и гладкость функций. Сравнивая эти модели с классическими моделями запас-пополнение, мы видим, что GAM может рассматриваться как их естественное обобщение: вместо фиксированной формы кривой Рикера или Бивертона-Холта GAM позволяет данным “говорить за себя”, выявляя оптимальную форму зависимости без предварительных гипотез, при этом сохраняя возможность включить нерестовый запас как один из гладких членов в модель, дополненный другими экологическими факторами. Однако при всей своей гибкости, GAM, как и LM с GLM, требует тщательной проверки предположений: мы анализируем графики остатков против предсказанных значений, чтобы убедиться в отсутствии систематических отклонений, проверяем нормальность остатков (для LM) или соответствие выбранному распределению (для GLM/GAM), и исследуем влияние влиятельных точек, которые могут исказить результаты, особенно в условиях ограниченных данных, характерных для гидробиологических исследований. Выбор между LM, GLM и GAM должен основываться не только на статистических критериях, таких как AIC или кросс-валидация, но и на биологической интерпретируемости результатов: иногда более простая модель с меньшей точностью предпочтительнее сложного “черного ящика”, особенно когда результаты должны быть понятны начальникам и менеджерам рыболовства. Практический подход, который обычно рекомендуется начинающим ихтиологам/гидробиологам, состоит в последовательном усложнении модели: начните с классической модели запас-пополнение, затем добавьте средовые факторы через LM/GLM, и только если зависимости явно нелинейны, перейдите к GAM, всегда проверяя, действительно ли усложнение модели приводит к биологически значимому улучшению понимания процесса. Важно помнить, что статистическая модель — это не самоцель, а инструмент для понимания биологических процессов, и даже самая изощренная модель бесполезна, если её результаты нельзя перевести на язык биологии и применить для устойчивого управления водными ресурсами. В конечном счете, сочетание классических представлений об экосистемах с современными статистическими методами позволяет нам строить мост между фундаментальной биологией и прикладной оценкой запасов, где каждая модель, от простой линейной регрессии до сложного GAM, вносит свой вклад в формирование целостного понимания динамики водных биоресурсов.\n\n# ==============================================================================\n# Версия: только LM / GLM(Gamma) / GAM\n# Без caret/train: стандартная оценка параметров lm/glm/gam, собственная time-slice CV,\n# выбор лучшей модели, прогноз 2022–2024, эмпирические интервалы и график.\n# ==============================================================================\n\n# 0) Пакеты и окружение --------------------------------------------------------\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  readxl, tidyverse, mgcv, lmtest, car, ggplot2, corrplot\n)\n\nrm(list = ls())\nset.seed(123)\nsetwd(\"C:/RECRUITMENT/\")  # при необходимости измените путь\n\n\n# 1) Подготовка данных ---------------------------------------------------------\n# Загрузка, приведение типов, создание NAOspring, фиксируем набор признаков\nDATA &lt;- readxl::read_excel(\"RECRUITMENT.xlsx\", sheet = \"RECRUITMENT\") %&gt;%\n  filter(YEAR &gt; 1989 & YEAR &lt; 2022) %&gt;%\n  mutate(\n    across(starts_with(\"T\"), as.numeric),\n    across(starts_with(\"I\"), as.numeric),\n    across(starts_with(\"O\"), as.numeric),\n    across(where(is.character), ~na_if(., \"NA\"))\n  )\n\nif (all(c(\"NAO3\",\"NAO4\",\"NAO5\") %in% names(DATA))) {\n  DATA &lt;- DATA %&gt;%\n    mutate(NAOspring = rowMeans(pick(NAO3, NAO4, NAO5), na.rm = TRUE)) %&gt;%\n    select(-NAO3, -NAO4, -NAO5)\n}\n\nneeded &lt;- c(\"codTSB\", \"T12\", \"I5\", \"NAOspring\", \"haddock68\")\nstopifnot(all(needed %in% names(DATA)))\n\nmodel_data &lt;- DATA %&gt;%\n  select(YEAR, all_of(needed), R3haddock) %&gt;%\n  drop_na() %&gt;%\n  arrange(YEAR)\n\nwrite.csv(model_data, \"selected_predictors_dataset.csv\", row.names = FALSE)\nglimpse(model_data)\n\nRows: 32\nColumns: 7\n$ YEAR      &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, ~\n$ codTSB    &lt;dbl&gt; 913000, 1347064, 1687381, 2197863, 2112773, 1849957, 1697388~\n$ T12       &lt;dbl&gt; 4.72, 4.66, 4.24, 3.90, 3.96, 4.27, 4.16, 4.07, 4.23, 5.08, ~\n$ I5        &lt;dbl&gt; 43, 55, 26, 49, 56, 28, 52, 51, 69, 68, 41, 48, 50, 63, 40, ~\n$ NAOspring &lt;dbl&gt; 0.64333333, 0.05666667, 1.78666667, 0.28666667, 0.61000000, ~\n$ haddock68 &lt;dbl&gt; 74586, 79205, 53195, 36337, 49122, 81514, 172177, 160886, 96~\n$ R3haddock &lt;dbl&gt; 812363, 389416, 99474, 98946, 118812, 63028, 147657, 83270, ~\n\n# 2) Формулы моделей и вспомогательные функции --------------------------------\nf_lm  &lt;- as.formula(\"R3haddock ~ codTSB + T12 + I5 + NAOspring + haddock68\")\nf_gam &lt;- as.formula(\"R3haddock ~ s(codTSB,bs='tp',k=5) + s(T12,bs='tp',k=5) + s(I5,bs='tp',k=5) + s(NAOspring,bs='tp',k=5) + s(haddock68,bs='tp',k=5)\")\n\nrmse &lt;- function(a, p) sqrt(mean((a - p)^2, na.rm = TRUE))\nmae  &lt;- function(a, p) mean(abs(a - p), na.rm = TRUE)\nr2   &lt;- function(a, p) 1 - sum((a - p)^2, na.rm = TRUE) / sum((a - mean(a))^2, na.rm = TRUE)\n\nsafe_fit &lt;- function(expr) {\n  out &lt;- try(eval(expr), silent = TRUE)\n  if (inherits(out, \"try-error\")) NULL else out\n}\n\n\n# 3) Time-slice CV (expanding window, h=3) + хронологический тест -------------\nmd &lt;- model_data\nmd_for_fit &lt;- md %&gt;% select(codTSB, T12, I5, NAOspring, haddock68, R3haddock)\n\nn &lt;- nrow(md_for_fit)\nholdout_frac &lt;- 0.2\nn_test &lt;- max(4, ceiling(n * holdout_frac))\ntrain_ts &lt;- head(md_for_fit, n - n_test)\ntest_ts  &lt;- tail(md_for_fit, n_test)\n\nn_train &lt;- nrow(train_ts)\ninitial_frac &lt;- 0.6\nhorizon      &lt;- 3\ninitialWindow &lt;- max(10, floor(initial_frac * n_train))\nif (initialWindow + horizon &gt; n_train) initialWindow &lt;- n_train - horizon\n\n# Аккумулируем метрики и остатки по срезам\ncv_summ &lt;- tibble(Model = character(), RMSE = double(), MAE = double())\nresids_cv &lt;- list(LM = c(), GLM = c(), GAM = c())\n\nslice_id &lt;- 0\nfor (i in seq(initialWindow, n_train - horizon)) {\n  slice_id &lt;- slice_id + 1\n  idx_tr &lt;- 1:i\n  idx_te &lt;- (i+1):(i+horizon)\n  dtr &lt;- train_ts[idx_tr, ]\n  dte &lt;- train_ts[idx_te, ]\n\n  # LM\n  lm_fit &lt;- safe_fit(quote(lm(f_lm, data = dtr)))\n  if (!is.null(lm_fit)) {\n    pr &lt;- try(predict(lm_fit, newdata = dte), silent = TRUE)\n    if (!inherits(pr, \"try-error\")) {\n      cv_summ &lt;- add_row(cv_summ, Model = \"LM\", RMSE = rmse(dte$R3haddock, pr), MAE = mae(dte$R3haddock, pr))\n      resids_cv$LM &lt;- c(resids_cv$LM, dte$R3haddock - pr)\n    }\n  }\n\n  # GLM (Gamma)\n  glm_fit &lt;- safe_fit(quote(glm(f_lm, data = dtr, family = Gamma(link = \"log\"))))\n  if (!is.null(glm_fit)) {\n    pr &lt;- try(predict(glm_fit, newdata = dte, type = \"response\"), silent = TRUE)\n    if (!inherits(pr, \"try-error\")) {\n      cv_summ &lt;- add_row(cv_summ, Model = \"GLM\", RMSE = rmse(dte$R3haddock, pr), MAE = mae(dte$R3haddock, pr))\n      resids_cv$GLM &lt;- c(resids_cv$GLM, dte$R3haddock - pr)\n    }\n  }\n\n  # GAM (Gamma log), ограничиваем сложность k для стабильности на малом n\n  gam_fit &lt;- safe_fit(quote(mgcv::gam(f_gam, data = dtr, family = Gamma(link = \"log\"), method = \"REML\", select = TRUE)))\n  if (!is.null(gam_fit)) {\n    pr &lt;- try(predict(gam_fit, newdata = dte, type = \"response\"), silent = TRUE)\n    if (!inherits(pr, \"try-error\")) {\n      cv_summ &lt;- add_row(cv_summ, Model = \"GAM\", RMSE = rmse(dte$R3haddock, pr), MAE = mae(dte$R3haddock, pr))\n      resids_cv$GAM &lt;- c(resids_cv$GAM, dte$R3haddock - pr)\n    }\n  }\n}\n\n# Средние метрики по моделям\ncv_rank &lt;- cv_summ %&gt;% group_by(Model) %&gt;% summarise(RMSE = mean(RMSE, na.rm = TRUE), MAE = mean(MAE, na.rm = TRUE), .groups = \"drop\") %&gt;% arrange(RMSE, MAE)\nprint(cv_rank)\n\n# A tibble: 3 x 3\n  Model    RMSE     MAE\n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 GLM   280259. 237187.\n2 LM    370298. 340884.\n3 GAM   504613. 432062.\n\nbest_model_name &lt;- cv_rank$Model[1]\ncat(sprintf(\"\\nЛучшая модель по time-slice CV: %s\\n\", best_model_name))\n\n\nЛучшая модель по time-slice CV: GLM\n\n# Хронологический тест: обучаем на всём train_ts, прогнозируем на test_ts\nfit_on &lt;- function(model_name, data) {\n  if (model_name == \"LM\") return(lm(f_lm, data = data))\n  if (model_name == \"GLM\") return(glm(f_lm, data = data, family = Gamma(link = \"log\")))\n  mgcv::gam(f_gam, data = data, family = Gamma(link = \"log\"), method = \"REML\", select = TRUE)\n}\n\npredict_on &lt;- function(fit, newdata, model_name) {\n  if (model_name == \"GLM\") return(predict(fit, newdata = newdata, type = \"response\"))\n  if (inherits(fit, \"gam\")) return(predict(fit, newdata = newdata, type = \"response\"))\n  predict(fit, newdata = newdata)\n}\n\nfit_train &lt;- fit_on(best_model_name, train_ts)\npred_te   &lt;- predict_on(fit_train, test_ts, best_model_name)\ntest_metrics &lt;- tibble(\n  Model = best_model_name,\n  RMSE  = rmse(test_ts$R3haddock, pred_te),\n  MAE   = mae (test_ts$R3haddock, pred_te),\n  R2    = r2  (test_ts$R3haddock, pred_te)\n)\nprint(test_metrics)\n\n# A tibble: 1 x 4\n  Model    RMSE     MAE    R2\n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 GLM   182048. 141692. 0.363\n\n# 4) Диагностика моделей (подгонка на всех данных до 2021) -------------------\nfull_fit_df &lt;- md_for_fit\n\nlm_full  &lt;- lm(f_lm,  data = full_fit_df)\nglm_full &lt;- glm(f_lm, data = full_fit_df, family = Gamma(link = \"log\"))\ngam_full &lt;- mgcv::gam(f_gam, data = full_fit_df, family = Gamma(link = \"log\"), method = \"REML\", select = TRUE)\n\ncat(\"\\n[LM] Сводка:\\n\"); print(summary(lm_full))\n\n\n[LM] Сводка:\n\n\n\nCall:\nlm(formula = f_lm, data = full_fit_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-257877 -155326  -18935  101135  326940 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -9.189e+05  4.459e+05  -2.061 0.049455 *  \ncodTSB      -2.406e-01  6.722e-02  -3.579 0.001386 ** \nT12          3.679e+05  8.296e+04   4.435 0.000149 ***\nI5          -1.770e+03  3.025e+03  -0.585 0.563536    \nNAOspring   -5.125e+04  5.427e+04  -0.944 0.353710    \nhaddock68    4.385e-01  5.395e-01   0.813 0.423698    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 192900 on 26 degrees of freedom\nMultiple R-squared:  0.547, Adjusted R-squared:  0.4599 \nF-statistic: 6.279 on 5 and 26 DF,  p-value: 0.0006042\n\ncat(\"\\n[LM] VIF:\\n\"); print(car::vif(lm_full))\n\n\n[LM] VIF:\n\n\n   codTSB       T12        I5 NAOspring haddock68 \n 2.487391  1.398254  1.275233  1.035349  2.386554 \n\ncat(\"\\n[LM] Breusch–Pagan:\\n\"); print(lmtest::bptest(lm_full))\n\n\n[LM] Breusch–Pagan:\n\n\n\n    studentized Breusch-Pagan test\n\ndata:  lm_full\nBP = 5.1481, df = 5, p-value = 0.3981\n\ncat(\"\\n[LM] Durbin–Watson:\\n\"); print(lmtest::dwtest(lm_full))\n\n\n[LM] Durbin–Watson:\n\n\n\n    Durbin-Watson test\n\ndata:  lm_full\nDW = 1.7745, p-value = 0.1264\nalternative hypothesis: true autocorrelation is greater than 0\n\nglm_resid &lt;- residuals(glm_full, type = \"pearson\")\ncat(\"\\n[GLM-Gamma] Сводка:\\n\"); print(summary(glm_full))\n\n\n[GLM-Gamma] Сводка:\n\n\n\nCall:\nglm(formula = f_lm, family = Gamma(link = \"log\"), data = full_fit_df)\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.907e+00  1.288e+00   5.361 1.30e-05 ***\ncodTSB      -6.525e-07  1.942e-07  -3.359  0.00242 ** \nT12          1.341e+00  2.397e-01   5.593 7.08e-06 ***\nI5           8.270e-03  8.740e-03   0.946  0.35278    \nNAOspring    4.898e-02  1.568e-01   0.312  0.75725    \nhaddock68    1.117e-06  1.559e-06   0.717  0.48000    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.3107759)\n\n    Null deviance: 19.8880  on 31  degrees of freedom\nResidual deviance:  8.5197  on 26  degrees of freedom\nAIC: 855.29\n\nNumber of Fisher Scoring iterations: 8\n\ncat(sprintf(\"[GLM-Gamma] Pearson dispersion: %.3f\\n\", sum(glm_resid^2, na.rm = TRUE) / glm_full$df.residual))\n\n[GLM-Gamma] Pearson dispersion: 0.311\n\ncat(\"\\n[GAM] Сводка:\\n\"); print(summary(gam_full))\n\n\n[GAM] Сводка:\n\n\n\nFamily: Gamma \nLink function: log \n\nFormula:\nR3haddock ~ s(codTSB, bs = \"tp\", k = 5) + s(T12, bs = \"tp\", k = 5) + \n    s(I5, bs = \"tp\", k = 5) + s(NAOspring, bs = \"tp\", k = 5) + \n    s(haddock68, bs = \"tp\", k = 5)\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 12.48948    0.08886   140.5   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                   edf Ref.df     F  p-value    \ns(codTSB)    1.7083407      4 4.917 7.43e-05 ***\ns(T12)       0.9669993      4 7.752 3.96e-06 ***\ns(I5)        0.0001638      4 0.000    0.616    \ns(NAOspring) 0.0001092      4 0.000    0.980    \ns(haddock68) 0.4529453      4 0.145    0.252    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.592   Deviance explained = 60.2%\n-REML = 426.83  Scale est. = 0.2527    n = 32\n\ncat(\"\\n[GAM] Concurvity (коротко):\\n\")\n\n\n[GAM] Concurvity (коротко):\n\nccv &lt;- try(mgcv::concurvity(gam_full, full = FALSE), silent = TRUE)\nif (!inherits(ccv, \"try-error\") && is.list(ccv)) {\n  # Выведем усечённо и безопасно\n  print(lapply(ccv, function(m) if (is.null(m)) NULL else round(m, 3)))\n} else {\n  cat(\"не удалось оценить concurvity\\n\")\n}\n\n$worst\n             para s(codTSB) s(T12) s(I5) s(NAOspring) s(haddock68)\npara            1     0.000  0.000 0.000        0.000        0.000\ns(codTSB)       0     1.000  0.554 0.298        0.178        0.821\ns(T12)          0     0.554  1.000 0.361        0.362        0.347\ns(I5)           0     0.298  0.361 1.000        0.182        0.132\ns(NAOspring)    0     0.178  0.362 0.182        1.000        0.216\ns(haddock68)    0     0.821  0.347 0.132        0.216        1.000\n\n$observed\n             para s(codTSB) s(T12) s(I5) s(NAOspring) s(haddock68)\npara            1     0.000  0.000 0.000        0.000        0.000\ns(codTSB)       0     1.000  0.392 0.166        0.045        0.385\ns(T12)          0     0.273  1.000 0.217        0.064        0.218\ns(I5)           0     0.166  0.283 1.000        0.047        0.044\ns(NAOspring)    0     0.031  0.128 0.114        1.000        0.049\ns(haddock68)    0     0.441  0.204 0.113        0.116        1.000\n\n$estimate\n             para s(codTSB) s(T12) s(I5) s(NAOspring) s(haddock68)\npara            1     0.000  0.000 0.000        0.000        0.000\ns(codTSB)       0     1.000  0.320 0.140        0.041        0.747\ns(T12)          0     0.281  1.000 0.201        0.068        0.243\ns(I5)           0     0.121  0.278 1.000        0.053        0.096\ns(NAOspring)    0     0.055  0.128 0.113        1.000        0.089\ns(haddock68)    0     0.544  0.205 0.099        0.136        1.000\n\ninvisible(try(mgcv::gam.check(gam_full), silent = TRUE))\n\n\n\n\n\n\n\n\n\nMethod: REML   Optimizer: outer newton\nfull convergence after 13 iterations.\nGradient range [-4.544099e-05,0.000320414]\n(score 426.834 & scale 0.2526969).\nHessian positive definite, eigenvalue range [5.946259e-06,16.95877].\nModel rank =  21 / 21 \n\nBasis dimension (k) checking results. Low p-value (k-index&lt;1) may\nindicate that k is too low, especially if edf is close to k'.\n\n                   k'      edf k-index p-value\ns(codTSB)    4.000000 1.708341    1.12    0.69\ns(T12)       4.000000 0.966999    1.29    0.95\ns(I5)        4.000000 0.000164    0.86    0.20\ns(NAOspring) 4.000000 0.000109    0.99    0.50\ns(haddock68) 4.000000 0.452945    1.10    0.73\n\n# 5) Прогноз 2022–2024 и эмпирические интервалы ------------------------------\nbest_full &lt;- switch(best_model_name,\n  LM  = lm_full,\n  GLM = glm_full,\n  GAM = gam_full\n)\n\n# Остатки для PI: из CV выбранной модели, иначе из полного фита\nresids &lt;- if (length(resids_cv[[best_model_name]]) &gt; 5) resids_cv[[best_model_name]] else residuals(best_full)\n\nq025 &lt;- as.numeric(quantile(resids, 0.025, na.rm = TRUE))\nq250 &lt;- as.numeric(quantile(resids, 0.250, na.rm = TRUE))\nq750 &lt;- as.numeric(quantile(resids, 0.750, na.rm = TRUE))\nq975 &lt;- as.numeric(quantile(resids, 0.975, na.rm = TRUE))\n\nfc_start &lt;- 2022\npred_cols &lt;- c(\"codTSB\",\"T12\",\"I5\",\"NAOspring\",\"haddock68\")\nmu &lt;- md %&gt;% filter(YEAR &gt; 1989 & YEAR &lt; fc_start) %&gt;% summarise(across(all_of(pred_cols), ~mean(.x, na.rm = TRUE))) %&gt;% as.list()\n\nif (!exists(\"user_future\")) user_future &lt;- NULL\n\nbuild_future &lt;- function(years, mu, user_df = NULL) {\n  df &lt;- tibble::tibble(YEAR = years)\n  for (v in pred_cols) df[[v]] &lt;- mu[[v]]\n  if (!is.null(user_df)) {\n    for (i in seq_len(nrow(user_df))) {\n      yr &lt;- user_df$YEAR[i]\n      if (yr %in% years) {\n        idx &lt;- which(df$YEAR == yr)\n        for (v in intersect(pred_cols, names(user_df))) {\n          val &lt;- user_df[[v]][i]\n          if (!is.na(val)) df[[v]][idx] &lt;- val\n        }\n      }\n    }\n  }\n  df\n}\n\nfuture_years &lt;- fc_start:2024\nscenario_future &lt;- build_future(future_years, mu, user_future)\n\npredict_best &lt;- function(fit, newdata, model_name) {\n  if (model_name == \"GLM\") return(predict(fit, newdata = newdata, type = \"response\"))\n  predict(fit, newdata = newdata)\n}\n\npred_future &lt;- predict_best(best_full, scenario_future, best_model_name)\n\nforecast_tbl &lt;- tibble::tibble(\n  YEAR      = scenario_future$YEAR,\n  Model     = best_model_name,\n  pred_mean = as.numeric(pred_future),\n  PI50_low  = pred_future + q250, PI50_high = pred_future + q750,\n  PI95_low  = pred_future + q025, PI95_high = pred_future + q975\n)\n\n\nknitr::kable(\n  forecast_tbl %&gt;% dplyr::mutate(dplyr::across(where(is.numeric), ~round(.x, 2))),\n  caption = \"Holdout-метрики (округлено до 2 знаков)\"\n)\n\n\nHoldout-метрики (округлено до 2 знаков)\n\n\nYEAR\nModel\npred_mean\nPI50_low\nPI50_high\nPI95_low\nPI95_high\n\n\n\n\n2022\nGLM\n268057.6\n172383\n509783.3\n-203196.1\n1051570\n\n\n2023\nGLM\n268057.6\n172383\n509783.3\n-203196.1\n1051570\n\n\n2024\nGLM\n268057.6\n172383\n509783.3\n-203196.1\n1051570\n\n\n\n\n# 6) Визуализация 1990–2024 ---------------------------------------------------\npred_df &lt;- bind_rows(\n  md %&gt;% select(YEAR, all_of(pred_cols)),\n  scenario_future\n) %&gt;% distinct(YEAR, .keep_all = TRUE) %&gt;% arrange(YEAR)\n\npred_df$Pred      &lt;- as.numeric(predict_best(best_full, pred_df, best_model_name))\npred_df$PI50_low  &lt;- pred_df$Pred + q250\npred_df$PI50_high &lt;- pred_df$Pred + q750\npred_df$PI95_low  &lt;- pred_df$Pred + q025\npred_df$PI95_high &lt;- pred_df$Pred + q975\n\nhist_df &lt;- md %&gt;% select(YEAR, R3haddock)\n\nggplot() +\n  geom_ribbon(data = pred_df, aes(x = YEAR, ymin = PI95_low, ymax = PI95_high), fill = \"grey80\", alpha = 0.25) +\n  geom_ribbon(data = pred_df, aes(x = YEAR, ymin = PI50_low, ymax = PI50_high), fill = \"grey60\", alpha = 0.35) +\n  geom_line(data = subset(pred_df, YEAR &lt; fc_start), aes(x = YEAR, y = Pred), color = \"steelblue4\", linewidth = 1) +\n  geom_line(data = subset(pred_df, YEAR &gt;= fc_start-1), aes(x = YEAR, y = Pred), color = \"steelblue4\", linewidth = 1, linetype = \"dashed\") +\n  geom_point(data = hist_df, aes(x = YEAR, y = R3haddock), color = \"black\", size = 2, alpha = 0.9) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0))) +\n  labs(title = paste0(\"Пополнение R3haddock: факт (1990–2021) и прогноз (2022–2024) — \", best_model_name),\n       subtitle = \"Прогноз — пунктир, интервалы — эмпирические из остатков\",\n       x = \"Год\", y = \"R3haddock\") +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n# AIC-таблица (LM/GLM сопоставимы напрямую; для GAM также показываем ML)\ncat(\"\\nAIC (LM): \",  AIC(lm_full),  \"\\n\", sep = \"\")\n\n\nAIC (LM): 877.0549\n\ncat(\"AIC (GLM): \", AIC(glm_full), \"\\n\", sep = \"\")\n\nAIC (GLM): 855.2949\n\ngam_full_ml &lt;- mgcv::gam(f_gam, data = full_fit_df, family = Gamma(link = \"log\"), method = \"ML\", select = TRUE)\ncat(\"AIC (GAM, REML): \", AIC(gam_full),    \"\\n\", sep = \"\")\n\nAIC (GAM, REML): 850.8686\n\ncat(\"AIC (GAM, ML):   \", AIC(gam_full_ml), \"\\n\", sep = \"\")\n\nAIC (GAM, ML):   850.7948\n\n# ============================================================================\n# Конец\n# ============================================================================",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Прогноз пополнения: от факторов до ансамбля</span>"
    ]
  },
  {
    "objectID": "chapter 7.html#полный-цикл-от-факторов-до-ансамблевого-прогноза",
    "href": "chapter 7.html#полный-цикл-от-факторов-до-ансамблевого-прогноза",
    "title": "8  Прогноз пополнения: от факторов до ансамбля",
    "section": "8.5 Полный цикл от факторов до ансамблевого прогноза",
    "text": "8.5 Полный цикл от факторов до ансамблевого прогноза\nПолный цикл анализа от идентификации ключевых факторов до создания надежного ансамблевого прогноза пополнения рыбных запасов представляет собой сложный, но систематизированный процесс, требующий как глубокого понимания биологических процессов, так и владения современными методами анализа данных. Начиная с формирования исходного набора предикторов, включающего как биологические переменные (нерестовый запас, биомасса хищников), так и комплексные океанографические показатели (температура, соленость, климатические индексы), мы проходим через строгую последовательность этапов, каждый из которых важен для конечного результата. На этапе подготовки данных мы не просто приводим информацию к числовому формату и заменяем строковые обозначения пропущенных значений «NA» на стандартные NA, но и проводим глубокий анализ корреляционной структуры, устраняя мультиколлинеарность через анализ корреляций и VIF-диагностику, что важно для корректной интерпретации последующих моделей. Для обработки пропусков мы применяем медианную импутацию, которая представляет собой простой и устойчивый к выбросам метод, хотя в некоторых случаях могут быть использованы и более сложные методы, такие как KNN-импутация или множественная импутация с использованием пакета MICE, особенно когда данные имеют сложную структуру или временные зависимости.\nЗатем следует этап отбора предикторов, где мы применяем два комплементарных метода: Boruta на основе Random Forest для выявления нелинейных зависимостей и LASSO-регрессию для линейного отбора с регуляризацией. Их объединение позволяет получить устойчивый набор предикторов, дополненный биологически значимыми переменными по экспертной оценке, что создает баланс между статистической значимостью и содержательной интерпретируемостью. Этот этап является мостом между классической ихтиологией и современными методами анализа, где экспертные знания биолога взаимодействуют с алгоритмической строгостью статистики, гарантируя включение ключевых факторов, таких как нерестовый запас, который должен присутствовать в модели по самой своей природе процесса пополнения.\nПосле подготовки данных мы переходим к сравнению различных семейств моделей через единую кросс-валидационную процедуру (5-fold CV) с последующим хронологическим тестированием на отложенной выборке. Помимо линейных и обобщенных линейных моделей (LM, GLM), обобщенных аддитивных моделей (GAM), мы тестируем современные алгоритмы машинного обучения: Random Forest для улавливания сложных нелинейных зависимостей и взаимодействий между факторами, будучи при этом устойчивым к шуму и выбросам; XGBoost, с его градиентным бустингом над деревьями решений, часто дающий высочайшую точность прогноза; SVM с радиальным ядром для сложных разделяющих поверхностей; и нейронные сети для автоматического извлечения признаков. Каждая модель оценивается по комплексу метрик: RMSE, MAE, R² и MAPE, что позволяет сравнивать их прогностическую силу на разных участках данных и выявлять модели, которые лучше всего справляются с конкретными аспектами прогнозирования.\nОсобое внимание уделяется временным характеристикам данных, поскольку при анализе водных биоресурсов мы имеем дело с временными рядами, где случайное перемешивание данных приведет к утечке информации из будущего в прошлое, искусственно завысив качество прогноза. Для решения этой проблемы мы применяем специализированную time-slice кросс-валидацию с расширяющимся окном и горизонтом прогноза 3 года, которая имитирует реальные условия прогнозирования, обучаясь только на данных из прошлого и проверяя на последующих периодах. Это позволяет оценить устойчивость моделей к временным сдвигам и их способность к экстраполяции, что критически важно для практических задач управления рыбными запасами.\nВыбор окончательной модели — это не просто вопрос максимальной точности на кросс-валидации, а сложный компромисс между точностью, интерпретируемостью и биологической правдоподобностью. Кульминацией цикла становится построение ансамблевой модели, комбинирующей сильные стороны отдельных алгоритмов. В нашем анализе оптимальный ансамбль (CUBIST + LM) строится через взвешенное усреднение предсказаний, где веса определяются на основе кросс-валидационной ошибки — например, 75% веса приходится на мощную нелинейную модель Cubist, а 25% — на простую и устойчивую линейную регрессию. Такой подход позволяет нивелировать индивидуальные недостатки моделей, сохранить интерпретируемость линейных моделей, где биолог может понять, как именно каждый фактор влияет на прогноз, и при этом использовать гибкость методов машинного обучения для захвата сложных нелинейных паттернов, которые могут ускользнуть от классических статистических методов.\nВажнейшим компонентом становится оценка неопределенности через эмпирические доверительные интервалы, построенные на основе распределения остатков ансамблевой модели. Мы используем квантили остатков из кросс-валидации для построения 50% и 95% доверительных интервалов, что позволяет получить не только точечный прогноз, но и меру его надежности, важную для принятия управленческих решений. Это дает возможность визуализировать не только ожидаемое значение пополнения, но и диапазон возможных сценариев, что особенно важно в условиях высокой экологической неопределенности.\nФинальная визуализация представляет собой совмещение исторических данных с прогнозом на 3 года вперед, где исторические данные отображаются сплошной линией, прогноз — пунктиром, а 50% и 95% доверительные интервалы — серыми лентами различной интенсивности. Такой график не только демонстрирует результат, но и позволяет визуально оценить точность модели на исторических данных и неопределенность будущих предсказаний, делая результаты доступными не только для статистиков, но и для управленцев и политиков, принимающих решения на основе этих прогнозов.\nПредставленный цикл является итеративным процессом: прогнозная точность ансамбля может быть улучшена через включение новых предикторов, изучение влияния предикторов с задержкой (лагами), тонкую настройку гиперпараметров моделей и обновление данных по мере их поступления. Этот подход представляет собой практический компромисс между статистической строгостью, вычислительной эффективностью и биологической интерпретируемостью, делая его мощным инструментом для решения прикладных задач оценки водных биоресурсов, где каждый этап, от первичной обработки данных до финального прогноза, подчинен одной цели — обеспечению устойчивого управления рыбными запасами на основе надежного научного анализа.\nСкрипт лучше скачать целиком).\n\n# ==============================================================================\n# ПРАКТИЧЕСКОЕ ЗАНЯТИЕ: АНАЛИЗ ФАКТОРОВ И ПРОГНОЗ ПОПОЛНЕНИЯ ЗАПАСА\n# Курс: \"Оценка водных биоресурсов в среде R (для начинающих)\"\n# Автор: Баканев С. В. Дата:20.08.2025\n# Структура:\n# 1) Подготовка данных и выбор предикторов\n# 2) Базовое сравнение моделей (5-fold CV + holdout)\n# 3) Выбор лучшей прогностической модели (time-slice CV на 3 года + хронологический тест)\n# 4) Прогноз 2022–2024 (ансамбль CUBIST+LM) и график 1990–2024 с ДИ\n# ------------------------------------------------------------------------------\n# Пояснения к занятию (для начинающих):\n# - Мы работаем с временным рядом пополнения запаса R3haddock и набором факторов\n#   среды/биомассы. Цель — построить понятные и проверяемые модели прогноза.\n# - Сначала отберём информативные предикторы (Boruta и LASSO), затем сравним\n#   разные модели машинного обучения на кросс-валидации (CV), после чего выберем\n#   лучшую схему по time-slice CV (учитывая хронологию), и сделаем прогноз.\n# ==============================================================================\n\n\n# ==============================================================================\n# 1) ВЫБОР ПРЕДИКТОРОВ\n# ------------------------------------------------------------------------------\n# Цель блока: привести данные к числовому виду, обработать пропуски, сократить\n# мультиколлинеарность (сильные корреляции), а затем автоматически выделить\n# кандидатов-предикторов двумя методами (Boruta, LASSO). В конце сформируем\n# финальный пул признаков и проверим их значимость в простой LM.\n# ==============================================================================\n\n# Установка и подключение необходимых библиотек\n# Для автоматического отбора предикторов нам понадобятся дополнительные пакеты\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  readxl, tidyverse, caret, corrplot, mgcv, randomForest, xgboost,\n  Boruta,GGally, FactoMineR, glmnet, recipes, rsample  # Новые библиотеки для автоматического отбора\n)\n\n# Очистка среды и установка рабочей директории\n# Совет: rm(list=ls()) очищает все объекты в памяти R; setwd задаёт папку,\n# где искать/сохранять файлы. Убедитесь, что путь корректен на вашей машине.\nrm(list = ls())\nsetwd(\"C:/RECRUITMENT/\")\n\n# Пакеты для расширенного отбора предикторов\n# Boruta — обёртка над Random Forest для отбора признаков;\n# glmnet — регуляризация (LASSO/ElasticNet) для отбора/усиления обобщающей способности;\n# FactoMineR — PCA и другие многомерные методы (используем как утилиту).\nlibrary(Boruta)   # Алгоритм обертки для отбора признаков\nlibrary(glmnet)   # LASSO-регрессия\nlibrary(FactoMineR) # PCA анализ\n\n\n# Загрузка и первичная обработка данных\n# Шаги: фильтруем годы, приводим типы к числовому, заменяем строковые \"NA\" на NA.\nDATA &lt;- readxl::read_excel(\"RECRUITMENT.xlsx\", sheet = \"RECRUITMENT\") %&gt;%\n  filter(YEAR &gt; 1989 & YEAR &lt; 2022) %&gt;%\n  # Преобразуем необходимые столбцы в числовой формат\n  mutate(\n    across(starts_with(\"T\"), as.numeric),\n    across(starts_with(\"I\"), as.numeric),\n    across(starts_with(\"O\"), as.numeric),\n  ) %&gt;%\n  # Обработка пропущенных значений (заменяем строку \"NA\" на NA)\n  mutate(across(where(is.character), ~na_if(., \"NA\")))\n\n# 1. Подготовка данных -------------------------------------------------------\n# Выделим все возможные предикторы, включая географию и индексы трески\n# Примечание: оставляем только числовые переменные, т.к. большинство моделей\n# требует числовой вход без категориальных уровней.\npredictors &lt;- DATA %&gt;% \n  select(-YEAR, -R3haddock) %&gt;% \n  select_if(is.numeric) # Только числовые переменные\n\n# Целевая переменная\nresponse &lt;- DATA$R3haddock\n\n# В статистическом анализе мы различаем:\n# - Отклик (response/target variable) - то, что мы пытаемся предсказать (в нашем случае R3haddock)\n# - Предикторы (predictors/features) - переменные, которые могут объяснять изменения отклика\n# Для корректного анализа важно, чтобы предикторы были числовыми или преобразованы в числовой формат.\n\n# 2. Обработка пропусков -----------------------------------------------------\n# Заполнение медианными значениями — простой и устойчивый способ справиться с NA.\n# Альтернативы: множественная иммутация (mice), KNN-impute и др.\npredictors_filled &lt;- predictors %&gt;%\n  mutate(across(everything(), ~ifelse(is.na(.), median(., na.rm = TRUE), .)))\n\n# Заполнение медианой - простой и устойчивый метод обработки пропусков для числовых переменных.\n# Медиана предпочтительнее среднего, так как менее чувствительна к выбросам.\n\n# 3. Предварительный анализ корреляций ---------------------------------------\n# Зачем: высокие корреляции затрудняют интерпретацию и могут вредить ряду моделей.\ncor_matrix &lt;- cor(predictors_filled, use = \"complete.obs\")\ncorrplot(cor_matrix, method = \"circle\", type = \"upper\", tl.cex = 0.7)\n\n\n\n\n\n\n\n# Удаляем высокоскоррелированные предикторы (r &gt; 0.8)\n# Это механическое сокращение мультиколлинеарности до этапа отбора.\nhigh_cor &lt;- findCorrelation(cor_matrix, cutoff = 0.8)\npredictors_filtered &lt;- predictors_filled[, -high_cor]\n\n# Высокая корреляция между предикторами (мультиколлинеарность) может привести к нестабильности моделей.\n# Например, если два предиктора почти идентичны, модель может неустойчиво распределять их влияние на отклик.\n# Удаление сильно коррелированных переменных (r &gt; 0.8) помогает улучшить интерпретируемость и стабильность моделей.\n\n\n# 4. Автоматизированный отбор Boruta (обертка Random Forest) -----------------\n# Идея: определить признаки, которые важнее, чем случайный шум (shadow features).\n\n\n# Визуализация результатов\nplot(boruta_output, cex.axis = 0.7, las = 2)\n\n\n\n\n\n\n\nboruta_stats &lt;- attStats(boruta_output)\nselected_vars &lt;- getSelectedAttributes(boruta_output, withTentative = TRUE)\n\n# Boruta - это алгоритм отбора признаков, основанный на методе случайного леса.\n# Он сравнивает важность реальных переменных с \"теневыми\" переменными (случайными копиями),\n# чтобы определить, действительно ли переменная информативна. \n# Результаты Boruta показывают: \n#   - Confirmed (зеленые) - значимые предикторы\n#   - Tentative (желтые) - предикторы, близкие к порогу значимости\n#   - Rejected (красные) - незначимые предикторы\n\n\n# 5. LASSO с более строгим критерием ------------------------------------------\n# Идея: L1-регуляризация зануляет коэффициенты «слабых» предикторов.\n# Выбор lambda.1se вместо lambda.min — более консервативный (простая модель).\nx &lt;- as.matrix(predictors_filtered)\ny &lt;- response\n\n# LASSO (Least Absolute Shrinkage and Selection Operator) - метод регрессии с L1-регуляризацией,\n# который одновременно выполняет отбор признаков и оценку коэффициентов. \n# Параметр lambda контролирует силу регуляризации:\n#   - lambda.min дает наименьшую ошибку, но может включать шумовые переменные\n#   - lambda.1se (на 1 стандартную ошибку больше) дает более простую модель с меньшим риском переобучения\n# Для прогнозирования мы предпочитаем более строгий критерий (lambda.1se), чтобы модель была устойчивее. \n\n# Кросс-валидация\ncv_fit &lt;- cv.glmnet(x, y, alpha = 1, nfolds = 10)\nplot(cv_fit)\n\n\n\n\n\n\n\n# ИСПОЛЬЗУЕМ lambda.1se вместо lambda.min — СТРОЖЕ!\nlasso_coef &lt;- coef(cv_fit, s = \"lambda.1se\")  # &lt;-- Ключевое изменение!\nlasso_vars &lt;- rownames(lasso_coef)[lasso_coef[,1] != 0][-1]  # исключаем (Intercept)\n\n\n# 6. Сравнение отобранных предикторов ----------------------------------------\n# Полезно видеть, какие признаки отмечают оба метода (устойчивые кандидаты).\ncat(\"Boruta selected:\", length(selected_vars), \"variables\\n\")\n\nBoruta selected: 3 variables\n\nprint(selected_vars)\n\n[1] \"codTSB\" \"T12\"    \"I5\"    \n\ncat(\"\\nLASSO selected:\", length(lasso_vars), \"variables\\n\")\n\n\nLASSO selected: 5 variables\n\nprint(lasso_vars)\n\n[1] \"codTSB\" \"T12\"    \"NAO3\"   \"NAO4\"   \"NAO5\"  \n\n# 7. Финальный набор предикторов (объединение результатов) -------------------\n# Логика: объединяем списки, добавляем биологически важные переменные вручную.\nfinal_vars &lt;- union(selected_vars, lasso_vars) \n\n# Добавляем обязательные переменные по биологической логике\nmandatory &lt;- c(\"haddock68\")\nfinal_vars &lt;- union(final_vars, mandatory) %&gt;% unique()\n\n# Мы объединяем результаты двух методов отбора признаков для большей надежности.\n# Также добавляем переменную haddock68 (нерестовый запас), так как биологически \n# логично, что пополнение запаса напрямую зависит от численности производителей. \n# Это пример интеграции экспертных знаний в статистический анализ - важный принцип \n# при работе с данными в биологических науках.\n\n# 8. Проверка значимости -----------------------------------------------------\n# Быстрая оценка значимости с LM: не как окончательный вывод, а как sanity-check.\nfinal_model &lt;- lm(response ~ as.matrix(predictors_filled[, final_vars]))\nsummary(final_model)\n\n\nCall:\nlm(formula = response ~ as.matrix(predictors_filled[, final_vars]))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-270986  -82376   -1037   98086  276129 \n\nCoefficients:\n                                                      Estimate Std. Error\n(Intercept)                                         -1.082e+06  3.943e+05\nas.matrix(predictors_filled[, final_vars])codTSB    -2.346e-01  5.536e-02\nas.matrix(predictors_filled[, final_vars])T12        3.864e+05  7.198e+04\nas.matrix(predictors_filled[, final_vars])I5        -1.825e+02  2.572e+03\nas.matrix(predictors_filled[, final_vars])NAO3      -5.801e+04  3.129e+04\nas.matrix(predictors_filled[, final_vars])NAO4       8.345e+04  3.035e+04\nas.matrix(predictors_filled[, final_vars])NAO5      -7.278e+04  2.488e+04\nas.matrix(predictors_filled[, final_vars])haddock68  1.232e-01  4.515e-01\n                                                    t value Pr(&gt;|t|)    \n(Intercept)                                          -2.744 0.011305 *  \nas.matrix(predictors_filled[, final_vars])codTSB     -4.238 0.000288 ***\nas.matrix(predictors_filled[, final_vars])T12         5.368 1.64e-05 ***\nas.matrix(predictors_filled[, final_vars])I5         -0.071 0.944028    \nas.matrix(predictors_filled[, final_vars])NAO3       -1.854 0.076118 .  \nas.matrix(predictors_filled[, final_vars])NAO4        2.750 0.011146 *  \nas.matrix(predictors_filled[, final_vars])NAO5       -2.925 0.007412 ** \nas.matrix(predictors_filled[, final_vars])haddock68   0.273 0.787227    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 158600 on 24 degrees of freedom\nMultiple R-squared:  0.7173,    Adjusted R-squared:  0.6348 \nF-statistic: 8.698 on 7 and 24 DF,  p-value: 2.58e-05\n\n# 9. Формирование финального датасета ----------------------------------------\n# Собираем набор с откликом и выбранными предикторами; удалим строки с NA.\nmodel_data &lt;- DATA %&gt;%\n  select(R3haddock, all_of(final_vars)) %&gt;%\n  drop_na()\n\n# Просмотр структуры финальных данных\nglimpse(model_data)\n\nRows: 32\nColumns: 8\n$ R3haddock &lt;dbl&gt; 812363, 389416, 99474, 98946, 118812, 63028, 147657, 83270, ~\n$ codTSB    &lt;dbl&gt; 913000, 1347064, 1687381, 2197863, 2112773, 1849957, 1697388~\n$ T12       &lt;dbl&gt; 4.72, 4.66, 4.24, 3.90, 3.96, 4.27, 4.16, 4.07, 4.23, 5.08, ~\n$ I5        &lt;dbl&gt; 43, 55, 26, 49, 56, 28, 52, 51, 69, 68, 41, 48, 50, 63, 40, ~\n$ NAO3      &lt;dbl&gt; 1.46, -0.20, 0.87, 0.67, 1.26, 1.25, -0.24, 1.46, 0.87, 0.23~\n$ NAO4      &lt;dbl&gt; 2.00, 0.29, 1.86, 0.97, 1.14, -0.85, -0.17, -1.02, -0.68, -0~\n$ NAO5      &lt;dbl&gt; -1.53, 0.08, 2.63, -0.78, -0.57, -1.49, -1.06, -0.28, -1.32,~\n$ haddock68 &lt;dbl&gt; 74586, 79205, 53195, 36337, 49122, 81514, 172177, 160886, 96~\n\n# Визуализация важности переменных\n# Внимание: важности от RF — относительные; сопоставляйте с предметной логикой.\nvar_importance &lt;- randomForest(R3haddock ~ ., data = model_data, importance = TRUE)\nvarImpPlot(var_importance, main = \"Важность предикторов\")\n\n\n\n\n\n\n\n# Перед окончательным выбором модели мы проверяем значимость предикторов с помощью линейной регрессии.\n# Функция summary() показывает p-значения коэффициентов - если p &lt; 0.05, переменная считается статистически значимой. \n# Визуализация важности переменных с помощью случайного леса дает дополнительную перспективу,\n# показывая, какие переменные наиболее информативны для предсказания без предположений о линейности.\n\n# ==============================================================================\n#  ПОДГОТОВКА ДАННЫХ\n# Создаём NAOspring, фиксируем финальный набор признаков, сохраняем CSV.\n# ------------------------------------------------------------------------------\n# Цель блока: стандартизировать набор признаков для дальнейшего сравнения\n# моделей и обеспечить воспроизводимость (фиксированный CSV с нужными полями).\n# ==============================================================================\n\n# 1.1 Пакеты и окружение\n# Примечание: блок повторяет базовую инициализацию для автономного запуска.\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(readxl, tidyverse, caret, corrplot)\n\nrm(list = ls())\nset.seed(123)\nsetwd(\"C:/RECRUITMENT/\")\n\n# 1.2 Загрузка исходных данных и приведение типов\nDATA &lt;- readxl::read_excel(\"RECRUITMENT.xlsx\", sheet = \"RECRUITMENT\") %&gt;%\n  filter(YEAR &gt; 1989 & YEAR &lt; 2022) %&gt;%\n  mutate(\n    across(starts_with(\"T\"), as.numeric),\n    across(starts_with(\"I\"), as.numeric),\n    across(starts_with(\"O\"), as.numeric),\n    across(where(is.character), ~na_if(., \"NA\"))\n  )\n\n# 1.3 Создаём NAOspring (если есть NAO3, NAO4, NAO5)\n# Идея: агрегируем весенний индекс NAO как среднее за месяцы 3–5.\nif (all(c(\"NAO3\",\"NAO4\",\"NAO5\") %in% names(DATA))) {\n  DATA &lt;- DATA %&gt;%\n    mutate(NAOspring = rowMeans(pick(NAO3, NAO4, NAO5), na.rm = TRUE)) %&gt;%\n    select(-NAO3, -NAO4, -NAO5)\n}\n\n# NAO (North Atlantic Oscillation) - важный климатический индекс, влияющий описывающий изменения атмосферного давления\n# над Северной Атлантикой. В частности, он отражает разницу в атмосферном давлении между Исландской депрессией и\n# Азорским максимумом. NAO влияет на силу и направление западных ветров, а также на траектории штормов в Северной Атлантике. \n# Мы создаем NAOspring как среднее значение за весенние месяцы (марта, апреля, мая),\n# так как именно в этот период происходят ключевые процессы, влияющие на нерест трески. \n# Создание составных переменных на основе экспертных знаний часто улучшает качество моделей.\n\n# 1.4 Финальный учебный набор предикторов (фиксируем)\n# Важно: проверяем присутствие нужных колонок и формируем компактный датасет.\nneeded &lt;- c(\"codTSB\", \"T12\", \"I5\", \"NAOspring\", \"haddock68\")\nstopifnot(all(needed %in% names(DATA)))\n\n# Сохраняем YEAR в CSV (ниже он будет отброшен при обучении, но нужен для графика)\nmodel_data &lt;- DATA %&gt;%\n  select(YEAR, all_of(needed), R3haddock) %&gt;%\n  drop_na()\n\nwrite.csv(model_data, \"selected_predictors_dataset.csv\", row.names = FALSE)\nglimpse(model_data)\n\nRows: 32\nColumns: 7\n$ YEAR      &lt;dbl&gt; 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, ~\n$ codTSB    &lt;dbl&gt; 913000, 1347064, 1687381, 2197863, 2112773, 1849957, 1697388~\n$ T12       &lt;dbl&gt; 4.72, 4.66, 4.24, 3.90, 3.96, 4.27, 4.16, 4.07, 4.23, 5.08, ~\n$ I5        &lt;dbl&gt; 43, 55, 26, 49, 56, 28, 52, 51, 69, 68, 41, 48, 50, 63, 40, ~\n$ NAOspring &lt;dbl&gt; 0.64333333, 0.05666667, 1.78666667, 0.28666667, 0.61000000, ~\n$ haddock68 &lt;dbl&gt; 74586, 79205, 53195, 36337, 49122, 81514, 172177, 160886, 96~\n$ R3haddock &lt;dbl&gt; 812363, 389416, 99474, 98946, 118812, 63028, 147657, 83270, ~\n\n# (необязательно) Глянуть попарные связи и корреляции\n# ggpairs может быть медленным, оставим по желанию\n ggpairs(model_data, columns = 2:7,\n         lower = list(continuous = wrap(\"smooth\", alpha = 0.3, size = 0.5)),\n         upper = list(cor = wrap(\"cor\", size = 3)))\n\n\n\n\n\n\n\n# ==============================================================================\n# 2) БАЗОВОЕ СРАВНЕНИЕ МОДЕЛЕЙ (5-FOLD CV + HOLDOUT)\n# Единые фолды CV, тренировочно-тестовое разбиение, сводка метрик.\n# ------------------------------------------------------------------------------\n# Идея блока: быстрая «панель» сравнения разных семейств моделей на одинаковых\n# условиях (одинаковые фолды CV) и внешний тест (holdout). Это помогает увидеть\n# уровни ошибок и выбрать несколько лидеров для более строгой проверки далее.\n# ==============================================================================\n\n# 2.1 Пакеты и данные\npacman::p_load(mgcv, randomForest, xgboost, nnet, earth, kernlab, pls, Cubist, ranger, gbm, lattice)\n\nmodel_data &lt;- read.csv(\"selected_predictors_dataset.csv\", header = TRUE, stringsAsFactors = FALSE)\n# Если YEAR отсутствует (на всякий случай), создадим\nif (!\"YEAR\" %in% names(model_data)) {\n  model_data$YEAR &lt;- seq(1990, by = 1, length.out = nrow(model_data))\n}\n\n# Используем только предикторы и отклик (YEAR исключаем)\nmodel_data &lt;- model_data %&gt;%\n  select(codTSB, T12, I5, NAOspring, haddock68, R3haddock) %&gt;%\n  na.omit()\n\n# 2.2 Holdout и CV-контроллер\n# Пропорция 80/20 обеспечивает внешний тест; внутри train — 5-fold CV для\n# корректной настройки моделей и оценки средней ошибки.\ntrain_idx &lt;- caret::createDataPartition(model_data$R3haddock, p = 0.8, list = FALSE)\ntrain &lt;- model_data[train_idx, ]\ntest  &lt;- model_data[-train_idx, ]\n\nctrl &lt;- caret::trainControl(method = \"cv\", number = 5, savePredictions = \"final\")\n\n# Holdout-метод: мы делим данные на обучающую (80%) и тестовую (20%) выборки.\n# Кросс-валидация (5-fold CV): данные разбиваются на 5 частей, модель обучается на 4 частях и тестируется на 5-й, \n# и этот процесс повторяется 5 раз. Это дает более надежную оценку качества модели, чем одно разбиение. \n\n\n# 2.3 Кастомный GAM (mgcv) для caret (bs=\"tp\", REML, select=TRUE)\n# GAM даёт гладкие нелинейности по каждому признаку; REML стабилизирует оценку.\ngam_spec &lt;- list(\n  type = \"Regression\", library = \"mgcv\", loop = NULL,\n  parameters = data.frame(parameter = \"none\", class = \"character\", label = \"none\"),\n  grid = function(x,y,len=NULL,search=\"grid\") data.frame(none = NA),\n  fit = function(x,y,...) {\n    df &lt;- x; df$R3haddock &lt;- y\n    mgcv::gam(\n      R3haddock ~ s(codTSB,bs=\"tp\") + s(T12,bs=\"tp\") + s(I5,bs=\"tp\") +\n                  s(NAOspring,bs=\"tp\") + s(haddock68,bs=\"tp\"),\n      data=df, method=\"REML\", select=TRUE, ...\n    )\n  },\n  predict = function(modelFit, newdata, submodels = NULL) {\n    predict(modelFit, newdata = newdata, type = \"response\")\n  },\n  prob = NULL, sort = function(x) x\n)\n\n# 2.4 Обучение моделей\n# Подсказка: разные методы по-разному чувствительны к масштабу, числу признаков\n# и мультиколлинеарности. Мы применяем одинаковые фолды CV для честного сравнения.\n\n# --- 1. Линейная регрессия (LM)\n# Учебный смысл: базовая линейная модель; ориентир для сравнения.\n# ПОЯСНЕНИЕ: LM предполагает линейную зависимость между предикторами и откликом.\n# Это простая модель, которая служит \"нижней планкой\" - более сложные модели могут быть лучше LM. \nlm_model    &lt;- caret::train(R3haddock ~ ., data = train, method = \"lm\", trControl = ctrl)\n\n# --- 2. Обобщённая линейная модель (GLM: Gamma с лог-ссылкой)\n# Учебный смысл: модель для положительных откликов; допускает нелинейность в шкале log.\n# ПОЯСНЕНИЕ: GLM с Gamma-распределением подходит для положительных непрерывных данных \n# (как размер популяции), где дисперсия зависит от среднего значения.\nglm_model   &lt;- caret::train(R3haddock ~ ., data = train, method = \"glm\",\n                            family = Gamma(link = \"log\"), trControl = ctrl)\n\n# --- 3. Обобщённая аддитивная модель (GAM, mgcv: bs=\"tp\", REML, select=TRUE)\n# Учебный смысл: гибкие гладкие нелинейности по каждому предиктору.\n# ПОЯСНЕНИЕ: GAM позволяет моделировать нелинейные зависимости с помощью гладких функций (splines),\n# сохраняя интерпретируемость отдельных эффектов. Это компромисс между простотой LM и сложностью ML.\ngam_model   &lt;- caret::train(x = train[, -which(names(train)==\"R3haddock\")],\n                            y = train$R3haddock, method = gam_spec, trControl = ctrl)\n\nWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,\n: There were missing values in resampled performance measures.\n\n# --- 4. Random Forest (rf: ntree=1000, mtry=1)\n# Учебный смысл: ансамбль деревьев; устойчив к шуму; нелинейности/взаимодействия \"из коробки\".\n# ПОЯСНЕНИЕ: Random Forest строит множество деревьев решений и усредняет их результаты.\n# Это мощный метод, который автоматически улавливает нелинейные зависимости и взаимодействия. \nrf_model    &lt;- caret::train(R3haddock ~ ., data = train, method = \"rf\", trControl = ctrl,\n                            ntree = 1000, tuneGrid = data.frame(mtry = 1), importance = TRUE)\n\n# --- 5. XGBoost (xgbTree) \n# Учебный смысл: бустинг деревьев; сильная ML-модель, легко переобучается без валидации.\n# ПОЯСНЕНИЕ: XGBoost - это градиентный бустинг над деревьями решений, который последовательно \n# строит деревья, исправляя ошибки предыдущих. Требует тщательной настройки параметров.\nxgb_grid    &lt;- expand.grid(nrounds=100, max_depth=4, eta=0.1, gamma=0,\n                           colsample_bytree=0.8, min_child_weight=1, subsample=0.8)\nxgb_model   &lt;- caret::train(R3haddock ~ ., data = train, method = \"xgbTree\",\n                            trControl = ctrl, tuneGrid = xgb_grid, verbose = 0)\n\n# --- 6. Нейросеть (MLP, nnet: линейный выход, стандартизация)\n# Учебный смысл: универсальный аппроксиматор; чувствителен к масштабу; требует регуляризации.\n# ПОЯСНЕНИЕ: Нейронные сети могут моделировать сложные нелинейные отношения. \n# Используемая архитектура (1 скрытый слой) - компромисс между гибкостью и риском переобучения.\n# Линейный выходной слой подходит для регрессии.\nnnet_model  &lt;- caret::train(R3haddock ~ ., data = train, method = \"nnet\",\n                            trControl = ctrl, preProcess = c(\"center\",\"scale\"),\n                            tuneGrid = expand.grid(size = 5, decay = 0.1),\n                            linout = TRUE, trace = FALSE, MaxNWts = 5000)\n\n# --- 7. Elastic Net (glmnet)\n# Учебный смысл: регуляризация (L1/L2), борьба с мультиколлинеарностью, частичный отбор признаков.\n# ПОЯСНЕНИЕ: Комбинирует L1 (лассо) и L2 (ридж) регуляризации. Автоматически отбирает признаки \n# и уменьшает влияние мультиколлинеарности. Параметр alpha балансирует между лассо и риджем.\nglmnet_model&lt;- caret::train(R3haddock ~ ., data = train, method = \"glmnet\",\n                            trControl = ctrl, preProcess = c(\"center\",\"scale\"), tuneLength = 10)\n\n# --- 8. MARS (earth)\n# Учебный смысл: кусочно-линейные сплайны + простые взаимодействия; гибкая интерпретация.\n# ПОЯСНЕНИЕ: Многомерные адаптивные регрессионные сплайны (MARS) строят кусочно-линейные модели \n# с автоматическим выбором точек излома. Поддерживает взаимодействия ограниченного порядка.\nearth_model &lt;- caret::train(R3haddock ~ ., data = train, method = \"earth\",\n                            trControl = ctrl, tuneLength = 10)\n\nWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,\n: There were missing values in resampled performance measures.\n\n# --- 9. SVM с радиальным ядром (svmRadial)\n# Учебный смысл: ядровой метод; улавливает сложные нелинейности; важна стандартизация.\n# ПОЯСНЕНИЕ: Метод опорных векторов с радиальным ядром проецирует данные в пространство \n# высокой размерности, где становится возможным линейное разделение. Параметр gamma управляет \n# гибкостью границы решения.\nsvm_model   &lt;- caret::train(R3haddock ~ ., data = train, method = \"svmRadial\",\n                            trControl = ctrl, preProcess = c(\"center\",\"scale\"), tuneLength = 8)\n\n# --- 10. k-ближайших соседей (kNN)\n# Учебный смысл: простая интуитивная нелинейная модель на расстояниях; чувствительна к масштабу.\n# ПОЯСНЕНИЕ: Предсказание основано на усреднении значений k ближайших наблюдений. \n# Требует вычисления попарных расстояний, что может быть ресурсоемким при больших данных.\nknn_model   &lt;- caret::train(R3haddock ~ ., data = train, method = \"knn\",\n                            trControl = ctrl, preProcess = c(\"center\",\"scale\"), tuneLength = 15)\n\nWarning in knnregTrain(train = structure(c(-1.54402860027016,\n-1.04267060653844, : k = 23 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.54402860027016,\n-1.04267060653844, : k = 25 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.54402860027016,\n-1.04267060653844, : k = 27 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.54402860027016,\n-1.04267060653844, : k = 29 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.54402860027016,\n-1.04267060653844, : k = 31 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.54402860027016,\n-1.04267060653844, : k = 33 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.32034464856588,\n-0.795974449614684, : k = 23 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.32034464856588,\n-0.795974449614684, : k = 25 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.32034464856588,\n-0.795974449614684, : k = 27 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.32034464856588,\n-0.795974449614684, : k = 29 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.32034464856588,\n-0.795974449614684, : k = 31 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.32034464856588,\n-0.795974449614684, : k = 33 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.59980040948893,\n-0.134264066935858, : k = 25 exceeds number 23 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.59980040948893,\n-0.134264066935858, : k = 27 exceeds number 23 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.59980040948893,\n-0.134264066935858, : k = 29 exceeds number 23 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.59980040948893,\n-0.134264066935858, : k = 31 exceeds number 23 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.59980040948893,\n-0.134264066935858, : k = 33 exceeds number 23 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.47821802102901,\n-0.982937987281781, : k = 23 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.47821802102901,\n-0.982937987281781, : k = 25 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.47821802102901,\n-0.982937987281781, : k = 27 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.47821802102901,\n-0.982937987281781, : k = 29 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.47821802102901,\n-0.982937987281781, : k = 31 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.47821802102901,\n-0.982937987281781, : k = 33 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.07995722209223,\n-0.0328010741655768, : k = 25 exceeds number 23 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.07995722209223,\n-0.0328010741655768, : k = 27 exceeds number 23 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.07995722209223,\n-0.0328010741655768, : k = 29 exceeds number 23 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.07995722209223,\n-0.0328010741655768, : k = 31 exceeds number 23 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.07995722209223,\n-0.0328010741655768, : k = 33 exceeds number 23 of patterns\n\n\nWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,\n: There were missing values in resampled performance measures.\n\n# --- 11. Ranger (быстрый Random Forest)\n# Учебный смысл: альтернативная/быстрая реализация леса; сравнить с randomForest.\n# ПОЯСНЕНИЕ: Оптимизированная реализация Random Forest на C++. Поддерживает распараллеливание \n# и эффективную работу с категориальными переменными. Важен параметр mtry (число признаков в узле).\nranger_model&lt;- caret::train(R3haddock ~ ., data = train, method = \"ranger\",\n                            trControl = ctrl, tuneLength = 3, importance = \"impurity\")\n\n# --- 12. GBM (классический градиентный бустинг)\n# Учебный смысл: другой бустинг деревьев; полезно сравнить с XGBoost.\n# ПОЯСНЕНИЕ: Градиентный бустинг строит деревья последовательно, где каждое новое дерево \n# корректирует ошибки предыдущих. Параметр shrinkage (темп обучения) контролирует скорость обучения.\ngbm_model   &lt;- caret::train(R3haddock ~ ., data = train, method = \"gbm\",\n                            trControl = ctrl,\n                            tuneGrid = expand.grid(n.trees=100, interaction.depth=1,\n                                                   shrinkage=0.1, n.minobsinnode=2),\n                            distribution = \"gaussian\", bag.fraction = 1, verbose = FALSE)\n\n# --- 13. PLS (Partial Least Squares)\n# Учебный смысл: проекция на скрытые компоненты с учетом отклика; решает мультиколлинеарность.\n# ПОЯСНЕНИЕ: Частные наименьшие квадраты (PLS) проецируют предикторы в латентное пространство, \n# максимизируя ковариацию с откликом. Эффективен при высокой корреляции признаков.\npls_model   &lt;- caret::train(R3haddock ~ ., data = train, method = \"pls\",\n                            trControl = ctrl, preProcess = c(\"center\",\"scale\"), tuneLength = 10)\n\n# --- 14. Cubist (правила + деревья)\n# Учебный смысл: интерпретируемые правила с комитетами; часто силен на табличных данных.\n# ПОЯСНЕНИЕ: Cubist объединяет деревья решений с линейными моделями в листьях. Генерирует \n# набор правил \"если-то\", что улучшает интерпретируемость. Комитеты (комитеты) уменьшают дисперсию.\ncubist_model&lt;- caret::train(R3haddock ~ ., data = train, method = \"cubist\",\n                            trControl = ctrl, tuneLength = 5)\n\nWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,\n: There were missing values in resampled performance measures.\n\n# 2.5 Метрики и оценка на тесте\n# Замечание: RMSE/MAE — абсолютные ошибки; R2 — доля объяснённой вариации;\n# MAPE/sMAPE — относительные ошибки (осторожно при малых значениях отклика).\nrmse  &lt;- function(a, p) sqrt(mean((a - p)^2, na.rm = TRUE))\nmae   &lt;- function(a, p) mean(abs(a - p), na.rm = TRUE)\nr2    &lt;- function(a, p) 1 - sum((a - p)^2, na.rm = TRUE) / sum((a - mean(a))^2, na.rm = TRUE)\nmape  &lt;- function(a, p) mean(abs((a - p) / a), na.rm = TRUE) * 100\nsmape &lt;- function(a, p) mean(2 * abs(p - a) / (abs(a) + abs(p)), na.rm = TRUE) * 100\nmetrics_vec &lt;- function(y, pred) c(RMSE=rmse(y,pred), MAE=mae(y,pred), R2=r2(y,pred),\n                                   MAPE=mape(y,pred), sMAPE=smape(y,pred))\n\n# Для оценки качества моделей мы используем несколько метрик:\n#   - RMSE (Root Mean Square Error): среднеквадратичная ошибка (чувствительна к выбросам)\n#   - MAE (Mean Absolute Error): средняя абсолютная ошибка (более интерпретируема)\n#   - R²: коэффициент детерминации (доля объясненной дисперсии)\n#   - MAPE: средняя абсолютная процентная ошибка (в процентах от фактического значения)\n#   - sMAPE: симметричная MAPE (устраняет проблему деления на ноль) \n\ny_test &lt;- test$R3haddock\npreds_test &lt;- list(\n  LM=predict(lm_model,test), GLM=predict(glm_model,test), GAM=predict(gam_model,test),\n  RF=predict(rf_model,test), XGB=predict(xgb_model,test), NNET=predict(nnet_model,test),\n  ENet=predict(glmnet_model,test), MARS=predict(earth_model,test), SVM=predict(svm_model,test),\n  kNN=predict(knn_model,test), RANGER=predict(ranger_model,test), GBM=predict(gbm_model,test),\n  PLS=predict(pls_model,test), CUBIST=predict(cubist_model,test)\n)\nmetrics_table &lt;- do.call(rbind, lapply(names(preds_test), function(nm){\n  data.frame(Model = nm, t(metrics_vec(y_test, preds_test[[nm]])), row.names = NULL)\n})) %&gt;% arrange(RMSE, MAE)\n\n# Создаем копию таблицы для округления\nmetrics_table_rounded &lt;- metrics_table\n\n# Находим индексы числовых столбцов (исключая первый столбец \"Model\")\nnumeric_cols &lt;- sapply(metrics_table_rounded, is.numeric)\n\n# Округляем только числовые столбцы до 2 знаков\nmetrics_table_rounded[numeric_cols] &lt;- round(metrics_table_rounded[numeric_cols], 2)\n\n# Выводим округленную таблицу\nprint(metrics_table_rounded)\n\n    Model      RMSE       MAE    R2   MAPE sMAPE\n1     GBM  65112.49  55805.52  0.76  34.41 27.07\n2    MARS  95150.47  78452.71  0.49  51.69 36.18\n3      RF 125056.40  97862.47  0.12  74.27 44.45\n4     PLS 130411.86 111694.80  0.04  62.51 47.69\n5      LM 131592.23 113063.92  0.02  63.62 48.29\n6     GAM 140393.68 121236.06 -0.11  70.56 48.99\n7  CUBIST 147031.92 123320.33 -0.22  50.52 46.56\n8    ENet 147470.05 124147.91 -0.23  81.27 52.96\n9  RANGER 148623.73 127762.15 -0.25  87.21 54.25\n10    kNN 149082.19 128657.28 -0.26  88.53 53.55\n11    GLM 151391.83 129510.77 -0.30  74.40 55.01\n12    SVM 167864.37 147269.48 -0.59 104.73 57.83\n13    XGB 208719.19 194346.48 -1.46  88.97 65.24\n14   NNET 216172.26 199594.44 -1.64  93.12 87.93\n\nknitr::kable(\n  metrics_table %&gt;% dplyr::mutate(dplyr::across(where(is.numeric), ~round(.x, 2))),\n  caption = \"Holdout-метрики (округлено до 2 знаков)\"\n)\n\n\nHoldout-метрики (округлено до 2 знаков)\n\n\nModel\nRMSE\nMAE\nR2\nMAPE\nsMAPE\n\n\n\n\nGBM\n65112.49\n55805.52\n0.76\n34.41\n27.07\n\n\nMARS\n95150.47\n78452.71\n0.49\n51.69\n36.18\n\n\nRF\n125056.40\n97862.47\n0.12\n74.27\n44.45\n\n\nPLS\n130411.86\n111694.80\n0.04\n62.51\n47.69\n\n\nLM\n131592.23\n113063.92\n0.02\n63.62\n48.29\n\n\nGAM\n140393.68\n121236.06\n-0.11\n70.56\n48.99\n\n\nCUBIST\n147031.92\n123320.33\n-0.22\n50.52\n46.56\n\n\nENet\n147470.05\n124147.91\n-0.23\n81.27\n52.96\n\n\nRANGER\n148623.73\n127762.15\n-0.25\n87.21\n54.25\n\n\nkNN\n149082.19\n128657.28\n-0.26\n88.53\n53.55\n\n\nGLM\n151391.83\n129510.77\n-0.30\n74.40\n55.01\n\n\nSVM\n167864.37\n147269.48\n-0.59\n104.73\n57.83\n\n\nXGB\n208719.19\n194346.48\n-1.46\n88.97\n65.24\n\n\nNNET\n216172.26\n199594.44\n-1.64\n93.12\n87.93\n\n\n\n\n# 2.6 CV-резюме\n# Сводим результаты CV по всем моделям и смотрим распределения ошибок.\nresults &lt;- caret::resamples(list(\n  LM=lm_model, GLM=glm_model, GAM=gam_model, RF=rf_model, XGB=xgb_model, NNET=nnet_model,\n  ENet=glmnet_model, MARS=earth_model, SVM=svm_model, kNN=knn_model, RANGER=ranger_model,\n  GBM=gbm_model, PLS=pls_model, CUBIST=cubist_model\n))\nsummary(results)\n\n\nCall:\nsummary.resamples(object = results)\n\nModels: LM, GLM, GAM, RF, XGB, NNET, ENet, MARS, SVM, kNN, RANGER, GBM, PLS, CUBIST \nNumber of resamples: 5 \n\nMAE \n            Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\nLM      57204.50 173765.7 178162.9 167545.5 210890.4 217704.1    0\nGLM    121162.89 123189.9 126872.5 161564.3 215648.4 220947.6    0\nGAM    113581.17 186001.4 194396.8 216924.0 243663.3 346977.3    0\nRF     140917.34 173192.3 183106.9 211428.5 199504.4 360421.6    0\nXGB    191739.57 196545.5 204224.0 220586.8 211582.9 298842.3    0\nNNET   210800.50 230696.3 231946.6 255228.9 268869.5 333831.8    0\nENet    95118.26 114161.5 186843.2 175901.3 203787.5 279596.0    0\nMARS   100715.25 160470.7 226674.7 224830.7 281753.1 354539.8    0\nSVM    137655.75 168734.2 186772.6 218295.0 270224.5 328087.8    0\nkNN    153725.61 173448.8 204644.5 201592.1 210974.4 265167.1    0\nRANGER 134039.92 173499.6 173657.3 188631.8 213348.0 248614.3    0\nGBM    142143.64 174377.4 182594.4 195116.5 210961.4 265505.7    0\nPLS    140180.64 169826.6 174374.4 174539.4 177221.3 211093.9    0\nCUBIST  40943.57 166731.9 172415.9 151410.2 183157.2 193802.4    0\n\nRMSE \n            Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\nLM      83394.05 204460.2 213949.1 198791.4 234397.7 257756.2    0\nGLM    144920.86 174777.3 199683.5 211248.8 268416.8 268445.7    0\nGAM    126481.10 212799.6 231166.1 251450.9 265213.5 421594.3    0\nRF     152505.15 221538.9 237863.1 264290.3 246285.2 463259.3    0\nXGB    224482.10 230814.5 274803.3 282033.4 324393.6 355673.5    0\nNNET   262262.48 292982.1 298735.5 322398.1 312361.7 445649.0    0\nENet    96405.72 194703.2 212260.2 215307.8 227408.1 345761.6    0\nMARS   133708.92 174187.4 275486.7 264992.8 296803.1 444778.0    0\nSVM    175110.30 208575.8 211026.8 261495.0 330657.7 382104.5    0\nkNN    191674.11 194743.2 293783.4 261451.2 307657.4 319397.8    0\nRANGER 179305.47 214964.7 252239.7 245471.8 256030.3 324818.7    0\nGBM    155235.18 236112.1 265637.9 269271.4 342304.1 347067.5    0\nPLS    192456.23 204052.4 206556.2 210244.7 207702.6 240455.9    0\nCUBIST  51000.20 217680.6 220028.3 190972.0 226862.3 239288.7    0\n\nRsquared \n              Min.    1st Qu.     Median      Mean   3rd Qu.      Max. NA's\nLM     0.038191154 0.34151126 0.59570117 0.5146318 0.6446897 0.9530659    0\nGLM    0.036094303 0.25361489 0.52140959 0.5247907 0.8499520 0.9628829    0\nGAM    0.078247285 0.20151523 0.39934478 0.3553497 0.5269644 0.5706765    0\nRF     0.007930602 0.01517051 0.11630358 0.1925039 0.1207826 0.7023323    0\nXGB    0.041587807 0.09841163 0.11696588 0.2060251 0.2118923 0.5612680    0\nNNET   0.018389559 0.02872886 0.07737108 0.1597232 0.1157484 0.5583779    0\nENet   0.170405604 0.55004140 0.62684865 0.5443111 0.6741520 0.7001081    0\nMARS   0.007289893 0.04026192 0.24769274 0.3088361 0.3755802 0.8733557    0\nSVM    0.044855520 0.06565037 0.24061923 0.2637711 0.4593310 0.5083994    0\nkNN    0.001714988 0.10251708 0.41997970 0.3013771 0.4201459 0.5625279    0\nRANGER 0.006761073 0.20688755 0.22338943 0.2919063 0.4553028 0.5671905    0\nGBM    0.056729819 0.15259735 0.27867315 0.2779509 0.3246546 0.5770994    0\nPLS    0.255560646 0.39058052 0.43207618 0.5269205 0.6127945 0.9435907    0\nCUBIST 0.004399571 0.20141307 0.52557866 0.5053060 0.8675585 0.9275803    0\n\nlattice::dotplot(results, metric = \"RMSE\")\n\n\n\n\n\n\n\n# ==============================================================================\n# 3) ВЫБОР ЛУЧШЕЙ ПРОГНОСТИЧЕСКОЙ МОДЕЛИ (TIME-SLICE CV НА 3 ГОДА + ХРОНО-ТЕСТ)\n# Делим последние годы в тест, внутри train — скользящее окно, h=3.\n# ------------------------------------------------------------------------------\n# Почему time-slice: временные данные нельзя случайно перемешивать, иначе мы\n# «подсматриваем в будущее». Создаём серии обучающих/валидационных окон,\n# увеличивая тренировочный период, и тестируем на ближайшем горизонте (3 года).\n# ==============================================================================\n\n# 3.1 Данные для time-slice (с YEAR)\nmodel_data &lt;- read.csv(\"selected_predictors_dataset.csv\", header = TRUE, stringsAsFactors = FALSE)\nif (!\"YEAR\" %in% names(model_data)) {\n  model_data$YEAR &lt;- seq(1990, by = 1, length.out = nrow(model_data))\n}\n# Хронологический порядок\nmodel_data &lt;- model_data %&gt;% arrange(YEAR)\n\n# Для временных рядов обычные методы кросс-валидации (случайное разбиение) неприменимы,\n# так как это приведет к утечке информации из будущего в прошлое. [[1]]\n# Time-slice CV (скользящее окно) имитирует реальную ситуацию прогнозирования:\n#   - Мы обучаемся на данных из прошлого\n#   - Прогнозируем на несколько шагов вперед\n#   - Последовательно сдвигаем окно обучения вперед\n\n# Исходные фичи (исключаем YEAR)\nmd_for_fit &lt;- model_data %&gt;% select(codTSB, T12, I5, NAOspring, haddock68, R3haddock)\n\n# 3.2 Хронологический holdout (последние годы)\n# Идея: отложим ~20% последних лет как полностью внешний тест будущего качества.\nn &lt;- nrow(md_for_fit)\nholdout_frac &lt;- 0.2\nn_test &lt;- max(4, ceiling(n * holdout_frac))\ntrain_ts &lt;- head(md_for_fit, n - n_test)\ntest_ts  &lt;- tail(md_for_fit, n_test)\n\n# 3.3 Time-slice CV (h=3, expanding window рекомендован: fixedWindow=FALSE)\n# initialWindow — размер первого «обучающего» фрагмента; horizon — горизонт\n# валидации (здесь 3 года). Далее окно расширяется.\nn_train &lt;- nrow(train_ts)\ninitial_frac &lt;- 0.6\nhorizon      &lt;- 3\ninitialWindow &lt;- max(10, floor(initial_frac * n_train))\nif (initialWindow + horizon &gt; n_train) initialWindow &lt;- n_train - horizon\n\nslices &lt;- caret::createTimeSlices(1:n_train, initialWindow = initialWindow,\n                                  horizon = horizon, fixedWindow = FALSE)\nctrl_ts &lt;- caret::trainControl(method = \"cv\", index = slices$train, indexOut = slices$test,\n                               savePredictions = \"final\")\n\n# В нашем случае:\n#   - horizon = 3: прогнозируем на 3 года вперед\n#   - expanding window: размер обучающей выборки увеличивается с каждым шагом\n#   - initialWindow: начальный размер обучающей выборки (60% от данных)\n# Этот подход наиболее реалистичен для задач прогнозирования временных рядов в гидробиологии.\n\n\n# 3.4 Обучение (ядро набора, без GBM — он нестабилен на малом n в timeslice)\n# Примечание: используем ту же рецептуру, что и в базовом сравнении, но с\n# хронологическими срезами.\n\nfit_ts &lt;- function(method, form, data, ctrl, ...) {\n  out &lt;- try(caret::train(form, data = data, method = method, trControl = ctrl, ...), TRUE)\n  if (inherits(out,\"try-error\")) NULL else out\n}\nlm_ts   &lt;- fit_ts(\"lm\",        R3haddock ~ ., train_ts, ctrl_ts)\nglm_ts  &lt;- fit_ts(\"glm\",       R3haddock ~ ., train_ts, ctrl_ts, family = Gamma(link=\"log\"))\ngam_ts  &lt;- caret::train(x = train_ts[, -which(names(train_ts)==\"R3haddock\")],\n                        y = train_ts$R3haddock, method = gam_spec, trControl = ctrl_ts)\n\nWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,\n: There were missing values in resampled performance measures.\n\nrf_ts   &lt;- fit_ts(\"rf\",        R3haddock ~ ., train_ts, ctrl_ts, ntree=1000, tuneGrid=data.frame(mtry=1))\nxgb_ts  &lt;- fit_ts(\"xgbTree\",   R3haddock ~ ., train_ts, ctrl_ts, tuneGrid = xgb_grid, verbose = 0)\nrgr_ts  &lt;- fit_ts(\"ranger\",    R3haddock ~ ., train_ts, ctrl_ts, tuneLength=3)\nnnet_ts &lt;- fit_ts(\"nnet\",      R3haddock ~ ., train_ts, ctrl_ts,\n                  preProcess=c(\"center\",\"scale\"),\n                  tuneGrid=expand.grid(size=5,decay=0.1), linout=TRUE, trace=FALSE, MaxNWts=5000)\n\nWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,\n: There were missing values in resampled performance measures.\n\nsvm_ts  &lt;- fit_ts(\"svmRadial\", R3haddock ~ ., train_ts, ctrl_ts, preProcess=c(\"center\",\"scale\"), tuneLength=8)\nknn_ts  &lt;- fit_ts(\"knn\",       R3haddock ~ ., train_ts, ctrl_ts, preProcess=c(\"center\",\"scale\"), tuneLength=15)\n\nWarning in knnregTrain(train = structure(c(-1.91776861098288,\n-0.63635090426016, : k = 17 exceeds number 15 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.91776861098288,\n-0.63635090426016, : k = 19 exceeds number 15 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.91776861098288,\n-0.63635090426016, : k = 21 exceeds number 15 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.91776861098288,\n-0.63635090426016, : k = 23 exceeds number 15 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.91776861098288,\n-0.63635090426016, : k = 25 exceeds number 15 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.91776861098288,\n-0.63635090426016, : k = 27 exceeds number 15 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.91776861098288,\n-0.63635090426016, : k = 29 exceeds number 15 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.91776861098288,\n-0.63635090426016, : k = 31 exceeds number 15 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.91776861098288,\n-0.63635090426016, : k = 33 exceeds number 15 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.97509275968546,\n-0.649515010512528, : k = 17 exceeds number 16 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.97509275968546,\n-0.649515010512528, : k = 19 exceeds number 16 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.97509275968546,\n-0.649515010512528, : k = 21 exceeds number 16 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.97509275968546,\n-0.649515010512528, : k = 23 exceeds number 16 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.97509275968546,\n-0.649515010512528, : k = 25 exceeds number 16 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.97509275968546,\n-0.649515010512528, : k = 27 exceeds number 16 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.97509275968546,\n-0.649515010512528, : k = 29 exceeds number 16 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.97509275968546,\n-0.649515010512528, : k = 31 exceeds number 16 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.97509275968546,\n-0.649515010512528, : k = 33 exceeds number 16 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.03591114922526,\n-0.667021070399982, : k = 19 exceeds number 17 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.03591114922526,\n-0.667021070399982, : k = 21 exceeds number 17 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.03591114922526,\n-0.667021070399982, : k = 23 exceeds number 17 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.03591114922526,\n-0.667021070399982, : k = 25 exceeds number 17 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.03591114922526,\n-0.667021070399982, : k = 27 exceeds number 17 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.03591114922526,\n-0.667021070399982, : k = 29 exceeds number 17 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.03591114922526,\n-0.667021070399982, : k = 31 exceeds number 17 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.03591114922526,\n-0.667021070399982, : k = 33 exceeds number 17 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.09685135650479,\n-0.723233808010845, : k = 19 exceeds number 18 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.09685135650479,\n-0.723233808010845, : k = 21 exceeds number 18 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.09685135650479,\n-0.723233808010845, : k = 23 exceeds number 18 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.09685135650479,\n-0.723233808010845, : k = 25 exceeds number 18 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.09685135650479,\n-0.723233808010845, : k = 27 exceeds number 18 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.09685135650479,\n-0.723233808010845, : k = 29 exceeds number 18 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.09685135650479,\n-0.723233808010845, : k = 31 exceeds number 18 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-2.09685135650479,\n-0.723233808010845, : k = 33 exceeds number 18 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.87781906605955,\n-0.736313775515053, : k = 21 exceeds number 19 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.87781906605955,\n-0.736313775515053, : k = 23 exceeds number 19 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.87781906605955,\n-0.736313775515053, : k = 25 exceeds number 19 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.87781906605955,\n-0.736313775515053, : k = 27 exceeds number 19 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.87781906605955,\n-0.736313775515053, : k = 29 exceeds number 19 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.87781906605955,\n-0.736313775515053, : k = 31 exceeds number 19 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.87781906605955,\n-0.736313775515053, : k = 33 exceeds number 19 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.59299667707382,\n-0.714710653867683, : k = 21 exceeds number 20 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.59299667707382,\n-0.714710653867683, : k = 23 exceeds number 20 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.59299667707382,\n-0.714710653867683, : k = 25 exceeds number 20 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.59299667707382,\n-0.714710653867683, : k = 27 exceeds number 20 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.59299667707382,\n-0.714710653867683, : k = 29 exceeds number 20 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.59299667707382,\n-0.714710653867683, : k = 31 exceeds number 20 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.59299667707382,\n-0.714710653867683, : k = 33 exceeds number 20 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.44471091878981,\n-0.719611760680745, : k = 23 exceeds number 21 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.44471091878981,\n-0.719611760680745, : k = 25 exceeds number 21 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.44471091878981,\n-0.719611760680745, : k = 27 exceeds number 21 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.44471091878981,\n-0.719611760680745, : k = 29 exceeds number 21 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.44471091878981,\n-0.719611760680745, : k = 31 exceeds number 21 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.44471091878981,\n-0.719611760680745, : k = 33 exceeds number 21 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.35845826709587,\n-0.734816317064085, : k = 23 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.35845826709587,\n-0.734816317064085, : k = 25 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.35845826709587,\n-0.734816317064085, : k = 27 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.35845826709587,\n-0.734816317064085, : k = 29 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.35845826709587,\n-0.734816317064085, : k = 31 exceeds number 22 of patterns\n\n\nWarning in knnregTrain(train = structure(c(-1.35845826709587,\n-0.734816317064085, : k = 33 exceeds number 22 of patterns\n\n\nWarning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,\n: There were missing values in resampled performance measures.\n\nenet_ts &lt;- fit_ts(\"glmnet\",    R3haddock ~ ., train_ts, ctrl_ts, preProcess=c(\"center\",\"scale\"), tuneLength=10)\nmars_ts &lt;- fit_ts(\"earth\",     R3haddock ~ ., train_ts, ctrl_ts, tuneLength=10)\npls_ts  &lt;- fit_ts(\"pls\",       R3haddock ~ ., train_ts, ctrl_ts, preProcess=c(\"center\",\"scale\"), tuneLength=10)\ncub_ts  &lt;- fit_ts(\"cubist\",    R3haddock ~ ., train_ts, ctrl_ts, tuneLength=5)\n\nmodels_ts &lt;- list(LM=lm_ts, GLM=glm_ts, GAM=gam_ts, RF=rf_ts, XGB=xgb_ts, RANGER=rgr_ts,\n                  NNET=nnet_ts, SVM=svm_ts, kNN=knn_ts, ENet=enet_ts, MARS=mars_ts, PLS=pls_ts, CUBIST=cub_ts)\nmodels_ts &lt;- models_ts[!vapply(models_ts, is.null, logical(1))]\n\n# 3.5 Ранжирование по time-slice CV и по хронологическому тесту\n# Сначала ранжируем по средним ошибкам на валидационных срезах, затем — по внешнему тесту.\ncv_metrics &lt;- function(m) {\n  if (is.null(m$pred) || !\"Resample\" %in% names(m$pred)) return(c(RMSE=NA, MAE=NA))\n  by_slice &lt;- m$pred %&gt;% group_by(Resample) %&gt;%\n    summarise(RMSE=rmse(obs,pred), MAE=mae(obs,pred), .groups=\"drop\")\n  c(RMSE = mean(by_slice$RMSE, na.rm = TRUE), MAE = mean(by_slice$MAE, na.rm = TRUE))\n}\ncv_rank &lt;- do.call(rbind, lapply(models_ts, cv_metrics)) %&gt;% as.data.frame()\ncv_rank$Model &lt;- rownames(cv_rank)\ncv_rank &lt;- cv_rank[is.finite(cv_rank$RMSE), ] %&gt;% relocate(Model) %&gt;% arrange(RMSE, MAE)\ncat(\"\\nTime-slice CV (h=3), средние RMSE/MAE:\\n\"); print(cv_rank)\n\n\nTime-slice CV (h=3), средние RMSE/MAE:\n\n\n        Model     RMSE      MAE\nSVM       SVM 227929.6 191921.6\nkNN       kNN 234897.8 197135.0\nENet     ENet 250989.0 214248.7\nXGB       XGB 277153.4 248532.6\nRANGER RANGER 280255.1 249992.1\nGLM       GLM 280259.5 237186.9\nNNET     NNET 296856.1 264368.2\nPLS       PLS 302968.3 274707.6\nRF         RF 303710.0 263019.5\nCUBIST CUBIST 314443.4 281437.9\nLM         LM 370298.1 340883.8\nMARS     MARS 427624.1 378476.5\nGAM       GAM 714951.0 625520.3\n\npreds_ts &lt;- lapply(models_ts, function(m) try(predict(m, newdata = test_ts), TRUE))\nkeep &lt;- vapply(preds_ts, function(p) is.numeric(p) && length(p)==nrow(test_ts) && all(is.finite(p)), logical(1))\npreds_ts &lt;- preds_ts[keep]\ntest_rank &lt;- do.call(rbind, lapply(names(preds_ts), function(nm){\n  data.frame(Model=nm, t(metrics_vec(test_ts$R3haddock, preds_ts[[nm]])), row.names = NULL)\n})) %&gt;% arrange(RMSE, MAE)\ncat(\"\\nХронологический тест (последние годы), RMSE/MAE/R2:\\n\"); print(test_rank)\n\n\nХронологический тест (последние годы), RMSE/MAE/R2:\n\n\n    Model     RMSE      MAE         R2      MAPE     sMAPE\n1  CUBIST 148248.4 107629.3  0.5774780  54.93724  38.06342\n2      LM 156940.0 129604.7  0.5264822  97.30313  49.10292\n3     GAM 158131.0 125038.0  0.5192677  51.33030  42.12742\n4     PLS 176786.2 138249.0  0.3991499 123.21995  50.93728\n5     GLM 182047.7 141692.4  0.3628531  73.71724  50.32932\n6      RF 185485.8 148117.2  0.3385600  96.29497  52.15688\n7     kNN 187966.9 143164.4  0.3207460  71.77551  50.80097\n8    ENet 195260.5 161191.7  0.2670102 115.55953  56.27135\n9  RANGER 208161.4 171717.0  0.1669526 115.93679  58.76935\n10    SVM 250994.6 197801.6 -0.2111500  84.52010  67.59732\n11   MARS 273186.2 208579.6 -0.4347849  85.29788  71.46314\n12    XGB 288167.4 233693.4 -0.5964639 102.19238  78.99024\n13   NNET 345227.3 291463.2 -1.2912878 233.62022 102.82204\n\n# ==============================================================================\n# 4) ПРОГНОЗ 2022–2024 (АНСАМБЛЬ CUBIST+LM) И ГРАФИК 1990–2024 С ДИ\n# Прогнозные линии (медиана и ДИ) — пунктир; исторические — сплошные.\n# Можно задать свои сценарии предикторов (user_future); по умолчанию — средние.\n# ------------------------------------------------------------------------------\n# Логика ансамбля: комбинируем сильную нелинейную модель (Cubist) с простой и\n# устойчивой линейной (LM). Веса можно настраивать. Доверительные интервалы\n# получаем эмпирически из распределения остатков (простая и наглядная эвристика).\n# ==============================================================================\n\n# 4.1 Полные модели для прогноза (на всех данных) и вес ансамбля\nmodel_data &lt;- read.csv(\"selected_predictors_dataset.csv\", header = TRUE, stringsAsFactors = FALSE)\nif (!\"YEAR\" %in% names(model_data)) {\n  model_data$YEAR &lt;- seq(1990, by = 1, length.out = nrow(model_data))\n}\nmodel_data &lt;- model_data %&gt;% arrange(YEAR)\n\ncubist_full &lt;- caret::train(R3haddock ~ codTSB + T12 + I5 + NAOspring + haddock68,\n                            data = model_data, method = \"cubist\",\n                            trControl = caret::trainControl(method=\"none\"),\n                            tuneGrid = if (exists(\"cubist_model\")) cubist_model$bestTune else NULL,\n                            tuneLength = if (exists(\"cubist_model\")) 1 else 5)\n\nlm_full &lt;- caret::train(R3haddock ~ codTSB + T12 + I5 + NAOspring + haddock68,\n                        data = model_data, method = \"lm\",\n                        trControl = caret::trainControl(method=\"none\"))\n\nalpha_opt &lt;- if (exists(\"alpha_opt\")) alpha_opt else 0.75\npredict_ensemble &lt;- function(newdata, alpha = alpha_opt) {\n  alpha * predict(cubist_full, newdata) + (1 - alpha) * predict(lm_full, newdata)\n}\n\n# Ансамбль моделей часто дает более точные и устойчивые прогнозы, чем отдельные модели. [[8]]\n# В нашем случае:\n#   - CUBIST: мощная модель, основанная на правилах, хорошо работающая с табличными данными\n#   - LM: простая интерпретируемая модель, устойчивая к шуму\n#   - alpha_opt = 0.75: веса ансамбля (75% CUBIST, 25% LM), оптимизированные ранее (см. скрипт \"ENS_WEIGHT.R\")\n# Комбинирование моделей с разными сильными сторонами снижает риск систематических ошибок.\n\n# 4.2 Остатки для ДИ (из CV, если есть; иначе — по фитам)\n# Эмпирические квантилы остатков дают «практические» интервалы прогноза без\n# предположения нормальности ошибок (хотя строгий PI требует аккуратности).\nget_residuals_for_pi &lt;- function() {\n  if (exists(\"lm_model\") && exists(\"cubist_model\") &&\n      !is.null(lm_model$pred) && !is.null(cubist_model$pred)) {\n    pl &lt;- lm_model$pred %&gt;% select(Resample,rowIndex,obs,p_lm=pred)\n    pc &lt;- cubist_model$pred %&gt;% select(Resample,rowIndex,p_cu=pred)\n    inner_join(pl, pc, by=c(\"Resample\",\"rowIndex\")) %&gt;%\n      mutate(p_ens = alpha_opt * p_cu + (1 - alpha_opt) * p_lm,\n             resid = obs - p_ens) %&gt;%\n      pull(resid) %&gt;% .[is.finite(.)]\n  } else {\n    model_data$R3haddock - predict_ensemble(model_data)\n  }\n}\nresids &lt;- get_residuals_for_pi()\nq025 &lt;- as.numeric(quantile(resids, 0.025, na.rm = TRUE))\nq250 &lt;- as.numeric(quantile(resids, 0.250, na.rm = TRUE))\nq750 &lt;- as.numeric(quantile(resids, 0.750, na.rm = TRUE))\nq975 &lt;- as.numeric(quantile(resids, 0.975, na.rm = TRUE))\n\n# Доверительные интервалы (ДИ) показывают неопределенность прогноза.\n# Мы используем квантили остатков из кросс-валидации для построения ДИ:\n#   - PI50 (50% интервал): между 25-м и 75-м процентилями\n#   - PI95 (95% интервал): между 2.5-м и 97.5-м процентилями\n# Это непараметрический подход, не требующий предположений о нормальности ошибок.\n\n# 4.3 Сценарии будущего (по умолчанию — средние; можно переопределить user_future)\nfc_start &lt;- 2022\npred_cols &lt;- c(\"codTSB\",\"T12\",\"I5\",\"NAOspring\",\"haddock68\")\ntrain_period &lt;- model_data %&gt;% filter(YEAR &gt; 1989 & YEAR &lt; fc_start)\nmu &lt;- train_period %&gt;% summarise(across(all_of(pred_cols), ~mean(.x, na.rm = TRUE))) %&gt;% as.list()\n\n# Пример пользовательского сценария:\n# user_future &lt;- tibble::tribble(\n#   ~YEAR, ~codTSB, ~T12, ~I5, ~NAOspring, ~haddock68,\n#   2022, 2100000, 5.1, 48,  0.3, 120000,\n#   2023, 2050000, 4.8, 50, -0.1, 115000,\n#   2024, 2150000, 5.0, 47,  0.2, 118000\n# )\nif (!exists(\"user_future\")) user_future &lt;- NULL\n\nbuild_future &lt;- function(years, mu, user_df=NULL) {\n  df &lt;- tibble::tibble(YEAR = years)\n  for (v in pred_cols) df[[v]] &lt;- mu[[v]]\n  if (!is.null(user_df)) {\n    for (i in seq_len(nrow(user_df))) {\n      yr &lt;- user_df$YEAR[i]\n      if (yr %in% years) {\n        idx &lt;- which(df$YEAR == yr)\n        for (v in intersect(pred_cols, names(user_df))) {\n          val &lt;- user_df[[v]][i]\n          if (!is.na(val)) df[[v]][idx] &lt;- val\n        }\n      }\n    }\n  }\n  df\n}\nfuture_years &lt;- fc_start:2024\nscenario_future &lt;- build_future(future_years, mu, user_future)\n\n# 4.4 Прогноз и таблица ДИ\npred_future &lt;- predict_ensemble(scenario_future)\nforecast_tbl &lt;- tibble::tibble(\n  YEAR      = scenario_future$YEAR,\n  pred_mean = as.numeric(pred_future),\n  PI50_low  = pred_future + q250, PI50_high = pred_future + q750,\n  PI95_low  = pred_future + q025, PI95_high = pred_future + q975\n)\n\n#### Таблица прогноза 2022–2024\nprint(forecast_tbl)\n\n# A tibble: 3 x 6\n   YEAR pred_mean PI50_low PI50_high PI95_low PI95_high\n  &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1  2022   253815.   63865.   536150.  -46219.   668189.\n2  2023   253815.   63865.   536150.  -46219.   668189.\n3  2024   253815.   63865.   536150.  -46219.   668189.\n\n# По умолчанию мы используем средние значения предикторов для прогноза.\n# Однако вы можете определить собственный сценарий (user_future), указав конкретные значения\n# для каждого года и каждого предиктора. Это позволяет моделировать различные экологические сценарии. \n\n# 4.5 Непрерывный ряд 1990–2024 и график: ленты сплошные; линии медианы/ДИ — сплошные до 2021, пунктир с 2022\npred_df &lt;- bind_rows(\n  model_data %&gt;% select(YEAR, all_of(pred_cols)),\n  scenario_future\n) %&gt;% distinct(YEAR, .keep_all = TRUE) %&gt;% arrange(YEAR)\n\npred_df$Pred      &lt;- as.numeric(predict_ensemble(pred_df))\npred_df$PI50_low  &lt;- pred_df$Pred + q250\npred_df$PI50_high &lt;- pred_df$Pred + q750\npred_df$PI95_low  &lt;- pred_df$Pred + q025\npred_df$PI95_high &lt;- pred_df$Pred + q975\n\nhist_df &lt;- model_data %&gt;% select(YEAR, R3haddock)\n\nggplot() +\n  geom_ribbon(data = pred_df, aes(x = YEAR, ymin = PI95_low, ymax = PI95_high),\n              fill = \"grey80\", alpha = 0.25) +\n  geom_ribbon(data = pred_df, aes(x = YEAR, ymin = PI50_low, ymax = PI50_high),\n              fill = \"grey60\", alpha = 0.35) +\n  geom_line(data = subset(pred_df, YEAR &lt; fc_start), aes(x = YEAR, y = PI95_low),\n            color = \"grey45\", linewidth = 0.6) +\n  geom_line(data = subset(pred_df, YEAR &lt; fc_start), aes(x = YEAR, y = PI95_high),\n            color = \"grey45\", linewidth = 0.6) +\n  geom_line(data = subset(pred_df, YEAR &lt; fc_start), aes(x = YEAR, y = PI50_low),\n            color = \"grey35\", linewidth = 0.6) +\n  geom_line(data = subset(pred_df, YEAR &lt; fc_start), aes(x = YEAR, y = PI50_high),\n            color = \"grey35\", linewidth = 0.6) +\n  geom_line(data = subset(pred_df, YEAR &gt;= fc_start-1), aes(x = YEAR, y = PI95_low),\n            color = \"grey45\", linewidth = 0.6, linetype = \"dashed\") +\n  geom_line(data = subset(pred_df, YEAR &gt;= fc_start-1), aes(x = YEAR, y = PI95_high),\n            color = \"grey45\", linewidth = 0.6, linetype = \"dashed\") +\n  geom_line(data = subset(pred_df, YEAR &gt;= fc_start-1), aes(x = YEAR, y = PI50_low),\n            color = \"grey35\", linewidth = 0.6, linetype = \"dashed\") +\n  geom_line(data = subset(pred_df, YEAR &gt;= fc_start-1), aes(x = YEAR, y = PI50_high),\n            color = \"grey35\", linewidth = 0.6, linetype = \"dashed\") +\n  geom_line(data = subset(pred_df, YEAR &lt; fc_start), aes(x = YEAR, y = Pred),\n            color = \"steelblue4\", linewidth = 1) +\n  geom_line(data = subset(pred_df, YEAR &gt;= fc_start-1), aes(x = YEAR, y = Pred),\n            color = \"steelblue4\", linewidth = 1, linetype = \"dashed\") +\n  geom_point(data = hist_df, aes(x = YEAR, y = R3haddock),\n             color = \"black\", size = 2, alpha = 0.9) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0))) +\n  labs(\n    title = \"Пополнение R3haddock: факт (1990–2021) и прогноз (2022–2024)\\nАнсамбль CUBIST+LM; непрерывные ДИ, прогноз — пунктир\",\n    x = \"Год\", y = \"R3haddock\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n# На графике:\n#   - Черные точки: исторические данные (1990-2021)\n#   - Сплошная синяя линия: прогнозные значения (1990-2021)\n#   - Пунктирная синяя линия: прогноз на 2022-2024\n#   - Серые ленты: 50% и 95% доверительные интервалы\n# Такая визуализация позволяет легко интерпретировать как исторические данные, \n# так и будущие прогнозы с учетом неопределенности.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Прогноз пополнения: от факторов до ансамбля</span>"
    ]
  },
  {
    "objectID": "chapter 9.html",
    "href": "chapter 9.html",
    "title": "10  Стандартизация CPUE",
    "section": "",
    "text": "10.1 Введение\nВ рамках данного практического занятия рассматриваются методы стандартизации улова на усилие (CPUE) с использованием обобщенных линейных (GLM), обобщенных аддитивных (GAM) и обобщенных аддитивных смешанных моделей (GAMM). Стандартизированный индекс CPUE служит важным показателем состояния запаса, который часто используется в качестве входных данных в моделях “запас-промысел”. Исходные данные уловов на усилие обычно содержат неучтенную вариацию, вызванную влиянием различных факторов, таких как сезон, район промысла, глубина, тип грунта, орудия лова или особенности конкретного судна . Если эту вариацию не устранить, то сырой, нестандартизированный индекс CPUE может давать искаженную картину динамики запаса. Цель стандартизации заключается в том, чтобы отделить изменение численности запаса от влияния этих побочных факторов, получив таким образом более надежный и сопоставимый с истиной численностью популяции (части популяции) индекс.\nПолный скрипт можно скачать по ссылке.\nДля работы скрипта:",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE</span>"
    ]
  },
  {
    "objectID": "chapter 9.html#загрузка-данных-и-первичный-осмотр",
    "href": "chapter 9.html#загрузка-данных-и-первичный-осмотр",
    "title": "10  Модели пространственного распределения видов (SDM)",
    "section": "10.2 Загрузка данных и первичный осмотр",
    "text": "10.2 Загрузка данных и первичный осмотр\nТекст. Текст. Текст.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Модели пространственного распределения видов (SDM)</span>"
    ]
  },
  {
    "objectID": "chapter 9.html#описательная-статистика-и-визуализация",
    "href": "chapter 9.html#описательная-статистика-и-визуализация",
    "title": "10  Модели пространственного распределения видов (SDM)",
    "section": "10.3 Описательная статистика и визуализация",
    "text": "10.3 Описательная статистика и визуализация\nТекст. Текст. Текст. Текст.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Модели пространственного распределения видов (SDM)</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Введение",
    "section": "",
    "text": "Настоящий ресурс посвящен применению современных методов анализа данных для оценки водных биоресурсов при недостаточном (второй уровень) информационном обеспечении. Изначально эти материалы создавались для очного курса, который пока не состоялся и, в силу разных обстоятельств, возможно, не состоится в ближайшее время. В настоящее время практические занятия опубликованы для свободного использования заинтересованными специалистами (лекции, возможно, позже).\nВ эпоху больших языковых моделей (LLM), когда любая стандартная методика может быть доступно объяснена нейросетью, а обучающий скрипт — сгенерирован за секунду, особую ценность приобретают не шаблонные решения, а профессиональный опыт, уникальные идеи и глубокое понимание способов анализа. Молодые специалисты относительно легко приобретают навыки сбора материала «в поле», но ключевой вопрос заключается в том, что делать с этими данными дальше. Ограничиться стандартной картой и графиком с коэффициентом корреляции — уже не вариант. Современный мир анализа данных полон мощных и интересных инструментов, позволяющих извлечь из информации гораздо больше. Задача этого репозитория — не только показать эти методы, но и научить «заставлять данные рассказывать о себе» по-разному, точнее и осмысленнее, предлагая множество альтернативных путей для интерпретации.”How data treat you?” - мне однажды задал ёрнический вопрос Аристотель. Действительно Aristo или Aristoteles, молодой специалист из Венесуэлы во время научно-исследовательской съемки прибрежных вод Фолклендских островов. Его вопрос я только понял в последствии.\nПри этом сегодня от исследователя уже не требуется безупречного владения продвинутыми навыками программирования. LLM стали мощными ассистентами, способными помочь написать, исправить, прокомментировать или продолжить скрипт, что значительно снижает порог входа в работу с современными методами. Этот подход можно охарактеризовать как «vibe coding» — итеративный процесс творческого взаимодействия с кодом, где специалист формулирует задачи на естественном языке, прототипирует идеи с помощью ИИ и оценивает результат, фокусируясь на смысле и интерпретации, а не на синтаксисе. Данный практикум стремится культивировать именно такой стиль работы. Многие из занятий появились в диалогах и дисскусиях с Cursor, DeepSeek, Qwen и KIMI.\nПрактикум представляет собой комплексное руководство по применению современных методов анализа данных, ориентированное на начинающих специалистов. Материал структурирован по разделам, охватывающим ключевые этапы работы: от первичной загрузки и обработки данных до продвинутого моделирования и визуализации. Включает подробные примеры кода, пояснения к методам и интерпретацию результатов, что позволяет не только освоить технические навыки работы в R, но и понять биологическую и управленческую значимость получаемых выводов.\nОсобое внимание уделено работе с ограниченными и неполными данными — ситуации, типичной для многих гидробиологических и рыбохозяйственных исследований. Практикум содержит как классические статистические методы (линейные и логистические регрессии, кластеризация, сравнение групп), так и современные подходы, включая пространственно-временное моделирование (sdmTMB), нейронные сети и байесовские методы оценки запасов (SPiCT, JABBA). Отдельный раздел посвящен картографированию и визуализации пространственных данных, что особенно ценно для подготовки публикаций и отчетов.\nМатериалы постоянно пополняются и доступны в открытом доступе, что делает их, пожалуй, ценным ресурсом для обучения и практического применения в научной и прикладной работе. Приветствуются предложения по сотрудничеству и материалы от коллег для публикации с указанием авторства. Также принимаются вопросы и предложения по улучшению представленных материалов.\nКонтакты для связи: Сергей Баканёв mombus@gmail.com",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Введение</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Оценка водных биоресурсов при недостатке данных в среде R (для начинающих)",
    "section": "",
    "text": "Аннотация\nБаканев С. В. (2025) Оценка водных биоресурсов при недостатке данных в среде R (для начинающих). — Курс лекций и практических занятий, адрес доступа: https://mombus.github.io/cRab\nДанный ресурс представляет собой сборник практических решений по применению современных статистических методов в гидробиологии и рыбохозяйственных исследований при анализе “неполных” данных. Курс включает пошаговые алгоритмы реализации методов анализа и оценки водных биоресурсов в среде R и ориентирован как на начинающих, так и просто - интересующихся специалистов.\nПрактическая программа охватывает ключевые методы оценки водных биоресурсов, выстроенные в логической последовательности: от основ анализа данных улова и картографии до продвинутого пространственно-временного моделирования (sdmTMB) и методов машинного обучения.\nРесурс постоянно развивается и дополняется новыми практическими примерами.",
    "crumbs": [
      "Аннотация"
    ]
  },
  {
    "objectID": "chapter 9.html#введение",
    "href": "chapter 9.html#введение",
    "title": "10  Стандартизация CPUE",
    "section": "",
    "text": "Скачайте файл данных (KARTOGRAPHIC.xlsx)\nУстановите рабочую директорию в setwd()\nУстановите необходимые пакеты : install.packages(c(\"readxl\", \"tidyverse, \"mgcv\", \"gamm4\", \"DHARMa\" )) и др.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE</span>"
    ]
  },
  {
    "objectID": "chapter 9.html#пошаговое-описание-скрипта",
    "href": "chapter 9.html#пошаговое-описание-скрипта",
    "title": "10  Стандартизация CPUE",
    "section": "10.2 Пошаговое описание скрипта",
    "text": "10.2 Пошаговое описание скрипта\nСкрипт начинается с загрузки необходимых пакетов для обработки данных, построения моделей и визуализации результатов. Среда настраивается путем установки рабочей директории и фиксации случайного зерна для обеспечения воспроизводимости всех последующих вычислений.\nНа следующем этапе происходит загрузка исходных данных из файла Excel. Данные представляют собой промысловую статистику, содержащую информацию о году, месяце, судне, районе, величине улова на усилие (CPUE) и др. Выполняется их предварительная обработка: фильтрация по осенним месяцам, преобразование типов переменных в факторы и числовой формат, а также удаление пропущенных значений. Поскольку для моделирования с гамма-распределением требуются строго положительные значения, для нулевых и отрицательных величин CPUE рассчитывается и добавляется малая поправка. Для первичного ознакомления с данными строится диаграмма размаха, показывающая распределение CPUE по годам.\nДалее определяются вспомогательные функции. Одна функция предназначена для нормировки рассчитанных индексов либо на среднее значение, либо на значение первого года. Другая функция использует метод маргинальных средних для расчета стандартизированных индексов и их доверительных интервалов на основе подобранной модели. Третья функция реализует расчет индексов и оценку неопределенности через бутстреп для моделей со сложной структурой.\nОсновная часть скрипта посвящена построению и анализу трех типов моделей. Первой подбирается обобщенная линейная модель (GLM) с гамма-распределением ошибок и логарифмической связью. В качестве предикторов используются факторы: год, месяц, судно и район. Для визуальной и численной диагностики адекватности модели выводятся ее сводка, таблица коэффициентов, стандартные диагностические графики и графики остатков, проверенные с помощью пакета DHARMa.\nСледующей строится обобщенная аддитивная модель (GAM). На этом этапе используется та же формула и семейство распределений, что и в GLM, но метод подбора гиперпараметров отличается. Проводится аналогичная диагностика модели с помощью функций summary и gam.check.\nЗатем подбирается обобщенная аддитивная смешанная модель (GAMM), которая дополнительно включает случайный эффект от судна. Это позволяет учесть вариацию, вызванную индивидуальными особенностями каждого судна, которые не описываются другими факторами. Диагностика этой модели более сложна и включает анализ остатков, проверку случайных эффектов и тест на гетероскедастичность.\nПосле построения всех моделей для каждой из них рассчитываются стандартизированные индексы CPUE и их доверительные интервалы. Для GLM и GAM это делается с помощью функции, основанной на маргинальных средних, а для GAMM применяется метод бутстрепа.\nФинальный этап включает объединение результатов всех трех моделей в единую таблицу и их визуальное сравнение на графике. На этот же график добавляются фактические медианные значения CPUE по годам из исходных данных для сопоставления со стандартизированными кривыми. В заключение модели сравниваются по информационным критериям (AIC, BIC) и другим метрикам, чтобы дать рекомендации по выбору наиболее адекватной из них.\nНиже приводится скрипт, а ниже скрипта - описание результатов моделирования.\n\n# ========================================================================================================================\n# ПРАКТИЧЕСКОЕ ЗАНЯТИЕ: СТАНДАРТИЗАЦИЯ CPUE С ИСПОЛЬЗОВАНИЕМ GLM, GAM И GAMM\n# Курс: \"Оценка водных биоресурсов в среде R (для начинающих)\"\n# Автор: Баканев С.В. \n# Дата: 20.08.2025\n# \n# Структура:\n# 1) Загрузка пакетов и настройка среды\n# 2) Загрузка и предварительная обработка данных\n# 3) Вспомогательные функции для расчета индексов\n# 4) Моделирование GLM (Gamma с лог-ссылкой)\n# 5) Моделирование GAM (обобщенная аддитивная модель)\n# 6) Моделирование GAMM (смешанная модель со случайными эффектами)\n# 7) Сравнение моделей и финальная визуализация результатов\n# ========================================================================================================================\n\n\n# ==============================================================================\n# БЛОК 1: ЗАГРУЗКА ПАКЕТОВ И НАСТРОЙКА СРЕДЫ\n# ==============================================================================\n\n# Отключаем вспомогательные сообщения при загрузке пакетов\nsuppressPackageStartupMessages({\n  library(tidyverse)   # Основные пакеты для обработки данных и визуализации\n  library(readxl)      # Чтение данных из Excel-файлов\n  library(mgcv)        # Обобщенные аддитивные модели (GAM)\n  library(gamm4)       # GAM со смешанными эффектами\n  library(emmeans)     # Расчет маргинальных средних и контрастов\n  library(broom)       # Преобразование результатов моделей в таблицы\n  library(broom.mixed) # Поддержка смешанных моделей для broom\n  library(DHARMa)      # Диагностика остатков обобщенных моделей\n  library(knitr)       # Форматирование таблиц для отчетов\n})\n\n# Установка рабочей директории\nsetwd(\"C:/GLM/\")\n\n# Фиксируем случайное зерно для воспроизводимости результатов\nset.seed(42)\n\n# ==============================================================================\n# БЛОК 2: ЗАГРУЗКА И ПРЕДОБРАБОТКА ДАННЫХ\n# ==============================================================================\n\n# Определяем путь к файлу с данными\nDATA_PATH &lt;- \"C:/GLM/data/KARTOGRAPHIC.xlsx\"\n\n# Чтение данных из листа \"FISHERY\" и фильтрация осенних месяцев\nDATA &lt;- read_excel(DATA_PATH, sheet = \"FISHERY\") %&gt;%\n  as_tibble() %&gt;%  # Преобразуем в современный формат таблицы\n  filter(MONTH &gt; 8 & MONTH &lt; 12)  # Сентябрь-ноябрь (осенний сезон)\n\n# Преобразование типов переменных и обработка пропусков\nDATA &lt;- DATA %&gt;%\n  mutate(\n    YEAR = as.factor(YEAR),           # Год как категориальная переменная\n    MONTH = as.factor(MONTH),         # Месяц как фактор\n    CALL = as.factor(CALL),           # Идентификатор судна\n    REGION = as.factor(REGION),       # Рыбохозяйственный район\n    VESSELNUMBER = as.factor(VESSELNUMBER),  # Номер судна\n    CPUE = as.numeric(CPUE)           # Целевой показатель - улов на усилие\n  ) %&gt;%\n  filter(!is.na(CPUE))  # Удаление строк с пропусками в CPUE\n\n# Обработка нулевых значений CPUE для Gamma-моделей\nif (any(DATA$CPUE &lt;= 0, na.rm = TRUE)) {\n  min_pos &lt;- min(DATA$CPUE[DATA$CPUE &gt; 0], na.rm = TRUE)  # Минимальный положительный улов\n  offset &lt;- min_pos / 2  # Величина поправки\n  DATA &lt;- DATA %&gt;% \n    mutate(CPUE_POS = if_else(CPUE &lt;= 0, CPUE + offset, CPUE))  # Добавляем поправку\n} else {\n  DATA &lt;- DATA %&gt;% \n    mutate(CPUE_POS = CPUE)  # Исходные данные если нулей нет\n}\n\n# Рассчитываем медианные значения CPUE по годам из исходных данных\nactual_medians &lt;- DATA %&gt;%\n  group_by(YEAR) %&gt;%\n  summarise(median_cpue = median(CPUE, na.rm = TRUE))\n# Рассчитываем медианные значения CPUE по годам из исходных данных для последующих графиков\nactual_medians\n\n# A tibble: 6 x 2\n  YEAR  median_cpue\n  &lt;fct&gt;       &lt;dbl&gt;\n1 2019        200. \n2 2020        116. \n3 2021        132. \n4 2022         84  \n5 2023         79.4\n6 2024         58.3\n\n# Экспресс-визуализация распределения CPUE по годам\nDATA %&gt;%\n  ggplot(aes(x = YEAR, y = CPUE)) +\n  geom_boxplot(outlier.alpha = 0.2) +\n  labs(title = \"Распределение CPUE по годам\", \n       x = \"Год\", \n       y = \"CPUE (улов на усилие)\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 3: ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ ДЛЯ РАСЧЕТА ИНДЕКСОВ\n# ==============================================================================\n\n# Функция нормировки индексов\nscale_to_index &lt;- function(values, method = c(\"mean\", \"first\")) {\n  method &lt;- match.arg(method)\n  if (method == \"mean\") {\n    # Нормировка на среднее значение\n    return(as.numeric(values) / mean(as.numeric(values), na.rm = TRUE))\n  }\n  if (method == \"first\") {\n    # Нормировка на значение первого года\n    return(as.numeric(values) / as.numeric(values[1]))\n  }\n}\n\n# Функция расчета индексов для GLM/GAM через маргинальные средние\nemmeans_standardized_index &lt;- function(model, variable = \"YEAR\") {\n  out &lt;- suppressWarnings(\n    emmeans(model, \n            specs = as.formula(paste0(\"~ \", variable)), \n            type = \"response\")\n  )\n  df &lt;- as_tibble(out) %&gt;% \n    select(!!sym(variable), response = response, lower.CL, upper.CL)\n  colnames(df) &lt;- c(\"YEAR\", \"value\", \"lcl\", \"ucl\")\n  df\n}\n\n# Функция расчета индексов для GAMM через бутстреп\ncompute_standardized_index &lt;- function(model, base_data, year_levels, predict_fun,\n                                      response_transform = identity, \n                                      n_boot = 200L, \n                                      seed = 7L) {\n  set.seed(seed)\n  acc &lt;- vector(\"list\", length(year_levels))\n  for (i in seq_along(year_levels)) {\n    newdata &lt;- base_data\n    newdata$YEAR &lt;- factor(year_levels[i], levels = levels(base_data$YEAR))\n    preds &lt;- suppressWarnings(predict_fun(model, newdata))\n    mu &lt;- mean(response_transform(preds), na.rm = TRUE)\n    # Бутстреп для оценки неопределенности\n    boot_vals &lt;- replicate(n_boot, {\n      idx &lt;- sample.int(nrow(base_data), nrow(base_data), replace = TRUE)\n      bd &lt;- newdata[idx, , drop = FALSE]\n      p &lt;- suppressWarnings(predict_fun(model, bd))\n      mean(response_transform(p), na.rm = TRUE)\n    })\n    ci &lt;- quantile(boot_vals, c(0.025, 0.975), na.rm = TRUE)\n    acc[[i]] &lt;- tibble(YEAR = year_levels[i], value = mu, lcl = ci[[1]], ucl = ci[[2]])\n  }\n  bind_rows(acc)\n}\n\n# ==============================================================================\n# БЛОК 4: МОДЕЛИРОВАНИЕ GLM (GAMMA С ЛОГ-ССЫЛКОЙ)\n# ==============================================================================\n\n# Подбор модели с фиксированными эффектами\nglm_gamma_fit &lt;- glm(\n  CPUE_POS ~ YEAR + MONTH + CALL + REGION,  # Формула с факторными предикторами\n  family = Gamma(link = \"log\"),            # Гамма-распределение с логарифмической связью\n  data = DATA\n)\n\n# Диагностика модели\nsummary(glm_gamma_fit)  # Стандартная сводка модели\n\n\nCall:\nglm(formula = CPUE_POS ~ YEAR + MONTH + CALL + REGION, family = Gamma(link = \"log\"), \n    data = DATA)\n\nCoefficients:\n                                                  Estimate Std. Error t value\n(Intercept)                                        5.57642    0.07942  70.216\nYEAR2020                                          -0.22713    0.04586  -4.953\nYEAR2021                                          -0.22438    0.04557  -4.924\nYEAR2022                                          -0.64329    0.04345 -14.806\nYEAR2023                                          -0.77311    0.04647 -16.637\nYEAR2024                                          -1.12817    0.05157 -21.879\nMONTH10                                           -0.13725    0.02443  -5.617\nMONTH11                                           -0.13714    0.03540  -3.874\nCALLUAAK                                          -0.29534    0.06092  -4.848\nCALLUAKC                                          -0.53490    0.06381  -8.382\nCALLUBEV                                          -3.67233    0.12187 -30.133\nCALLUBQQ                                          -0.35433    0.07057  -5.021\nCALLUBSR                                          -0.33516    0.06266  -5.349\nCALLUBUR                                          -0.58246    0.06175  -9.433\nCALLUBYT                                          -0.21520    0.06088  -3.535\nCALLUCFF                                          -0.06756    0.09825  -0.688\nCALLUCXF                                          -2.34302    0.10638 -22.025\nCALLUDII                                          -0.46287    0.05710  -8.107\nCALLUDUT                                          -1.02162    0.07550 -13.532\nCALLUDWM                                          -2.42502    0.09480 -25.582\nCALLUEBK                                           0.25852    0.13371   1.934\nCALLUEMO                                          -0.17024    0.08103  -2.101\nCALLUENZ                                           0.04928    0.06442   0.765\nCALLUFIK                                           0.29700    0.13043   2.277\nCALLUGXE                                          -0.56384    0.06265  -9.000\nCALLUIVO                                          -0.21572    0.06500  -3.319\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.16521    0.46672   0.354\nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            -0.07615    0.15513  -0.491\nREGIONCEBEPO-KAHИHCKAЯ БAHKA                       0.16332    0.08236   1.983\nREGIONKAHИHCKAЯ БAHKA                              0.06291    0.07875   0.799\nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)  0.21310    0.08519   2.501\nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE              0.18223    0.07757   2.349\nREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.07737    0.07753   0.998\nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.72882    0.46327   1.573\nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                         0.13328    0.08416   1.584\nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      0.64238    0.11646   5.516\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       0.69320    0.13068   5.305\n                                                  Pr(&gt;|t|)    \n(Intercept)                                        &lt; 2e-16 ***\nYEAR2020                                          7.62e-07 ***\nYEAR2021                                          8.85e-07 ***\nYEAR2022                                           &lt; 2e-16 ***\nYEAR2023                                           &lt; 2e-16 ***\nYEAR2024                                           &lt; 2e-16 ***\nMONTH10                                           2.08e-08 ***\nMONTH11                                           0.000109 ***\nCALLUAAK                                          1.30e-06 ***\nCALLUAKC                                           &lt; 2e-16 ***\nCALLUBEV                                           &lt; 2e-16 ***\nCALLUBQQ                                          5.36e-07 ***\nCALLUBSR                                          9.37e-08 ***\nCALLUBUR                                           &lt; 2e-16 ***\nCALLUBYT                                          0.000413 ***\nCALLUCFF                                          0.491691    \nCALLUCXF                                           &lt; 2e-16 ***\nCALLUDII                                          6.93e-16 ***\nCALLUDUT                                           &lt; 2e-16 ***\nCALLUDWM                                           &lt; 2e-16 ***\nCALLUEBK                                          0.053247 .  \nCALLUEMO                                          0.035718 *  \nCALLUENZ                                          0.444299    \nCALLUFIK                                          0.022839 *  \nCALLUGXE                                           &lt; 2e-16 ***\nCALLUIVO                                          0.000913 ***\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                        0.723377    \nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            0.623533    \nREGIONCEBEPO-KAHИHCKAЯ БAHKA                      0.047425 *  \nREGIONKAHИHCKAЯ БAHKA                             0.424416    \nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH) 0.012413 *  \nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE             0.018863 *  \nREGIONMУPMAHCKOE MEЛKOBOДЬE                       0.318379    \nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                         0.115753    \nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                        0.113361    \nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                     3.69e-08 ***\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                      1.19e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.4172272)\n\n    Null deviance: 2980.2  on 3890  degrees of freedom\nResidual deviance: 1785.6  on 3854  degrees of freedom\nAIC: 42851\n\nNumber of Fisher Scoring iterations: 11\n\n# Таблица коэффициентов в форматированном виде\nbroom::tidy(glm_gamma_fit) %&gt;%\n  mutate(across(estimate:statistic, ~round(.x, 4))) %&gt;%\n  kable(caption = \"Коэффициенты GLM модели\", align = \"lrrrr\")\n\n\nКоэффициенты GLM модели\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n5.5764\n0.0794\n70.2164\n0.0000000\n\n\nYEAR2020\n-0.2271\n0.0459\n-4.9530\n0.0000008\n\n\nYEAR2021\n-0.2244\n0.0456\n-4.9236\n0.0000009\n\n\nYEAR2022\n-0.6433\n0.0434\n-14.8059\n0.0000000\n\n\nYEAR2023\n-0.7731\n0.0465\n-16.6372\n0.0000000\n\n\nYEAR2024\n-1.1282\n0.0516\n-21.8785\n0.0000000\n\n\nMONTH10\n-0.1372\n0.0244\n-5.6170\n0.0000000\n\n\nMONTH11\n-0.1371\n0.0354\n-3.8736\n0.0001090\n\n\nCALLUAAK\n-0.2953\n0.0609\n-4.8479\n0.0000013\n\n\nCALLUAKC\n-0.5349\n0.0638\n-8.3823\n0.0000000\n\n\nCALLUBEV\n-3.6723\n0.1219\n-30.1334\n0.0000000\n\n\nCALLUBQQ\n-0.3543\n0.0706\n-5.0213\n0.0000005\n\n\nCALLUBSR\n-0.3352\n0.0627\n-5.3488\n0.0000001\n\n\nCALLUBUR\n-0.5825\n0.0618\n-9.4326\n0.0000000\n\n\nCALLUBYT\n-0.2152\n0.0609\n-3.5347\n0.0004130\n\n\nCALLUCFF\n-0.0676\n0.0982\n-0.6877\n0.4916914\n\n\nCALLUCXF\n-2.3430\n0.1064\n-22.0254\n0.0000000\n\n\nCALLUDII\n-0.4629\n0.0571\n-8.1065\n0.0000000\n\n\nCALLUDUT\n-1.0216\n0.0755\n-13.5319\n0.0000000\n\n\nCALLUDWM\n-2.4250\n0.0948\n-25.5817\n0.0000000\n\n\nCALLUEBK\n0.2585\n0.1337\n1.9335\n0.0532474\n\n\nCALLUEMO\n-0.1702\n0.0810\n-2.1009\n0.0357185\n\n\nCALLUENZ\n0.0493\n0.0644\n0.7650\n0.4442989\n\n\nCALLUFIK\n0.2970\n0.1304\n2.2770\n0.0228387\n\n\nCALLUGXE\n-0.5638\n0.0627\n-8.9996\n0.0000000\n\n\nCALLUIVO\n-0.2157\n0.0650\n-3.3187\n0.0009126\n\n\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H\n0.1652\n0.4667\n0.3540\n0.7233768\n\n\nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ\n-0.0762\n0.1551\n-0.4909\n0.6235329\n\n\nREGIONCEBEPO-KAHИHCKAЯ БAHKA\n0.1633\n0.0824\n1.9831\n0.0474248\n\n\nREGIONKAHИHCKAЯ БAHKA\n0.0629\n0.0788\n0.7989\n0.4244161\n\n\nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)\n0.2131\n0.0852\n2.5013\n0.0124133\n\n\nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE\n0.1822\n0.0776\n2.3492\n0.0188631\n\n\nREGIONMУPMAHCKOE MEЛKOBOДЬE\n0.0774\n0.0775\n0.9979\n0.3183790\n\n\nREGIONЗAП.-ПPИБPEЖHЫЙ P-H\n0.7288\n0.4633\n1.5732\n0.1157534\n\n\nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H\n0.1333\n0.0842\n1.5836\n0.1133609\n\n\nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ\n0.6424\n0.1165\n5.5160\n0.0000000\n\n\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ\n0.6932\n0.1307\n5.3046\n0.0000001\n\n\n\n\n# Графики диагностики остатков\npar(mfrow = c(2, 2))\nplot(glm_gamma_fit)  # Стандартные диагностические графики GLM\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n# Диагностика остатков GLM с использованием DHARMa\nsim_glm &lt;- simulateResiduals(glm_gamma_fit, n = 1000, refit = FALSE)\nplot(sim_glm, main = \"GLM\")\n\n\n\n\n\n\n\n# Расчет и визуализация индексов\nidx_glm &lt;- emmeans_standardized_index(glm_gamma_fit) %&gt;%\n  mutate(model = \"GLM_Gamma\",\n         index_mean = scale_to_index(value, \"mean\"),\n         index_first = scale_to_index(value, \"first\"))\n\n# Добавление доверительных интервалов\nidx_glm &lt;- idx_glm %&gt;%\n  mutate(\n    lcl_index_mean = scale_to_index(lcl, \"mean\"),\n    ucl_index_mean = scale_to_index(ucl, \"mean\")\n  )\n\n# Визуализация индексов GLM\n\nidx_glm %&gt;%\n  ggplot(aes(x = YEAR, y = value, group = 1)) +\n  geom_line() +\n  geom_point() +\n  geom_ribbon(aes(ymin = lcl, ymax = ucl), alpha = 0.3) +\n  geom_point(data = actual_medians, \n           aes(x = YEAR, y = median_cpue), \n           shape = 4,  # 4 соответствует крестику (x)\n           size = 3, \n           color = \"black\", \n           inherit.aes = FALSE)+\nlabs(title = \"Индексы CPUE по GLM модели (крестики - факт)\", \n       x = \"Год\", \n       y = \"Стандартизированный индекс\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 5: МОДЕЛИРОВАНИЕ GAM\n# ==============================================================================\n\n# Подбор обобщенной аддитивной модели\ngam_fit &lt;- gam(\n  CPUE_POS ~ YEAR + MONTH + CALL + REGION,  # Линейная формула без сглаживания\n  family = Gamma(link = \"log\"),            # Аналогичное GLM распределение\n  method = \"REML\",                         # Метод оптимизации гиперпараметров\n  data = DATA\n)\n\nsummary(gam_fit)  # Сводка модели\n\n\nFamily: Gamma \nLink function: log \n\nFormula:\nCPUE_POS ~ YEAR + MONTH + CALL + REGION\n\nParametric coefficients:\n                                                  Estimate Std. Error t value\n(Intercept)                                        5.57646    0.07942  70.217\nYEAR2020                                          -0.22712    0.04586  -4.953\nYEAR2021                                          -0.22438    0.04557  -4.924\nYEAR2022                                          -0.64329    0.04345 -14.806\nYEAR2023                                          -0.77309    0.04647 -16.637\nYEAR2024                                          -1.12812    0.05156 -21.878\nMONTH10                                           -0.13725    0.02443  -5.617\nMONTH11                                           -0.13714    0.03540  -3.874\nCALLUAAK                                          -0.29528    0.06092  -4.847\nCALLUAKC                                          -0.53484    0.06381  -8.381\nCALLUBEV                                          -3.67226    0.12187 -30.133\nCALLUBQQ                                          -0.35427    0.07057  -5.020\nCALLUBSR                                          -0.33512    0.06266  -5.348\nCALLUBUR                                          -0.58242    0.06175  -9.432\nCALLUBYT                                          -0.21516    0.06088  -3.534\nCALLUCFF                                          -0.06750    0.09825  -0.687\nCALLUCXF                                          -2.34296    0.10638 -22.025\nCALLUDII                                          -0.46282    0.05710  -8.106\nCALLUDUT                                          -1.02155    0.07550 -13.531\nCALLUDWM                                          -2.42497    0.09479 -25.581\nCALLUEBK                                           0.25858    0.13371   1.934\nCALLUEMO                                          -0.17018    0.08103  -2.100\nCALLUENZ                                           0.04934    0.06442   0.766\nCALLUFIK                                           0.29706    0.13043   2.278\nCALLUGXE                                          -0.56375    0.06265  -8.998\nCALLUIVO                                          -0.21565    0.06500  -3.318\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.16508    0.46672   0.354\nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            -0.07627    0.15513  -0.492\nREGIONCEBEPO-KAHИHCKAЯ БAHKA                       0.16322    0.08236   1.982\nREGIONKAHИHCKAЯ БAHKA                              0.06281    0.07875   0.798\nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)  0.21299    0.08519   2.500\nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE              0.18213    0.07757   2.348\nREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.07728    0.07753   0.997\nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.72877    0.46327   1.573\nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                         0.13318    0.08416   1.583\nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      0.64226    0.11646   5.515\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       0.69310    0.13068   5.304\n                                                  Pr(&gt;|t|)    \n(Intercept)                                        &lt; 2e-16 ***\nYEAR2020                                          7.62e-07 ***\nYEAR2021                                          8.85e-07 ***\nYEAR2022                                           &lt; 2e-16 ***\nYEAR2023                                           &lt; 2e-16 ***\nYEAR2024                                           &lt; 2e-16 ***\nMONTH10                                           2.08e-08 ***\nMONTH11                                           0.000109 ***\nCALLUAAK                                          1.30e-06 ***\nCALLUAKC                                           &lt; 2e-16 ***\nCALLUBEV                                           &lt; 2e-16 ***\nCALLUBQQ                                          5.39e-07 ***\nCALLUBSR                                          9.39e-08 ***\nCALLUBUR                                           &lt; 2e-16 ***\nCALLUBYT                                          0.000414 ***\nCALLUCFF                                          0.492100    \nCALLUCXF                                           &lt; 2e-16 ***\nCALLUDII                                          6.98e-16 ***\nCALLUDUT                                           &lt; 2e-16 ***\nCALLUDWM                                           &lt; 2e-16 ***\nCALLUEBK                                          0.053187 .  \nCALLUEMO                                          0.035785 *  \nCALLUENZ                                          0.443735    \nCALLUFIK                                          0.022810 *  \nCALLUGXE                                           &lt; 2e-16 ***\nCALLUIVO                                          0.000916 ***\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                        0.723578    \nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            0.623006    \nREGIONCEBEPO-KAHИHCKAЯ БAHKA                      0.047563 *  \nREGIONKAHИHCKAЯ БAHKA                             0.425185    \nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH) 0.012456 *  \nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE             0.018931 *  \nREGIONMУPMAHCKOE MEЛKOBOДЬE                       0.318981    \nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                         0.115776    \nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                        0.113615    \nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                     3.72e-08 ***\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                      1.20e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nR-sq.(adj) =  0.397   Deviance explained = 40.1%\n-REML =  21455  Scale est. = 0.41722   n = 3891\n\n# Проверка адекватности модели (графики остатков)\nmgcv::gam.check(gam_fit)\n\n\n\n\n\n\n\n\n\nMethod: REML   Optimizer: outer newton\nfull convergence after 5 iterations.\nGradient range [-0.0003574844,-0.0003574844]\n(score 21454.84 & scale 0.4172217).\nHessian positive definite, eigenvalue range [2198.061,2198.061].\nModel rank =  37 / 37 \n\n# Диагностика остатков GAM с использованием DHARMa\nsim_gam &lt;- simulateResiduals(gam_fit, n = 1000, refit = FALSE)\n\nRegistered S3 method overwritten by 'mgcViz':\n  method from   \n  +.gg   ggplot2\n\nplot(sim_gam, main = \"GAM\")\n\n\n\n\n\n\n\n# Расчет индексов\nidx_gam &lt;- emmeans_standardized_index(gam_fit) %&gt;%\n  mutate(model = \"GAM\",\n         index_mean = scale_to_index(value, \"mean\"),\n         index_first = scale_to_index(value, \"first\"))\n\n# Доверительные интервалы\nidx_gam &lt;- idx_gam %&gt;%\n  mutate(\n    lcl_index_mean = scale_to_index(lcl, \"mean\"),\n    ucl_index_mean = scale_to_index(ucl, \"mean\")\n  )\n\n\n# Визуализация\nidx_gam %&gt;%\n  ggplot(aes(x = YEAR, y = value, group = 1)) +\n  geom_line() +\n  geom_point() +\n  geom_ribbon(aes(ymin = lcl, ymax = ucl), alpha = 0.3) +\n  geom_point(data = actual_medians, \n           aes(x = YEAR, y = median_cpue), \n           shape = 4,  # 4 соответствует крестику (x)\n           size = 3, \n           color = \"black\", \n           inherit.aes = FALSE)+\n  labs(title = \"Индексы CPUE по GAM модели (крестики - факт\", \n       x = \"Год\", \n       y = \"Стандартизированный индекс\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 6: МОДЕЛИРОВАНИЕ GAMM (СМЕШАННАЯ МОДЕЛЬ)\n# ==============================================================================\n\n# Подбор модели со смешанными эффектами\ngamm_fit &lt;- gamm4::gamm4(\n  formula = CPUE_POS ~ YEAR + MONTH + REGION,  # Фиксированные эффекты\n  random = ~ (1 | CALL),                       # Случайный эффект для судна\n  family = Gamma(link = \"log\"),               # Распределение\n  data = DATA\n)\n\n# 1. График остатков от предсказанных значений\nplot(fitted(gamm_fit$gam), residuals(gamm_fit$gam, type = \"deviance\"),\n     xlab = \"Предсказанные значения\", ylab = \"Девиансные остатки\",\n     main = \"Остатки GAMM vs. Предсказания\")\nabline(h = 0, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n# 2. QQ-plot для остатков\nqqnorm(residuals(gamm_fit$gam, type = \"deviance\"),\n       main = \"QQ-plot для остатков GAMM\")\nqqline(residuals(gamm_fit$gam, type = \"deviance\"), col = \"red\")\n\n\n\n\n\n\n\n# 3. Диагностика случайных эффектов\ncat(\"\\nСлучайные эффекты (CALL):\\n\")\n\n\nСлучайные эффекты (CALL):\n\nprint(summary(ranef(gamm_fit$mer)$CALL))\n\n  (Intercept)      \n Min.   :-2.92229  \n 1st Qu.: 0.09295  \n Median : 0.32996  \n Mean   : 0.00306  \n 3rd Qu.: 0.54065  \n Max.   : 0.93271  \n\n# График случайных эффектов\nrandom_effects &lt;- ranef(gamm_fit$mer)$CALL\nplot(density(random_effects[,1]), main = \"Распределение случайных эффектов\",\n     xlab = \"Случайный эффект\", ylab = \"Плотность\")\n\n\n\n\n\n\n\n# 5. Проверка гетероскедастичности\nlibrary(lmtest)\n\nЗагрузка требуемого пакета: zoo\n\n\n\nПрисоединяю пакет: 'zoo'\n\n\nСледующие объекты скрыты от 'package:base':\n\n    as.Date, as.Date.numeric\n\nbptest(gamm_fit$gam$y ~ fitted(gamm_fit$gam)) %&gt;% \n  print()\n\n\n    studentized Breusch-Pagan test\n\ndata:  gamm_fit$gam$y ~ fitted(gamm_fit$gam)\nBP = 222.14, df = 1, p-value &lt; 2.2e-16\n\n# 6. Сводка по модели\ncat(\"\\nСводка GAMM модели:\\n\")\n\n\nСводка GAMM модели:\n\nprint(summary(gamm_fit$gam))\n\n\nFamily: Gamma \nLink function: log \n\nFormula:\nCPUE_POS ~ YEAR + MONTH + REGION\n\nParametric coefficients:\n                                                  Estimate Std. Error t value\n(Intercept)                                        4.91649    0.17171  28.632\nYEAR2020                                          -0.23162    0.04580  -5.058\nYEAR2021                                          -0.22798    0.04552  -5.008\nYEAR2022                                          -0.64763    0.04338 -14.928\nYEAR2023                                          -0.77570    0.04641 -16.716\nYEAR2024                                          -1.13070    0.05152 -21.947\nMONTH10                                           -0.13620    0.02445  -5.571\nMONTH11                                           -0.13630    0.03542  -3.848\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.16149    0.46710   0.346\nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            -0.08013    0.15524  -0.516\nREGIONCEBEPO-KAHИHCKAЯ БAHKA                       0.15971    0.08238   1.939\nREGIONKAHИHCKAЯ БAHKA                              0.05886    0.07877   0.747\nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)  0.20859    0.08522   2.448\nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE              0.17834    0.07759   2.299\nREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.07353    0.07755   0.948\nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.72926    0.46366   1.573\nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                         0.12967    0.08419   1.540\nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      0.63836    0.11653   5.478\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       0.68988    0.13078   5.275\n                                                  Pr(&gt;|t|)    \n(Intercept)                                        &lt; 2e-16 ***\nYEAR2020                                          4.44e-07 ***\nYEAR2021                                          5.74e-07 ***\nYEAR2022                                           &lt; 2e-16 ***\nYEAR2023                                           &lt; 2e-16 ***\nYEAR2024                                           &lt; 2e-16 ***\nMONTH10                                           2.70e-08 ***\nMONTH11                                           0.000121 ***\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                        0.729566    \nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            0.605763    \nREGIONCEBEPO-KAHИHCKAЯ БAHKA                      0.052628 .  \nREGIONKAHИHCKAЯ БAHKA                             0.455013    \nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH) 0.014424 *  \nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE             0.021580 *  \nREGIONMУPMAHCKOE MEЛKOBOДЬE                       0.343099    \nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                         0.115842    \nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                        0.123604    \nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                     4.57e-08 ***\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                      1.40e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nR-sq.(adj) =  0.172   \nglmer.ML =   1786  Scale est. = 0.41793   n = 3891\n\nprint(summary(gamm_fit$mer))\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: Gamma  ( log )\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n  42933.5   43065.1  -21445.7   42891.5      3870 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.5364 -0.6769 -0.1721  0.4716 11.0577 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n CALL     (Intercept) 0.4320   0.6573  \n Residual             0.4179   0.6465  \nNumber of obs: 3891, groups:  CALL, 19\n\nFixed effects:\n                                                   Estimate Std. Error t value\nX(Intercept)                                        4.91649    0.23488  20.932\nXYEAR2020                                          -0.23162    0.02474  -9.363\nXYEAR2021                                          -0.22798    0.02513  -9.073\nXYEAR2022                                          -0.64763    0.02299 -28.167\nXYEAR2023                                          -0.77570    0.02376 -32.652\nXYEAR2024                                          -1.13070    0.02603 -43.443\nXMONTH10                                           -0.13620    0.01914  -7.116\nXMONTH11                                           -0.13630    0.02359  -5.777\nXREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.16149    0.46456   0.348\nXREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            -0.08013    0.03506  -2.285\nXREGIONCEBEPO-KAHИHCKAЯ БAHKA                       0.15971    0.02670   5.982\nXREGIONKAHИHCKAЯ БAHKA                              0.05886    0.02653   2.218\nXREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)  0.20859    0.02808   7.428\nXREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE              0.17834    0.02200   8.108\nXREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.07353    0.02318   3.172\nXREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.72926    0.46533   1.567\nXREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                         0.12967    0.02736   4.739\nXREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      0.63836    0.03291  19.400\nXREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       0.68988    0.03447  20.015\n                                                   Pr(&gt;|z|)    \nX(Intercept)                                        &lt; 2e-16 ***\nXYEAR2020                                           &lt; 2e-16 ***\nXYEAR2021                                           &lt; 2e-16 ***\nXYEAR2022                                           &lt; 2e-16 ***\nXYEAR2023                                           &lt; 2e-16 ***\nXYEAR2024                                           &lt; 2e-16 ***\nXMONTH10                                           1.11e-12 ***\nXMONTH11                                           7.60e-09 ***\nXREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.72813    \nXREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ             0.02229 *  \nXREGIONCEBEPO-KAHИHCKAЯ БAHKA                      2.20e-09 ***\nXREGIONKAHИHCKAЯ БAHKA                              0.02654 *  \nXREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH) 1.10e-13 ***\nXREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE             5.16e-16 ***\nXREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.00151 ** \nXREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.11707    \nXREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                        2.15e-06 ***\nXREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      &lt; 2e-16 ***\nXREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCorrelation matrix not shown by default, as p = 19 &gt; 12.\nUse print(summary(gamm_fit$mer), correlation=TRUE)  or\n    vcov(summary(gamm_fit$mer))        if you need it\n\n# Создание сетки для предсказания\nnewdata_grid &lt;- expand.grid(\n  YEAR = levels(DATA$YEAR),\n  MONTH = levels(DATA$MONTH),\n  REGION = levels(DATA$REGION),\n  CALL = levels(DATA$CALL)[1]  # Фиксированное значение для случайного эффекта\n)\n\n# Предсказание на сетке\nnewdata_grid$pred &lt;- predict(gamm_fit$gam, \n                            newdata = newdata_grid, \n                            type = \"response\")\n\n# Усреднение предсказаний по годам\nidx_gamm &lt;- newdata_grid %&gt;%\n  group_by(YEAR) %&gt;%\n  summarise(value = mean(pred, na.rm = TRUE)) %&gt;%\n  mutate(\n    model = \"GAMM (mgcv)\",\n    index_mean = scale_to_index(value, \"mean\"),\n    index_first = scale_to_index(value, \"first\")\n  )\n\n# Функция расчета доверительных интервалов через бутстреп\ncompute_gamm_ci &lt;- function(model, newdata, n_boot = 100) {\n  boot_means &lt;- replicate(n_boot, {\n    boot_data &lt;- newdata[sample(nrow(newdata), replace = TRUE), ]\n    preds &lt;- predict(model, newdata = boot_data, type = \"response\")\n    boot_data %&gt;%\n      mutate(pred = preds) %&gt;%\n      group_by(YEAR) %&gt;%\n      summarise(mean_pred = mean(pred, na.rm = TRUE)) %&gt;%\n      pull(mean_pred)\n  })\n  \n  ci &lt;- apply(boot_means, 1, function(x) quantile(x, c(0.025, 0.975), na.rm = TRUE))\n  return(list(mean = rowMeans(boot_means), lcl = ci[1, ], ucl = ci[2, ]))\n}\n\n# Расчет интервалов\ngamm_ci &lt;- compute_gamm_ci(gamm_fit$gam, newdata_grid)\n\n# Добавление интервалов к индексам\nidx_gamm &lt;- idx_gamm %&gt;%\n  mutate(\n    lcl = gamm_ci$lcl,\n    ucl = gamm_ci$ucl,\n    lcl_index_mean = scale_to_index(lcl, \"mean\"),\n    ucl_index_mean = scale_to_index(ucl, \"mean\")\n  )\n\n# Визуализация\nidx_gamm %&gt;%\n  ggplot(aes(x = YEAR, y = value, group = 1)) +\n  geom_line() +\n  geom_point() +\n  geom_ribbon(aes(ymin = lcl, ymax = ucl), alpha = 0.3) +\n  geom_point(data = actual_medians, \n           aes(x = YEAR, y = median_cpue), \n           shape = 4,  # 4 соответствует крестику (x)\n           size = 3, \n           color = \"black\", \n           inherit.aes = FALSE)+\nlabs(title = \"Индексы CPUE по GAMM модели (крестики - факт)\", \n       x = \"Год\", \n       y = \"Стандартизированный индекс\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 7: СРАВНЕНИЕ МОДЕЛЕЙ И ФИНАЛЬНАЯ ВИЗУАЛИЗАЦИЯ\n# ==============================================================================\n\n# Объединение результатов всех моделей\nindices_all &lt;- bind_rows(\n  idx_glm %&gt;% select(YEAR, value, lcl, ucl, model, index_mean, lcl_index_mean, ucl_index_mean),\n  idx_gam %&gt;% select(YEAR, value, lcl, ucl, model, index_mean, lcl_index_mean, ucl_index_mean),\n  idx_gamm %&gt;% select(YEAR, value, lcl, ucl, model, index_mean, lcl_index_mean, ucl_index_mean)\n) %&gt;% mutate(YEAR = factor(YEAR, levels = levels(DATA$YEAR)))\n\n# Сводная таблица результатов\nindices_all %&gt;% \n  kable(caption = \"Сравнение индексов CPUE по разным моделям\")\n\n\nСравнение индексов CPUE по разным моделям\n\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nvalue\nlcl\nucl\nmodel\nindex_mean\nlcl_index_mean\nucl_index_mean\n\n\n\n\n2019\n158.81216\n138.93290\n181.53585\nGLM_Gamma\n1.5358638\n1.5299542\n1.5417869\n\n\n2020\n126.54457\n111.15088\n144.07018\nGLM_Gamma\n1.2238057\n1.2240136\n1.2235904\n\n\n2021\n126.89292\n111.57409\n144.31498\nGLM_Gamma\n1.2271746\n1.2286741\n1.2256695\n\n\n2022\n83.46580\n73.52525\n94.75032\nGLM_Gamma\n0.8071933\n0.8096733\n0.8047160\n\n\n2023\n73.30390\n64.40714\n83.42960\nGLM_Gamma\n0.7089181\n0.7092631\n0.7085690\n\n\n2024\n51.39565\n45.26094\n58.36186\nGLM_Gamma\n0.4970445\n0.4984216\n0.4956683\n\n\n2019\n158.81218\n138.93304\n181.53572\nGAM\n1.5358554\n1.5299458\n1.5417784\n\n\n2020\n126.54503\n111.15138\n144.07058\nGAM\n1.2238033\n1.2240112\n1.2235880\n\n\n2021\n126.89280\n111.57408\n144.31473\nGAM\n1.2271665\n1.2286660\n1.2256615\n\n\n2022\n83.46561\n73.52514\n94.75002\nGAM\n0.8071869\n0.8096669\n0.8047096\n\n\n2023\n73.30495\n64.40811\n83.43072\nGAM\n0.7089242\n0.7092692\n0.7085751\n\n\n2024\n51.39792\n45.26297\n58.36439\nGAM\n0.4970637\n0.4984408\n0.4956874\n\n\n2019\n165.88930\n153.27889\n186.43794\nGAMM (mgcv)\n1.5400976\n1.5751123\n1.5695052\n\n\n2020\n131.59142\n116.54705\n144.02703\nGAMM (mgcv)\n1.2216800\n1.1976514\n1.2124741\n\n\n2021\n132.07110\n118.64017\n145.21926\nGAMM (mgcv)\n1.2261333\n1.2191606\n1.2225107\n\n\n2022\n86.80692\n79.26688\n96.71028\nGAMM (mgcv)\n0.8059057\n0.8145559\n0.8141438\n\n\n2023\n76.37202\n67.94329\n82.24327\nGAMM (mgcv)\n0.7090292\n0.6981933\n0.6923550\n\n\n2024\n53.55022\n48.20170\n58.08852\nGAMM (mgcv)\n0.4971542\n0.4953264\n0.4890111\n\n\n\n\nindices_all %&gt;%\n  ggplot(aes(x = YEAR, y = value, color = model, group = model, fill = model)) +\n  geom_line() +\n  geom_point() +\n  geom_ribbon(aes(ymin = lcl, ymax = ucl), alpha = 0.1, linetype = \"dashed\") +\ngeom_point(data = actual_medians, \n           aes(x = YEAR, y = median_cpue), \n           shape = 4,  # 4 соответствует крестику (x)\n           size = 3, \n           color = \"black\", \n           inherit.aes = FALSE)+\n  labs(title = \"Сравнение стандартизированных индексов CPUE (крестики - факт)\", \n       x = \"Год\", \n       y = \"Индекс CPUE (кг/ловушку)\", \n       color = \"Модель\", \n       fill = \"Модель\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 9: СРАВНЕНИЕ МОДЕЛЕЙ ПО ИНФОРМАЦИОННЫМ КРИТЕРИЯМ\n# ==============================================================================\n\ncat(\"\\n=== СРАВНИТЕЛЬНЫЙ АНАЛИЗ МОДЕЛЕЙ ПО ИНФОРМАЦИОННЫМ КРИТЕРИЯМ ===\\n\")\n\n\n=== СРАВНИТЕЛЬНЫЙ АНАЛИЗ МОДЕЛЕЙ ПО ИНФОРМАЦИОННЫМ КРИТЕРИЯМ ===\n\n# Упрощенная функция для извлечения ключевых критериев из моделей\nextract_model_metrics &lt;- function(model, model_name, model_type = \"glm\") {\n  if (model_type == \"glm\") {\n    aic_val &lt;- AIC(model)\n    bic_val &lt;- BIC(model)\n    loglik_val &lt;- as.numeric(logLik(model))\n    df_val &lt;- model$rank\n    null_dev &lt;- model$null.deviance\n    dev &lt;- model$deviance\n  } else if (model_type == \"gam\") {\n    aic_val &lt;- AIC(model)\n    bic_val &lt;- BIC(model)\n    loglik_val &lt;- as.numeric(logLik(model))\n    df_val &lt;- sum(model$edf)\n    null_dev &lt;- model$null.deviance\n    dev &lt;- model$deviance\n  } else if (model_type == \"gamm\") {\n    aic_val &lt;- AIC(model$mer)\n    bic_val &lt;- BIC(model$mer)\n    loglik_val &lt;- as.numeric(logLik(model$mer))\n    df_val &lt;- length(fixef(model$mer)) + 1  # +1 для случайного эффекта\n    null_dev &lt;- model$gam$null.deviance\n    dev &lt;- model$gam$deviance\n  }\n  \n  # Вычисляем долю объясненной девиации\n  deviance_explained &lt;- ifelse(!is.null(null_dev) && !is.null(dev) && null_dev &gt; 0,\n                              (null_dev - dev) / null_dev, NA)\n  \n  data.frame(\n    Model = model_name,\n    AIC = round(aic_val, 2),\n    BIC = round(bic_val, 2),\n    LogLik = round(loglik_val, 2),\n    DF = round(df_val, 2),\n    Deviance_Explained = round(deviance_explained, 4)\n  )\n}\n\n# Извлекаем метрики для всех моделей\nmodel_metrics &lt;- bind_rows(\n  extract_model_metrics(glm_gamma_fit, \"GLM (Gamma)\", \"glm\"),\n  extract_model_metrics(gam_fit, \"GAM\", \"gam\"),\n  extract_model_metrics(gamm_fit, \"GAMM\", \"gamm\")\n)\n\n# Добавляем разницу в AIC относительно наилучшей модели\nmin_aic &lt;- min(model_metrics$AIC)\nmodel_metrics &lt;- model_metrics %&gt;%\n  mutate(Delta_AIC = AIC - min_aic,\n         AIC_Weight = exp(-0.5 * Delta_AIC) / sum(exp(-0.5 * Delta_AIC)))\n\n# Форматируем таблицу для вывода\ncomparison_table &lt;- model_metrics %&gt;%\n  mutate(across(where(is.numeric), ~round(., 3))) %&gt;%\n  arrange(AIC)  # Сортируем по AIC (лучшая модель первая)\n\n# Выводим таблицу сравнения\ncat(\"\\nТАБЛИЦА СРАВНЕНИЯ МОДЕЛЕЙ:\\n\")\n\n\nТАБЛИЦА СРАВНЕНИЯ МОДЕЛЕЙ:\n\nprint(comparison_table)\n\n        Model      AIC      BIC    LogLik DF Deviance_Explained Delta_AIC\n1         GAM 42840.91 43079.03 -21382.45 37              0.401      0.00\n2 GLM (Gamma) 42850.76 43088.88 -21387.38 37              0.401      9.85\n3        GAMM 42933.49 43065.09 -21445.75 20                 NA     92.58\n  AIC_Weight\n1      0.993\n2      0.007\n3      0.000\n\n# Выводим итоговые рекомендации\ncat(\"\\n=== ИТОГОВЫЕ РЕКОМЕНДАЦИИ ПО ВЫБОРУ МОДЕЛИ ===\\n\")\n\n\n=== ИТОГОВЫЕ РЕКОМЕНДАЦИИ ПО ВЫБОРУ МОДЕЛИ ===\n\nbest_model &lt;- comparison_table$Model[1]\ncat(\"Наилучшая модель по критерию AIC:\", best_model, \"\\n\")\n\nНаилучшая модель по критерию AIC: GAM \n\ncat(\"Вес AIC для наилучшей модели:\", round(comparison_table$AIC_Weight[1], 3), \"\\n\")\n\nВес AIC для наилучшей модели: 0.993 \n\nif (nrow(comparison_table) &gt; 1 && comparison_table$Delta_AIC[2] &gt; 2) {\n  cat(\"Наилучшая модель существенно лучше остальных (?AIC &gt; 2).\\n\")\n} else if (nrow(comparison_table) &gt; 1) {\n  cat(\"Несколько моделей имеют сходное качество (?AIC &lt; 2).\\n\")\n}\n\nНаилучшая модель существенно лучше остальных (?AIC &gt; 2).\n\ncat(\"Доля объясненной девиации наилучшей модели:\", \n    round(comparison_table$Deviance_Explained[1], 3), \"\\n\")\n\nДоля объясненной девиации наилучшей модели: 0.401",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE</span>"
    ]
  },
  {
    "objectID": "chapter 9.html#анализ-glm-модели-с-гамма-распределением-и-лог-ссылкой",
    "href": "chapter 9.html#анализ-glm-модели-с-гамма-распределением-и-лог-ссылкой",
    "title": "10  Стандартизация CPUE",
    "section": "10.3 Анализ GLM модели с гамма-распределением и лог-ссылкой",
    "text": "10.3 Анализ GLM модели с гамма-распределением и лог-ссылкой\nПодобранная обобщенная линейная модель (GLM) использует гамма-распределение для ошибок и логарифмическую функцию связи. Данное распределение выбрано, поскольку CPUE представляет собой непрерывную положительную величину, а гамма-распределение хорошо описывает такие данные. Логарифмическая связь обеспечивает мультипликативность эффектов факторов, что интерпретируется как относительное изменение CPUE при изменении фактора. Модель включает четыре факторные переменные: год (YEAR), месяц (MONTH), позывной судна (CALL) и район промысла (REGION). Все переменные представлены как факторы, что означает, что для каждого уровня фактора оценивается свой коэффициент, интерпретируемый как отклонение от базового уровня. Базовыми уровнями являются: 2019 год для YEAR, сентябрь (MONTH9) для MONTH, первое судно в алфавитном порядке для CALL и первый район для REGION. Из сводки модели видно, что многие коэффициенты статистически значимы. Все годовые коэффициенты отрицательны и значимы, что указывает на снижение CPUE относительно базового 2019 года. Наибольшее снижение наблюдается в 2024 году (коэффициент -1.128). Месячные коэффициенты также отрицательны и значимы, что говорит о снижении CPUE в октябре и ноябре по сравнению с сентябрем. Большинство коэффициентов для судов значимы и отрицательны, что указывает на то, что уловы на усилие у этих судов в среднем ниже, чем у базового судна. Однако некоторые суда имеют положительные коэффициенты, что означает более высокую производительность. Для районов значимыми оказались лишь некоторые коэффициенты, в основном положительные, что говорит о более высоких уловах в этих районах по сравнению с базовым. Дисперсионный параметр для гамма-семейства равен 0.417, что указывает на умеренную дисперсию. Null deviance составляет 2980.2 при 3890 степенях свободы, а остаточная deviance — 1785.6 при 3854 степенях свободы. Снижение девиации указывает на то, что модель объясняет существенную часть вариации данных. AIC модели равен 42851. Диагностические графики стандартных остатков GLM включают график остатков против предсказанных значений, Q-Q plot, график масштаба-местоположения и график остатков против влияния. Эти графики позволяют оценить гомоскедастичность, нормальность остатков и наличие выбросов. Дополнительная диагностика с помощью пакета DHARMa показывает, что распределение остатков соответствует ожидаемому, что подтверждает адекватность выбранного семейства распределений. Расчет стандартизированных индексов с помощью функции emmeans показывает, что индекс CPUE постепенно снижается с 2019 по 2024 год, что согласуется с отрицательными годовыми коэффициентами. В 2019 году индекс составляет 159, а к 2024 падает до 51.4. Доверительные интервалы не перекрываются между крайними годами, что указывает на статистически значимое снижение. Сравнение с медианными значениями CPUE по годам из исходных данных показывает, что модель несколько сглаживает исходные данные, но общая тенденция снижения сохраняется. Например, в 2019 году медианное значение CPUE было 200, а стандартизированный индекс — 159, что может быть связано с учетом влияния других факторов. Преимущества GLM подхода включают простоту интерпретации коэффициентов, вычислительную эффективность и широкую распространенность. Недостатки заключаются в том, что GLM предполагает линейность влияния факторов на логарифм отклика, что может не всегда выполняться. Кроме того, модель с фиксированными эффектами может не учитывать некоторые источники вариации, такие как пространственно-временная автокорреляция или случайные эффекты судов. В целом, модель адекватно описывает данные и может быть использована для стандартизации CPUE, но для более сложных данных могут потребоваться более гибкие модели, такие как GAM или GAMM.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE</span>"
    ]
  },
  {
    "objectID": "chapter 9.html#анализ-gam-модели-с-гамма-распределением-и-логарифмической-связью",
    "href": "chapter 9.html#анализ-gam-модели-с-гамма-распределением-и-логарифмической-связью",
    "title": "10  Стандартизация CPUE",
    "section": "10.4 Анализ GAM модели с гамма-распределением и логарифмической связью",
    "text": "10.4 Анализ GAM модели с гамма-распределением и логарифмической связью\nАнализ подобранной обобщенной аддитивной модели (GAM) с гамма-распределением и логарифмической связью показывает результаты, практически идентичные полученным ранее для GLM модели, что ожидаемо, поскольку в данной реализации GAM использовалась полностью параметрическая формула без сглаживающих функций. Модель была построена с теми же предикторами - годом, месяцем, идентификатором судна и районом промысла.\nСводка модели демонстрирует параметрические коэффициенты, которые практически не отличаются от оценок GLM модели. Все годовые коэффициенты остаются отрицательными и статистически значимыми, подтверждая устойчивую тенденцию снижения стандартизированного индекса CPUE с 2019 по 2024 год. Месячные коэффициенты также значимы и отрицательны, указывая на сезонное снижение уловов в октябре и ноябре по сравнению с сентябрем. Оценки для различных судов и районов промысла практически идентичны полученным в GLM, с сохранением статистической значимости для тех же уровней факторов.\nМодель объясняет 40.1% девиации данных, что полностью соответствует показателю GLM. Значение REML составляет 21455, а оценка дисперсии равна 0.41722, что также практически совпадает с соответствующими показателями GLM модели.\nПроверка адекватности модели с помощью функции gam.check показывает успешную сходимость алгоритма оптимизации после 5 итераций. Градиент близок к нулю, а гессиан положительно определен, что свидетельствует о достижении устойчивого решения. Поскольку в модели отсутствуют сглаживающие компоненты, диагностика не выявляет проблем, связанных с выбором базовой размерности или неадекватностью сглаживания.\nДиагностика остатков с использованием пакета DHARMa показывает равномерное распределение без систематических паттернов, что указывает на соответствие остатков теоретическому гамма-распределению. Графики остатков демонстрируют отсутствие гетероскедастичности и значимых выбросов, что подтверждает адекватность модели.\nРасчет стандартизированных индексов методом маргинальных средних дает значения, практически идентичные полученным из GLM модели. Индекс снижается с 159 в 2019 году до 51.4 в 2024 году, с доверительными интервалами, не перекрывающимися между крайними годами. Нормированные индексы относительно среднего и первого года также полностью совпадают с GLM результатами.\nОсновное преимущество использования GAM в данном случае заключается в методологическом подходе - использовании метода REML для оптимизации, который может обеспечивать более стабильные оценки параметров по сравнению с методом максимального правдоподобия, используемым в GLM. Хотя в данной конкретной реализации с полностью параметрической формулой это преимущество не реализуется в полной мере, GAM предоставляет основу для легкого включения нелинейных эффектов через сглаживающие функции, если такая необходимость возникнет в дальнейшем.\nК недостаткам данного подхода можно отнести избыточную сложность GAM для полностью параметрической модели, поскольку вычислительные затраты выше, чем для GLM, без существенного улучшения качества подгонки. Фактически, в данном случае GAM работает как GLM, но с более сложным алгоритмом оптимизации. Кроме того, диагностика GAM требует дополнительных проверок, связанных со сходимостью алгоритма и адекватностью сглаживания, которые не актуальны для параметрических моделей.\nВ целом, данная реализация GAM не демонстрирует преимуществ перед GLM моделью, но предоставляет основу для будущего расширения модели за счет включения нелинейных эффектов, если анализ данных покажет такую необходимость. Результаты стандартизации CPUE полностью согласуются с полученными ранее средствами GLM.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE</span>"
    ]
  },
  {
    "objectID": "chapter 9.html#анализ-gamm-моделей",
    "href": "chapter 9.html#анализ-gamm-моделей",
    "title": "10  Стандартизация CPUE",
    "section": "10.5 Анализ GAMM моделей",
    "text": "10.5 Анализ GAMM моделей\nОсобенности смешанных моделей и случайные эффекты\nСмешанные модели, включая GAMM, расширяют возможности стандартных моделей за счет введения случайных эффектов. В то время как фиксированные эффекты оценивают среднее влияние факторов на всю популяцию, случайные эффекты позволяют учесть вариацию, связанную с отдельными группами наблюдений. В ихтиологических исследованиях случайные эффекты часто применяются для учета индивидуальных особенностей судов, различий между районами промысла, или временной автокорреляции.\nСлучайные эффекты особенно полезны, когда:\n\nДанные имеют иерархическую структуру (например, уловы по нескольким судам)\nНаблюдения внутри групп коррелированы\nКоличество уровней фактора велико, и мы хотим обобщить выводы на всю популяцию групп\nНас интересует вариация между группами, а не конкретные сравнения между отдельными уровнями\n\nВ данном случае случайный эффект для судна (CALL) позволяет учесть, что разные суда могут иметь систематические различия в эффективности промысла, не объясняемые другими переменными модели.\nАнализ результатов GAMM модели\nАнализ обобщенной аддитивной смешанной модели показывает несколько важных особенностей. Модель включает фиксированные эффекты года, месяца и района, а также случайный эффект для судна, что позволяет учесть индивидуальные различия между судами в уровне уловов.\nГрафик остатков от предсказанных значений показывает распределение девиансных остатков вокруг нулевой линии. Наблюдается некоторая гетероскедастичность - разброс остатков увеличивается с ростом предсказанных значений, что характерно для данных по уловам. QQ-plot демонстрирует отклонение распределения остатков от нормального в крайних значениях, что ожидаемо для данных с гамма-распределением.\nАнализ случайных эффектов для судов показывает существенную вариацию между разными судами. Значения случайных эффектов варьируют от -2.92 до 0.93, что указывает на значительные различия в эффективности промысла между судами после учета влияния года, месяца и района. Распределение случайных эффектов близко к нормальному с центром около нуля.\nТест Бреуша-Пагана подтверждает наличие гетероскедастичности в модели, что является общей проблемой для моделей с данными по уловам.\nСводка параметрических коэффициентов показывает, что все годовые эффекты статистически значимы и отрицательны, подтверждая общую тенденцию снижения уловов с течением времени. Месячные эффекты также значимы и отрицательны, указывая на сезонное снижение уловов в октябре и ноябре по сравнению с сентябрем. Среди районов промысла несколько показали статистически значимые отличия от базового уровня.\nМодель объясняет 17.2% дисперсии данных, что меньше, чем в предыдущих моделях, что может быть связано с учетом части вариации через случайные эффекты. Информационные критерии AIC (42933.5) и BIC (43065.1) выше, чем у GLM и GAM моделей, что указывает на худшее соответствие данных этой модели с учетом ее сложности.\nПреимущества и недостатки подхода GAMM\nОсновное преимущество GAMM подхода заключается в возможности учета групповой структуры данных через случайные эффекты. Это позволяет более адекватно оценить неопределенность предсказаний и избежать завышения значимости эффектов из-за псевдорепликации. Модель обеспечивает более реалистичную оценку вариации в данных, учитывая как фиксированные эффекты, так и случайную вариацию между группами.\nК недостаткам можно отнести повышенную вычислительную сложность и потенциальные проблемы со сходимостью алгоритмов оптимизации. Интерпретация результатов становится сложнее, особенно при наличии взаимодействий между фиксированными и случайными эффектами. В данном случае модель показала худшие показатели качества подгонки по сравнению с более простыми GLM и GAM моделями, что может свидетельствовать о избыточной сложности модели для данного набора данных.\nВ целом, GAMM представляет собой мощный инструмент для анализа данных с иерархической структурой, но его применение должно быть обосновано теоретически и подтверждено улучшением качества модели по сравнению с более простыми альтернативами.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE</span>"
    ]
  },
  {
    "objectID": "chapter 9.html#сравнительный-анализ-моделей-по-информационным-критериям",
    "href": "chapter 9.html#сравнительный-анализ-моделей-по-информационным-критериям",
    "title": "10  Стандартизация CPUE",
    "section": "10.6 Сравнительный анализ моделей по информационным критериям",
    "text": "10.6 Сравнительный анализ моделей по информационным критериям\nВ данном разделе проводится систематическое сравнение трех альтернативных моделей - GLM, GAM и GAMM - с использованием информационных критериев и других метрик качества. Для унификации процесса сравнения создана специализированная функция extract_model_metrics, которая адаптирована для извлечения сопоставимых показателей из моделей разной структуры.\nДля GLM и GAM моделей используются стандартные методы расчета критериев, включая AIC, BIC, логарифмическое правдоподобие и долю объясненной девиации. Для GAMM модели, имеющей более сложную смешанную структуру, метрики извлекаются из компонентов mer и gam объекта, с дополнительным учетом случайных эффектов при расчете сложности модели.\nРезультаты сравнения представлены в виде структурированной таблицы, где модели упорядочены по возрастанию AIC - информационного критерия Акаике, который балансирует качество подгонки и сложность модели. Дополнительно вычисляются дельта-AIC (разница относительно наилучшей модели) и веса AIC, которые интерпретируются как вероятности того, что данная модель является наилучшей среди рассматриваемых.\nАнализ результатов показывает четкое разделение моделей по качеству. Модель GAM демонстрирует наилучшие показатели с AIC = 42840.91 и весом AIC 0.993, что означает 99.3% вероятность того, что эта модель является наилучшей среди сравниваемых. Модель GLM показывает очень близкие результаты по объясненной дисперсии (0.401), но несколько худшие значения AIC (42850.76) и минимальный вес (0.007). Модель GAMM значительно уступает по всем критериям с AIC = 42933.49 и нулевым весом в рамках данного сравнения.\nРазница в AIC между GAM и GLM составляет 9.85 единиц, что превышает пороговое значение 2, принятое для утверждения о существенном преимуществе одной модели над другой. Еще более значительная разница в 92.58 единиц между GAM и GAMM подтверждает статистически значимое превосходство GAM модели.\nНа основе проведенного анализа формулируются итоговые рекомендации по выбору модели. Модель GAM идентифицируется как наилучшая с очень высокой степенью уверенности (вес AIC 0.993). Объясняющая способность модели составляет 40.1%, что указывает на хорошее соответствие модели данным.\nДанный сравнительный подход обеспечивает объективную основу для выбора окончательной модели, позволяя учесть как качество подгонки, так и сложность модели, избегая таким образом как избыточного усложнения, так и излишнего упрощения.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE</span>"
    ]
  },
  {
    "objectID": "chapter 9.html#анализ-gamm-модели",
    "href": "chapter 9.html#анализ-gamm-модели",
    "title": "10  Стандартизация CPUE",
    "section": "10.5 Анализ GAMM модели",
    "text": "10.5 Анализ GAMM модели\nОсобенности смешанных моделей и случайные эффекты\nСмешанные модели, включая GAMM, расширяют возможности стандартных моделей за счет введения случайных эффектов. В то время как фиксированные эффекты оценивают среднее влияние факторов на всю популяцию, случайные эффекты позволяют учесть вариацию, связанную с отдельными группами наблюдений. В ихтиологических исследованиях случайные эффекты часто применяются для учета индивидуальных особенностей судов, различий между районами промысла, или временной автокорреляции.\nСлучайные эффекты особенно полезны, когда:\n\nДанные имеют иерархическую структуру (например, уловы по нескольким судам)\nНаблюдения внутри групп коррелированы\nКоличество уровней фактора велико, и мы хотим обобщить выводы на всю популяцию групп\nНас интересует вариация между группами, а не конкретные сравнения между отдельными уровнями\n\nВ данном случае случайный эффект для судна (CALL) позволяет учесть, что разные суда могут иметь систематические различия в эффективности промысла, не объясняемые другими переменными модели.\nАнализ результатов GAMM модели\nАнализ обобщенной аддитивной смешанной модели показывает несколько важных особенностей. Модель включает фиксированные эффекты года, месяца и района, а также случайный эффект для судна, что позволяет учесть индивидуальные различия между судами в уровне уловов.\nГрафик остатков от предсказанных значений показывает распределение девиансных остатков вокруг нулевой линии. Наблюдается некоторая гетероскедастичность - разброс остатков увеличивается с ростом предсказанных значений, что характерно для данных по уловам. QQ-plot демонстрирует отклонение распределения остатков от нормального в крайних значениях, что ожидаемо для данных с гамма-распределением.\nАнализ случайных эффектов для судов показывает существенную вариацию между разными судами. Значения случайных эффектов варьируют от -2.92 до 0.93, что указывает на значительные различия в эффективности промысла между судами после учета влияния года, месяца и района. Распределение случайных эффектов близко к нормальному с центром около нуля.\nТест Бреуша-Пагана подтверждает наличие гетероскедастичности в модели, что является общей проблемой для моделей с данными по уловам.\nСводка параметрических коэффициентов показывает, что все годовые эффекты статистически значимы и отрицательны, подтверждая общую тенденцию снижения уловов с течением времени. Месячные эффекты также значимы и отрицательны, указывая на сезонное снижение уловов в октябре и ноябре по сравнению с сентябрем. Среди районов промысла несколько показали статистически значимые отличия от базового уровня.\nМодель объясняет 17.2% дисперсии данных, что меньше, чем в предыдущих моделях, что может быть связано с учетом части вариации через случайные эффекты. Информационные критерии AIC (42933.5) и BIC (43065.1) выше, чем у GLM и GAM моделей, что указывает на худшее соответствие данных этой модели с учетом ее сложности.\nГрафик случайных эффектов с тремя модами на значениях 0.5, -1.5 и -3 демонстрирует выраженную стратификацию судов по их промысловой эффективности. Такое распределение указывает на наличие трех различных групп в промысловом флоте, каждая со своими характеристиками. Группа с модой на 0.5 представляет суда с повышенной эффективностью, чьи уловы примерно на 65% (exp(0.5) ≈ 0.65) превышают средний уровень. Эти суда, вероятно, оснащены современным оборудованием, укомплектованы опытными экипажами и работают на наиболее продуктивных участках.\nВторая группа с модой на -1.5 соответствует судам со значительно сниженной эффективностью, показывающим уловы примерно на 78% ниже среднего показателя. Такие результаты могут быть связаны с устаревшим техническим оснащением, менее оптимальными методами лова или работой в менее продуктивных районах. Третья группа с модой на -3 представляет суда с крайне низкой эффективностью, демонстрирующие уловы на 95% ниже среднего уровня. Столь значительное отставание может объясняться серьезными техническими проблемами, отсутствием современного оборудования, неопытностью экипажей или систематическими организационными трудностями.А возможно работой не на мороженном крабе, а живом - требующим другой технологической работы.\nНаличие трех четких мод в распределении случайных эффектов свидетельствует о существенной неоднородности промыслового флота. Это указывает на то, что предположение о нормальном распределении случайных эффектов не выполняется, а данные имеют выраженную групповую структуру. Модель успешно выявляет эту скрытую стратификацию, что подтверждает важность учета случайных эффектов при анализе промысловых данных. Полученные результаты подчеркивают необходимость дифференцированного подхода к анализу эффективности судов и разработки управленческих решений с учетом выявленной группировки. Различные моды могут отражать не только технические различия между судами, но и различные стратегии промысла, доступ к ресурсам или уровень организации работы.\nПреимущества и недостатки подхода GAMM\nОсновное преимущество GAMM подхода заключается в возможности учета групповой структуры данных через случайные эффекты. Это позволяет более адекватно оценить неопределенность предсказаний и избежать завышения значимости эффектов из-за псевдорепликации. Модель обеспечивает более реалистичную оценку вариации в данных, учитывая как фиксированные эффекты, так и случайную вариацию между группами.\nК недостаткам можно отнести повышенную вычислительную сложность и потенциальные проблемы со сходимостью алгоритмов оптимизации. Интерпретация результатов становится сложнее, особенно при наличии взаимодействий между фиксированными и случайными эффектами. В данном случае модель показала худшие показатели качества подгонки по сравнению с более простыми GLM и GAM моделями, что может свидетельствовать о избыточной сложности модели для данного набора данных.\nВ целом, GAMM представляет собой мощный инструмент для анализа данных с иерархической структурой, но его применение должно быть обосновано теоретически и подтверждено улучшением качества модели по сравнению с более простыми альтернативами.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Стандартизация CPUE</span>"
    ]
  },
  {
    "objectID": "chapter 6.html",
    "href": "chapter 6.html",
    "title": "7  Продукционная модель JABBA",
    "section": "",
    "text": "7.1 Введение\nБиблиотека JABBA https://github.com/jabbamodel/JABBA - оценка запаса с помощью стохастической версии продукционной модели и байесовского подхода. JABBA и SPiCT – наиболее распространенные в международной практике инструменты, реализующие продукционный подход к оценке запасов гидробионтов при нехватки данных.\nПомимо R JABBA требует дополнительно установки JAGS. Для демонстрации основных функций пакета в настоящем скрипте используются входные данные из примера SPiCT, поэтому в скрипте демонстрации модели JABBA сценарий моделирования назван “SPiCT_adapted”.\nСкрипт этого практического занятия можно скачать по ссылке.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Продукционная модель JABBA</span>"
    ]
  },
  {
    "objectID": "chapter 6.html#подготовка-среды-и-загрузка-данных",
    "href": "chapter 6.html#подготовка-среды-и-загрузка-данных",
    "title": "7  Продукционная модель JABBA",
    "section": "7.2 Подготовка среды и загрузка данных",
    "text": "7.2 Подготовка среды и загрузка данных\nВ данном разделе выполняется базовая настройка среды R для работы с пакетом JABBA. Инициируется загрузка двух необходимых пакетов: JABBA (основной инструмент оценки запасов) и reshape2 (для преобразования структур данных). Создается целевая директория “NEW JABBA” для автоматического сохранения всех результатов анализа, после чего рабочая среда переключается на эту папку.\nФормируются три обязательных компонента входных данных:\n\nДанные по вылову (catch): Годовые значения уловов за 20-летний период (2005-2024 гг.), представленные в виде вектора из 20 числовых значений.\nДва индекса обилия:\n\n\nCPUE (улов на единицу усилия): 20 наблюдений\nBESS (альтернативный индекс, например, данные съемок): 19 наблюдений (первое значение отсутствует, обозначено как NA)\n\n\nСтандартные ошибки (SE) для индексов: Для упрощения примера задаются фиксированным коэффициентом вариации (CV=20%). Это означает, что для каждого ненулевого значения индекса SE рассчитывается как 20% от его величины. Пропуски в индексах (NA) автоматически сохраняются как NA в таблице SE.\n\nВсе данные структурируются в три таблицы с единой временной осью (2005-2024 гг.): отдельно для уловов, значений индексов и их стандартных ошибок. Эта подготовка обеспечивает корректный формат входных данных, необходимых для последующего построения продукционной модели в JABBA.\n\n# ------------------------- 1. ПОДГОТОВКА СРЕДЫ ---------------------------\n\n# Загрузка необходимых пакетов\nlibrary(JABBA) # Основной пакет для оценки запасов\nlibrary(reshape2) # Для преобразования данных (функция dcast)\n\n# Установка рабочей директории (папки, где будут храниться результаты)\nsetwd(\"C:/BAKANEV/JABBA\")\n\n# Создание папки для результатов анализа\nassessment &lt;- \"NEW JABBA\" # Название оценки\noutput.dir &lt;- file.path(getwd(), assessment) # Создание пути к папке\ndir.create(output.dir, showWarnings = FALSE) # Создание папки (если не существует)\nsetwd(output.dir) # Переход в созданную папку\n\n# ------------------------- 2. ЗАГРУЗКА И ПОДГОТОВКА ДАННЫХ ---------------------------\n\n# Создание вектора лет анализа\nYear &lt;- 2005:2024 # Последовательность лет от 2005 до 2024\n\n# Вектор данных об уловах (catch)\nCatch &lt;- c(5,7,6,10,14,25,28,30,32,35,25,20,15,12,10,12,10,13,11,12)\n\n# Вектор данных индекса обилия CPUE (catch per unit effort)\nCPUE &lt;- c(27.4,26.8,16.8,23.0,29.0,30.0,16.5,17.2,10.5,14.6,8.3,11.4,15.5,13.8,11.5,15.3,12.2,15.6,16.2,13.4)\n# Вектор данных индекса обилия BESS\nBESS &lt;- c(NA,16.3,20.7,15.1,18.6,16.0,13.8,13.3,11.7,11.8,9.3,7.1,8.0,9.2,10.3,9.8,10.3,11.7,13.7,13.4)\n\n# Форматирование данных в таблицы для JABBA\ncatch_data &lt;- data.frame(year = Year, catch = Catch) # Таблица уловов\ncpue_data &lt;- data.frame(year = Year, CPUE = CPUE, BESS = BESS) # Таблица индексов\n\n# Расчет стандартных ошибок (SE) для индексов\n# Используем коэффициент вариации (CV) = 20% (0.2)\n\nse_data &lt;- data.frame(\n year = Year,\n CPUE = ifelse(is.na(CPUE), NA, 0.2),\n BESS = ifelse(is.na(BESS), NA, 0.2))",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Продукционная модель JABBA</span>"
    ]
  },
  {
    "objectID": "chapter 6.html#настройка-и-запуск-модели-jabba",
    "href": "chapter 6.html#настройка-и-запуск-модели-jabba",
    "title": "7  Продукционная модель JABBA",
    "section": "7.3 Настройка и запуск модели JABBA",
    "text": "7.3 Настройка и запуск модели JABBA\nВ этом разделе выполняется конфигурация и запуск JABBA. Сначала с помощью функции build_jabba формируется структура входных данных для модели, куда передаются подготовленные таблицы уловов, индексов CPUE/BESS и их стандартных ошибок. Указывается название оценки (“NEW JABBA”) и сценарий моделирования (“SPiCT_adapted”). В качестве биологической основы выбрана модель Шефера (логистический рост). Настраиваются ключевые априорные распределения: для темпа роста популяции (r) задано нормальное распределение N(0.2±0.5), для емкости среды (K) - логнормальное LN(189.6±0.795), для начальной заполненности запаса (ψ) - бета-распределение Beta(0.75±0.25). Установлена оценка процессной ошибки (sigma.est=TRUE) и слабоинформативные априоры для дисперсии наблюдений.\nНепосредственный запуск Байесовской оценки выполняется функцией fit_jabba, которая использует MCMC-алгоритм. Конфигурация MCMC включает 50,000 итераций с отбрасыванием первых 10,000 (фаза “burn-in”), прореживанием цепей в 5 раз и запуском 2 независимых цепей для проверки сходимости. Результатом работы является объект fit, содержащий апостериорные распределения параметров, оценки биомассы и диагностику модели, которые будут использоваться для последующего анализа состояния запаса.\n\n# ------------------- 3. НАСТРОЙКА И ЗАПУСК МОДЕЛИ JABBA --------------------\n\n\n# Создание входных данных для модели\n\njbinput &lt;- build_jabba(\ncatch = catch_data,# Данные об уловах\ncpue = cpue_data,# Данные индексов обилия\nse = se_data,# Стандартные ошибки\nassessment = assessment, # Название оценки\nscenario = \"SPiCT_adapted\", # Сценарий модели\nmodel.type = \"Schaefer\", # Тип модели (Шефера)\nsigma.est = TRUE, # Оценивать изменчивость процесса?\nr.prior = c(0.2, 0.5),# Априорное распределение для r (среднее, SD)\nK.prior = c(189.6, 0.795),# Априорное для K (среднее, SD)\npsi.prior = c(0.75, 0.25),# Априорное для начального заполнения\nigamma = c(0.001, 0.001), # Параметры для дисперсии наблюдений\nverbose = FALSE # Отключить подробный вывод\n)\n\n# Запуск Байесовской модели (MCMC)\n\nfit &lt;- fit_jabba(\njbinput,# Входные данные\nni = 50000, # Общее количество итераций\nnb = 10000, # Количество \"выжигаемых\" итераций (burn-in)\nnt = 5,# Частота прореживания (thinning)\nnc = 2 # Количество цепей MCMC\n)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Продукционная модель JABBA</span>"
    ]
  },
  {
    "objectID": "chapter 6.html#анализ-параметров-модели-jabba-fitpars",
    "href": "chapter 6.html#анализ-параметров-модели-jabba-fitpars",
    "title": "7  Продукционная модель JABBA",
    "section": "7.4 Анализ параметров модели JABBA (fit$pars)",
    "text": "7.4 Анализ параметров модели JABBA (fit$pars)\nКоманда fit$pars выведет таблицу, содержит медианные значения, 95% доверительные интервалы и результаты тестов сходимости MCMC для ключевых характеристик модели.\n\n&gt; fit$pars\n\n        Median        LCI           UCI          Geweke.p Heidel.p\nK      257.137636616 178.4613660245 442.25933810 0.533    0.401\nr      0.268924223   0.1517493450   0.42756749   0.324    0.864\nq.1    0.102043488   0.0565010978   0.15490243   0.920    0.967\nq.2    0.078076035   0.0433099875   0.11858679   0.986    0.954\npsi    0.875023951   0.5909908905   1.23643434   0.970    0.470\nsigma2 0.003477230   0.0005645686   0.02110338   0.369    0.563\ntau2.1 0.006817871   0.0006978604   0.05031429   0.845    0.392\ntau2.2 0.002775946   0.0004835058   0.01978467   0.522    0.445\nm      2.000000000   2.0000000000   2.00000000   NaN      NA\n&gt;\n\nБиологические параметры:\n\nK(емкость среды): Медиана 257.14 единиц биомассы, например тыс.тонн (95% ДИ: 178.46–442.26). Широкий доверительный интервал отражает типичную неопределенность при отсутствии данных о периоде, когда запас приближался к нетронутому состоянию.\nr(темп роста): Медиана 0.269 год⁻¹ (95% ДИ: 0.152–0.428) соответствует биологическим ожиданиям для многих промысловых видов рыб.\nψ(начальная биомасса): Медиана 0.875 (95% ДИ: 0.591–1.236) указывает, что в 2005 году биомасса составляла ~87.5% от K.\n\nПараметры наблюдений:\n\nq.1(коэффициент уловистости (улавливаемости) CPUE): Медиана 0.102 (95% ДИ: 0.056–0.155)\nq.2(коэффициент уловистости (улавливаемости) BESS): Медиана 0.078 (95% ДИ: 0.043–0.119) Широкие доверительные интервалы (&gt;50% от медианы) подтверждают недостаточную информативность данных для точной оценки этих параметров.\n\nОценки ошибок:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nПараметр\n\nМедиана\n\n95% ДИ\n\nНазначение\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsigma2\n\n0.0035\n\n[0.0006, 0.021]\n\nДисперсия ошибки процесса\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntau2.1\n\n0.0068\n\n[0.0007, 0.050]\n\nДисперсия ошибки CPUE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntau2.2\n\n0.0028\n\n[0.0005, 0.020]\n\nДисперсия ошибки BESS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nСоотношение σ²/τ² показывает:\n\nДля CPUE: 0.0035/0.0068 ≈ 0.51\n\nДля BESS: 0.0035/0.0028 ≈ 1.25\n\n\n\n\n\n\nЭто свидетельствует, что неопределенность в большей степени обусловлена погрешностью данных, чем стохастичностью биологической динамики.\nДиагностика сходимости MCMC: Все p-значения тестов (Geweke, Heidel) превышают 0.05, что подтверждает сходимость цепей:\nУправленческие выводы:\n1.Из-за неопределенности в оценках K и q интерпретацию следует фокусировать на относительных показателях (B/Bmsy, F/Fmsy).\n2.Для повышения точности модели требуется:\n\nДополнительные данные за периоды высокой биомассы (для уточнения K)\nКалибровка индексов обилия (для снижения τ²)\n\n3.Высокие значения τ² указывают на необходимость улучшения качества данных CPUE и BESS.\nДиагностика и визуализация результатов\nПосле выполнения байесовской оценки в JABBA проводится комплексная диагностика и визуализация результатов. Автоматически генерируется набор стандартных графиков через функцию jabba_plots, которые сохраняются в рабочую директорию. Для углубленного анализа последовательно строятся специализированные графики: динамика уловов с модельными значениями, согласованность наблюдаемых и предсказанных индексов CPUE/BESS, сравнение априорных и апостериорных распределений ключевых параметров (r, K, q), а также диагностика остатков модели. Особое внимание уделяется сходимости MCMC-цепей для исключения вычислительных ошибок.\nВажнейшая часть анализа - визуализация временных трендов: абсолютной биомассы (B), промысловой смертности (F) и их соотношений с целевыми уровнями (B/Bmsy, F/Fmsy). Фазовый портрет и Кобэ-график интегрируют эти показатели, наглядно отображая историческую и текущую позицию запаса относительно ориентиров управления (перелов/недолов). Дополнительно выполняются тест на случайность остатков, логарифмические аппроксимации и анализ отклонений процесса, что обеспечивает всестороннюю проверку адекватности модели. Финал этапа - экспорт рассчитанных временных рядов (биомасса, F, B/Bmsy и др.) в CSV-файл для дальнейшего использования.\n\n# ------------------- 4. ДИАГНОСТИКА И ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ --------------------\n\n# Генерация стандартных диагностических графиков\n\njbplot_ensemble(fit)\njabba_plots(fit, output.dir = output.dir)\n\n# Индивидуальные графики для детального анализа:\n\njbplot_catch(fit)# График уловов\njbplot_cpuefits(fit)# Сравнение модельных и наблюдаемых индексов\njbplot_ppdist(fit)# Распределения априорных и апостериорных параметров\njbplot_residuals(fit)# Остатки модели\njbplot_mcmc(fit)# Диагностика сходимости MCMC\njbplot_trj(fit, type = \"B\")# Динамика биомассы\njbplot_trj(fit, type = \"F\")# Динамика промысловой смертности\njbplot_trj(fit, type = \"BBmsy\")# Отношение *B/B~msy~*\njbplot_trj(fit, type = \"FFmsy\")# Отношение *F/F~msy~*\njbplot_spphase(fit)# **График продуктивности запаса с разметкой фаз Kobe**\njbplot_kobe(fit)# Кобэ-график (*B/B~msy~* vs *F/F~msy~*)\n\n# Дополнительные диагностики:\n\njbplot_runstest(fit)# Тест на случайность остатков\njbplot_logfits(fit)# Графики в логарифмической шкале\n\njbplot_procdev(fit)# Отклонения процесса\n\n# Сохранение временных рядов результатов\n\nwrite.csv(fit$timeseries, file = \"results.csv\", row.names = FALSE)\n\n\n\n\nРис. 1.: Генерация стандартных графиков: относительной и абсолютной промысловой биомассы, а также смертности, ошибки процесса и динамики вылова.\n\n\n\n\n\nРис. 2.: Сравнение модельных и наблюдаемых индексов\n\n\nГрафик сравнения позволяет визуально оценить адекватность модели реальным данным и выявить систематические расхождения. Он отображает: 1.Наблюдаемые значенияиндексов (например, CPUE и BESS) в виде точек с вертикальными отрезками, отражающими доверительные интервалы на основе стандартных ошибок. 2.Модельные предсказания в виде сплошной линии с затененной областью (50 и 95% доверительные интервалы апостериорного распределения).\nКлючевые аспекты интерпретации:\nСогласованность: Если модельная кривая проходит в пределах доверительных интервалов наблюдаемых точек, это свидетельствует о хорошем описании трендов. Смещения: Систематическое занижение/завышение предсказаний для определенных периодов указывает на недостатки модели (например, недоучет факторов среды или нелегального вылова). Чувствительность индексов: Различия в точности аппроксимации CPUE и BESS помогают оценить, какой индекс информативнее отражает динамику биомассы. Аномалии: Резкие выбросы точек за пределы доверительной зоны модели сигнализируют о годах с нетипичными условиями (ошибки данных, природные катаклизмы). Практическое значение: График отвечает на вопрос — способна ли выбранная продукционная модель (в данном случае Шефера) достоверно воспроизводить историческую динамику запаса, что является основой для корректных прогнозов.\n\n\n\nРис. 3.: Распределения априорных и апостериорных параметров\n\n\nЭтот график предоставляет инструмент для анализа влияния данных на исходные предположения модели. Он визуализирует:\n1.Априорные распределения(темные области): - Заданные до анализа (например:r ~ N(0.2, 0.5),K ~ LN(189.6, 0.795)). - Отражают экспертные гипотезы или литературные данные о параметрах.\n2.Апостериорные распределения(светлые области): - Рассчитанные в ходе Байесовского вывода (MCMC) после учета данных (уловы, индексы). - Показывают,как фактическая информация модифицировала первоначальные предположения.\nАспекты интерпретации:\nСдвиг пиков: Если апостериор смещен относительно априора (напр., пик для r сдвинулся от 0.2 к 0.3) – данные “перевесили” априорную гипотезу. Сужение кривой: Резкое сокращение дисперсии апостериора (напр., для K) свидетельствует о высокой информативности данных по этому параметру. Конфликт: Если апостериорный пик находится в “хвосте” априора (напр., априор для q задан N(1,0.2), а апостериор с пиком при 2.5) – сигнал о несоответствии данных или модели.\nПараметры-индикаторы:\n\nr (темп роста): Четкий апостериор указывает на надежную оценку продуктивности запаса.\nK (емкость среды): Узкий апостериор – уверенность в оценке исторической биомассы.\nψ (начальная заполненность): Расхождение с априором может указывать на ошибку в задании начальных условий.\n\nДиагностическое значение:\nЕсли апостериоры близки к априорам – данные не внесли новую информацию (требует пересмотра индексов). Если апостериоры асимметричны/многомодальны – возможны проблемы идентификации параметров (необходимы дополнительные диагностики).\nВывод: График отвечает на вопрос – насколько исходные биологические гипотезы подтвердились реальными данными, что критично для обоснованности оценки.\nКасательно графиков коэффициентов пропорциональности или улавливаемости q. Здесь, для простоты примера, вручную не задаются. JABBA по умолчанию (автоматически) назначает слабый или малоинформативный априор: q ~ LogNormal(mean = 1, SD = 1000) Это практически равномерное распределение в широком диапазоне (от ~0 до +∞). Поэтому на графиках не видны темные области априорных распределений q1 и q2. Физический смысл: Мы не знаем, во сколько раз индекс отличается от абсолютной биомассы.\nPPMR и PPVR: диагностические показатели в JABBA\nВ байесовском анализе, который лежит в основе работы JABBA, ключевым этапом является проверка сходимости MCMC-цепей. Именно для этой цели используются диагностические показатели PPMR (Potential Scale Reduction Factor for Multivariate Monitoring) и PPVR (Potential Scale Reduction Factor for Predictive Variance). Эти статистики позволяют оценить, насколько надежны полученные оценки параметров модели. PPMR представляет собой многомерный аналог классического R-hat критерия и оценивает сходимость сразу для всех параметров модели, учитывая их взаимосвязи. Он рассчитывается как корень из отношения дисперсии между цепями к дисперсии внутри цепей. Идеальное значение PPMR должно быть близко к 1, а значения выше 1.1 указывают на серьезные проблемы со сходимостью. PPVR же фокусируется конкретно на сходимости дисперсии апостериорных предсказаний, что особенно важно для оценки надежности доверительных интервалов прогнозируемых величин, таких как B/Bmsy или F/Fmsy. Значения PPVR также должны стремиться к 1.\nВ вашем конкретном случае анализ этих показателей дает неоднозначную картину. Для параметра K (несущая способность) мы видим практически идеальную сходимость: PPMR равен 0.97, что даже немного меньше 1, что указывает на превосходную стабильность оценок между цепями, а крайне низкое значение PPVR (0.109) говорит о высокой согласованности в оценке неопределенности. Это позволяет с уверенностью доверять полученным значениям K. Однако ситуация с параметром r (темп роста популяции) вызывает серьезные опасения. Значение PPMR 1.471 существенно превышает критический порог, что свидетельствует о явных проблемах со сходимостью цепей. Хотя PPVR 0.322 выглядит лучше, это не компенсирует высокий PPMR. Такая ситуация часто возникает при слишком широких априорных распределениях или недостатке информативных данных, особенно в периоды роста популяции. Для параметра ψ (начальная заполненность запаса) ситуация промежуточная: PPMR 1.174 находится на границе допустимого, а PPVR 0.501 указывает на умеренную согласованность в оценке неопределенности.\nДля улучшения сходимости рекомендуется предпринять несколько шагов. Во-первых, стоит значительно увеличить количество итераций MCMC - например, до 100000 для ni и 20000 для фазы “burn-in” (nb). Во-вторых, необходимо пересмотреть априорные распределения, особенно для параметра r: возможно, стоит уменьшить стандартное отклонение с 0.5 до 0.2-0.3, если есть экспертные основания для такого ужесточения. В-третьих, стоит проверить качество входных данных - достаточно ли репрезентативны имеющиеся индексы обилия, особенно в ключевые периоды динамики популяции. Важно понимать, что при сохраняющихся проблемах со сходимостью абсолютные оценки биомассы и темпа роста могут оставаться ненадежными, однако относительные показатели, такие как B/Bmsy, часто оказываются более устойчивыми к подобным проблемам. Это связано с тем, что они в меньшей степени зависят от абсолютных значений проблемных параметров. Таким образом, несмотря на выявленные сложности, модель может оставаться полезной для принятия управленческих решений, особенно если фокусироваться на относительных показателях состояния запаса.\n\n\n\nРис. 4.: Остатки модели\n\n\nГрафик остатков в JABBA (jbplot_residuals) представляет собой важный диагностический инструмент, позволяющий оценить качество соответствия модели реальным данным. На этом графике отображаются остатки - разницы между наблюдаемыми значениями индексов обилия (CPUE и BESS) и их модельными оценками. В вашем случае график строится на основе конкретных значений остатков, где для CPUE они варьируются от -0.38 до +0.31, а для BESS - от -0.20 до +0.17, с отсутствующим значением (NA) для BESS в 2005 году.\nГрафик имеет несколько ключевых элементов. Во-первых, это боксплоты, которые визуализируют распределение остатков для каждого индекса в целом, показывая медиану, квартили и возможные выбросы. Во-вторых, на график накладывается сглаженная линия (loess), которая помогает выявить систематические тренды в остатках. Например, если остатки демонстрируют явную тенденцию к увеличению или уменьшению со временем, это может указывать на неучтенные факторы в модели. В ваших данных остатки CPUE показывают некоторую изменчивость, но без явного тренда, в то время как BESS имеет более стабильные остатки с меньшим разбросом.\nИнтерпретация остатков имеет решающее значение. В идеале остатки должны быть случайно распределены вокруг нуля без видимых закономерностей. Наличие кластеров положительных или отрицательных остатков в определенные периоды может указывать на систематические ошибки модели. В нашем случае отсутствие явных трендов на графике - хороший знак, хотя отдельные выбросы, такие как отрицательный остаток CPUE в 2013 году (-0.38), заслуживают внимания. Размеры остатков также важны: значения, превышающие по модулю 0.5, считаются значительными и могут указывать на проблемы с данными или спецификацией модели.\nГрафик остатков особенно полезен для сравнения разных индексов. В нашем анализе видно, что остатки CPUE имеют больший разброс по сравнению с BESS, что может говорить либо о более высокой вариабельности данных CPUE, либо о том, что модель хуже описывает эту компоненту. Отсутствие данных BESS для 2005 года (NA) корректно обрабатывается графиком. Важно отметить, что систематические смещения остатков вверх или вниз могут указывать на проблемы с калибровкой коэффициентов уловистости (q), что согласуется с ранее выявленными сложностями в их оценке.\n\n\n\nРис. 5.: График продуктивности запаса с разметкой фаз Кобэ с динамикой вылова\n\n\nГрафик представляет собой комплексную визуализацию, объединяющую три ключевых аспекта анализа продукционной модели: 1) продукционную функцию (дуга), 2) динамику вылова относительно биомассы и 3) фазовые переходы состояния запаса в координатах Кобэ-графика\nНа графике по оси X отображается биомасса (в абсолютных единицах или относительно Bmsy), а по оси Y — вылов и чистая продукция (surplus production). Кривая производственной функции (обычно параболическая для модели Шефера) показывает зависимость между биомассой и устойчивым выловом. Точки на графике представляют фактические годовые значения биомассы и вылова, соединенные линиями в хронологическом порядке. Цвет точек кодирует фазовое состояние запаса согласно классификации Kobe: зеленый — устойчивое состояние (B/Bmsy, F/Fmsy), желтый/оранжевый — перелов (B/Bmsy, F/Fmsy или B/Bmsy, F/Fmsy), красный — коллапс (B/Bmsy, F/Fmsy).\n\n\n\nРис. 6.: Кобэ-график (B/Bmsy vs F/Fmsy) с динамикой вылова\n\n\nГрафик Кобэ, генерируемый функцией jbplot_kobe(fit), представляет собой фазовый портрет, где по оси X отложено отношение биомассы к целевому уровню (B/Bmsy), а по оси Y — отношение промысловой смертности к устойчивому уровню (F/Fmsy). Этот график разделен на четыре квадранта, определяющих статус запаса. Зеленый квадрант (B/Bmsy &gt; 1, F/Fmsy &lt; 1) соответствует устойчивому состоянию без перелова. Желтый квадрант (B/Bmsy &gt; 1, F/Fmsy &gt; 1) сигнализирует о риске перелова. Оранжевый квадрант (B/Bmsy &lt; 1, F/Fmsy &gt; 1) указывает на активный перелов, а желтый (B/Bmsy &lt; 1, F/Fmsy &lt; 1) — на фазу восстановления запаса.\nВ нашем анализе целевые ориентиры рассчитаны на основе параметров модели: Bmsy = K/2 = 257.14/2 ≈ 128.57, а MSY = r×K/4 ≈ 0.269×257.14/4 ≈ 17.29. На графике отображена траектория запаса с 2005 по 2024 годы, где каждая точка соответствует медианным оценкам за год, а соединяющие их линии показывают хронологическую динамику. В 2005 году запас находился в идеальном состоянии: B/Bmsy = 1.83 (95% ДИ: 1.25–2.52), F/Fmsy = 0.15 (0.09–0.26), что помещает его глубоко в зеленый квадрант.\nПериод 2010-2015 годов демонстрирует критическое ухудшение состояния: к 2013 году B/Bmsy снижается до 0.89 (0.64–1.15), а F/Fmsy достигает пика 1.74 (1.16–2.86) в 2011 году, что соответствует оранжевому квадранту активного перелова. Это совпадает с историческими данными о максимальных уловах (28-35 единиц в 2009-2013 гг.), превышающих расчетный MSY (17.29). Последующий период (2016-2024) показывает восстановление: к 2024 году B/Bmsy возрастает до 1.29 (0.90–1.64), а F/Fmsy снижается до 0.51 (0.31–0.93), возвращая запас в зеленый квадрант.\nТекущее положение (2024 год) указывает на восстановление запаса, однако горизонтально вытянутое облако неопределенности для B/Bmsy отражает чувствительность к оценке параметра K, чей широкий доверительный интервал (178–442) обусловлен исторической нехваткой данных о периоде высокой биомассы. Вертикальная компактность F/Fmsy подтверждает относительно точную оценку промысловой смертности. Управленческая рекомендация основывается на медианных значениях: поддержание F/Fmsy на уровне ≈0.5 позволит сохранить запас в устойчивом состоянии. Однако из-за неопределенности в оценке B/Bmsy (риск попадания в желтый квадрант при нижней границе ДИ 0.90) необходим ежегодный мониторинг с обновлением модели по новым данным. Исторический пример перелова 2011-2013 годов демонстрирует последствия превышения F/Fmsy &gt;1.5, что должно учитываться при установке лимитов вылова.\n\n7.4.1 Дополнительные диагностики\n\n# Дополнительные диагностики:\njbplot_runstest(fit)    # Тест на случайность остатков\njbplot_logfits(fit)     # Графики в логарифмической шкале\njbplot_procdev(fit)     # Отклонения процесса\n\n# Сохранение временных рядов результатов\nwrite.csv(fit$timeseries, file = \"results.csv\", row.names = FALSE)\n\n\n\n\nРис. 7.: График теста серий (runs test) для диагностики остатков\n\n\nДублирование графика остатков, но для каждого индекса выводится отдельный график. На графике отображаются остатки модели (разницы между наблюдаемыми и предсказанными значениями индексов обилия) в виде последовательности точек, упорядоченных по времени.Тест серий (runs test) анализирует последовательность чередований положительных и отрицательных остатков. Случайное распределение остатков (что является желаемым результатом) будет проявляться в частом чередовании положительных и отрицательных значений. Напротив, наличие длинных серий (несколько положительных или отрицательных остатков подряд) может указывать на:\n\nНеучтенные временные зависимости в данных\nНеадекватность структуры модели (например, пропущенные важные переменные)\nСистематические ошибки в данных\nНеправильную спецификацию функциональной формы модели\n\nГрафик отклонений процесса (Process Deviations) в JABBA\n\n\n\nРис. 8.: Отклонения процесса\n\n\nГрафик отклонений процесса (jbplot_procdev(fit)) отображает различия между фактической динамикой биомассы и теоретическими предсказаниями продукционной модели. Эти отклонения (Bdev) количественно выражают влияние неучтенных моделью факторов на популяцию — от климатических аномалий до изменений в кормовой базе. В нашем анализе медианные значения Bdev колеблются в узком диапазоне от -0.024 (2011) до +0.021 (2017), при этом все 95% доверительные интервалы включают ноль. Это свидетельствует об отсутствии статистически значимых отклонений, что подтверждает адекватность базовой модели Шефера. Биологически положительные Bdev указывают на неожиданный рост биомассы (например, за счет улучшения условий воспроизводства), тогда как отрицательные — на незапланированные потери (эпизоотии, незарегистрированную смертность).\nОсобый интерес представляют два периода: 2011 год с минимальным Bdev (-0.024) совпадает с пиком промысловой нагрузки (F/Fmsy ≈ 1.74), что может отражать дополнительную естественную смертность, вызванную переловом. В 2017 году положительное отклонение (+0.021) соответствует фазе активного восстановления запаса. Важно, что 80% лет показывают абсолютные значения Bdev &lt; 0.01 — исключительно высокий показатель, подчеркивающий надежность модели. Приемлемым диапазоном считаются отклонения в пределах ±0.05 при сохранении доверительных интервалов, пересекающих ноль; наши данные существенно строже этих критериев.\nСущественное влияние на отклонения процесса оказывает неучтенный вылов. Если такой вылов присутствует, модель, не получая данных о реальном изъятии, будет систематически переоценивать биомассу. Это проявляется как стабильно отрицательные Bdev, особенно выраженные в периоды интенсивного промысла. Например, при ежегодном неучтенном изъятии в 20% от официального улова, медианные отклонения сместились бы в зону -0.05…-0.10, а доверительные интервалы перестали бы включать ноль. В нашем случае отсутствие таких систематических сдвигов (разброс Bdev симметричен относительно нуля) позволяет заключить, что неучтенный вылов не является критическим фактором для данной популяции. Однако для окончательных выводов требуется анализ ретроспективных данных по промысловому усилию и независимая верификация учетных методик.\nПомимо визуализации, используя нижеприведенный скрипт, можно получить фактические значения, например, с 90%-ным доверительным интервалом: years &lt;- fit$yr\n\n# Агрегировать Bdev по годам (медиана и 90% интервал)\n\nproc_dev \\&lt;- aggregate(Bdev \\~ year, data = fit\\$kbtrj, FUN = function(x) c(median = median(x), lci = quantile(x, 0.05), uci = quantile(x, 0.95)))\n\nprint(proc_dev)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Продукционная модель JABBA</span>"
    ]
  },
  {
    "objectID": "chapter 6.html#ретроспективный-анализ",
    "href": "chapter 6.html#ретроспективный-анализ",
    "title": "7  Продукционная модель JABBA",
    "section": "7.5 Ретроспективный анализ",
    "text": "7.5 Ретроспективный анализ\nМы переходим к ретроспективному анализу (hindcasting), который является важным инструментом для оценки устойчивости модели и ее чувствительности к новым данным. В ретроспективном анализе модель последовательно переоценивается с исключением последних лет данных (по одному году за раз, в данном случае от 1 до 5 лет). Это позволяет проверить, насколько сильно меняются оценки ключевых параметров и статуса запаса при поступлении новых данных.\nВ вашем скрипте ретроспективный анализ запускается функцией `hindcast_jabba()`, которая использует исходные настройки модели (`jbinput`) и результаты базовой оценки (`fit`). Аргумент `peels = 1:5` указывает, что нужно последовательно удалять от 1 до 5 последних лет данных. Результаты сохраняются в объект `hc`.\nЗатем с помощью функции `jbplot_retro()` визуализируются результаты ретроспективного анализа. График показывает, как меняется оценка биомассы (или B/Bmsy) при исключении данных за последние годы. На графике будет изображена траектория базовой оценки (со всеми данными) и траектории, полученные при удалении 1, 2, 3, 4 и 5 лет. Также рассчитывается и отображается статистика Мона (Mohn’s rho), которая количественно оценивает смещение ретроспективных оценок относительно базовой.\n\n# ------------------- 5. РЕТРОСПЕКТИВНЫЙ АНАЛИЗ --------------------\n\n# Создание папки для результатов ретроспективы\nretro.dir &lt;- file.path(output.dir, \"retro\")\ndir.create(retro.dir, showWarnings = FALSE)\n\n# Запуск ретроспективного анализа (убираем по 1-5 лет)\nhc &lt;- hindcast_jabba(jbinput = jbinput, fit = fit, peels = 1:5)\n\n# Визуализация ретроспективного анализа\nmohnsrho &lt;- jbplot_retro(\n  hc, \n  as.png = FALSE,         # Чтобы сохранить как PNG-файл установите TRUE\n  output.dir = retro.dir,\n  xlim = c(2007, 2022)   # Ограничения по годам на графике\n)\n\n# Кросс-валидация\nmase &lt;- jbplot_hcxval(hc, as.png = FALSE, output.dir = retro.dir)\n\nСтатистика Мона (Mohn’s rho):\nКлючевой показатель смещения, рассчитываемый как относительная разница между ретроспективной и базовой оценкой в год исключения:\n\\[\n\\rho = \\frac{X_{\\text{ретро}} - X_{\\text{база}}}{X_{\\text{база}}}\n\\]\n\n&gt; mohnsrho\n                 B           F         Bmsy        Fmsy         procB\n2024   -0.01949857  0.01635894  0.031098563 -0.05870471  0.0019184659\n2023    0.06336652 -0.05341885 -0.009782004  0.03945419 -0.0004440846\n2022   -0.04605748  0.04811313 -0.043482407  0.10142418 -0.0029895725\n2021   -0.04274631  0.03790912  0.014020696 -0.03150997  0.0011936097\n2020   -0.04268405  0.04748624 -0.034149276  0.04684297 -0.0006575862\nrho.mu -0.01752398  0.01928972 -0.008458886  0.01950133 -0.0001958335\n               MSY\n2024    0.02871203\n2023   -0.02266077\n2022   -0.03747819\n2021    0.02474720\n2020    0.00148479\nrho.mu -0.00103899\n&gt; \n\n\n\n\nРис. 9.: Графики ретроспективного анализа\n\n\n\nНаши результаты:\n\nБиомасса (*Bм): ρ=−0.018 (слабое отрицательное смещение)\nСмертность (F): ρ=+0.019 (слабое положительное смещение)\nMSY: ρ=−0.001 (незначимое смещение) Критерий: ∣ρ∣&lt;0.2 приемлемо наши значения ≪0.2.\n\nВизуализация (jbplot_retro) показывает:\n\nКак меняется траектория биомассы при исключении данных\n“Веер” расходящихся линий: чем сильнее расхождение, тем выше нестабильность модели\nВ вашем случае линии остаются близкими — модель устойчива.\n\n\nМетрика MASE (Mean Absolute Scaled Error).\nКросс-валидация с помощью jbplot_hcxval() оценивает предсказательную способность модели. Для каждого “среза” (peel) модель предсказывает индекс обилия для удаленных лет, а затем эти предсказания сравниваются с фактическими наблюдениями. Рассчитывается MASE (Mean Absolute Scaled Error) — средняя абсолютная ошибка прогноза, нормированная на ошибку наивного прогноза (который предполагает, что будущее значение равно последнему наблюдённому).\n\\[\n\\mathrm{MASE} = \\frac{\\text{Средняя ошибка прогноза}}{\\text{Средняя ошибка наивного прогноза}}\n\\]\n\nMASE &lt; 1: Модель лучше наивного метода (предсказывающего “завтра=сегодня”)\nMASE &gt; 1: Модель работает хуже наивного метода\n\n\n\n\nРис. 10.: Метрика MASE\n\n\n\n&gt; mase\n  Index      MASE  MASE.adj     MAE.PR   MAE.base n.eval\n1  CPUE 0.6806899 0.6402326 0.13413055 0.19705090      5\n2  BESS 0.9539647 0.6632760 0.07763672 0.08138322      5\n3 joint 0.7605651 0.7605651 0.10588363 0.13921706     10\n\nНаши результаты показывают, что для CPUE модель предсказывает лучше, чем наивный метод (0.68&lt;1), а для BESS — немного хуже (0.95≈1). Совместный MASE (0.76) указывает на удовлетворительную общую прогнозную способность. Однако для индекса BESS стоит обратить внимание на возможные улучшения.\n\n\n\n\n\n\n\n\nИндекс\nMASE\nИнтерпретация\n\n\n\n\nCPUE\n0.68\nХорошо: Прогноз на 32% точнее наивного\n\n\nBESS\n0.95\nУдовлетворительно: Почти эквивалентен наивному методу\n\n\nСовместно\n0.76\nПриемлемая общая точность\n\n\n\nПочему это важно?\n\nДля управления запасами:\n\n\nСтабильность Mohn’s rho (ρ≈0) означает, что текущие рекомендации по вылову не изменятся радикально при получении новых данных.\nНизкий MASE подтверждает надежность краткосрочных прогнозов.\n\n\nДля диагностики модели:\n\n\nСистематическое смещение ρB&gt;0.3 могло бы указывать на переоценку запаса (риск перелова).\nMASE &gt; 1 для BESS требует улучшения описания этого индекса (например, через калибровку q).\n\n\nИсторический контекст:\nВ наших данных слабое смещение для MSY (ρ=−0.001) подтверждает, что модель корректно определяет максимальный устойчивый вылов (17.29), несмотря на проблемы с оценкой r (PPMR=1.47).\n\nВыводы для нашего случая:\nРетроспективный анализ показал:\n\nВысокую стабильность: Смещения параметров статистически незначимы.\nУдовлетворительную прогнозную силу: Особенно для CPUE (MASE=0.68).\nОбласть улучшения: Индекс BESS требует внимания (MASE=0.95), возможно, за счет включения ковариат или пересмотра ошибок наблюдений.\nНадежность управленческих выводов: Текущие оценки статуса запаса (B/Bmsy = 1.29, F/Fmsy = 0.51) устойчивы к добавлению новых данных.\n\nЭтот этап завершает валидацию модели, подтверждая, что она пригодна для разработки рекомендаций по управлению промыслом.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Продукционная модель JABBA</span>"
    ]
  },
  {
    "objectID": "chapter 6.html#прогнозирование",
    "href": "chapter 6.html#прогнозирование",
    "title": "7  Продукционная модель JABBA",
    "section": "7.6 Прогнозирование",
    "text": "7.6 Прогнозирование\nПрогнозирование в JABBA представляет собой заключительный этап оценки запасов, позволяющий смоделировать будущую динамику популяции при различных сценариях управления промыслом. В нашем случае был выполнен 10-летний стохастический прогноз (2025-2034 гг.), основанный на текущем состоянии запаса, где биомасса в 2024 году оценивается в 148.6 тыс. т при соотношении B/Bmsy = 1.29 и промысловой нагрузке F/Fmsy = 0.51. Были рассмотрены четыре сценария годового изъятия: консервативный (10 тыс. т), умеренные (12 и 14 тыс. т) и интенсивный (16 тыс. т), что соответствует 58-93% от расчетного максимального устойчивого улова (MSY = 17.29).\n\n# ------------------- 6. ПРОГНОЗИРОВАНИЕ --------------------\n\n# Прогноз на основе F (ловушечное усилие)\nfw1 &lt;- fw_jabba(\n  fit,\n  nyears = 10,       # Длина прогноза (лет)\n  imp.yr = 1,        # Год внедрения новых правил\n  imp.values = seq(10, 16, 2), # Варианты управления (уровни улова)\n  quant = \"Catch\",   # Прогнозировать по уловам\n  type = \"abs\",      # Абсолютные значения\n  stochastic = TRUE  # Стохастический прогноз\n)\n\n# Графики ансамбля прогнозов\njbpar(mfrow = c(3, 2)) # Настройка макета графиков (3 строки, 2 столбца)\njbplot_ensemble(fw1)    # Основной график прогнозов\n\n\n\n\nРис. 11.: Прогностические графики\n\n\nКлючевой особенностью прогноза является его стохастическая природа — каждый сценарий учитывает неопределенность параметров модели, включая вариабельность темпа роста популяции (r) и ёмкости среды (K), а также ошибку процесса (σ² = 0.0035). Это позволяет получить не точечные предсказания, а вероятностные распределения будущих состояний. Результаты показывают дифференцированную динамику: при вылове 10-12 тыс. т биомасса демонстрирует устойчивый рост (до 178 и 168 тыс. т к 2034 году), сценарий с 14 тыс. т стабилизирует запас на уровне около 158 тыс. т, тогда как интенсивный вылов (16 тыс. т) приводит к постепенному снижению биомассы до 147 единиц.\nБиологическая интерпретация этих траекторий основывается на соотношении прогнозируемых показателей с целевыми ориентирами. Для сценария C16 к 2034 году ожидается приближение B/Bmsy к 1.14, что хотя и остается выше единицы, но указывает на сокращение “буферного” запаса. Особое внимание следует уделить чувствительности модели к оценке параметра r, чья высокая неопределенность (PPMR = 1.47) может существенно влиять на долгосрочные прогнозы — например, если реальный темп роста окажется ближе к нижней границе доверительного интервала (0.15), сценарий C16 может привести к переходу в зону перелова уже к 2030 году.\nУправленческие рекомендации, вытекающие из анализа, предлагают компромисс между экономической эффективностью и предосторожностью. Оптимальным признается диапазон вылова 12-14 единиц, обеспечивающий 70-80% от потенциального прироста продукции без риска снижения запаса ниже целевого уровня. Сценарий C16 может рассматриваться как временная мера только при наличии подтверждающих данных о высоком продуктивном потенциале популяции, но требует ежегодного мониторинга с коррекцией лимитов. Визуализация результатов через jbplot_ensemble() наглядно демонстрирует “веер” траекторий, где расхождение доверительных интервалов усиливается к концу периода прогноза — это прямое отражение кумулятивного эффекта неопределенности параметров и случайных факторов среды.\nВажным аспектом является интеграция прогноза в адаптивную систему управления: установив начальный лимит на уровне 14 тыс. т, следует планировать повторные оценки по данным ежегодных съемок, что позволит корректировать вылов в зависимости от фактического состояния запаса. Такой подход минимизирует риски, связанные с ограниченной точностью продукционных моделей при работе с данными низкой разрешающей способности. Исторический урок нашего анализа — пример перелова 2011-2013 годов — напоминает, что превышение F/Fmsy &gt; 1.5 способно за несколько лет подорвать даже запас, находившийся в благополучном состоянии.\nПри работе с JABBA есть трудности в получении различных графиков и фактических значений, например прогнозных. Ниже приводятся скрипты получения отдельных прогностических графиков и таблицы прогнозных значений выловов и биомасс.\n\n# График для B/Bmsy с кастомизацией\njbplot_ensemble(\n  fw1,\n  subplots = c(1),        # Только B/Bmsy\n  add = TRUE,             # Добавить к текущему графику\n  xlim = c(2020, 2035),   # Ограничение по годам\n  legend.loc = \"topleft\"  # Позиция легенды\n)\n\n\n\n\nРис. 12.: Отдельный график прогноза\n\n\nИзвлечение прогостических данных:\n\n# Фильтрация данных прогноза (2025-2034) для выбранных сценариев\nforecast_data &lt;- subset(\n  fw1, \n  year %in% 2025:2034 &    # Годы прогноза\n    run %in% c(\"C10\", \"C12\", \"C14\", \"C16\") & # Сценарии управления\n    type == \"prj\"           # Только прогнозные значения\n)\n\n# Расчет медиан биомассы (B) по годам и сценариям\nmedian_B &lt;- aggregate(\n  B ~ year + run,          # Формула: группировка по году и сценарию\n  data = forecast_data, \n  FUN = median             # Функция агрегации\n)\n\n# Расчет медиан улова (Catch) по годам и сценариям\nmedian_Catch &lt;- aggregate(\n  Catch ~ year + run, \n  data = forecast_data, \n  FUN = median\n)\n\n# Преобразование в широкий формат (годы по строкам, сценарии по столбцам)\nb_table &lt;- dcast(median_B, year ~ run, value.var = \"B\")\ncatch_table &lt;- dcast(median_Catch, year ~ run, value.var = \"Catch\")\n\n# Вывод таблиц\nprint(\"Медианная биомасса:\")\nprint(b_table)\n\nprint(\"Медианные уловы:\")\nprint(catch_table)\n\n# Сохранение таблиц\nwrite.csv(b_table, \"biomass_forecast.csv\", row.names = TRUE)\nwrite.csv(catch_table, \"catch_forecast.csv\", row.names = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Продукционная модель JABBA</span>"
    ]
  },
  {
    "objectID": "chapter 10.html",
    "href": "chapter 10.html",
    "title": "11  Съёмка: оптимизация маршрута",
    "section": "",
    "text": "11.1 Введение\nЭтот R-скрипт выполняет геопространственный анализ и моделирование станций исследований в ходе научно-исследовательских съемок.\nОсновная цель\nСкрипт моделирует оптимальные маршруты для станций в разных вариантах исследовательского полигона, чтобы определить, как изменение площади и формы полигона влияет на длину необходимого маршрута. Полный скрипт можно скачать по ссылке.\nДля работы скрипта:\nПошаговая работа скрипта\n1. Подготовка данных\n2. Моделирование расширенных полигонов\nСоздан алгоритм, который асимметрично расширяет полигон на север (имитируя расширение зоны исследования в арктическом направлении):\n3. Генерация траловых станций\n4. Оптимизация маршрутов\nКлючевая часть скрипта — решение задачи коммивояжера (TSP) для оптимизации маршрута судна:\n5. Анализ результатов\nСкрипт рассчитывает и сравнивает:\nИнтерпретация результатов\nИз сводной таблицы видно, как увеличение площади полигона влияет на длину маршрута:\nВажные наблюдения:\nПрактическое применение\nЭтот анализ полезен для:\nСкрипт демонстрирует, как геопространственный анализ и алгоритмы оптимизации могут помочь в принятии решений при планировании полевых исследований водных биоресурсов, особенно в условиях арктических морей, где логистика особенно сложна и дорогостояща.\n# ========================================================================================================================\n# ПРАКТИЧЕСКОЕ ЗАНЯТИЕ: ПЛАНИРОВАНИЕ МАРШРУТА СЪЕМКИ ПРИ ОГРАНИЧЕННОМ ВРЕМЕННОМ РЕСУРСЕ\n# Курс: \"Современные методы анализа данных в оценке водных биоресурсов\"\n# Автор: Баканев С.В.\n# Дата: 24.04.2025\n# \n# Цель: Освоить методы геопространственного анализа и оптимизации для планирования научно-исследовательских съемок\n# \n# Структура:\n# 1. Загрузка пакетов и настройка среды\n# 2. Загрузка и подготовка исходных данных\n# 3. Создание расширенных полигонов\n# 4. Генерация схемы станций\n# 5. Построение оптимальных маршрутов\n# 6. Визуализация результатов\n# 7. Сравнительный анализ и экспорт результатов\n# \n# Описание: Скрипт демонстрирует подход к планированию морских исследований с использованием\n#           методов пространственного анализа и решения задачи коммивояжера (TSP).\n#           Моделируются различные сценарии расширения района работ с оценкой\n#           их влияния на протяженность маршрута.\n# ========================================================================================================================\n\n# ЗАГРУЗКА НЕОБХОДИМЫХ ПАКЕТОВ -----------------------------------------------\n# Все пакеты должны быть предварительно установлены (install.packages(...))\n\nlibrary(sf)            # Базовые операции с пространственными данными (вектор)\n\nLinking to GEOS 3.13.1, GDAL 3.10.2, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(tidyverse)     # Метасборка пакетов для обработки и визуализации данных\n\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.4     v readr     2.1.5\nv forcats   1.0.0     v stringr   1.5.1\nv ggplot2   3.5.2     v tibble    3.2.1\nv lubridate 1.9.4     v tidyr     1.3.1\nv purrr     1.0.4     \n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(rnaturalearth) # Загрузка готовых полигональных карт мира (для фона)\nlibrary(ggplot2)       # Создание продвинутых графиков (входит в tidyverse, но подключаем для ясности)\nlibrary(geosphere)     # Геодезические расчеты на сфере (расчет расстояний между точками)\nlibrary(TSP)           # Решение \"Задачи коммивояжера\" (Traveling Salesman Problem)\n\n\n# 1. НАСТРОЙКА СРЕДЫ ----------------------------------------------------------\n# Установка рабочей директории (замените на путь к своей папке)\nsetwd(\"C:/SURVEY/\")\n\n# 2. ЗАГРУЗКА ИСХОДНЫХ ДАННЫХ -------------------------------------------------\n# Загрузка предварительно созданного файла с полигонами\nload(\"polygons.RData\")\n\n# Фильтрация полигона за 2020 год и извлечение его геометрии\npolygon_2020 &lt;- polygons %&gt;%\n  filter(YEAR == 2020) %&gt;%\n  st_geometry()\n\n# 3. ПРЕОБРАЗОВАНИЕ СИСТЕМЫ КООРДИНАТ -----------------------------------------\n# Преобразование из географических координат (WGS84) в проекцию UTM (зона 40N).\n# Это необходимо для корректного вычисления площадей и расстояний в метрах.\npolygon_2020_utm &lt;- st_transform(polygon_2020, 32640)\n\n# 4. РАСЧЕТ ПЛОЩАДИ ИСХОДНОГО ПОЛИГОНА ----------------------------------------\n# Вычисление площади в кв. метрах (st_area) и конвертация в кв. километры (/ 1e6)\narea_km2_original &lt;- (st_area(polygon_2020_utm) / 1e6) %&gt;% as.numeric()\n# Вывод результата в консоль\ncat(\"Площадь полигона 2020 года: \", round(area_km2_original, 2), \" км²\\n\")\n\nПлощадь полигона 2020 года:  63101.31  км&lt;U+00B2&gt;\n\n# 5. ФУНКЦИЯ ДЛЯ ЭКСПАНСИИ ПОЛИГОНА НА СЕВЕР -----------------------------------\n# Создание функции, которая \"растягивает\" северную часть полигона на заданный множитель.\n# Аргументы:\n#   poly - исходный полигон (в UTM)\n#   factor - коэффициент расширения (например, 1.5 - увеличить на 50%)\nexpand_polygon_north &lt;- function(poly, factor) {\n  # Извлечение координат вершин полигона и преобразование в DataFrame\n  coords &lt;- st_coordinates(poly)[, 1:2] %&gt;%\n    as.data.frame() %&gt;%\n    rename(x = X, y = Y)\n\n  # ЛОГИКА РАСШИРЕНИЯ:\n  # 1. Определяем \"северную\" часть полигона (верхние 30% точек по оси Y)\n  north_threshold &lt;- quantile(coords$y, 0.7)\n  # 2. Находим общий разброс полигона по оси Y (высоту)\n  y_range &lt;- diff(range(coords$y))\n  # 3. Сдвигаем все северные точки на север на величину (factor - 1) * высоту_полигона\n  coords[coords$y &gt;= north_threshold, \"y\"] &lt;-\n    coords[coords$y &gt;= north_threshold, \"y\"] + y_range * (factor - 1)\n\n  # Создание нового полигона из модифицированных точек:\n  # 1. Преобразование точек в spatial object\n  # 2. Объединение точек в один объект\n  # 3. Построение выпуклой оболочки для получения гладкого полигона\n  expanded_poly &lt;- st_as_sf(coords, coords = c(\"x\", \"y\"), crs = st_crs(poly)) %&gt;%\n    st_combine() %&gt;%\n    st_convex_hull()\n\n  return(expanded_poly)\n}\n\n# 6. СОЗДАНИЕ НАБОРА ЭКСПАНДИРОВАННЫХ ПОЛИГОНОВ -------------------------------\n# Применение функции к коэффициентам 1.5, 2 и 3\nfactors &lt;- c(1.5, 2, 3)\nexpanded_polygons &lt;- map(factors, ~ expand_polygon_north(polygon_2020_utm, .x))\n\n# 7. РАСЧЕТ ПЛОЩАДЕЙ НОВЫХ ПОЛИГОНОВ ------------------------------------------\nareas_expanded &lt;- map_dbl(expanded_polygons, ~ {\n  (st_area(.x) / 1e6) %&gt;% as.numeric() # Площадь в кв. км.\n})\n\n# 8. ФОРМИРОВАНИЕ ЕДИНОЙ ТАБЛИЦЫ С ВСЕМИ ПОЛИГОНАМИ ---------------------------\n# Создание именованного списка всех полигонов\nall_polygons &lt;- list(\n  Original = polygon_2020_utm,\n  Expanded_x1_5 = expanded_polygons[[1]],\n  Expanded_x2 = expanded_polygons[[2]],\n  Expanded_x3 = expanded_polygons[[3]]\n)\n\n# Вектор меток и площадей\nlabels &lt;- c(\"Original\", \"Expanded_x1_5\", \"Expanded_x2\", \"Expanded_x3\")\nareas &lt;- c(area_km2_original, areas_expanded)\n\n# Комбинирование геометрий и создание итогового SF-объекта\ngeometry &lt;- do.call(c, all_polygons) # Объединение геометрий в один вектор\n\npolygon_df &lt;- tibble(\n  label = factor(labels, levels = labels), # Метка как фактор для сохранения порядка\n  area_km2 = areas,                        # Площадь\n  geometry = st_sfc(geometry)              # Геометрия\n) %&gt;%\n  st_as_sf() # Преобразование в пространственный объект\n\n# 9. ГЕНЕРАЦИЯ СЕТКИ ТОЧЕК (СТАНЦИЙ) ВНУТРИ КАЖДОГО ПОЛИГОНА -----------------\n# Генерация 137 точек по регулярной сетке внутри каждого полигона.\n# Используется rowwise для применения функции к каждой строке-полигону.\nsample_points &lt;- polygon_df %&gt;%\n  rowwise() %&gt;%\n  mutate(points = list(st_sample(geometry, size = 137, type = \"regular\"))) %&gt;%\n  ungroup()\n\n# 10. СОЗДАНИЕ ЕДИНОЙ ТАБЛИЦЫ ВСЕХ ТОЧЕК --------------------------------------\n# Преобразование вложенного списка точек в плоскую таблицу\npoints_list &lt;- map2(sample_points$geometry, sample_points$label, ~ {\n  st_sample(.x, size = 137, type = \"regular\") %&gt;% # Извлечение точек\n    st_as_sf() %&gt;%                                # Конвертация в SF\n    mutate(label = .y)                            # Добавление метки полигона\n})\n\n# Объединение всех точек в один DataFrame\npoints_df &lt;- do.call(rbind, points_list) %&gt;%\n  rename(geometry = x) %&gt;%\n  st_set_geometry(\"geometry\") %&gt;%\n  st_set_crs(st_crs(polygon_2020_utm)) # Важно: явно задаем систему координат\n\n# 11. ПРЕОБРАЗОВАНИЕ В WGS84 ДЛЯ ВИЗУАЛИЗАЦИИ И РАСЧЕТОВ ----------------------\n# Большинство картографических пакетов и функций расчета расстояний работают с WGS84\npolygon_wgs84 &lt;- st_transform(polygon_df, 4326) # WGS84 (широта/долгота)\npoints_wgs84 &lt;- st_transform(points_df, 4326)\n\n# 12. ЗАГРУЗКА ФОНОВОЙ КАРТЫ (ГРАНИЦЫ РОССИИ) ---------------------------------\nrussia &lt;- ne_countries(scale = \"medium\", country = \"Russia\", returnclass = \"sf\") %&gt;%\n  st_transform(4326) # Преобразование в WGS84\n\n# 13. ВИЗУАЛИЗАЦИЯ: ПОЛИГОНЫ И ТОЧКИ ------------------------------------------\n# Построение карты с фацетами (subplots) для каждого варианта полигона\nggplot() +\n  geom_sf(data = russia, fill = \"lightgray\", color = \"black\", linewidth = 0.3) + # Фон\n  geom_sf(data = polygon_wgs84, aes(fill = label), alpha = 0.6, color = \"darkred\", linewidth = 0.5) + # Полигоны\n  geom_sf(data = points_wgs84, aes(color = label), shape = 16, size = 1) + # Точки\n  facet_wrap(~ label, scales = \"fixed\") + # Фацеты по варианту полигона\n  coord_sf(xlim = c(35, 50), ylim = c(68, 75)) + # Обрезка карты до нужного региона\n  labs(\n    title = \"Полигоны с разной площадью и траловыми станциями\",\n    subtitle = \"Регулярное распределение 137 точек внутри каждого полигона\",\n    fill = \"Вариант\", color = \"Вариант\"\n  ) +\n  theme_minimal() +\n  theme(strip.background = element_rect(fill = \"lightblue\"))\n\n\n\n\n\n\n\n# 14. ФУНКЦИЯ ДЛЯ ПОСТРОЕНИЯ ОПТИМАЛЬНОГО МАРШРУТА (TSP) ----------------------\n# Создает маршрут, проходящий через все точки, с фиксацией начала и конца.\ncreate_route &lt;- function(points) {\n  # Извлечение координат (долгота, широта) из SF-объекта\n  coords &lt;- st_coordinates(points)\n\n  # СТРАТЕГИЯ: Начало и конец маршрута - две самые западные точки.\n  # Это имитирует выход судна из порта и возврат в него.\n  west_points &lt;- order(coords[,1])[1:2] # Индексы двух точек с min долготой\n\n  # Расчет матрицы расстояний между всеми точками (в метрах)\n  dist_matrix &lt;- distm(coords, fun = distHaversine)\n\n  # СОЗДАНИЕ И НАСТРОЙКА ЗАДАЧИ KОММИВОЯЖЕРА (TSP):\n  tsp &lt;- TSP(dist_matrix / 1000) # Создание объекта TSP (расстояния в км)\n  atsp &lt;- as.ATSP(tsp)           # Преобразование в Asymmetric TSP\n\n  # ФИКСАЦИЯ НАЧАЛА И КОНЦА:\n  # Обнуляем расстояния ДО стартовой точки -&gt; она станет первой.\n  atsp[, west_points[1]] &lt;- 0\n  # Обнуляем расстояния ОТ конечной точки -&gt; она станет последней.\n  atsp[west_points[2], ] &lt;- 0\n\n  # РЕШЕНИЕ TSP: метод \"Ближайшая вставка\" (быстрый, но не всегда оптимальный)\n  tour &lt;- solve_TSP(atsp, method = \"nearest_insertion\")\n\n  # ФОРМИРОВАНИЕ ПОСЛЕДОВАТЕЛЬНОСТИ ТОЧЕК МАРШРУТА:\n  # Начало -&gt; Маршрут -&gt; Конец. unique() убирает возможные дубликаты.\n  ordered_indices &lt;- c(west_points[1], as.integer(tour), west_points[2])\n  ordered_indices &lt;- unique(ordered_indices)\n\n  return(ordered_indices)\n}\n\n# 15. ПОСТРОЕНИЕ МАРШРУТОВ ДЛЯ КАЖДОГО ПОЛИГОНА -------------------------------\n# Применение функции create_route к каждой группе точек\nroutes &lt;- points_wgs84 %&gt;%\n  group_by(label) %&gt;%        # Группировка по варианту полигона\n  group_modify(~ {\n    ids &lt;- create_route(.x)  # Получение упорядоченного списка индексов точек\n    # Соединение точек в линию (маршрут)\n    route_line &lt;- st_combine(.x$geometry[ids]) %&gt;%\n      st_cast(\"LINESTRING\")  # Явное указание типа геометрии\n\n    tibble(geometry = st_sfc(route_line, crs = 4326)) # Возврат маршрута\n  }) %&gt;%\n  st_as_sf() # Преобразование результата в SF-объект\n\n# 16. ВИЗУАЛИЗАЦИЯ: ПОЛИГОНЫ, ТОЧКИ И МАРШРУТЫ --------------------------------\nggplot() +\n  geom_sf(data = russia, fill = \"lightgray\", color = \"black\", linewidth = 0.3) +\n  geom_sf(data = polygon_wgs84, aes(fill = label), alpha = 0.6, linewidth = 0.5) +\n  geom_sf(data = points_wgs84, aes(color = label), shape = 16, size = 1) +\n  geom_sf(data = routes, color = \"darkblue\", linewidth = 0.8) + # Маршруты\n  facet_wrap(~ label, scales = \"fixed\") +\n  coord_sf(xlim = c(35, 50), ylim = c(68, 74.5)) +\n  labs(\n    title = \"Полигоны с оптимальными маршрутами\",\n    subtitle = \"Начало и конец маршрута - две самые западные точки\",\n    fill = \"Вариант\", color = \"Вариант\"\n  ) +\n  theme_minimal() +\n  theme(strip.background = element_rect(fill = \"lightblue\"))\n\n\n\n\n\n\n\n# 17. СОХРАНЕНИЕ КАРТЫ В ФАЙЛ -------------------------------------------------\nggsave(\"polygon_with_optimal_routes.png\", width = 12, height = 10, dpi = 300)\n\n# 18. СОХРАНЕНИЕ ДАННЫХ МАРШРУТОВ (Ошибка: файл уже существует) ---------------\n# st_write(routes, \"optimal_routes.gpkg\") # Раскомментируйте и используйте append=FALSE для перезаписи\n# st_write(routes, \"optimal_routes.gpkg\", append=FALSE)\n\n# 19. ФИНАЛЬНЫЙ СРАВНИТЕЛЬНЫЙ АНАЛИЗ ------------------------------------------\n# Создание сводной таблицы с ключевыми метриками для каждого сценария\nsurvey_summary &lt;- routes %&gt;%\n  # Добавление данных о площади из таблицы полигонов\n  left_join(st_drop_geometry(polygon_wgs84), by = \"label\") %&gt;%\n  mutate(\n    `Количество тралений` = 137, # Константа по условию задачи\n    # Расчет длины маршрута: st_length(geometry) возвращает длину в метрах, делим на 1000 для перевода в км.\n    `Длина маршрута (км)` = round(as.numeric(st_length(geometry)) / 1000, 1),\n    `Площадь полигона (км2)` = round(area_km2, 1)\n  ) %&gt;%\n  select( # Выбор и переименование колонок для итоговой таблицы\n    Вариант = label,\n    `Количество тралений`,\n    `Длина маршрута (км)`,\n    `Площадь полигона (км2)`\n  )\n\n# 20. ВЫВОД ИТОГОВОЙ ТАБЛИЦЫ В КОНСОЛЬ ----------------------------------------\ncat(\"\\nСводная статистика по вариантам:\\n\")\n\n\nСводная статистика по вариантам:\n\nprint(survey_summary)\n\nSimple feature collection with 4 features and 4 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 36.88572 ymin: 68.49336 xmax: 47.7208 ymax: 74.30314\nGeodetic CRS:  WGS 84\n# A tibble: 4 x 5\n# Groups:   Вариант [4]\n  Вариант     `Количество тралений` `Длина маршрута (км)` Площадь полигона (км~1\n  &lt;fct&gt;                       &lt;dbl&gt;                 &lt;dbl&gt;                  &lt;dbl&gt;\n1 Original                      137                 3630.                 63101.\n2 Expanded_x~                   137                 4489.                 99791.\n3 Expanded_x2                   137                 5367.                135352.\n4 Expanded_x3                   137                 6227.                207066.\n# i abbreviated name: 1: `Площадь полигона (км2)`\n# i 1 more variable: geometry &lt;LINESTRING [arc_degree]&gt;",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Съёмка: оптимизация маршрута</span>"
    ]
  },
  {
    "objectID": "chapter 10.html#введение",
    "href": "chapter 10.html#введение",
    "title": "11  Съёмка: оптимизация маршрута",
    "section": "",
    "text": "Скачайте файл данных (polygons.RData)\nУстановите рабочую директорию в setwd()\nУстановите необходимые пакеты.`\n\n\n\n\nЗагружается полигон за 2020 год из файла polygons.RData\nПолигон преобразуется в систему координат UTM зоны 40N (EPSG:32640) для точных метрических вычислений\nРассчитывается площадь полигона: 63,101.31 км²\n\n\n\n\nexpand_polygon_north() определяет северную часть (верхние 30% точек)\nРасширяет только эту часть на заданный коэффициент\nСоздаются 3 варианта: увеличенные на 1.5x, 2x и 3x\n\n\n\nДля каждого полигона генерируются 137 равномерно распределенных точек (метод “regular”)\nЭто имитирует расположение траловых станций в исследовательском полигоне\nКоличество станций одинаково для всех вариантов полигона\n\n\n\n\nНачало и конец маршрута фиксируются как две самые западные точки (логично для судна, приходящего с запада)\nИспользуется алгоритм ближайшего включения (nearest_insertion)\nМатрица расстояний рассчитывается с помощью distHaversine (точное геодезическое расстояние)\n\n\n\n\nПлощадь каждого полигона\nДлину оптимального маршрута для 137 станций\nВизуализирует все варианты на карте\n\n\n\n\n\n\n\n\n\n\n\n\nВариант\nКоличество тралений\nДлина маршрута (км)\nПлощадь полигона (км²)\n\n\n\n\nOriginal\n137\n3,745\n63,101.3\n\n\nExpanded_x1.5\n137\n4,076\n99,791.0\n\n\nExpanded_x2\n137\n4,701\n135,352.0\n\n\nExpanded_x3\n137\n6,038\n207,066.0\n\n\n\n\n\nПри увеличении площади на 57% (до 99,791 км²) длина маршрута возрастает только на 9% (до 4,076 км)\nПри троекратном увеличении площади (до 207,066 км²) длина маршрута возрастает на 61% (до 6,038 км)\nЭто показывает нелинейную зависимость между площадью полигона и длиной маршрута\n\n\n\n\nПланирования гидробиологических исследований в условиях ограниченного бюджета\nОценки дополнительных затрат при расширении зоны исследования\nОптимизации маршрутов научно-исследовательских судов\nМоделирования последствий изменения границ охраняемых территорий",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Съёмка: оптимизация маршрута</span>"
    ]
  },
  {
    "objectID": "chapter 10.html#пошаговое-описание-скрипта",
    "href": "chapter 10.html#пошаговое-описание-скрипта",
    "title": "11  Стандартизация CPUE",
    "section": "11.2 Пошаговое описание скрипта",
    "text": "11.2 Пошаговое описание скрипта\nСкрипт начинается с загрузки необходимых пакетов для обработки данных, построения моделей и визуализации результатов. Среда настраивается путем установки рабочей директории и фиксации случайного зерна для обеспечения воспроизводимости всех последующих вычислений.\nНа следующем этапе происходит загрузка исходных данных из файла Excel. Данные представляют собой промысловую статистику, содержащую информацию о году, месяце, судне, районе, величине улова на усилие (CPUE) и др. Выполняется их предварительная обработка: фильтрация по осенним месяцам, преобразование типов переменных в факторы и числовой формат, а также удаление пропущенных значений. Поскольку для моделирования с гамма-распределением требуются строго положительные значения, для нулевых и отрицательных величин CPUE рассчитывается и добавляется малая поправка. Для первичного ознакомления с данными строится диаграмма размаха, показывающая распределение CPUE по годам.\nДалее определяются вспомогательные функции. Одна функция предназначена для нормировки рассчитанных индексов либо на среднее значение, либо на значение первого года. Другая функция использует метод маргинальных средних для расчета стандартизированных индексов и их доверительных интервалов на основе подобранной модели. Третья функция реализует расчет индексов и оценку неопределенности через бутстреп для моделей со сложной структурой.\nОсновная часть скрипта посвящена построению и анализу трех типов моделей. Первой подбирается обобщенная линейная модель (GLM) с гамма-распределением ошибок и логарифмической связью. В качестве предикторов используются факторы: год, месяц, судно и район. Для визуальной и численной диагностики адекватности модели выводятся ее сводка, таблица коэффициентов, стандартные диагностические графики и графики остатков, проверенные с помощью пакета DHARMa.\nСледующей строится обобщенная аддитивная модель (GAM). На этом этапе используется та же формула и семейство распределений, что и в GLM, но метод подбора гиперпараметров отличается. Проводится аналогичная диагностика модели с помощью функций summary и gam.check.\nЗатем подбирается обобщенная аддитивная смешанная модель (GAMM), которая дополнительно включает случайный эффект от судна. Это позволяет учесть вариацию, вызванную индивидуальными особенностями каждого судна, которые не описываются другими факторами. Диагностика этой модели более сложна и включает анализ остатков, проверку случайных эффектов и тест на гетероскедастичность.\nПосле построения всех моделей для каждой из них рассчитываются стандартизированные индексы CPUE и их доверительные интервалы. Для GLM и GAM это делается с помощью функции, основанной на маргинальных средних, а для GAMM применяется метод бутстрепа.\nФинальный этап включает объединение результатов всех трех моделей в единую таблицу и их визуальное сравнение на графике. На этот же график добавляются фактические медианные значения CPUE по годам из исходных данных для сопоставления со стандартизированными кривыми. В заключение модели сравниваются по информационным критериям (AIC, BIC) и другим метрикам, чтобы дать рекомендации по выбору наиболее адекватной из них.\nНиже приводится скрипт, а ниже скрипта - описание результатов моделирования.\n\n# ========================================================================================================================\n# ПРАКТИЧЕСКОЕ ЗАНЯТИЕ: СТАНДАРТИЗАЦИЯ CPUE С ИСПОЛЬЗОВАНИЕМ GLM, GAM И GAMM\n# Курс: \"Оценка водных биоресурсов в среде R (для начинающих)\"\n# Автор: Баканев С.В. \n# Дата: 20.08.2025\n# \n# Структура:\n# 1) Загрузка пакетов и настройка среды\n# 2) Загрузка и предварительная обработка данных\n# 3) Вспомогательные функции для расчета индексов\n# 4) Моделирование GLM (Gamma с лог-ссылкой)\n# 5) Моделирование GAM (обобщенная аддитивная модель)\n# 6) Моделирование GAMM (смешанная модель со случайными эффектами)\n# 7) Сравнение моделей и финальная визуализация результатов\n# ========================================================================================================================\n\n\n# ==============================================================================\n# БЛОК 1: ЗАГРУЗКА ПАКЕТОВ И НАСТРОЙКА СРЕДЫ\n# ==============================================================================\n\n# Отключаем вспомогательные сообщения при загрузке пакетов\nsuppressPackageStartupMessages({\n  library(tidyverse)   # Основные пакеты для обработки данных и визуализации\n  library(readxl)      # Чтение данных из Excel-файлов\n  library(mgcv)        # Обобщенные аддитивные модели (GAM)\n  library(gamm4)       # GAM со смешанными эффектами\n  library(emmeans)     # Расчет маргинальных средних и контрастов\n  library(broom)       # Преобразование результатов моделей в таблицы\n  library(broom.mixed) # Поддержка смешанных моделей для broom\n  library(DHARMa)      # Диагностика остатков обобщенных моделей\n  library(knitr)       # Форматирование таблиц для отчетов\n})\n\n# Установка рабочей директории\nsetwd(\"C:/GLM/\")\n\n# Фиксируем случайное зерно для воспроизводимости результатов\nset.seed(42)\n\n# ==============================================================================\n# БЛОК 2: ЗАГРУЗКА И ПРЕДОБРАБОТКА ДАННЫХ\n# ==============================================================================\n\n# Определяем путь к файлу с данными\nDATA_PATH &lt;- \"C:/GLM/data/KARTOGRAPHIC.xlsx\"\n\n# Чтение данных из листа \"FISHERY\" и фильтрация осенних месяцев\nDATA &lt;- read_excel(DATA_PATH, sheet = \"FISHERY\") %&gt;%\n  as_tibble() %&gt;%  # Преобразуем в современный формат таблицы\n  filter(MONTH &gt; 8 & MONTH &lt; 12)  # Сентябрь-ноябрь (осенний сезон)\n\n# Преобразование типов переменных и обработка пропусков\nDATA &lt;- DATA %&gt;%\n  mutate(\n    YEAR = as.factor(YEAR),           # Год как категориальная переменная\n    MONTH = as.factor(MONTH),         # Месяц как фактор\n    CALL = as.factor(CALL),           # Идентификатор судна\n    REGION = as.factor(REGION),       # Рыбохозяйственный район\n    VESSELNUMBER = as.factor(VESSELNUMBER),  # Номер судна\n    CPUE = as.numeric(CPUE)           # Целевой показатель - улов на усилие\n  ) %&gt;%\n  filter(!is.na(CPUE))  # Удаление строк с пропусками в CPUE\n\n# Обработка нулевых значений CPUE для Gamma-моделей\nif (any(DATA$CPUE &lt;= 0, na.rm = TRUE)) {\n  min_pos &lt;- min(DATA$CPUE[DATA$CPUE &gt; 0], na.rm = TRUE)  # Минимальный положительный улов\n  offset &lt;- min_pos / 2  # Величина поправки\n  DATA &lt;- DATA %&gt;% \n    mutate(CPUE_POS = if_else(CPUE &lt;= 0, CPUE + offset, CPUE))  # Добавляем поправку\n} else {\n  DATA &lt;- DATA %&gt;% \n    mutate(CPUE_POS = CPUE)  # Исходные данные если нулей нет\n}\n\n# Рассчитываем медианные значения CPUE по годам из исходных данных\nactual_medians &lt;- DATA %&gt;%\n  group_by(YEAR) %&gt;%\n  summarise(median_cpue = median(CPUE, na.rm = TRUE))\n# Рассчитываем медианные значения CPUE по годам из исходных данных для последующих графиков\nactual_medians\n\n# A tibble: 6 x 2\n  YEAR  median_cpue\n  &lt;fct&gt;       &lt;dbl&gt;\n1 2019        200. \n2 2020        116. \n3 2021        132. \n4 2022         84  \n5 2023         79.4\n6 2024         58.3\n\n# Экспресс-визуализация распределения CPUE по годам\nDATA %&gt;%\n  ggplot(aes(x = YEAR, y = CPUE)) +\n  geom_boxplot(outlier.alpha = 0.2) +\n  labs(title = \"Распределение CPUE по годам\", \n       x = \"Год\", \n       y = \"CPUE (улов на усилие)\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 3: ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ ДЛЯ РАСЧЕТА ИНДЕКСОВ\n# ==============================================================================\n\n# Функция нормировки индексов\nscale_to_index &lt;- function(values, method = c(\"mean\", \"first\")) {\n  method &lt;- match.arg(method)\n  if (method == \"mean\") {\n    # Нормировка на среднее значение\n    return(as.numeric(values) / mean(as.numeric(values), na.rm = TRUE))\n  }\n  if (method == \"first\") {\n    # Нормировка на значение первого года\n    return(as.numeric(values) / as.numeric(values[1]))\n  }\n}\n\n# Функция расчета индексов для GLM/GAM через маргинальные средние\nemmeans_standardized_index &lt;- function(model, variable = \"YEAR\") {\n  out &lt;- suppressWarnings(\n    emmeans(model, \n            specs = as.formula(paste0(\"~ \", variable)), \n            type = \"response\")\n  )\n  df &lt;- as_tibble(out) %&gt;% \n    select(!!sym(variable), response = response, lower.CL, upper.CL)\n  colnames(df) &lt;- c(\"YEAR\", \"value\", \"lcl\", \"ucl\")\n  df\n}\n\n# Функция расчета индексов для GAMM через бутстреп\ncompute_standardized_index &lt;- function(model, base_data, year_levels, predict_fun,\n                                      response_transform = identity, \n                                      n_boot = 200L, \n                                      seed = 7L) {\n  set.seed(seed)\n  acc &lt;- vector(\"list\", length(year_levels))\n  for (i in seq_along(year_levels)) {\n    newdata &lt;- base_data\n    newdata$YEAR &lt;- factor(year_levels[i], levels = levels(base_data$YEAR))\n    preds &lt;- suppressWarnings(predict_fun(model, newdata))\n    mu &lt;- mean(response_transform(preds), na.rm = TRUE)\n    # Бутстреп для оценки неопределенности\n    boot_vals &lt;- replicate(n_boot, {\n      idx &lt;- sample.int(nrow(base_data), nrow(base_data), replace = TRUE)\n      bd &lt;- newdata[idx, , drop = FALSE]\n      p &lt;- suppressWarnings(predict_fun(model, bd))\n      mean(response_transform(p), na.rm = TRUE)\n    })\n    ci &lt;- quantile(boot_vals, c(0.025, 0.975), na.rm = TRUE)\n    acc[[i]] &lt;- tibble(YEAR = year_levels[i], value = mu, lcl = ci[[1]], ucl = ci[[2]])\n  }\n  bind_rows(acc)\n}\n\n# ==============================================================================\n# БЛОК 4: МОДЕЛИРОВАНИЕ GLM (GAMMA С ЛОГ-ССЫЛКОЙ)\n# ==============================================================================\n\n# Подбор модели с фиксированными эффектами\nglm_gamma_fit &lt;- glm(\n  CPUE_POS ~ YEAR + MONTH + CALL + REGION,  # Формула с факторными предикторами\n  family = Gamma(link = \"log\"),            # Гамма-распределение с логарифмической связью\n  data = DATA\n)\n\n# Диагностика модели\nsummary(glm_gamma_fit)  # Стандартная сводка модели\n\n\nCall:\nglm(formula = CPUE_POS ~ YEAR + MONTH + CALL + REGION, family = Gamma(link = \"log\"), \n    data = DATA)\n\nCoefficients:\n                                                  Estimate Std. Error t value\n(Intercept)                                        5.57642    0.07942  70.216\nYEAR2020                                          -0.22713    0.04586  -4.953\nYEAR2021                                          -0.22438    0.04557  -4.924\nYEAR2022                                          -0.64329    0.04345 -14.806\nYEAR2023                                          -0.77311    0.04647 -16.637\nYEAR2024                                          -1.12817    0.05157 -21.879\nMONTH10                                           -0.13725    0.02443  -5.617\nMONTH11                                           -0.13714    0.03540  -3.874\nCALLUAAK                                          -0.29534    0.06092  -4.848\nCALLUAKC                                          -0.53490    0.06381  -8.382\nCALLUBEV                                          -3.67233    0.12187 -30.133\nCALLUBQQ                                          -0.35433    0.07057  -5.021\nCALLUBSR                                          -0.33516    0.06266  -5.349\nCALLUBUR                                          -0.58246    0.06175  -9.433\nCALLUBYT                                          -0.21520    0.06088  -3.535\nCALLUCFF                                          -0.06756    0.09825  -0.688\nCALLUCXF                                          -2.34302    0.10638 -22.025\nCALLUDII                                          -0.46287    0.05710  -8.107\nCALLUDUT                                          -1.02162    0.07550 -13.532\nCALLUDWM                                          -2.42502    0.09480 -25.582\nCALLUEBK                                           0.25852    0.13371   1.934\nCALLUEMO                                          -0.17024    0.08103  -2.101\nCALLUENZ                                           0.04928    0.06442   0.765\nCALLUFIK                                           0.29700    0.13043   2.277\nCALLUGXE                                          -0.56384    0.06265  -9.000\nCALLUIVO                                          -0.21572    0.06500  -3.319\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.16521    0.46672   0.354\nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            -0.07615    0.15513  -0.491\nREGIONCEBEPO-KAHИHCKAЯ БAHKA                       0.16332    0.08236   1.983\nREGIONKAHИHCKAЯ БAHKA                              0.06291    0.07875   0.799\nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)  0.21310    0.08519   2.501\nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE              0.18223    0.07757   2.349\nREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.07737    0.07753   0.998\nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.72882    0.46327   1.573\nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                         0.13328    0.08416   1.584\nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      0.64238    0.11646   5.516\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       0.69320    0.13068   5.305\n                                                  Pr(&gt;|t|)    \n(Intercept)                                        &lt; 2e-16 ***\nYEAR2020                                          7.62e-07 ***\nYEAR2021                                          8.85e-07 ***\nYEAR2022                                           &lt; 2e-16 ***\nYEAR2023                                           &lt; 2e-16 ***\nYEAR2024                                           &lt; 2e-16 ***\nMONTH10                                           2.08e-08 ***\nMONTH11                                           0.000109 ***\nCALLUAAK                                          1.30e-06 ***\nCALLUAKC                                           &lt; 2e-16 ***\nCALLUBEV                                           &lt; 2e-16 ***\nCALLUBQQ                                          5.36e-07 ***\nCALLUBSR                                          9.37e-08 ***\nCALLUBUR                                           &lt; 2e-16 ***\nCALLUBYT                                          0.000413 ***\nCALLUCFF                                          0.491691    \nCALLUCXF                                           &lt; 2e-16 ***\nCALLUDII                                          6.93e-16 ***\nCALLUDUT                                           &lt; 2e-16 ***\nCALLUDWM                                           &lt; 2e-16 ***\nCALLUEBK                                          0.053247 .  \nCALLUEMO                                          0.035718 *  \nCALLUENZ                                          0.444299    \nCALLUFIK                                          0.022839 *  \nCALLUGXE                                           &lt; 2e-16 ***\nCALLUIVO                                          0.000913 ***\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                        0.723377    \nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            0.623533    \nREGIONCEBEPO-KAHИHCKAЯ БAHKA                      0.047425 *  \nREGIONKAHИHCKAЯ БAHKA                             0.424416    \nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH) 0.012413 *  \nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE             0.018863 *  \nREGIONMУPMAHCKOE MEЛKOBOДЬE                       0.318379    \nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                         0.115753    \nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                        0.113361    \nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                     3.69e-08 ***\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                      1.19e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Gamma family taken to be 0.4172272)\n\n    Null deviance: 2980.2  on 3890  degrees of freedom\nResidual deviance: 1785.6  on 3854  degrees of freedom\nAIC: 42851\n\nNumber of Fisher Scoring iterations: 11\n\n# Таблица коэффициентов в форматированном виде\nbroom::tidy(glm_gamma_fit) %&gt;%\n  mutate(across(estimate:statistic, ~round(.x, 4))) %&gt;%\n  kable(caption = \"Коэффициенты GLM модели\", align = \"lrrrr\")\n\n\nКоэффициенты GLM модели\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n5.5764\n0.0794\n70.2164\n0.0000000\n\n\nYEAR2020\n-0.2271\n0.0459\n-4.9530\n0.0000008\n\n\nYEAR2021\n-0.2244\n0.0456\n-4.9236\n0.0000009\n\n\nYEAR2022\n-0.6433\n0.0434\n-14.8059\n0.0000000\n\n\nYEAR2023\n-0.7731\n0.0465\n-16.6372\n0.0000000\n\n\nYEAR2024\n-1.1282\n0.0516\n-21.8785\n0.0000000\n\n\nMONTH10\n-0.1372\n0.0244\n-5.6170\n0.0000000\n\n\nMONTH11\n-0.1371\n0.0354\n-3.8736\n0.0001090\n\n\nCALLUAAK\n-0.2953\n0.0609\n-4.8479\n0.0000013\n\n\nCALLUAKC\n-0.5349\n0.0638\n-8.3823\n0.0000000\n\n\nCALLUBEV\n-3.6723\n0.1219\n-30.1334\n0.0000000\n\n\nCALLUBQQ\n-0.3543\n0.0706\n-5.0213\n0.0000005\n\n\nCALLUBSR\n-0.3352\n0.0627\n-5.3488\n0.0000001\n\n\nCALLUBUR\n-0.5825\n0.0618\n-9.4326\n0.0000000\n\n\nCALLUBYT\n-0.2152\n0.0609\n-3.5347\n0.0004130\n\n\nCALLUCFF\n-0.0676\n0.0982\n-0.6877\n0.4916914\n\n\nCALLUCXF\n-2.3430\n0.1064\n-22.0254\n0.0000000\n\n\nCALLUDII\n-0.4629\n0.0571\n-8.1065\n0.0000000\n\n\nCALLUDUT\n-1.0216\n0.0755\n-13.5319\n0.0000000\n\n\nCALLUDWM\n-2.4250\n0.0948\n-25.5817\n0.0000000\n\n\nCALLUEBK\n0.2585\n0.1337\n1.9335\n0.0532474\n\n\nCALLUEMO\n-0.1702\n0.0810\n-2.1009\n0.0357185\n\n\nCALLUENZ\n0.0493\n0.0644\n0.7650\n0.4442989\n\n\nCALLUFIK\n0.2970\n0.1304\n2.2770\n0.0228387\n\n\nCALLUGXE\n-0.5638\n0.0627\n-8.9996\n0.0000000\n\n\nCALLUIVO\n-0.2157\n0.0650\n-3.3187\n0.0009126\n\n\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H\n0.1652\n0.4667\n0.3540\n0.7233768\n\n\nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ\n-0.0762\n0.1551\n-0.4909\n0.6235329\n\n\nREGIONCEBEPO-KAHИHCKAЯ БAHKA\n0.1633\n0.0824\n1.9831\n0.0474248\n\n\nREGIONKAHИHCKAЯ БAHKA\n0.0629\n0.0788\n0.7989\n0.4244161\n\n\nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)\n0.2131\n0.0852\n2.5013\n0.0124133\n\n\nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE\n0.1822\n0.0776\n2.3492\n0.0188631\n\n\nREGIONMУPMAHCKOE MEЛKOBOДЬE\n0.0774\n0.0775\n0.9979\n0.3183790\n\n\nREGIONЗAП.-ПPИБPEЖHЫЙ P-H\n0.7288\n0.4633\n1.5732\n0.1157534\n\n\nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H\n0.1333\n0.0842\n1.5836\n0.1133609\n\n\nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ\n0.6424\n0.1165\n5.5160\n0.0000000\n\n\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ\n0.6932\n0.1307\n5.3046\n0.0000001\n\n\n\n\n# Графики диагностики остатков\npar(mfrow = c(2, 2))\nplot(glm_gamma_fit)  # Стандартные диагностические графики GLM\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n# Диагностика остатков GLM с использованием DHARMa\nsim_glm &lt;- simulateResiduals(glm_gamma_fit, n = 1000, refit = FALSE)\nplot(sim_glm, main = \"GLM\")\n\n\n\n\n\n\n\n# Расчет и визуализация индексов\nidx_glm &lt;- emmeans_standardized_index(glm_gamma_fit) %&gt;%\n  mutate(model = \"GLM_Gamma\",\n         index_mean = scale_to_index(value, \"mean\"),\n         index_first = scale_to_index(value, \"first\"))\n\n# Добавление доверительных интервалов\nidx_glm &lt;- idx_glm %&gt;%\n  mutate(\n    lcl_index_mean = scale_to_index(lcl, \"mean\"),\n    ucl_index_mean = scale_to_index(ucl, \"mean\")\n  )\n\n# Визуализация индексов GLM\n\nidx_glm %&gt;%\n  ggplot(aes(x = YEAR, y = value, group = 1)) +\n  geom_line() +\n  geom_point() +\n  geom_ribbon(aes(ymin = lcl, ymax = ucl), alpha = 0.3) +\n  geom_point(data = actual_medians, \n           aes(x = YEAR, y = median_cpue), \n           shape = 4,  # 4 соответствует крестику (x)\n           size = 3, \n           color = \"black\", \n           inherit.aes = FALSE)+\nlabs(title = \"Индексы CPUE по GLM модели (крестики - факт)\", \n       x = \"Год\", \n       y = \"Стандартизированный индекс\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 5: МОДЕЛИРОВАНИЕ GAM\n# ==============================================================================\n\n# Подбор обобщенной аддитивной модели\ngam_fit &lt;- gam(\n  CPUE_POS ~ YEAR + MONTH + CALL + REGION,  # Линейная формула без сглаживания\n  family = Gamma(link = \"log\"),            # Аналогичное GLM распределение\n  method = \"REML\",                         # Метод оптимизации гиперпараметров\n  data = DATA\n)\n\nsummary(gam_fit)  # Сводка модели\n\n\nFamily: Gamma \nLink function: log \n\nFormula:\nCPUE_POS ~ YEAR + MONTH + CALL + REGION\n\nParametric coefficients:\n                                                  Estimate Std. Error t value\n(Intercept)                                        5.57646    0.07942  70.217\nYEAR2020                                          -0.22712    0.04586  -4.953\nYEAR2021                                          -0.22438    0.04557  -4.924\nYEAR2022                                          -0.64329    0.04345 -14.806\nYEAR2023                                          -0.77309    0.04647 -16.637\nYEAR2024                                          -1.12812    0.05156 -21.878\nMONTH10                                           -0.13725    0.02443  -5.617\nMONTH11                                           -0.13714    0.03540  -3.874\nCALLUAAK                                          -0.29528    0.06092  -4.847\nCALLUAKC                                          -0.53484    0.06381  -8.381\nCALLUBEV                                          -3.67226    0.12187 -30.133\nCALLUBQQ                                          -0.35427    0.07057  -5.020\nCALLUBSR                                          -0.33512    0.06266  -5.348\nCALLUBUR                                          -0.58242    0.06175  -9.432\nCALLUBYT                                          -0.21516    0.06088  -3.534\nCALLUCFF                                          -0.06750    0.09825  -0.687\nCALLUCXF                                          -2.34296    0.10638 -22.025\nCALLUDII                                          -0.46282    0.05710  -8.106\nCALLUDUT                                          -1.02155    0.07550 -13.531\nCALLUDWM                                          -2.42497    0.09479 -25.581\nCALLUEBK                                           0.25858    0.13371   1.934\nCALLUEMO                                          -0.17018    0.08103  -2.100\nCALLUENZ                                           0.04934    0.06442   0.766\nCALLUFIK                                           0.29706    0.13043   2.278\nCALLUGXE                                          -0.56375    0.06265  -8.998\nCALLUIVO                                          -0.21565    0.06500  -3.318\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.16508    0.46672   0.354\nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            -0.07627    0.15513  -0.492\nREGIONCEBEPO-KAHИHCKAЯ БAHKA                       0.16322    0.08236   1.982\nREGIONKAHИHCKAЯ БAHKA                              0.06281    0.07875   0.798\nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)  0.21299    0.08519   2.500\nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE              0.18213    0.07757   2.348\nREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.07728    0.07753   0.997\nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.72877    0.46327   1.573\nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                         0.13318    0.08416   1.583\nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      0.64226    0.11646   5.515\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       0.69310    0.13068   5.304\n                                                  Pr(&gt;|t|)    \n(Intercept)                                        &lt; 2e-16 ***\nYEAR2020                                          7.62e-07 ***\nYEAR2021                                          8.85e-07 ***\nYEAR2022                                           &lt; 2e-16 ***\nYEAR2023                                           &lt; 2e-16 ***\nYEAR2024                                           &lt; 2e-16 ***\nMONTH10                                           2.08e-08 ***\nMONTH11                                           0.000109 ***\nCALLUAAK                                          1.30e-06 ***\nCALLUAKC                                           &lt; 2e-16 ***\nCALLUBEV                                           &lt; 2e-16 ***\nCALLUBQQ                                          5.39e-07 ***\nCALLUBSR                                          9.39e-08 ***\nCALLUBUR                                           &lt; 2e-16 ***\nCALLUBYT                                          0.000414 ***\nCALLUCFF                                          0.492100    \nCALLUCXF                                           &lt; 2e-16 ***\nCALLUDII                                          6.98e-16 ***\nCALLUDUT                                           &lt; 2e-16 ***\nCALLUDWM                                           &lt; 2e-16 ***\nCALLUEBK                                          0.053187 .  \nCALLUEMO                                          0.035785 *  \nCALLUENZ                                          0.443735    \nCALLUFIK                                          0.022810 *  \nCALLUGXE                                           &lt; 2e-16 ***\nCALLUIVO                                          0.000916 ***\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                        0.723578    \nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            0.623006    \nREGIONCEBEPO-KAHИHCKAЯ БAHKA                      0.047563 *  \nREGIONKAHИHCKAЯ БAHKA                             0.425185    \nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH) 0.012456 *  \nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE             0.018931 *  \nREGIONMУPMAHCKOE MEЛKOBOДЬE                       0.318981    \nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                         0.115776    \nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                        0.113615    \nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                     3.72e-08 ***\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                      1.20e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nR-sq.(adj) =  0.397   Deviance explained = 40.1%\n-REML =  21455  Scale est. = 0.41722   n = 3891\n\n# Проверка адекватности модели (графики остатков)\nmgcv::gam.check(gam_fit)\n\n\n\n\n\n\n\n\n\nMethod: REML   Optimizer: outer newton\nfull convergence after 5 iterations.\nGradient range [-0.0003574844,-0.0003574844]\n(score 21454.84 & scale 0.4172217).\nHessian positive definite, eigenvalue range [2198.061,2198.061].\nModel rank =  37 / 37 \n\n# Диагностика остатков GAM с использованием DHARMa\nsim_gam &lt;- simulateResiduals(gam_fit, n = 1000, refit = FALSE)\n\nRegistered S3 method overwritten by 'mgcViz':\n  method from   \n  +.gg   ggplot2\n\nplot(sim_gam, main = \"GAM\")\n\n\n\n\n\n\n\n# Расчет индексов\nidx_gam &lt;- emmeans_standardized_index(gam_fit) %&gt;%\n  mutate(model = \"GAM\",\n         index_mean = scale_to_index(value, \"mean\"),\n         index_first = scale_to_index(value, \"first\"))\n\n# Доверительные интервалы\nidx_gam &lt;- idx_gam %&gt;%\n  mutate(\n    lcl_index_mean = scale_to_index(lcl, \"mean\"),\n    ucl_index_mean = scale_to_index(ucl, \"mean\")\n  )\n\n\n# Визуализация\nidx_gam %&gt;%\n  ggplot(aes(x = YEAR, y = value, group = 1)) +\n  geom_line() +\n  geom_point() +\n  geom_ribbon(aes(ymin = lcl, ymax = ucl), alpha = 0.3) +\n  geom_point(data = actual_medians, \n           aes(x = YEAR, y = median_cpue), \n           shape = 4,  # 4 соответствует крестику (x)\n           size = 3, \n           color = \"black\", \n           inherit.aes = FALSE)+\n  labs(title = \"Индексы CPUE по GAM модели (крестики - факт\", \n       x = \"Год\", \n       y = \"Стандартизированный индекс\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 6: МОДЕЛИРОВАНИЕ GAMM (СМЕШАННАЯ МОДЕЛЬ)\n# ==============================================================================\n\n# Подбор модели со смешанными эффектами\ngamm_fit &lt;- gamm4::gamm4(\n  formula = CPUE_POS ~ YEAR + MONTH + REGION,  # Фиксированные эффекты\n  random = ~ (1 | CALL),                       # Случайный эффект для судна\n  family = Gamma(link = \"log\"),               # Распределение\n  data = DATA\n)\n\n# 1. График остатков от предсказанных значений\nplot(fitted(gamm_fit$gam), residuals(gamm_fit$gam, type = \"deviance\"),\n     xlab = \"Предсказанные значения\", ylab = \"Девиансные остатки\",\n     main = \"Остатки GAMM vs. Предсказания\")\nabline(h = 0, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n# 2. QQ-plot для остатков\nqqnorm(residuals(gamm_fit$gam, type = \"deviance\"),\n       main = \"QQ-plot для остатков GAMM\")\nqqline(residuals(gamm_fit$gam, type = \"deviance\"), col = \"red\")\n\n\n\n\n\n\n\n# 3. Диагностика случайных эффектов\ncat(\"\\nСлучайные эффекты (CALL):\\n\")\n\n\nСлучайные эффекты (CALL):\n\nprint(summary(ranef(gamm_fit$mer)$CALL))\n\n  (Intercept)      \n Min.   :-2.92229  \n 1st Qu.: 0.09295  \n Median : 0.32996  \n Mean   : 0.00306  \n 3rd Qu.: 0.54065  \n Max.   : 0.93271  \n\n# График случайных эффектов\nrandom_effects &lt;- ranef(gamm_fit$mer)$CALL\nplot(density(random_effects[,1]), main = \"Распределение случайных эффектов\",\n     xlab = \"Случайный эффект\", ylab = \"Плотность\")\n\n\n\n\n\n\n\n# 5. Проверка гетероскедастичности\nlibrary(lmtest)\n\nЗагрузка требуемого пакета: zoo\n\n\n\nПрисоединяю пакет: 'zoo'\n\n\nСледующие объекты скрыты от 'package:base':\n\n    as.Date, as.Date.numeric\n\nbptest(gamm_fit$gam$y ~ fitted(gamm_fit$gam)) %&gt;% \n  print()\n\n\n    studentized Breusch-Pagan test\n\ndata:  gamm_fit$gam$y ~ fitted(gamm_fit$gam)\nBP = 222.14, df = 1, p-value &lt; 2.2e-16\n\n# 6. Сводка по модели\ncat(\"\\nСводка GAMM модели:\\n\")\n\n\nСводка GAMM модели:\n\nprint(summary(gamm_fit$gam))\n\n\nFamily: Gamma \nLink function: log \n\nFormula:\nCPUE_POS ~ YEAR + MONTH + REGION\n\nParametric coefficients:\n                                                  Estimate Std. Error t value\n(Intercept)                                        4.91649    0.17171  28.632\nYEAR2020                                          -0.23162    0.04580  -5.058\nYEAR2021                                          -0.22798    0.04552  -5.008\nYEAR2022                                          -0.64763    0.04338 -14.928\nYEAR2023                                          -0.77570    0.04641 -16.716\nYEAR2024                                          -1.13070    0.05152 -21.947\nMONTH10                                           -0.13620    0.02445  -5.571\nMONTH11                                           -0.13630    0.03542  -3.848\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.16149    0.46710   0.346\nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            -0.08013    0.15524  -0.516\nREGIONCEBEPO-KAHИHCKAЯ БAHKA                       0.15971    0.08238   1.939\nREGIONKAHИHCKAЯ БAHKA                              0.05886    0.07877   0.747\nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)  0.20859    0.08522   2.448\nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE              0.17834    0.07759   2.299\nREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.07353    0.07755   0.948\nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.72926    0.46366   1.573\nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                         0.12967    0.08419   1.540\nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      0.63836    0.11653   5.478\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       0.68988    0.13078   5.275\n                                                  Pr(&gt;|t|)    \n(Intercept)                                        &lt; 2e-16 ***\nYEAR2020                                          4.44e-07 ***\nYEAR2021                                          5.74e-07 ***\nYEAR2022                                           &lt; 2e-16 ***\nYEAR2023                                           &lt; 2e-16 ***\nYEAR2024                                           &lt; 2e-16 ***\nMONTH10                                           2.70e-08 ***\nMONTH11                                           0.000121 ***\nREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                        0.729566    \nREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            0.605763    \nREGIONCEBEPO-KAHИHCKAЯ БAHKA                      0.052628 .  \nREGIONKAHИHCKAЯ БAHKA                             0.455013    \nREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH) 0.014424 *  \nREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE             0.021580 *  \nREGIONMУPMAHCKOE MEЛKOBOДЬE                       0.343099    \nREGIONЗAП.-ПPИБPEЖHЫЙ P-H                         0.115842    \nREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                        0.123604    \nREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                     4.57e-08 ***\nREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                      1.40e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nR-sq.(adj) =  0.172   \nglmer.ML =   1786  Scale est. = 0.41793   n = 3891\n\nprint(summary(gamm_fit$mer))\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: Gamma  ( log )\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n  42933.5   43065.1  -21445.7   42891.5      3870 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.5364 -0.6769 -0.1721  0.4716 11.0577 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n CALL     (Intercept) 0.4320   0.6573  \n Residual             0.4179   0.6465  \nNumber of obs: 3891, groups:  CALL, 19\n\nFixed effects:\n                                                   Estimate Std. Error t value\nX(Intercept)                                        4.91649    0.23488  20.932\nXYEAR2020                                          -0.23162    0.02474  -9.363\nXYEAR2021                                          -0.22798    0.02513  -9.073\nXYEAR2022                                          -0.64763    0.02299 -28.167\nXYEAR2023                                          -0.77570    0.02376 -32.652\nXYEAR2024                                          -1.13070    0.02603 -43.443\nXMONTH10                                           -0.13620    0.01914  -7.116\nXMONTH11                                           -0.13630    0.02359  -5.777\nXREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.16149    0.46456   0.348\nXREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ            -0.08013    0.03506  -2.285\nXREGIONCEBEPO-KAHИHCKAЯ БAHKA                       0.15971    0.02670   5.982\nXREGIONKAHИHCKAЯ БAHKA                              0.05886    0.02653   2.218\nXREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH)  0.20859    0.02808   7.428\nXREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE              0.17834    0.02200   8.108\nXREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.07353    0.02318   3.172\nXREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.72926    0.46533   1.567\nXREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                         0.12967    0.02736   4.739\nXREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      0.63836    0.03291  19.400\nXREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       0.68988    0.03447  20.015\n                                                   Pr(&gt;|z|)    \nX(Intercept)                                        &lt; 2e-16 ***\nXYEAR2020                                           &lt; 2e-16 ***\nXYEAR2021                                           &lt; 2e-16 ***\nXYEAR2022                                           &lt; 2e-16 ***\nXYEAR2023                                           &lt; 2e-16 ***\nXYEAR2024                                           &lt; 2e-16 ***\nXMONTH10                                           1.11e-12 ***\nXMONTH11                                           7.60e-09 ***\nXREGIONCEB.-ЦEHTPAЛЬHЫЙ P-H                         0.72813    \nXREGIONCEB.CKЛOH MУPMAHCKOГO MEЛKOBOДЬЯ             0.02229 *  \nXREGIONCEBEPO-KAHИHCKAЯ БAHKA                      2.20e-09 ***\nXREGIONKAHИHCKAЯ БAHKA                              0.02654 *  \nXREGIONKAHИHCKO- KOЛГУEBCKOE MEЛKOBOДЬE(CEB.CKЛOH) 1.10e-13 ***\nXREGIONKAHИHCKO-KOЛГУEBCKOE MEЛKOBOДЬE             5.16e-16 ***\nXREGIONMУPMAHCKOE MEЛKOBOДЬE                        0.00151 ** \nXREGIONЗAП.-ПPИБPEЖHЫЙ P-H                          0.11707    \nXREGIONЗAП.-ЦEHTPAЛЬHЫЙ P-H                        2.15e-06 ***\nXREGIONЗAП.CKЛOH ГУCИHOЙ БAHKИ                      &lt; 2e-16 ***\nXREGIONЮЖ.CKЛOH ГУCИHOЙ БAHKИ                       &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCorrelation matrix not shown by default, as p = 19 &gt; 12.\nUse print(summary(gamm_fit$mer), correlation=TRUE)  or\n    vcov(summary(gamm_fit$mer))        if you need it\n\n# Создание сетки для предсказания\nnewdata_grid &lt;- expand.grid(\n  YEAR = levels(DATA$YEAR),\n  MONTH = levels(DATA$MONTH),\n  REGION = levels(DATA$REGION),\n  CALL = levels(DATA$CALL)[1]  # Фиксированное значение для случайного эффекта\n)\n\n# Предсказание на сетке\nnewdata_grid$pred &lt;- predict(gamm_fit$gam, \n                            newdata = newdata_grid, \n                            type = \"response\")\n\n# Усреднение предсказаний по годам\nidx_gamm &lt;- newdata_grid %&gt;%\n  group_by(YEAR) %&gt;%\n  summarise(value = mean(pred, na.rm = TRUE)) %&gt;%\n  mutate(\n    model = \"GAMM (mgcv)\",\n    index_mean = scale_to_index(value, \"mean\"),\n    index_first = scale_to_index(value, \"first\")\n  )\n\n# Функция расчета доверительных интервалов через бутстреп\ncompute_gamm_ci &lt;- function(model, newdata, n_boot = 100) {\n  boot_means &lt;- replicate(n_boot, {\n    boot_data &lt;- newdata[sample(nrow(newdata), replace = TRUE), ]\n    preds &lt;- predict(model, newdata = boot_data, type = \"response\")\n    boot_data %&gt;%\n      mutate(pred = preds) %&gt;%\n      group_by(YEAR) %&gt;%\n      summarise(mean_pred = mean(pred, na.rm = TRUE)) %&gt;%\n      pull(mean_pred)\n  })\n  \n  ci &lt;- apply(boot_means, 1, function(x) quantile(x, c(0.025, 0.975), na.rm = TRUE))\n  return(list(mean = rowMeans(boot_means), lcl = ci[1, ], ucl = ci[2, ]))\n}\n\n# Расчет интервалов\ngamm_ci &lt;- compute_gamm_ci(gamm_fit$gam, newdata_grid)\n\n# Добавление интервалов к индексам\nidx_gamm &lt;- idx_gamm %&gt;%\n  mutate(\n    lcl = gamm_ci$lcl,\n    ucl = gamm_ci$ucl,\n    lcl_index_mean = scale_to_index(lcl, \"mean\"),\n    ucl_index_mean = scale_to_index(ucl, \"mean\")\n  )\n\n# Визуализация\nidx_gamm %&gt;%\n  ggplot(aes(x = YEAR, y = value, group = 1)) +\n  geom_line() +\n  geom_point() +\n  geom_ribbon(aes(ymin = lcl, ymax = ucl), alpha = 0.3) +\n  geom_point(data = actual_medians, \n           aes(x = YEAR, y = median_cpue), \n           shape = 4,  # 4 соответствует крестику (x)\n           size = 3, \n           color = \"black\", \n           inherit.aes = FALSE)+\nlabs(title = \"Индексы CPUE по GAMM модели (крестики - факт)\", \n       x = \"Год\", \n       y = \"Стандартизированный индекс\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 7: СРАВНЕНИЕ МОДЕЛЕЙ И ФИНАЛЬНАЯ ВИЗУАЛИЗАЦИЯ\n# ==============================================================================\n\n# Объединение результатов всех моделей\nindices_all &lt;- bind_rows(\n  idx_glm %&gt;% select(YEAR, value, lcl, ucl, model, index_mean, lcl_index_mean, ucl_index_mean),\n  idx_gam %&gt;% select(YEAR, value, lcl, ucl, model, index_mean, lcl_index_mean, ucl_index_mean),\n  idx_gamm %&gt;% select(YEAR, value, lcl, ucl, model, index_mean, lcl_index_mean, ucl_index_mean)\n) %&gt;% mutate(YEAR = factor(YEAR, levels = levels(DATA$YEAR)))\n\n# Сводная таблица результатов\nindices_all %&gt;% \n  kable(caption = \"Сравнение индексов CPUE по разным моделям\")\n\n\nСравнение индексов CPUE по разным моделям\n\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nvalue\nlcl\nucl\nmodel\nindex_mean\nlcl_index_mean\nucl_index_mean\n\n\n\n\n2019\n158.81216\n138.93290\n181.53585\nGLM_Gamma\n1.5358638\n1.5299542\n1.5417869\n\n\n2020\n126.54457\n111.15088\n144.07018\nGLM_Gamma\n1.2238057\n1.2240136\n1.2235904\n\n\n2021\n126.89292\n111.57409\n144.31498\nGLM_Gamma\n1.2271746\n1.2286741\n1.2256695\n\n\n2022\n83.46580\n73.52525\n94.75032\nGLM_Gamma\n0.8071933\n0.8096733\n0.8047160\n\n\n2023\n73.30390\n64.40714\n83.42960\nGLM_Gamma\n0.7089181\n0.7092631\n0.7085690\n\n\n2024\n51.39565\n45.26094\n58.36186\nGLM_Gamma\n0.4970445\n0.4984216\n0.4956683\n\n\n2019\n158.81218\n138.93304\n181.53572\nGAM\n1.5358554\n1.5299458\n1.5417784\n\n\n2020\n126.54503\n111.15138\n144.07058\nGAM\n1.2238033\n1.2240112\n1.2235880\n\n\n2021\n126.89280\n111.57408\n144.31473\nGAM\n1.2271665\n1.2286660\n1.2256615\n\n\n2022\n83.46561\n73.52514\n94.75002\nGAM\n0.8071869\n0.8096669\n0.8047096\n\n\n2023\n73.30495\n64.40811\n83.43072\nGAM\n0.7089242\n0.7092692\n0.7085751\n\n\n2024\n51.39792\n45.26297\n58.36439\nGAM\n0.4970637\n0.4984408\n0.4956874\n\n\n2019\n165.88930\n153.27889\n186.43794\nGAMM (mgcv)\n1.5400976\n1.5751123\n1.5695052\n\n\n2020\n131.59142\n116.54705\n144.02703\nGAMM (mgcv)\n1.2216800\n1.1976514\n1.2124741\n\n\n2021\n132.07110\n118.64017\n145.21926\nGAMM (mgcv)\n1.2261333\n1.2191606\n1.2225107\n\n\n2022\n86.80692\n79.26688\n96.71028\nGAMM (mgcv)\n0.8059057\n0.8145559\n0.8141438\n\n\n2023\n76.37202\n67.94329\n82.24327\nGAMM (mgcv)\n0.7090292\n0.6981933\n0.6923550\n\n\n2024\n53.55022\n48.20170\n58.08852\nGAMM (mgcv)\n0.4971542\n0.4953264\n0.4890111\n\n\n\n\nindices_all %&gt;%\n  ggplot(aes(x = YEAR, y = value, color = model, group = model, fill = model)) +\n  geom_line() +\n  geom_point() +\n  geom_ribbon(aes(ymin = lcl, ymax = ucl), alpha = 0.1, linetype = \"dashed\") +\ngeom_point(data = actual_medians, \n           aes(x = YEAR, y = median_cpue), \n           shape = 4,  # 4 соответствует крестику (x)\n           size = 3, \n           color = \"black\", \n           inherit.aes = FALSE)+\n  labs(title = \"Сравнение стандартизированных индексов CPUE (крестики - факт)\", \n       x = \"Год\", \n       y = \"Индекс CPUE (кг/ловушку)\", \n       color = \"Модель\", \n       fill = \"Модель\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n# ==============================================================================\n# БЛОК 9: СРАВНЕНИЕ МОДЕЛЕЙ ПО ИНФОРМАЦИОННЫМ КРИТЕРИЯМ\n# ==============================================================================\n\ncat(\"\\n=== СРАВНИТЕЛЬНЫЙ АНАЛИЗ МОДЕЛЕЙ ПО ИНФОРМАЦИОННЫМ КРИТЕРИЯМ ===\\n\")\n\n\n=== СРАВНИТЕЛЬНЫЙ АНАЛИЗ МОДЕЛЕЙ ПО ИНФОРМАЦИОННЫМ КРИТЕРИЯМ ===\n\n# Упрощенная функция для извлечения ключевых критериев из моделей\nextract_model_metrics &lt;- function(model, model_name, model_type = \"glm\") {\n  if (model_type == \"glm\") {\n    aic_val &lt;- AIC(model)\n    bic_val &lt;- BIC(model)\n    loglik_val &lt;- as.numeric(logLik(model))\n    df_val &lt;- model$rank\n    null_dev &lt;- model$null.deviance\n    dev &lt;- model$deviance\n  } else if (model_type == \"gam\") {\n    aic_val &lt;- AIC(model)\n    bic_val &lt;- BIC(model)\n    loglik_val &lt;- as.numeric(logLik(model))\n    df_val &lt;- sum(model$edf)\n    null_dev &lt;- model$null.deviance\n    dev &lt;- model$deviance\n  } else if (model_type == \"gamm\") {\n    aic_val &lt;- AIC(model$mer)\n    bic_val &lt;- BIC(model$mer)\n    loglik_val &lt;- as.numeric(logLik(model$mer))\n    df_val &lt;- length(fixef(model$mer)) + 1  # +1 для случайного эффекта\n    null_dev &lt;- model$gam$null.deviance\n    dev &lt;- model$gam$deviance\n  }\n  \n  # Вычисляем долю объясненной девиации\n  deviance_explained &lt;- ifelse(!is.null(null_dev) && !is.null(dev) && null_dev &gt; 0,\n                              (null_dev - dev) / null_dev, NA)\n  \n  data.frame(\n    Model = model_name,\n    AIC = round(aic_val, 2),\n    BIC = round(bic_val, 2),\n    LogLik = round(loglik_val, 2),\n    DF = round(df_val, 2),\n    Deviance_Explained = round(deviance_explained, 4)\n  )\n}\n\n# Извлекаем метрики для всех моделей\nmodel_metrics &lt;- bind_rows(\n  extract_model_metrics(glm_gamma_fit, \"GLM (Gamma)\", \"glm\"),\n  extract_model_metrics(gam_fit, \"GAM\", \"gam\"),\n  extract_model_metrics(gamm_fit, \"GAMM\", \"gamm\")\n)\n\n# Добавляем разницу в AIC относительно наилучшей модели\nmin_aic &lt;- min(model_metrics$AIC)\nmodel_metrics &lt;- model_metrics %&gt;%\n  mutate(Delta_AIC = AIC - min_aic,\n         AIC_Weight = exp(-0.5 * Delta_AIC) / sum(exp(-0.5 * Delta_AIC)))\n\n# Форматируем таблицу для вывода\ncomparison_table &lt;- model_metrics %&gt;%\n  mutate(across(where(is.numeric), ~round(., 3))) %&gt;%\n  arrange(AIC)  # Сортируем по AIC (лучшая модель первая)\n\n# Выводим таблицу сравнения\ncat(\"\\nТАБЛИЦА СРАВНЕНИЯ МОДЕЛЕЙ:\\n\")\n\n\nТАБЛИЦА СРАВНЕНИЯ МОДЕЛЕЙ:\n\nprint(comparison_table)\n\n        Model      AIC      BIC    LogLik DF Deviance_Explained Delta_AIC\n1         GAM 42840.91 43079.03 -21382.45 37              0.401      0.00\n2 GLM (Gamma) 42850.76 43088.88 -21387.38 37              0.401      9.85\n3        GAMM 42933.49 43065.09 -21445.75 20                 NA     92.58\n  AIC_Weight\n1      0.993\n2      0.007\n3      0.000\n\n# Выводим итоговые рекомендации\ncat(\"\\n=== ИТОГОВЫЕ РЕКОМЕНДАЦИИ ПО ВЫБОРУ МОДЕЛИ ===\\n\")\n\n\n=== ИТОГОВЫЕ РЕКОМЕНДАЦИИ ПО ВЫБОРУ МОДЕЛИ ===\n\nbest_model &lt;- comparison_table$Model[1]\ncat(\"Наилучшая модель по критерию AIC:\", best_model, \"\\n\")\n\nНаилучшая модель по критерию AIC: GAM \n\ncat(\"Вес AIC для наилучшей модели:\", round(comparison_table$AIC_Weight[1], 3), \"\\n\")\n\nВес AIC для наилучшей модели: 0.993 \n\nif (nrow(comparison_table) &gt; 1 && comparison_table$Delta_AIC[2] &gt; 2) {\n  cat(\"Наилучшая модель существенно лучше остальных (?AIC &gt; 2).\\n\")\n} else if (nrow(comparison_table) &gt; 1) {\n  cat(\"Несколько моделей имеют сходное качество (?AIC &lt; 2).\\n\")\n}\n\nНаилучшая модель существенно лучше остальных (?AIC &gt; 2).\n\ncat(\"Доля объясненной девиации наилучшей модели:\", \n    round(comparison_table$Deviance_Explained[1], 3), \"\\n\")\n\nДоля объясненной девиации наилучшей модели: 0.401",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Стандартизация CPUE</span>"
    ]
  },
  {
    "objectID": "chapter 10.html#анализ-glm-модели-с-гамма-распределением-и-лог-ссылкой",
    "href": "chapter 10.html#анализ-glm-модели-с-гамма-распределением-и-лог-ссылкой",
    "title": "11  Стандартизация CPUE",
    "section": "11.3 Анализ GLM модели с гамма-распределением и лог-ссылкой",
    "text": "11.3 Анализ GLM модели с гамма-распределением и лог-ссылкой\nПодобранная обобщенная линейная модель (GLM) использует гамма-распределение для ошибок и логарифмическую функцию связи. Данное распределение выбрано, поскольку CPUE представляет собой непрерывную положительную величину, а гамма-распределение хорошо описывает такие данные. Логарифмическая связь обеспечивает мультипликативность эффектов факторов, что интерпретируется как относительное изменение CPUE при изменении фактора. Модель включает четыре факторные переменные: год (YEAR), месяц (MONTH), позывной судна (CALL) и район промысла (REGION). Все переменные представлены как факторы, что означает, что для каждого уровня фактора оценивается свой коэффициент, интерпретируемый как отклонение от базового уровня. Базовыми уровнями являются: 2019 год для YEAR, сентябрь (MONTH9) для MONTH, первое судно в алфавитном порядке для CALL и первый район для REGION. Из сводки модели видно, что многие коэффициенты статистически значимы. Все годовые коэффициенты отрицательны и значимы, что указывает на снижение CPUE относительно базового 2019 года. Наибольшее снижение наблюдается в 2024 году (коэффициент -1.128). Месячные коэффициенты также отрицательны и значимы, что говорит о снижении CPUE в октябре и ноябре по сравнению с сентябрем. Большинство коэффициентов для судов значимы и отрицательны, что указывает на то, что уловы на усилие у этих судов в среднем ниже, чем у базового судна. Однако некоторые суда имеют положительные коэффициенты, что означает более высокую производительность. Для районов значимыми оказались лишь некоторые коэффициенты, в основном положительные, что говорит о более высоких уловах в этих районах по сравнению с базовым. Дисперсионный параметр для гамма-семейства равен 0.417, что указывает на умеренную дисперсию. Null deviance составляет 2980.2 при 3890 степенях свободы, а остаточная deviance — 1785.6 при 3854 степенях свободы. Снижение девиации указывает на то, что модель объясняет существенную часть вариации данных. AIC модели равен 42851. Диагностические графики стандартных остатков GLM включают график остатков против предсказанных значений, Q-Q plot, график масштаба-местоположения и график остатков против влияния. Эти графики позволяют оценить гомоскедастичность, нормальность остатков и наличие выбросов. Дополнительная диагностика с помощью пакета DHARMa показывает, что распределение остатков соответствует ожидаемому, что подтверждает адекватность выбранного семейства распределений. Расчет стандартизированных индексов с помощью функции emmeans показывает, что индекс CPUE постепенно снижается с 2019 по 2024 год, что согласуется с отрицательными годовыми коэффициентами. В 2019 году индекс составляет 159, а к 2024 падает до 51.4. Доверительные интервалы не перекрываются между крайними годами, что указывает на статистически значимое снижение. Сравнение с медианными значениями CPUE по годам из исходных данных показывает, что модель несколько сглаживает исходные данные, но общая тенденция снижения сохраняется. Например, в 2019 году медианное значение CPUE было 200, а стандартизированный индекс — 159, что может быть связано с учетом влияния других факторов. Преимущества GLM подхода включают простоту интерпретации коэффициентов, вычислительную эффективность и широкую распространенность. Недостатки заключаются в том, что GLM предполагает линейность влияния факторов на логарифм отклика, что может не всегда выполняться. Кроме того, модель с фиксированными эффектами может не учитывать некоторые источники вариации, такие как пространственно-временная автокорреляция или случайные эффекты судов. В целом, модель адекватно описывает данные и может быть использована для стандартизации CPUE, но для более сложных данных могут потребоваться более гибкие модели, такие как GAM или GAMM.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Стандартизация CPUE</span>"
    ]
  },
  {
    "objectID": "chapter 10.html#анализ-gam-модели-с-гамма-распределением-и-логарифмической-связью",
    "href": "chapter 10.html#анализ-gam-модели-с-гамма-распределением-и-логарифмической-связью",
    "title": "11  Стандартизация CPUE",
    "section": "11.4 Анализ GAM модели с гамма-распределением и логарифмической связью",
    "text": "11.4 Анализ GAM модели с гамма-распределением и логарифмической связью\nАнализ подобранной обобщенной аддитивной модели (GAM) с гамма-распределением и логарифмической связью показывает результаты, практически идентичные полученным ранее для GLM модели, что ожидаемо, поскольку в данной реализации GAM использовалась полностью параметрическая формула без сглаживающих функций. Модель была построена с теми же предикторами - годом, месяцем, идентификатором судна и районом промысла.\nСводка модели демонстрирует параметрические коэффициенты, которые практически не отличаются от оценок GLM модели. Все годовые коэффициенты остаются отрицательными и статистически значимыми, подтверждая устойчивую тенденцию снижения стандартизированного индекса CPUE с 2019 по 2024 год. Месячные коэффициенты также значимы и отрицательны, указывая на сезонное снижение уловов в октябре и ноябре по сравнению с сентябрем. Оценки для различных судов и районов промысла практически идентичны полученным в GLM, с сохранением статистической значимости для тех же уровней факторов.\nМодель объясняет 40.1% девиации данных, что полностью соответствует показателю GLM. Значение REML составляет 21455, а оценка дисперсии равна 0.41722, что также практически совпадает с соответствующими показателями GLM модели.\nПроверка адекватности модели с помощью функции gam.check показывает успешную сходимость алгоритма оптимизации после 5 итераций. Градиент близок к нулю, а гессиан положительно определен, что свидетельствует о достижении устойчивого решения. Поскольку в модели отсутствуют сглаживающие компоненты, диагностика не выявляет проблем, связанных с выбором базовой размерности или неадекватностью сглаживания.\nДиагностика остатков с использованием пакета DHARMa показывает равномерное распределение без систематических паттернов, что указывает на соответствие остатков теоретическому гамма-распределению. Графики остатков демонстрируют отсутствие гетероскедастичности и значимых выбросов, что подтверждает адекватность модели.\nРасчет стандартизированных индексов методом маргинальных средних дает значения, практически идентичные полученным из GLM модели. Индекс снижается с 159 в 2019 году до 51.4 в 2024 году, с доверительными интервалами, не перекрывающимися между крайними годами. Нормированные индексы относительно среднего и первого года также полностью совпадают с GLM результатами.\nОсновное преимущество использования GAM в данном случае заключается в методологическом подходе - использовании метода REML для оптимизации, который может обеспечивать более стабильные оценки параметров по сравнению с методом максимального правдоподобия, используемым в GLM. Хотя в данной конкретной реализации с полностью параметрической формулой это преимущество не реализуется в полной мере, GAM предоставляет основу для легкого включения нелинейных эффектов через сглаживающие функции, если такая необходимость возникнет в дальнейшем.\nК недостаткам данного подхода можно отнести избыточную сложность GAM для полностью параметрической модели, поскольку вычислительные затраты выше, чем для GLM, без существенного улучшения качества подгонки. Фактически, в данном случае GAM работает как GLM, но с более сложным алгоритмом оптимизации. Кроме того, диагностика GAM требует дополнительных проверок, связанных со сходимостью алгоритма и адекватностью сглаживания, которые не актуальны для параметрических моделей.\nВ целом, данная реализация GAM не демонстрирует преимуществ перед GLM моделью, но предоставляет основу для будущего расширения модели за счет включения нелинейных эффектов, если анализ данных покажет такую необходимость. Результаты стандартизации CPUE полностью согласуются с полученными ранее средствами GLM.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Стандартизация CPUE</span>"
    ]
  },
  {
    "objectID": "chapter 10.html#анализ-gamm-модели",
    "href": "chapter 10.html#анализ-gamm-модели",
    "title": "11  Стандартизация CPUE",
    "section": "11.5 Анализ GAMM модели",
    "text": "11.5 Анализ GAMM модели\nОсобенности смешанных моделей и случайные эффекты\nСмешанные модели, включая GAMM, расширяют возможности стандартных моделей за счет введения случайных эффектов. В то время как фиксированные эффекты оценивают среднее влияние факторов на всю популяцию, случайные эффекты позволяют учесть вариацию, связанную с отдельными группами наблюдений. В ихтиологических исследованиях случайные эффекты часто применяются для учета индивидуальных особенностей судов, различий между районами промысла, или временной автокорреляции.\nСлучайные эффекты особенно полезны, когда:\n\nДанные имеют иерархическую структуру (например, уловы по нескольким судам)\nНаблюдения внутри групп коррелированы\nКоличество уровней фактора велико, и мы хотим обобщить выводы на всю популяцию групп\nНас интересует вариация между группами, а не конкретные сравнения между отдельными уровнями\n\nВ данном случае случайный эффект для судна (CALL) позволяет учесть, что разные суда могут иметь систематические различия в эффективности промысла, не объясняемые другими переменными модели.\nАнализ результатов GAMM модели\nАнализ обобщенной аддитивной смешанной модели показывает несколько важных особенностей. Модель включает фиксированные эффекты года, месяца и района, а также случайный эффект для судна, что позволяет учесть индивидуальные различия между судами в уровне уловов.\nГрафик остатков от предсказанных значений показывает распределение девиансных остатков вокруг нулевой линии. Наблюдается некоторая гетероскедастичность - разброс остатков увеличивается с ростом предсказанных значений, что характерно для данных по уловам. QQ-plot демонстрирует отклонение распределения остатков от нормального в крайних значениях, что ожидаемо для данных с гамма-распределением.\nАнализ случайных эффектов для судов показывает существенную вариацию между разными судами. Значения случайных эффектов варьируют от -2.92 до 0.93, что указывает на значительные различия в эффективности промысла между судами после учета влияния года, месяца и района. Распределение случайных эффектов близко к нормальному с центром около нуля.\nТест Бреуша-Пагана подтверждает наличие гетероскедастичности в модели, что является общей проблемой для моделей с данными по уловам.\nСводка параметрических коэффициентов показывает, что все годовые эффекты статистически значимы и отрицательны, подтверждая общую тенденцию снижения уловов с течением времени. Месячные эффекты также значимы и отрицательны, указывая на сезонное снижение уловов в октябре и ноябре по сравнению с сентябрем. Среди районов промысла несколько показали статистически значимые отличия от базового уровня.\nМодель объясняет 17.2% дисперсии данных, что меньше, чем в предыдущих моделях, что может быть связано с учетом части вариации через случайные эффекты. Информационные критерии AIC (42933.5) и BIC (43065.1) выше, чем у GLM и GAM моделей, что указывает на худшее соответствие данных этой модели с учетом ее сложности.\nГрафик случайных эффектов с тремя модами на значениях 0.5, -1.5 и -3 демонстрирует выраженную стратификацию судов по их промысловой эффективности. Такое распределение указывает на наличие трех различных групп в промысловом флоте, каждая со своими характеристиками. Группа с модой на 0.5 представляет суда с повышенной эффективностью, чьи уловы примерно на 65% (exp(0.5) ≈ 0.65) превышают средний уровень. Эти суда, вероятно, оснащены современным оборудованием, укомплектованы опытными экипажами и работают на наиболее продуктивных участках.\nВторая группа с модой на -1.5 соответствует судам со значительно сниженной эффективностью, показывающим уловы примерно на 78% ниже среднего показателя. Такие результаты могут быть связаны с устаревшим техническим оснащением, менее оптимальными методами лова или работой в менее продуктивных районах. Третья группа с модой на -3 представляет суда с крайне низкой эффективностью, демонстрирующие уловы на 95% ниже среднего уровня. Столь значительное отставание может объясняться серьезными техническими проблемами, отсутствием современного оборудования, неопытностью экипажей или систематическими организационными трудностями.А возможно работой не на мороженном крабе, а живом - требующим другой технологической работы.\nНаличие трех четких мод в распределении случайных эффектов свидетельствует о существенной неоднородности промыслового флота. Это указывает на то, что предположение о нормальном распределении случайных эффектов не выполняется, а данные имеют выраженную групповую структуру. Модель успешно выявляет эту скрытую стратификацию, что подтверждает важность учета случайных эффектов при анализе промысловых данных. Полученные результаты подчеркивают необходимость дифференцированного подхода к анализу эффективности судов и разработки управленческих решений с учетом выявленной группировки. Различные моды могут отражать не только технические различия между судами, но и различные стратегии промысла, доступ к ресурсам или уровень организации работы.\nПреимущества и недостатки подхода GAMM\nОсновное преимущество GAMM подхода заключается в возможности учета групповой структуры данных через случайные эффекты. Это позволяет более адекватно оценить неопределенность предсказаний и избежать завышения значимости эффектов из-за псевдорепликации. Модель обеспечивает более реалистичную оценку вариации в данных, учитывая как фиксированные эффекты, так и случайную вариацию между группами.\nК недостаткам можно отнести повышенную вычислительную сложность и потенциальные проблемы со сходимостью алгоритмов оптимизации. Интерпретация результатов становится сложнее, особенно при наличии взаимодействий между фиксированными и случайными эффектами. В данном случае модель показала худшие показатели качества подгонки по сравнению с более простыми GLM и GAM моделями, что может свидетельствовать о избыточной сложности модели для данного набора данных.\nВ целом, GAMM представляет собой мощный инструмент для анализа данных с иерархической структурой, но его применение должно быть обосновано теоретически и подтверждено улучшением качества модели по сравнению с более простыми альтернативами.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Стандартизация CPUE</span>"
    ]
  },
  {
    "objectID": "chapter 10.html#сравнительный-анализ-моделей-по-информационным-критериям",
    "href": "chapter 10.html#сравнительный-анализ-моделей-по-информационным-критериям",
    "title": "11  Стандартизация CPUE",
    "section": "11.6 Сравнительный анализ моделей по информационным критериям",
    "text": "11.6 Сравнительный анализ моделей по информационным критериям\nВ данном разделе проводится систематическое сравнение трех альтернативных моделей - GLM, GAM и GAMM - с использованием информационных критериев и других метрик качества. Для унификации процесса сравнения создана специализированная функция extract_model_metrics, которая адаптирована для извлечения сопоставимых показателей из моделей разной структуры.\nДля GLM и GAM моделей используются стандартные методы расчета критериев, включая AIC, BIC, логарифмическое правдоподобие и долю объясненной девиации. Для GAMM модели, имеющей более сложную смешанную структуру, метрики извлекаются из компонентов mer и gam объекта, с дополнительным учетом случайных эффектов при расчете сложности модели.\nРезультаты сравнения представлены в виде структурированной таблицы, где модели упорядочены по возрастанию AIC - информационного критерия Акаике, который балансирует качество подгонки и сложность модели. Дополнительно вычисляются дельта-AIC (разница относительно наилучшей модели) и веса AIC, которые интерпретируются как вероятности того, что данная модель является наилучшей среди рассматриваемых.\nАнализ результатов показывает четкое разделение моделей по качеству. Модель GAM демонстрирует наилучшие показатели с AIC = 42840.91 и весом AIC 0.993, что означает 99.3% вероятность того, что эта модель является наилучшей среди сравниваемых. Модель GLM показывает очень близкие результаты по объясненной дисперсии (0.401), но несколько худшие значения AIC (42850.76) и минимальный вес (0.007). Модель GAMM значительно уступает по всем критериям с AIC = 42933.49 и нулевым весом в рамках данного сравнения.\nРазница в AIC между GAM и GLM составляет 9.85 единиц, что превышает пороговое значение 2, принятое для утверждения о существенном преимуществе одной модели над другой. Еще более значительная разница в 92.58 единиц между GAM и GAMM подтверждает статистически значимое превосходство GAM модели.\nНа основе проведенного анализа формулируются итоговые рекомендации по выбору модели. Модель GAM идентифицируется как наилучшая с очень высокой степенью уверенности (вес AIC 0.993). Объясняющая способность модели составляет 40.1%, что указывает на хорошее соответствие модели данным.\nДанный сравнительный подход обеспечивает объективную основу для выбора окончательной модели, позволяя учесть как качество подгонки, так и сложность модели, избегая таким образом как избыточного усложнения, так и излишнего упрощения.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Стандартизация CPUE</span>"
    ]
  },
  {
    "objectID": "chapter 10.html#основная-цель",
    "href": "chapter 10.html#основная-цель",
    "title": "11  Съёмка: оптимизация маршрута",
    "section": "11.2 Основная цель",
    "text": "11.2 Основная цель\nСкрипт моделирует оптимальные маршруты для станций в разных вариантах исследовательского полигона, чтобы определить, как изменение площади и формы полигона влияет на длину необходимого маршрута. Полный скрипт можно скачать по ссылке.\nДля работы скрипта:\n\nСкачайте файл данных (polygons.RData)\nУстановите рабочую директорию в setwd()\nУстановите необходимые пакеты.`",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Съёмка: оптимизация маршрута</span>"
    ]
  },
  {
    "objectID": "chapter 10.html#пошаговая-работа-скрипта",
    "href": "chapter 10.html#пошаговая-работа-скрипта",
    "title": "11  Съёмка: оптимизация маршрута",
    "section": "11.3 Пошаговая работа скрипта",
    "text": "11.3 Пошаговая работа скрипта\n\n11.3.1 1. Подготовка данных\n\nЗагружается полигон за 2020 год из файла polygons.RData\nПолигон преобразуется в систему координат UTM зоны 40N (EPSG:32640) для точных метрических вычислений\nРассчитывается площадь полигона: 63,101.31 км²\n\n\n\n11.3.2 2. Моделирование расширенных полигонов\nСоздан алгоритм, который асимметрично расширяет полигон на север (имитируя расширение зоны исследования в арктическом направлении):\n\nexpand_polygon_north() определяет северную часть (верхние 30% точек)\nРасширяет только эту часть на заданный коэффициент\nСоздаются 3 варианта: увеличенные на 1.5x, 2x и 3x\n\n\n\n11.3.3 3. Генерация траловых станций\n\nДля каждого полигона генерируются 137 равномерно распределенных точек (метод “regular”)\nЭто имитирует расположение траловых станций в исследовательском полигоне\nКоличество станций одинаково для всех вариантов полигона\n\n\n\n11.3.4 4. Оптимизация маршрутов\nКлючевая часть скрипта — решение задачи коммивояжера (TSP) для оптимизации маршрута судна:\n\nНачало и конец маршрута фиксируются как две самые западные точки (логично для судна, приходящего с запада)\nИспользуется алгоритм ближайшего включения (nearest_insertion)\nМатрица расстояний рассчитывается с помощью distHaversine (точное геодезическое расстояние)\n\n\n\n11.3.5 5. Анализ результатов\nСкрипт рассчитывает и сравнивает:\n\nПлощадь каждого полигона\nДлину оптимального маршрута для 137 станций\nВизуализирует все варианты на карте",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Съёмка: оптимизация маршрута</span>"
    ]
  },
  {
    "objectID": "chapter 10.html#интерпретация-результатов",
    "href": "chapter 10.html#интерпретация-результатов",
    "title": "11  Съёмка: оптимизация маршрута",
    "section": "11.4 Интерпретация результатов",
    "text": "11.4 Интерпретация результатов\nИз сводной таблицы видно, как увеличение площади полигона влияет на длину маршрута:\n\n\n\n\n\n\n\n\n\nВариант\nКоличество тралений\nДлина маршрута (км)\nПлощадь полигона (км²)\n\n\n\n\nOriginal\n137\n3,745\n63,101.3\n\n\nExpanded_x1.5\n137\n4,076\n99,791.0\n\n\nExpanded_x2\n137\n4,701\n135,352.0\n\n\nExpanded_x3\n137\n6,038\n207,066.0\n\n\n\nВажные наблюдения:\n\nПри увеличении площади на 57% (до 99,791 км²) длина маршрута возрастает только на 9% (до 4,076 км)\nПри троекратном увеличении площади (до 207,066 км²) длина маршрута возрастает на 61% (до 6,038 км)\nЭто показывает нелинейную зависимость между площадью полигона и длиной маршрута",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Съёмка: оптимизация маршрута</span>"
    ]
  },
  {
    "objectID": "chapter 10.html#практическое-применение",
    "href": "chapter 10.html#практическое-применение",
    "title": "11  Съёмка: оптимизация маршрута",
    "section": "11.5 Практическое применение",
    "text": "11.5 Практическое применение\nЭтот анализ полезен для:\n\nПланирования гидробиологических исследований в условиях ограниченного бюджета\nОценки дополнительных затрат при расширении зоны исследования\nОптимизации маршрутов научно-исследовательских судов\nМоделирования последствий изменения границ охраняемых территорий\n\nСкрипт демонстрирует, как геопространственный анализ и алгоритмы оптимизации могут помочь в принятии решений при планировании полевых исследований водных биоресурсов, особенно в условиях арктических морей, где логистика особенно сложна и дорогостояща.\n\n# ========================================================================================================================\n# ПРАКТИЧЕСКОЕ ЗАНЯТИЕ: СТАНДАРТИЗАЦИЯ CPUE С ИСПОЛЬЗОВАНИЕМ GLM, GAM И GAMM\n# Курс: \"Оценка водных биоресурсов в среде R (для начинающих)\"\n# Автор: Баканев С.В. \n# Дата: 20.08.2025\n# \n# Структура:\n# 1) Загрузка пакетов и настройка среды\n# 2) Загрузка и предварительная обработка данных\n# 3) Вспомогательные функции для расчета индексов\n# 4) Моделирование GLM (Gamma с лог-ссылкой)\n# 5) Моделирование GAM (обобщенная аддитивная модель)\n# 6) Моделирование GAMM (смешанная модель со случайными эффектами)\n# 7) Сравнение моделей и финальная визуализация результатов\n# ========================================================================================================================\n\n\n# ==============================================================================\n# БЛОК 1: ЗАГРУЗКА ПАКЕТОВ И НАСТРОЙКА СРЕДЫ\n# ==============================================================================",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Съёмка: оптимизация маршрута</span>"
    ]
  }
]
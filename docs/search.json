[
  {
    "objectID": "chapter32.html",
    "href": "chapter32.html",
    "title": "33  Случайное блуждание RW и автокорреляция AR(1)",
    "section": "",
    "text": "33.1 Введение\nВодные экосистемы по своей природе стохастичны — их динамика рождается на стыке закономерностей и случайности. Исторический опыт рыбохозяйственной науки показывает: чисто детерминистические модели часто неспособны адекватно предсказывать состояние водных биоресурсов, поскольку не учитывают фундаментальную неопределенность, в которой существуют реальные популяции.\nСлучайное блуждание (random walk) и авторегрессия первого порядка (AR(1)) — два принципиальных подхода к моделированию такой стохастической динамики. Практическая ценность их различий особенно очевидна в задачах управления промыслом: ошибочная идентификация типа процесса может вести либо к недолову (неэффективное использование), либо к перелову (угроза запасу).\nВизуальное сравнение траекторий обоих процессов раскрывает их суть. Десять реализаций случайного блуждания похожи на веер расходящихся путей — это процесс без «памяти», не возвращающийся к исходному состоянию. В гидробиологии так могут вести себя кумулятивные изменения, например, в генетической структуре изолированной популяции.\nНапротив, траектории AR(1) с φ = 0.8 колеблются вокруг среднего, демонстрируя «упругость» — система стремится вернуться к равновесию после отклонения. Параметр φ здесь — мера памяти системы. Такое поведение характерно для многих природных процессов: суточные колебания температуры у организмов, сезонная динамика зоопланктона.\nСкрипт рисунка",
    "crumbs": [
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Случайное блуждание RW и автокорреляция AR(1)</span>"
    ]
  },
  {
    "objectID": "chapter32.html#случайное-блуждание",
    "href": "chapter32.html#случайное-блуждание",
    "title": "33  Случайное блуждание RW и автокорреляция AR(1)",
    "section": "33.2 Случайное блуждание",
    "text": "33.2 Случайное блуждание\nСлучайное блуждание - одна из самых фундаментальных и в то же время элегантных математических концепций, которая пронизывает практически все разделы современной гидробиологии. Эта идея, родившаяся из простых наблюдений за движением частиц в воде, превратилась в мощный инструмент для описания и понимания сложнейших биологических процессов в водных экосистемах.\nИстория случайного блуждания начинается с капли воды. В 1827 году Роберт Броун, тщательный и внимательный ботаник, разглядывал в микроскоп взвесь пыльцы в воде и заметил нечто удивительное - частицы совершали беспорядочные, хаотические движения, которые невозможно было объяснить ни течениями, ни конвекцией. Это наблюдение, сделанное в скромной лаборатории над обычной каплей воды, положило начало целому направлению в науке. Броун был настолько озадачен этим явлением, что проверил его на неорганических материалах - частичках горных пород, и убедился, что движение продолжается. Он так и не смог объяснить природу этого феномена, но его тщательные записи и описания стали отправной точкой для будущих поколений ученых.\nПотребовалось почти восемьдесят лет, чтобы гениальный ум Альберта Эйнштейна в 1905 году дал объяснение этому явлению. В своей работе о броуновском движении Эйнштейн показал, что хаотическое движение частиц вызывается постоянными столкновениями с невидимыми молекулами воды. Это было не просто объяснение конкретного явления - это было подтверждение атомно-молекулярной теории вещества. Таким образом, простое наблюдение за поведением частиц в воде привело к одному из фундаментальных открытий в физике.\nМатематически случайное блуждание записывается как:\nxₜ = xₜ₋₁ + εₜ, где εₜ ∼ N(0,σ²) - случайная компонента (белый шум).\nНо что все это имеет общего с гидробиологией? Оказывается, самое прямое. Представьте себе зоопланктон в толще воды - его движение, особенно в отсутствие сильных течений, во многом напоминает то самое броуновское движение. Личинки рыб, дрейфующие в океанических водах, также подчиняются законам случайного блуждания, хотя и с добавлением некоторых направленных компонентов. Даже распространение загрязняющих веществ в водоемах, миграции водных организмов, распределение питательных веществ - все эти процессы могут быть описаны с помощью моделей случайного блуждания.\nВ популяционной экологии случайное блуждание нашло свое применение при описании динамики численности организмов. Когда мы изучаем колебания численности популяции рыбы из года в год, мы видим не только детерминированные тренды, связанные с воспроизводством и смертностью, но и случайные компоненты, обусловленные непредсказуемыми изменениями окружающей среды - температурными аномалиями, изменениями кормовой базы, эпидемиями. Именно эти случайные компоненты часто оказывают решающее влияние на судьбу популяции.\nПри оценке запасов водных биоресурсов мы постоянно сталкиваемся с необходимостью отделить реальные изменения в популяции от погрешностей наших методов наблюдения. Траловые съемки, акустические оценки, данные промысловой статистики - все они несут в себе элемент случайности, и понимание природы этой случайности позволяет нам делать более точные и надежные выводы. Интересно проследить, как математическая абстракция случайного блуждания постепенно проникала в биологию. В начале XX века английский статистик Карл Пирсон впервые ввел сам термин “случайное блуждание - random walk” и разработал его математический аппарат. Затем, в 1920-х годах, Рональд Фишер начал применять стохастические модели в генетике для описания дрейфа генов. Постепенно эти идеи проникли в экологию, и к 1950-м годам случайное блуждание стало стандартным инструментом для моделирования популяционной динамики.\nОдин из самых ярких примеров применения случайного блуждания в гидробиологии связан с работами Лотки и Вольтерры, которые, хотя и разрабатывали в основном детерминистические модели, заложили основы для последующего включения стохастических компонентов. Их последователи поняли, что без учета случайных факторов модели популяционной динамики часто оказываются слишком идеализированными и не соответствующими реальным данным.\nВ современной гидробиологии случайное блуждание используется в самых разных контекстах - от моделирования движения отдельных организмов до прогнозирования динамики целых экосистем. Когда мы изучаем распространение инвазивных видов в новых водоемах, когда моделируем последствия климатических изменений для распределения рыб, когда пытаемся предсказать вспышки численности вредоносного фитопланктона - везде мы используем аппарат случайного блуждания и связанных с ним стохастических процессов.\nВажно понимать, что случайное блуждание - это не просто “учет случайности” как некоего недостатка наших знаний. Во многих случаях стохастичность является фундаментальным свойством биологических систем. Как отмечал известный эколог Роберт Мэй, “сложные экологические системы по своей природе содержат элемент непредсказуемости, и попытки описать их исключительно детерминистическими моделями часто приводят к ошибочным выводам”.\nОт абстрактной теории случайного блуждания перейдем к его практическому воплощению — моделированию распространения запаха приманки в воде (например в крабовой ловушке). Эта простая, но биологически обоснованная модель показывает, как математическая абстракция работает в реальных условиях промысла.\nМы имитируем работу ловушки, выпускающей частицы аттрактанта в течение 24 часов. Каждая частица начинает движение из точки приманки и далее следует уравнению случайного блуждания с дрейфом: к случайному смещению добавляется постоянная компонента течения. Именно эта комбинация — хаос микроскопических столкновений и упорядоченный поток воды — создает ту самую картину распространения запаха, которую детектируют хеморецепторы крабов и рыб.\n• Первый график — эволюция шлейфа через 6, 12, 18 и 24 часа. Компактное облако частиц постепенно растягивается течением, формируя вытянутый шлейф с высокой концентрацией у источника и разреженный на периферии.\nСкрипт рисунков\n\n\n\n\n\n• Второй график — индивидуальные траектории 20 случайно выбранных частиц. Каждый путь уникален, но вместе они демонстрируют общую тенденцию: течение задает преимущественное направление, превращая хаос в упорядоченную структуру. вытянутый шлейф с высокой концентрацией у источника и разреженный на периферии.\n\n\n\n\n\nАвторегрессия первого порядка AR(1)\nПродолжаем наше путешествие по стохастическим ландшафтам гидробиологии — и если в прошлый раз мы шли по следам случайного блуждания, где каждое новое положение рождалось из предыдущего плюс чистый шум, то теперь обратимся к его более «дисциплинированному» родственнику — авторегрессии первого порядка, или AR(1). Эта модель, столь же простая по форме, но гораздо более сдержанная в поведении, играет ключевую роль в описании тех биологических процессов, где прошлое влияет на настоящее, но не диктует ему судьбу.\nПредставьте себе не частицу, дрейфующую в океане, а температуру на нерестилище. Она не уходит в бесконечность — несмотря на годовые флуктуации, она колеблется вокруг некой климатической нормальности. Если в этом году вода была аномально тёплой, велика вероятность, что и в следующем году она будет чуть теплее среднего — но не обязательно такой же горячей. И со временем система возвращается к своему среднему состоянию. Именно это поведение и описывает AR(1).\nМатематически AR(1) записывается так:\nxt​=ϕ⋅xt−1​+εt​, εt​∼N(0,σ2),∣ϕ∣&lt;1\nЗдесь коэффициент ϕ — «память» системы. Чем ближе он к 1, тем дольше сохраняется влияние прошлого; чем ближе к 0 — тем быстрее система «забывает» и возвращается к среднему. И главное отличие от случайного блуждания: при ∣ϕ∣&lt;1 процесс стационарен — его статистические свойства (среднее, дисперсия, автокорреляция) не меняются со временем.\nВ отличие от RW, где траектория может уйти в бесконечность, AR(1) — это процесс с упругой памятью. Такое поведение типично для многих гидробиологических переменных:\n\nТемпература воды в конкретном районе: она флуктуирует, но не уходит в экстремумы без внешнего воздействия.\nПополнение гидробионтов, если оно зависит от средовых условий с короткой памятью (например, весенняя продуктивность).\nКоэффициент уловистости (q), если его изменчивость вызвана краткосрочными факторами (опыт экипажа, состояние техники), но не систематическим трендом.\nОстатки в моделях «запас–пополнение», когда необъяснённая часть динамики сохраняет корреляцию от года к году, но не накапливается.\n\n\nAR(1) — это модель «умеренного консерватизма» природы: система реагирует на прошлое, но не позволяет ему доминировать.\nХотя идея авторегрессии зародилась в начале XX века в работах Юла и Слуцкого при анализе экономических временных рядов, её проникновение в экологию произошло позже — в 1960–1970-х годах, когда исследователи начали осознавать, что не всякая корреляция во времени — это тренд. Особенно важным стал вклад Роберта Мэя и Питера Тёрчина, которые показали, что даже в детерминистических моделях популяционной динамики (например, логистическом уравнении с запаздыванием) могут возникать стохастически-подобные колебания, которые лучше всего аппроксимируются AR(1)-процессами.\nВ гидробиологии AR(1) стал стандартом при моделировании коррелированного шума в индексах численности, ошибках наблюдений и скрытых состояниях в фильтрах Калмана. Например, в байесовских моделях оценки запасов (SPiCT, JABBA) AR(1) часто используется для описания временной структуры отклонений от детерминированной траектории — именно там, где RW был бы слишком «вольным», а белый шум — слишком «холодным».\nДанный скрипт демонстрирует работу авторегрессионной модели первого порядка AR(1) на примере моделирования колебаний температуры воды в водных экосистемах. Он генерирует множественные траектории температурных отклонений от среднего значения для четырех различных уровней “памяти” системы (φ = 0.2, 0.5, 0.8, 0.95), визуализируя, как параметр φ влияет на скорость возврата системы к равновесному состоянию после случайных возмущений.\nНа выходе скрипт создает компактный график с четырьмя фасетками, где каждая панель показывает шесть реализаций AR(1) процесса для соответствующего значения φ. Это наглядно иллюстрирует фундаментальное свойство AR(1) процессов — способность колебаться вокруг среднего значения с разной степенью инерции, что соответствует различным типам водных экосистем: от быстро реагирующих мелководий до инерционных глубоководных бассейнов.",
    "crumbs": [
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Случайное блуждание RW и автокорреляция AR(1)</span>"
    ]
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "2  Анализ и визуализация данных улова",
    "section": "",
    "text": "2.1 Введение\nЭто занятие — про первый шаг в анализе уловов: аккуратно загрузить данные, посмотреть на них без иллюзий и задать простые, проверяемые вопросы. Наша цель сейчас убедиться, что мы видим именно то, что реально записано в файле: сколько строк, какие переменные, каких они типов и не прячутся ли среди них ошибки, способные испортить весь последующий анализ.\nНачинаем с того, чтобы R «видел» правильную папку. Рабочая директория должна указывать туда, где лежит файл shrimp_catch.csv. Простая установка пути — это не бюрократия, а воспроизводимость: на другом компьютере тот же код должен читать те же данные, а не «что‑то похожее». После этого подключаем пакет tidyverse: это набор инструментов, который унифицирует чтение, преобразование и визуализацию. read_csv считывает таблицу и сразу создаёт tibble — «вежливую» версию data.frame с чётким хранением типов. Уже на этом шаге стоит помнить о банальных, но частых ловушках: десятичный разделитель должен совпадать с вашими региональными настройками, пустые строки и «NA» в файле должны превращаться в пропуски, а не в нули или текст.\nПервичный осмотр — это короткий разговор с данными без интерпретации. Команда glimpse выдаёт компактный снимок: сколько строк, каковы названия столбцов и их классы, примеры значений. В нашем наборе ожидаем пять столбцов: id как целое число, age как целое число 1–4, length как числовая величина длины, weight как числовая величина массы и sex как текстовый признак пола. Если вы видите, что length внезапно «chr» или sex закодирован числами — это сигнал остановиться и привести типы в порядок сейчас, а не объяснять странные результаты потом. Аналогичная команда str показывает внутреннюю структуру и подтверждает, что R понимает объект так же, как и вы. Эти две команды — «микроскоп 4×»: быстро и без украшательств.\nДальше имеет смысл задать несколько контрольных вопросов, которые одновременно проверяют здравый смысл и раскрывают базовую статистику. Команда summary покажет минимумы, медианы и квартильные точки для количественных переменных и распределение для категориальных. Если где‑то возникает отрицательный вес, нулевая длина или возраст за пределами 1–4 — это не «особенности популяции», это данные, требующие чистки. table и prop.table дадут частоты по полу; если соотношение полов выглядит нереалистично для вашей промысловой выборки — проверьте этап предобработки. Наконец, простой cor.test между длиной и весом покажет, есть ли ожидаемая сильная положительная связь; но здесь важно помнить о дисциплине: корреляция — это не причинность, и даже высокая r требует подтверждения графиком рассеяния и проверкой на аутлайеры.\nЗачем столько внимания «мелочам» до любых моделей? Потому что в прикладной биостатистике именно этот участок пути отделяет полезные выводы от красивых, но пустых графиков. Проверка типов и диапазонов, явное обращение с пропусками, подтверждение структурой — это те скромные процедуры, которые экономят часы на поздних этапах. И если позволить себе лёгкую ремарку, то лучший способ повысить интеллектуальную честность анализа — не верить по умолчанию ни себе, ни данным, пока вы не посмотрели на них под простейшим светом glimpse или str.\nКогда эти шаги пройдены, можно переходить к описательной статистике и первичной визуализации. Гистограмма длины даст быстрый набросок формы распределения, а простые группировки по возрасту покажут, как меняются средние и разброс. Но это уже следующий раздел. Сейчас важнее, чтобы R и вы одинаково понимали, что такое «наши данные», и чтобы каждый последующий результат опирался на корректно загруженную и проверенную таблицу shrimp_catch.csv.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter1.html#загрузка-данных-и-первичный-осмотр",
    "href": "chapter1.html#загрузка-данных-и-первичный-осмотр",
    "title": "2  Анализ и визуализация данных улова",
    "section": "2.2 Загрузка данных и первичный осмотр",
    "text": "2.2 Загрузка данных и первичный осмотр\nссылка на файл: shrimp_catch.csv\n\n# Установка рабочей директории\nsetwd(\"C:/TEXTBOOK/\")\n# Загрузка библиотек\nlibrary(tidyverse)\n# Загрузка данных\ndata &lt;- read_csv(\"shrimp_catch.csv\")\n\nКоманда glimpse знакомит со структурой данных:\n\n# Просмотр структуры и первых строк загруженных данных\nglimpse(data)\n\n\nRows: 230\nColumns: 5\n$ id     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, ~\n$ age    &lt;int&gt; 2, 4, 4, 4, 1, 4, 2, 2, 4, 3, 4, 3, 2, 1, 2, 1, 2, 2, 2, 2, 3, ~\n$ length &lt;dbl&gt; 20.45450, 25.88928, 29.42257, 30.68292, 12.46059, 28.52152, 17.~\n$ weight &lt;dbl&gt; 1.28221748, 1.97476899, 2.65412595, 3.44746476, 0.13404801, 2.3~\n$ sex    &lt;chr&gt; \"M\", \"F\", \"F\", \"F\", \"M\", \"F\", \"M\", \"M\", \"F\", \"F\", \"F\", \"F\", \"M\"~\n&gt; \n\nМожно использовать команду str — показывает внутреннюю структуру объекта , включая количество строк, столбцов, названия переменных, их типы (chr, num, int и др.), а также несколько первых значений.\n\nstr(data)\n\n\n'data.frame':   230 obs. of  5 variables:\n $ id    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ age   : int  2 4 4 4 1 4 2 2 4 3 ...\n $ length: num  20.5 25.9 29.4 30.7 12.5 ...\n $ weight: num  1.282 1.975 2.654 3.447 0.134 ...\n $ sex   : chr  \"M\" \"F\" \"F\" \"F\" ...\n&gt;",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter1.html#описательная-статистика-и-визуализация",
    "href": "chapter1.html#описательная-статистика-и-визуализация",
    "title": "2  Анализ и визуализация данных улова",
    "section": "2.3 Описательная статистика и визуализация",
    "text": "2.3 Описательная статистика и визуализация\nКоманда summary выводит описательную статистику для каждой числовой переменной: минимум, 1-й квартиль, медиана, среднее, 3-й квартиль, максимум; для категориальных переменных — частоты.\n\n# Общая статистика\nsummary(data)\n\n\n       id              age            length          weight       \n Min.   :  1.00   Min.   :1.000   Min.   : 7.65   Min.   :-0.3334  \n 1st Qu.: 58.25   1st Qu.:2.000   1st Qu.:17.62   1st Qu.: 0.6320  \n Median :115.50   Median :3.000   Median :22.49   Median : 1.3660  \n Mean   :115.50   Mean   :2.509   Mean   :21.68   Mean   : 1.4933  \n 3rd Qu.:172.75   3rd Qu.:3.000   3rd Qu.:26.03   3rd Qu.: 2.1148  \n Max.   :230.00   Max.   :4.000   Max.   :36.02   Max.   : 5.1316  \n     sex           \n Length:230        \n Class :character  \n Mode  :character  \n\nПростейшими командами можно вычислить, например, соотоношение полов или корреляцию длина-вес.\n\n# Соотношение полов\nprop.table(table(data$sex)) %&gt;% round(2)\n\n\n   F    M \n0.35 0.65 \n\n\n# Корреляция длина-вес с p-value\ncor_test &lt;- cor.test(data$length, data$weight, \n                     method = \"pearson\", \n                     exact = FALSE,\n                     na.action = na.omit)\n \ncor_coef &lt;- round(cor_test$estimate, 2)\np_value &lt;- scales::pvalue(cor_test$p.value, accuracy = .001)\n \ncat(\"Корреляция Пирсона: r =\", cor_coef, \", p =\", p_value, \"\\n\")\n\n\nКорреляция Пирсона: r = 0.95 , p = &lt;0.001 \n\n\n# Распределение возраста\ntable(data$age)\n\n\n1  2  3  4 \n43 68 77 40 \n\n\n# Средние значения длины и веса по группам\ndata %&gt;%\n   group_by(age) %&gt;%\n   summarise(\n     mean_length = mean(length),\n     sd_length = sd(length),\n     mean_weight = mean(weight),\n     sd_weight = sd(weight))\n\n\n# A tibble: 4 x 5\n    age mean_length sd_length mean_weight sd_weight\n  &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1     1        12.7      1.37       0.249     0.234\n2     2        19.2      1.88       0.919     0.341\n3     3        24.8      1.72       1.88      0.424\n4     4        29.1      2.28       2.96      0.804\n&gt; \n\n\n2.3.1 Построение гистограммы для переменной ‘length’ (длина креветок)\nДля первого визуального знакомства команда hist строит гистограмму — простой график, который показывает, как распределены значения числовой переменной. В данном случае отображается распределение длин креветок из набора данных.\n\nhist(data$length, \n     main = \"Гистограмма длины креветок\",          # Заголовок графика\n     xlab = \"Длина (см)\",                          # Подпись оси X\n     ylab = \"Частота\",                             # Подпись оси Y\n     col = \"lightblue\",                            # Цвет столбцов\n     border = \"black\",                             # Цвет границ столбцов\n     breaks = 15)                                   # Количество интервалов\n\n\n\n\nРис. 1.1: Гистограмма длины креветок\n\n\n\n\n2.3.2 Визуализация в ggridges\nДля элегантных и компактных графиков подходит библиотека ggridges. Построим распределение длины креветки в зависимости от пола и возраста.\n\nlibrary(ggplot2)\nlibrary(ggridges)\n\nggplot(data, aes(x = length, \n                 y = sex, \n                 group = sex, \n                 fill = sex)) +\n  geom_density_ridges(scale = 2, alpha = 0.7) +\n  scale_y_discrete(expand = c(0, 0)) +\n  scale_x_continuous(expand = c(0, 0)) +\n  labs(\n    title = \"Распределение длины карапакса по полу\",\n    x = \"Длина карапакса (мм)\",\n    y = \"Пол\"\n  ) +\n  theme(\n    panel.border = element_blank(),  # Убирает рамку вокруг графика\n    axis.line = element_line(color = \"black\")  # Сохраняет осевые линии (опционально)\n  )\n\n\n\n\nРис. 1.2: Пол-длина креветок с использованием ggridges",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter1.html#выявление-аутлайеров-выбросов",
    "href": "chapter1.html#выявление-аутлайеров-выбросов",
    "title": "2  Анализ и визуализация данных улова",
    "section": "2.4 Выявление аутлайеров (выбросов)",
    "text": "2.4 Выявление аутлайеров (выбросов)\nАутлаеры (выбросы) — наблюдения, значительно отклоняющиеся от общего распределения данных. Их идентификация необходима, так как они могут искажать результаты анализа. Один из надёжных методов обнаружения выбросов — метод межквартильного размаха (IQR).\n\n2.4.1 Теория метода\n\nРасчёт квартилей:\n\nQ1 (25-й перцентиль): значение, ниже которого находится 25% данных.\nQ3 (75-й перцентиль): значение, ниже которого находится 75% данных.\nIQR = Q3 - Q1: мера разброса средней половины данных.\n\nГраницы аутлаеров:\n\nНижняя граница: Q1−1.5×IQR\nВерхняя граница: Q3+1.5×IQR\nНаблюдения за этими пределами считаются выбросами.\n\n\n\n\n2.4.2 Преимущества метода\n\nУстойчивость к асимметрии распределения.\nНе требует предположения о нормальности данных.\n\n\n# Метод межквартильного размаха\noutliers &lt;- data %&gt;%\n  mutate(\n    length_z = scale(length),\n    weight_z = scale(weight)\n  ) %&gt;% \n  filter(abs(length_z) &gt; 3 | abs(weight_z) &gt; 3)\n\n# Визуализация\nggplot(data, aes(x = length, y = weight)) +\n  geom_point(aes(color = \"Обычные\"), alpha = 0.5) +\n  geom_point(data = outliers, aes(color = \"Аутлаеры\"), size = 3) +\n  scale_color_manual(values = c(\"Обычные\" = \"grey50\", \"Аутлаеры\" = \"red\")) +\n  labs(title = \"Выявление аномальных наблюдений\", color = \"Тип\")\n\n\n\n\nРис. 1.3: Распределение длины карапакса",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter1.html#определение-возрастной-структуры-статистические-методы-анализа-размерных-данных",
    "href": "chapter1.html#определение-возрастной-структуры-статистические-методы-анализа-размерных-данных",
    "title": "2  Анализ и визуализация данных улова",
    "section": "2.5 Определение возрастной структуры: статистические методы анализа размерных данных",
    "text": "2.5 Определение возрастной структуры: статистические методы анализа размерных данных\nЛирическое отступление\nОпределять возрастную структуру по размерным данным — это не попытка «угадать» возраст, а дисциплинированный способ выделить в общей смеси несколько закономерных мод, за которыми почти всегда стоят биологические процессы: вариации в пополнении, различия в темпах роста, селективность промысла. Мы не видим возраст напрямую, зато видим след его накопления в длине, и задача статистики здесь — разложить смешанное распределение на осмысленные компоненты, не выдавая желаемое за действительное. Начинать разумно с простого: гистограмма и сглаженная плотность дают первичную картину, где «пики» — это кандидаты на возрастные группы. Выбор ширины бинов (диапазонов) — не косметика: слишком широкие бины сливают моды, слишком узкие создают шумовые «зубцы». Ядерная плотность (сглаживание) полезна как независимая проверка: если пик виден и на гистограмме, и на сглаженной плотности, это хороший знак. Уже на этом шаге важно исключить явные аутлаеры и убедиться, что анализируется однородная по сезону и району выборка: смешение сезонов способно превратить один чёткий пик в два слабых и наоборот.\nМетод K‑means привлекателен скоростью и простотой, но его допущения жестковаты для биологии: он делит по ближайшему центру и фактически предполагает равные дисперсии у групп. Для черновой разметки это приемлемо: задали K, получили кластеры, посмотрели, не распилили ли явный пик пополам и не смешали ли крайние хвосты. Но трактовать эти кластеры как «возрастные классы» без дополнительных проверок нельзя. Минимальный набор проверок — «локальный смысл»: центры кластеров должны быть упорядочены по длине, доли групп не должны выглядеть абсурдно для вашей системы, а границы между кластерами — приходиться на спады между модами гистограммы. Полезно пробежать несколько значений K, посмотреть «локоть» по внутрикластерной дисперсии или силуэт; если модель жадно «доедает» шум, она не помогает задаче.\nДекомпозиция смесью нормалей с EM‑алгоритмом ближе к тому, что нам нужно: каждая компонента имеет свой средний размер, свою дисперсию и свою долю, а принадлежность особи — вероятностная, а не «жёсткая». Это лучше отражает реальность: возрастные группы перекрываются, и жёсткое отнесение на границе избыточно уверенно. Здесь ключевая инженерная мысль — инициализация и выбор числа компонент. Стартовать можно от пиковой структуры гистограммы или от грубых центров k‑means; число компонент выбирать по BIC/AIC и здравому смыслу, помня, что каждая лишняя компонента почти всегда «объясняет» шум. Параметры смеси имеют прозрачную интерпретацию: μ — модальный размер группы, σ — разброс (ростовая гетерогенность плюс измерительная ошибка), λ — доля группы в выборке. Для отчётности полезно ранжировать компоненты по μ, чтобы избежать «перескока меток» между запусками, и дать доверительные интервалы (обычный приём — бутстрэп).\nМетод Бхаттачарии, классика промысловой гидробиологии, по сути делает то же в терминах гистограммы: линейнизует лог‑разности соседних бинов и позволяет визуально «вынуть» наклон, соответствующий компоненте нормального распределения. Он чувствителен к выбору ширины бина и к ровности хвостов, зато нагляден и хорошо работает там, где пики действительно нормальны и отделены. В паре с EM это сильная связка: Бхаттачария помогает выбрать разумное K и старт, EM — уточняет параметры и даёт вероятностные принадлежности. Сопоставление результатов этих двух подходов повышает доверие: если оба «видят» четыре группы с близкими μ, это гораздо лучше, чем красивый рисунок одного метода.\nНа практике полезно придерживаться алгоритма «снизу вверх». Сначала — чистая визуализация: гистограмма, ядерная плотность, по возможности разрезы по полу; это помогает понять, не смешиваем ли мы биологически разные контексты. Затем — черновая кластеризация k‑means для ориентировочных центров и грубого K. Далее — смеси нормалей с EM, выбор K по BIC и проверка стабильности решения от разных стартов. После подгонки — диагностика: наложить компоненты и суммарную смесь на гистограмму, проверить, не «улетели» ли σ, нет ли «дублирующих» компонент с почти одинаковыми μ, сопоставить λ с ожидаемыми долями когорт. И главное — помнить, что «модальные группы по длине» и «возрастные классы» совпадают не автоматом: для перевода мод в возраст нужен ростовой ключ (например, параметры Берталанфи) или независимая информация о когортности. Без этого честнее говорить «модальные размерные группы».\nНаконец, стоит держать в голове пару дисциплинарных напоминаний. Любая смесь будет пытаться объяснить артефакты данных, поэтому контроль качества измерений и фильтрация аутлаеров — не опция, а необходимость. Сезонная выборка и селективность сдвигают доли и средние: если орудия ловят неравномерно, λ смеси — это не «структура популяции», а «структура улова». И, как бы прозаично это ни звучало, фиксируйте зерно генератора случайных чисел и документируйте выбор K и стартовые значения: это делает ваш результат воспроизводимым, а спор — предметным. Такой дисциплинированный ход — от картинки к модели, от модели к диагностике, от диагностики к осторожной интерпретации — позволяет извлечь из длины то, что она действительно хранит про возраст, и не больше.\nИ так, возрастная структура популяции — часто важна для расчёта промысловой смертности, оценки репродуктивного потенциала и прогнозирования динамики запасов. Поскольку прямое измерение возраста часто невозможно (например, у беспозвоночных или рыб без четких возрастных меток), используются статистические методы, выделяющие группы в смешанных распределениях размеров.\nОсновные подходы:\n\nМетод k-средних (k-means) — алгоритм кластеризации, группирующий особи в заданное число кластеров (возрастных групп) на основе их размеров.\nМетод Бхаттачарии — статистический подход для разделения смешанных нормальных распределений, часто применяемый для идентификации мод в гистограммах. Название метода происходит от фамилии его создателя — Ананды Кумара Бхаттачарии (Ananda Kumar Bhattacharya), индийского статистика, который предложил этот метод в 1967 году.\nEM-алгоритм (Expectation-Maximization algorithm) — оценка параметров смеси распределений, подходящая для данных с перекрывающимися возрастными группами.\nГауссовы смеси (GMM) — расширение метода Бхаттачарии для многомерного анализа.\nЯдерное сглаживание — непараметрический метод визуализации плотности, помогающий выявить скрытые моды.\n\nРассмотрим метод k-средних (k-means) и метод Бхаттачарии, предварительно построив гистограмму.\n\n# Загрузка библиотек\nlibrary(tidyverse)\nlibrary(mixtools)\n# Гистограмма длины с наложением плотности\nggplot(data, aes(x = length)) +\n  geom_histogram(aes(y = after_stat(density)), fill = \"steelblue\", bins = 20, alpha = 0.7) +\n  geom_density(color = \"#FC4E07\", linewidth = 1) +\n  labs(title = \"Распределение длины карапакса\", \n       subtitle = \"Пики могут соответствовать возрастным группам\",\n       x = \"Длина (мм)\")\n\n\n\n\nРис. 1.3: Распределение длины карапакса и “ядерное сглаживание”\n\n\n\n# Кластеризация по длине (K-means как пример)\nset.seed(123)\nclusters &lt;- kmeans(data$length, centers = 4)  # Предполагаем 4 возрастные группы\ndata$cluster &lt;- factor(clusters$cluster)\n\n# Визуализация кластеров\nggplot(data, aes(x = length, fill = cluster)) +\n  geom_histogram(bins = 25, alpha = 0.7) +\n  labs(title = \"Кластеризация по длине)\", \n       x = \"Длина (мм)\")\n\n\n\n\nРис. 1.4: Кластеризация по длине (метод K-means)\n\n\n\n# Установка рабочей директории\nsetwd(\"C:/TEXTBOOK/\")\n\n# Загрузка библиотек\nlibrary(tidyverse)\nlibrary(mixtools)\n\n# Загрузка данных\ndata &lt;- read.csv(\"shrimp_catch.csv\")\n\n# 1. Построение и отображение гистограммы\nhist(data$length, breaks = 20, main = \"Гистограмма распределения длин карапаксов\",\n     xlab = \"Длина карапакса (мм)\", ylab = \"Частота\")\n\n# 2. Инициализация параметров (предположим 4 возрастные группы)\ninit_params &lt;- list(\n  lambda = rep(1/4, 4),\n  mu = c(13, 19, 25, 32),\n  sigma = c(1.5, 1.75, 1.75, 2.5)\n)\n\n# 3. Разделение смеси распределений методом EM\nfit &lt;- normalmixEM(data$length, k = 4, maxit = 1000, epsilon = 1e-3,\n                   lambda = init_params$lambda,\n                   mu = init_params$mu,\n                   sigma = init_params$sigma)\n\n# 4. Визуализация результатов с ggplot2\n# Генерация сетки для построения кривых\nx_grid &lt;- seq(min(data$length), max(data$length), length.out = 500)\n\n# Функция смеси\nmixture_density &lt;- function(x) {\n  fit$lambda[1] * dnorm(x, fit$mu[1], fit$sigma[1]) +\n  fit$lambda[2] * dnorm(x, fit$mu[2], fit$sigma[2]) +\n  fit$lambda[3] * dnorm(x, fit$mu[3], fit$sigma[3]) +\n  fit$lambda[4] * dnorm(x, fit$mu[4], fit$sigma[4])\n}\n\n# График\nggplot(data, aes(x = length)) +\n  # Гистограмма\n  geom_histogram(aes(y = after_stat(density)), bins = 20, fill = \"white\", color = \"black\", alpha = 0.7) +\n  # Исходное распределение (гладкая линия)\n  geom_density(color = \"red\", lwd = 1.2) +\n  # Смесь распределений\n  stat_function(fun = mixture_density, color = \"black\", lwd = 1.5) +\n  # Компоненты смеси\n  stat_function(fun = function(x) fit$lambda[1] * dnorm(x, fit$mu[1], fit$sigma[1]), color = \"blue\", lwd = 1) +\n  stat_function(fun = function(x) fit$lambda[2] * dnorm(x, fit$mu[2], fit$sigma[2]), color = \"green\", lwd = 1) +\n  stat_function(fun = function(x) fit$lambda[3] * dnorm(x, fit$mu[3], fit$sigma[3]), color = \"orange\", lwd = 1) +\n  stat_function(fun = function(x) fit$lambda[4] * dnorm(x, fit$mu[4], fit$sigma[4]), color = \"purple\", lwd = 1) +\n  \n  # Настройка темы и легенды\n  theme_minimal() +\n  labs(\n    x = \"Длина карапакса (мм)\",\n    y = \"Плотность\",\n    title = \"Разделение возрастных групп методом EM\"\n  )\n\n\n\n\nРис. 1.5: EM-алгоритм (Expectation-Maximization algorithm)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter1.html#уравнение-берталанфи",
    "href": "chapter1.html#уравнение-берталанфи",
    "title": "2  Анализ и визуализация данных улова",
    "section": "2.6 Уравнение Берталанфи",
    "text": "2.6 Уравнение Берталанфи\nУравнение Берталанфи — фундаментальная модель в рыбохозяйственной науке, описывающая асимптотический рост организмов. Оно имеет вид: \\[\nL(t) = L_{\\infty} \\cdot \\left(1 - e^{-k \\cdot (t - t_0)}\\right)\n\\] где L∞— теоретическая максимальная длина особи, k— коэффициент скорости роста, t0— гипотетический возраст при нулевой длине.\nВ приведённом коде модель применяется для анализа роста северной креветки :\n\nПодготовка данных: Удаление аутлаеров (например, строк 10 и 50) повышает точность оценки параметров.\nИнициализация параметров:\n\nL∞ задаётся как максимальная наблюдаемая длина в данных.\nk и t0 подбираются итеративно методом нелинейных наименьших квадратов (nls).\n\nВизуализация: График сопоставляет эмпирические данные (точки) с предсказаниями модели (красная линия), демонстрируя, как рост замедляется с приближением к L∞.\n\nИнтерпретация параметров:\n\nВысокое значение k (&gt;0.3) указывает на быстрый рост молоди.\nt0&lt;0 может отражать ранний метаморфоз личинок.\n\n\n# Загрузка библиотек\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(nlme)\n\n# Загрузка данных\ndata &lt;- read.csv(\"shrimp_catch.csv\")\n\n# Преобразование возраста в числовой формат\ndata$age_num &lt;- as.numeric(data$age)\n\n# Удаление аутлайеров (если необходимо)\ndata_clean &lt;- data %&gt;%\n  filter(!id %in% c(10, 50))  # Пример удаления строк с аномалиями\n\n# Начальные параметры на основе данных\nL_inf_start &lt;- max(data_clean$length, na.rm = TRUE)  # Максимальная длина\nk_start &lt;- 0.3                                        # Средняя скорость роста\nt0_start &lt;- -0.5                                      # Гипотетический возраст\n\n# Подгонка модели с увеличенным числом итераций\nmodel &lt;- nls(\n  length ~ L_inf * (1 - exp(-k * (age_num - t0))),\n  data = data_clean,\n  start = list(L_inf = L_inf_start, k = k_start, t0 = t0_start),\n  control = nls.control(maxiter = 200, warnOnly = TRUE)  # Увеличиваем лимит итераций\n)\n\n# Вывод результатов\nsummary(model)\n\n# Создание последовательности возрастов для предсказания\nage_seq &lt;- seq(min(data_clean$age_num), max(data_clean$age_num), by = 0.1)\n\n# Предсказание значений длины\nlength_pred &lt;- predict(model, newdata = data.frame(age_num = age_seq))\n\n# Построение графика\nggplot(data_clean, aes(x = age_num, y = length)) +\n  geom_point(aes(color = age), alpha = 0.7) +\n  geom_line(data = data.frame(age_num = age_seq, length = length_pred), \n            aes(x = age_num, y = length), color = \"red\", linewidth = 1.2) +\n  labs(\n    title = \"Рост креветок по уравнению Берталанфи\",\n    x = \"Возраст (годы)\",\n    y = \"Длина карапакса (мм)\",\n    color = \"Возрастная группа\"\n  ) +\n  theme_minimal()\n\n# Сохранение графика\nggsave(\"bertalanffy_model.png\", width = 8, height = 6)\n\n\n\n\nРис. 1.6: Рост креветок по уравнению Берталанфи",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter1.html#огива-логистическая-кривая-и-50-ное-созревание",
    "href": "chapter1.html#огива-логистическая-кривая-и-50-ное-созревание",
    "title": "2  Анализ и визуализация данных улова",
    "section": "2.7 Огива, логистическая кривая и 50%-ное созревание",
    "text": "2.7 Огива, логистическая кривая и 50%-ное созревание\nЛогистическая регрессия удобна там, где исход — бинарный: созрел/не созрел, самка/самец. Для протоандрической креветки вероятность быть самкой естественно растёт с длиной, и логистическая кривая описывает это гладким переходом от 0 к 1; её центральная точка даёт L50 = −β0/β1 — длину, при которой половина особей уже самки. Огива (кумулятивная функция распределения) — это та же история, но накопительно (на фактических данных): как доля самок нарастает по мере увеличения длины; она наглядна для сравнения годов/районов и проверки сдвигов зрелости. Качество логистической модели удобно проверять ROC/AUC: AUC ≈ 0.9+ означает, что длина хорошо ранжирует вероятность женского пола, но не отменяет проверки калибровки. Знак и величина β1 интерпретируются просто: положительный β1 — с каждым миллиметром шансы быть самкой растут, exp(β1) — во сколько раз растут эти шансы на единицу длины. Биологически L50 концентрирует ключевой сигнал: при стабильных условиях он держится в узком интервале (для Pandalus sp. около 25–28 мм), а его снижение обычно маркирует стресс среды или избирательный вылов, «подталкивающий» к более раннему созреванию. В прикладном учёте это даёт два практичных числа — L50 и AUC — и две опоры для интерпретации: насколько резко идёт переход (крутизна кривой) и насколько надёжен прогноз (дискриминация и калибровка).\nЛогистическая кривая — ключевой инструмент для моделирования бинарных процессов, таких как созревание или смена пола у организмов. В случае протоандрических креветок (Pandalus sp.), которые меняют пол с возрастом, зависимость вероятности быть самкой от длины карапакса можно описать логистической функцией:\n\\[\nP(F) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 \\cdot длина)}}\n\\]\nгде P(F) — вероятность принадлежности к женскому полу, β0 — интерсепт, β1 — коэффициент влияния длины.\nТочка перегиба логистической кривой соответствует длине, при которой вероятность быть самкой равна 50%: \\[\nL_{50} = -\\frac{\\beta_0}{\\beta_1}\n\\]\n\n\n\nРис. 1.7: Логистическая кривая\n\n\nОгива (кумулятивная кривая) показывает накопление вероятности с увеличением длины. Для анализа созревания её можно построить через интеграл логистической функции. Визуально она демонстрирует, как доля самок возрастает с размером.\n\n\n\nРис. 1.8: Огива\n\n\n\n2.7.1 Оценка модели\n\nROC-кривая и AUC:\n\nПлощадь под ROC-кривой (AUC) &gt;0.7 указывает на хорошую предсказательную способность модели.\nЗначение AUC = 0.94(пример из кода) подтверждает сильную связь длины и пола.\n\n\n\n\n\nРис. 1.9: ROC-кривая и AUC\n\n\n\nИнтерпретация коэффициентов:\n\nПоложительный β1 означает: с ростом длины вероятность быть самкой увеличивается.\nНапример, β1=0.25 → увеличение длины на 1 мм повышает шансы в e0.25≈1.28 раза.\n\n\n\n\n2.7.2 Биологический контекст\n\nПротоандрический гермафродитизм: У креветок смена пола с самцов на самок происходит при достижении критического размера (~25-28 мм).\nL50 как индикатор: Снижение L50 в популяции может сигнализировать о стрессовых условиях (перелов, изменение среды), ускоряющих созревание.\n\n\n# Установка рабочей директории\nsetwd(\"C:/TEXTBOOK/\")\n\n# Загрузка библиотек\nlibrary(tidyverse)\nlibrary(pROC)\nlibrary(ggplot2)\n\n# Загрузка данных\ndata &lt;- read_csv(\"shrimp_catch.csv\")\n\n# 1. Предобработка данных -----------------------------------------------------\n# Удаление аутлаеров методом IQR\nQ1 &lt;- quantile(data$length, 0.25)\nQ3 &lt;- quantile(data$length, 0.75)\nIQR &lt;- Q3 - Q1\ndata_clean &lt;- data %&gt;%\n  filter(length &gt;= Q1 - 1.5*IQR & length &lt;= Q3 + 1.5*IQR)\n\n# 2. Логистическая регрессия --------------------------------------------------\n# Преобразование пола в бинарную переменную\ndata_clean$sex_binary &lt;- ifelse(data_clean$sex == \"F\", 1, 0)\n\n# Подгонка модели\nmodel_logit &lt;- glm(sex_binary ~ length, \n                   data = data_clean, \n                   family = binomial(link = \"logit\"))\n\n# Расчет коэффициентов\nbeta0 &lt;- coef(model_logit)[1]\nbeta1 &lt;- coef(model_logit)[2]\n\n# Вычисление L50 (длина 50% созревания)\nL50 &lt;- round(-beta0/beta1, 1)\n\n# 3. Визуализация ------------------------------------------------------------\n# Логистическая кривая\nggplot(data_clean, aes(x = length, y = sex_binary)) +\n  geom_point(aes(color = sex), alpha = 0.6, size = 2) +\n  geom_line(aes(y = predict(model_logit, type = \"response\")), \n            color = \"#D81B60\", linewidth = 1.5) +\n  geom_vline(xintercept = L50, linetype = \"dashed\", color = \"#1E88E5\") +\n  annotate(\"text\", x = L50 + 2, y = 0.2, \n           label = paste(\"L50 =\", L50, \"мм\"), color = \"#1E88E5\") +\n  scale_color_manual(values = c(\"#FFC107\", \"#1976D2\")) +\n  labs(\n    title = \"Зависимость пола от длины карапакса\",\n    subtitle = \"Логистическая регрессия с 50%-ной точкой созревания\",\n    x = \"Длина карапакса (мм)\",\n    y = \"Вероятность быть самкой (P(F))\"\n  ) +\n  theme_minimal(base_size = 12)\n\n# Огива (кумулятивное распределение)\ndata_ogive &lt;- data_clean %&gt;%\n  arrange(length) %&gt;%\n  mutate(\n    cum_females = cumsum(sex_binary),\n    cum_prob = cum_females / max(cum_females)\n  )\n\nggplot(data_ogive, aes(x = length, y = cum_prob)) +\n  geom_line(color = \"#4CAF50\", linewidth = 1.5) +\n  geom_vline(xintercept = L50, linetype = \"dashed\", color = \"#1E88E5\") +\n  geom_hline(yintercept = 0.5, linetype = \"dotted\", color = \"#757575\") +\n  annotate(\"text\", x = L50 + 2, y = 0.55, \n           label = paste(\"50% созревание при\", L50, \"мм\"), color = \"#1E88E5\") +\n  scale_y_continuous(labels = scales::percent) +\n  labs(\n    title = \"Огива: Кумулятивное распределение самок\",\n    x = \"Длина карапакса (мм)\",\n    y = \"Накопленная доля самок\"\n  ) +\n  theme_minimal(base_size = 12)\n\n# 4. Оценка модели -----------------------------------------------------------\n# ROC-анализ\nroc_obj &lt;- roc(data_clean$sex_binary, predict(model_logit, type = \"response\"))\nauc_value &lt;- round(auc(roc_obj), 2)\n\n# График ROC-кривой\nplot(roc_obj, col = \"#E53935\", main = paste(\"ROC-кривая (AUC =\", auc_value, \")\"))\n\n# 5. Сохранение результатов --------------------------------------------------\nggsave(\"logistic_curve.png\", width = 8, height = 6, dpi = 300)\nggsave(\"ogive_curve.png\", width = 8, height = 6, dpi = 300)\n\n# Вывод ключевых метрик\ncat(\"Результаты анализа:\\n\")\ncat(\"- Длина 50%-ного созревания (L50):\", L50, \"мм\\n\")\ncat(\"- AUC модели:\", auc_value, \"\\n\")\ncat(\"- Коэффициенты модели:\\n\")\ncat(\"  Intercept (β0):\", round(beta0, 2), \"\\n\")\ncat(\"  Slope (β1):\", round(beta1, 2), \"\\n\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter1.html#сравнение-групп-параметров-моделей",
    "href": "chapter1.html#сравнение-групп-параметров-моделей",
    "title": "2  Анализ и визуализация данных улова",
    "section": "2.8 Сравнение групп, параметров, моделей",
    "text": "2.8 Сравнение групп, параметров, моделей\nСравнивать группы — это не про охоту за маленькими p-value, а про проверяемые ответы на конкретные биологические вопросы. «Самки длиннее самцов?» — переводим в аккуратную статистическую формулировку, начинаем с гигиены данных и только потом подбираем тест. Предобработка банальна, но критична: убираем очевидные аутлайеры по понятному правилу (IQR или заранее согласованный протокол), не «чистим» хвосты до совершенства, сохраняем независимость наблюдений. Разбиваем выборку на подмножества (по полу, по сезону), проверяем типы переменных, смотрим на формы распределений и пропуски. И дальше — не прыжок к t‑тесту, а короткая остановка у предпосылок: нормальность и гомогенность дисперсий — это про остатки и разумность аппроксимации, а не про «магическое число 0.05». При несхожих дисперсиях уместнее Уэлч, при явной ненормальности и неробастности — Манн–Уитни, а при больших n классический t‑тест часто держится благодаря центральной предельной теореме. В любом случае голые p‑значения не заканчивают разговор: эффект размера (Cohen’s d) и доверительные интервалы говорят «на сколько», а не только «есть/нет».\nВизуализация в этом месте — не иллюстрация, а часть доказательства. Boxplot/violin помогают увидеть медианы, разброс и асимметрию; добавленная на график оценка p‑value дисциплинирует интерпретацию, но не подменяет её. Полезно в той же системе координат показать точки, чтобы помнить: каждая точка — отдельная особь, а не абстрактная «генеральная совокупность». И если позволить себе короткую ремарку: мозг с удовольствием «видит» разницу там, где её нет, поэтому лучше сначала смотреть на график, потом на число, а не наоборот.\nКогда вопрос — уже не «кто крупнее», а «кто растёт быстрее», сравнение средних сменяется сравнением параметров модели. Самый прозрачный путь — объединённая линейная модель с взаимодействием: length ~ age * sex. Значимый коэффициент при взаимодействии — это формализованная фраза «наклоны различаются». Диагностика здесь важнее, чем когда‑либо: линейность, разброс остатков, потенциальные leverage‑точки. Альтернатива — раздельные модели по полу и прямое сравнение наклонов через тест Вальда; он удобен как независимая проверка и часто даёт те же выводы, что и взаимодействие, если структура данных не экзотична. Интерпретация должна оставаться биологической: различающиеся наклоны — это не «магия пола», а потенциальная разница в темпе роста, доступе к корму или сезоне отбора проб.\nДальше мы неизбежно приходим к форме связи «вес–длина». Линейная модель соблазнительно проста, но биологически мир чаще степенной: масса масштабируется примерно как длина в степени 3, с поправками на форму и состояние. Полиномиальная регрессия третьего порядка часто выигрывает в AIC и R², потому что ловит сгибы и плечи; у неё есть и оборотная сторона — склонность к переобучению и слабая интерпретируемость коэффициентов. Степенная модель почти всегда немного проигрывает по «сухим метрикам», зато даёт ясный смысл: параметр b близок к 3 — всё ожидаемо; заметное отклонение — есть предмет для обсуждения физиологии, питания, сезонности. Какой из подходов «лучший»? Тот, у которого остатки ведут себя прилично, AIC не кричит о лишней сложности, а биолог рассказывает связную историю, не пряча глаза. Хорошая практика — сопоставить все три, показать таблицу R²/AIC, приложить графики остатков и проговорить компромисс между точностью и объяснимостью.\nИ в сравнении групп, и в сравнении параметров, и в выборе модели действуют три простых правила. Первое — формулируйте вопрос до теста: это экономит десятки необязательных проверок. Второе — показывайте эффект с интервалами: «на сколько» важнее «насколько значимо». Третье — проверяйте устойчивость: замены теста (t ↔︎ Уэлч ↔︎ Манн–Уитни), альтернативная спецификация модели, бутстрэп интервалов — всё это помогает отличить сигнал от удачного совпадения. И, наконец, не забывайте про контекст отбора проб: если улов по орудиям и глубинам неоднороден, то и выводы про «среднего самца» или «типичную самку» легко превращаются в выводы про «типичный улов». Статистическая аккуратность здесь — это не педантизм, а способ говорить о биологии без самообмана.\n\n2.8.1 Сравнение групп (на примере самцов и самок)\nРассмотрим методы сравнения количественных характеристик (длина, вес) между самцами и самками северной креветки. Анализ включает проверку нормальности распределения, выбор подходящего статистического теста и визуализацию различий.\n\n2.8.1.1 Подготовка данных\nЗагрузим данные и выделим подвыборки для самцов и самок:\n\n# Установка рабочей директории\nsetwd(\"C:/TEXTBOOK/\")\n\n# Загрузка библиотек  \nlibrary(tidyverse)  \nlibrary(ggplot2)  \nlibrary(rstatix)\nlibrary(ggpubr)\n\n# Загрузка данных  \ndata &lt;- read_csv(\"shrimp_catch.csv\") %&gt;%\n  filter(!id %in% c(10, 50))  # Удаление аномальных наблюдений \n\n# Фильтрация данных по полу  \nmales &lt;- data %&gt;% filter(sex == \"M\")  \nfemales &lt;- data %&gt;% filter(sex == \"F\") \n\n\n\n2.8.1.2 Проверка нормальности распределения\nПеред сравнением групп проверим, соответствуют ли данные нормальному распределению (тест Шапиро-Уилка):\n\n# Проверка нормальности для длины самцов  \nshapiro_test(males$length)  \n# Проверка нормальности для длины самок  \nshapiro_test(females$length) \n\nЕсли p-value &gt; 0.05, распределение считается нормальным. В противном случае используем непараметрические методы.\n\n\n2.8.1.3 Сравнение средних значений\nЕсли данные нормальны: t-тест\n\n# T-тест для сравнения длин самцов и самок  \nt_test_result &lt;- t_test(length ~ sex, data = data)  \nt_test_result \n\nЕсли данные не нормальны: U-тест Манна-Уитни\n\n# U-тест для сравнения длин самцов и самок  \nmannwhitney_result &lt;- wilcox_test(length ~ sex, data = data)  \nmannwhitney_result \n\n\n\n2.8.1.4 Эффект размера (коэффициент Коэна)\nДля оценки практической значимости различий рассчитаем коэффициент Коэна:\n\n# Расчет коэффициента Коэна  \ncohens_d_result &lt;- cohens_d(length ~ sex, data = data)  \ncohens_d_result  \n\n\nd &lt; 0.2 : малый эффект,\nd ≈ 0.5 : средний эффект,\nd &gt; 0.8 : большой эффект.\n\n\n\n2.8.1.5 Визуализация различий\nПостроим boxplot для визуального сравнения длин самцов и самок:\n\nggplot(data, aes(x = sex, y = length, fill = sex)) +  \n  geom_boxplot(color = \"black\", alpha = 0.7) +  \n  stat_compare_means(method = \"t.test\") +  # Добавление p-value  \n  labs(title = \"Сравнение длин самцов и самок\",  \n       x = \"Пол\", y = \"Длина карапакса (мм)\") +  \n  theme_minimal() \n\n\n\n\nРис. 1.10: Boxplot сравнения длин самцов и самок\n\n\n\n\n2.8.1.6 Интерпретация результатов\n\nЕсли p-value &lt; 0.05, различия между группами статистически значимы.\nЭффект размера помогает оценить биологическую важность различий. Например, если самки значительно крупнее самцов (d = 1.2), это может указывать на половой диморфизм, связанный с репродуктивной стратегией.\n2.8.1.7 Пример полного анализа для веса\n\n\n# Полный анализ для веса  \nweight_analysis &lt;- data %&gt;%  \n  group_by(sex) %&gt;%  \n  summarise(  \n    mean_weight = mean(weight),  \n    sd_weight = sd(weight),  \n    n = n()  \n  ) %&gt;%  \n  mutate(  \n    t_test = list(t_test(weight ~ sex, data = data)),  \n    cohens_d = list(cohens_d(weight ~ sex, data = data))  \n  )  \n\n# Вывод результатов  \nprint(weight_analysis) \n\n# Распределение веса по полу\nggplot(data, aes(x = factor(sex), y = weight, fill = factor(sex))) +\n  geom_violin(trim = FALSE, alpha = 0.7) +\n  geom_boxplot(width = 0.2, outlier.shape = NA, fill = \"white\") +\n  labs(title = \"Распределение веса по полу\", x = \"Пол\", y = \"Вес (г)\") +\n  theme_minimal()\n\n\n\n\nРис. 1.12: Violin plot для визуализации распределения веса\n\n\n\n\n2.8.1.8 Выводы\n\nИспользуйте t-тест для нормальных данных и U-тест для ненормальных.\nДополните анализ оценкой эффекта размера для биологической интерпретации.\nВизуализируйте различия с помощью boxplot или violin plot.\n\nРекомендации :\n\nДля многомерных данных (например, одновременное сравнение длины, веса и возраста) применяйте MANOVA.\nЕсли группы неоднородны (например, разный возрастной состав), используйте ковариационный анализ (ANCOVA).\n\nЧто делать, если тест на нормальность не пройден для одной из групп?\nПри сравнении количественных характеристик (например, длины карапакса у самцов и самок) важно учитывать, соответствуют ли данные нормальному распределению. Если тест на нормальность (например, Шапиро-Уилка) показывает значимое отклонение от нормальности для одной из групп, это влияет на выбор статистического теста и интерпретацию результатов.\nПример из нашего анализа\nМы провели сравнение длины карапакса между самцами и самками:\n\n-   Для самцов: **`shapiro_test(males$length)`** → p-value = **0.000574** (нормальность отвергнута).\n\n-   Для самок: **`shapiro_test(females$length)`** → p-value = **0.891** (нормальность подтверждена).\n\nНесмотря на это, мы применили как **t-тест** , так и **U-тест Манна-Уитни** :\n\n-   **t-тест** : p-value = 1.46e-40 (значимо).\n\n-   **U-тест** : p-value = 1.97e-27 (значимо).\n\n-   Коэффициент Коэна: d = 2.14 (большой эффект).\nПочему это работает?\n1.  **t-тест устойчив к умеренным отклонениям от нормальности** :\n\n    -   При больших выборках (n \\&gt; 30) центральная предельная теорема позволяет использовать t-тест даже при слабо выраженной асимметрии.\n\n    -   В вашем случае выборка самцов (n = 149) достаточно велика, чтобы компенсировать отклонение от нормальности.\n\n2.  **U-тест Манна-Уитни — непараметрическая альтернатива** :\n\n    -   Этот тест не требует нормальности и сравнивает ранги, а не средние значения.\n\n    -   Он подтверждает значимость различий, что усиливает доверие к выводу.\n\n3.  **Эффект размера (коэффициент Кобена)** :\n\n    -   d = 2.14 указывает на **большой эффект** , что важно для биологической интерпретации, даже если p-values значимы.\n\n\n\n2.8.2 Сравнение параметров (линейные модели для оценки межгрупповых различий)\nДля сравнения параметров двух линейных моделей (например, скорости роста самцов и самок) используем следующий подход.\n\n# Установка рабочей директории\nsetwd(\"C:/TEXTBOOK/\")\n\n# Загрузка библиотек\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(broom)\nlibrary(knitr)\n\n# Загрузка данных\ndata &lt;- read_csv(\"shrimp_catch.csv\") %&gt;%\n  filter(!id %in% c(10, 50))  # Удаление аномальных наблюдений\n\n# Фильтрация данных по полу\ndata_male &lt;- data %&gt;% filter(sex == \"M\")\ndata_female &lt;- data %&gt;% filter(sex == \"F\")\n\n# Построение моделей\nmodel_male &lt;- lm(length ~ age, data = data_male)\nmodel_female &lt;- lm(length ~ age, data = data_female)\n\nggplot(data, aes(age, length, color = sex)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", formula = y ~ x) +\n  scale_color_manual(values = c(\"#E7B800\", \"#00AFBB\")) +\n  labs(x = \"Возраст\", y = \"Длина (мм)\") +\n  theme_minimal()\n\n\n\n\nРис. 1.15: Визуализация моделей\n\n\nМетод 1: Объединенная модель с взаимодействиями\n\n# Установка рабочей директории\njoint_model &lt;- lm(length ~ age * sex, data = data)\nsummary(joint_model) %&gt;% \n  broom::tidy() %&gt;% \n  filter(term == \"age:sexM\") %&gt;% \n  kable(caption = \"Проверка различия наклонов\", digits = 3)\n\n\nTable: Проверка различия наклонов\n\n|term     | estimate| std.error| statistic| p.value|\n|:--------|--------:|---------:|---------:|-------:|\n|age:sexM |     1.86|     0.459|     4.053|       0|\n&gt; \n\nИнтерпретация:\nЗначимый коэффициент взаимодействия age:sexM (p &lt; 0.05) указывает на статистически значимые различия в скорости роста между полами.\nМетод 2: Тест Вальда\n\nlibrary(car)\ndelta_beta &lt;- coef(model_male)[\"age\"] - coef(model_female)[\"age\"]\nse_diff &lt;- sqrt(vcov(model_male)[\"age\",\"age\"] + vcov(model_female)[\"age\",\"age\"])\nz_score &lt;- delta_beta / se_diff\np_value &lt;- 2 * pnorm(-abs(z_score))\n\ncat(\"Разница коэффициентов:\", round(delta_beta, 3), \n    \"\\nZ-статистика:\", round(z_score, 3),\n    \"\\np-value:\", format.pval(p_value, digits = 2))\n\n\ncomparison_table &lt;- data.frame(\n  Параметр = c(\"Скорость роста самцов\", \"Скорость роста самок\", \"Разница\"),\n  Значение = c(\n    round(coef(model_male)[\"age\"], 2),\n    round(coef(model_female)[\"age\"], 2),\n    round(delta_beta, 2)\n  ),\n  `p-value` = c(\n    format.pval(summary(model_male)$coefficients[\"age\",4], digits = 2),\n    format.pval(summary(model_female)$coefficients[\"age\",4], digits = 2),\n    format.pval(p_value, digits = 2)\n  )\n)\nkable(comparison_table, caption = \"Сравнение коэффициентов роста\")\n\nВывод\n\n: Сравнение коэффициентов роста\n\n|Параметр              | Значение|p.value |\n|:---------------------|--------:|:-------|\n|Скорость роста самцов |     5.95|&lt;2e-16  |\n|Скорость роста самок  |     4.09|5.2e-13 |\n|Разница               |     1.86|0.00024 |\n&gt; \n\nИнтерпретация:\nЗначимая разница (p &lt; 0.05) указывает на статистически значимые различия в скорости роста между полами.\n\n\n2.8.3 Сравнение моделей\nОдним из ключевых аспектов анализа биологических данных является определение формы зависимости между переменными. В данном разделе мы рассмотрим основы подбора модели зависимости между длиной и весом креветок. Начиная с простой линейной модели, мы постепенно перейдем к более сложным нелинейным моделям, чтобы продемонстрировать методику выбора наилучшей модели. Cравним три модели — линейную, полиномиальную и степенную — чтобы определить, какая из них наилучшим образом описывает данные. Цель анализа — найти математическую зависимость, которая:\n\nТочно предсказывает вес креветки по её длине.\nИмеет биологическую интерпретацию.\nМинимизирует ошибку предсказания.\n\n\n2.8.3.1 Модели и их параметры\n\nЛинейная: \\(\\text{weight} = \\beta_0 + \\beta_1\\cdot\\text{length}\\)\nПолиномиальная 3-й степени: \\(\\text{weight} = \\beta_0 + \\beta_1\\cdot\\text{length} + \\beta_2\\cdot\\text{length}^2 + \\beta_3\\cdot\\text{length}^3\\)\nСтепенная: \\(\\text{weight} = a\\cdot\\text{length}^b\\)\n\n\n\n2.8.3.2 Метрики\n\nR² - (коэффициент детерминации): чем ближе к 1, тем лучше модель объясняет данные.\nAIC -(информационный критерий Акаике): чем меньше значение, тем лучше модель с учётом её сложности.\n\n\n\n2.8.3.3 Результаты\n\n2.8.3.3.1 1. Линейная модель\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.115      0.085     -24.86   &lt;2e-16 ***\nlength       0.1665     0.0038    43.71    &lt;2e-16 ***\n\n\nR² = 0.894\nAIC = 148.02\n\n\n\n\nРис. 1.5: Линейная модель\n\n\n\n\n2.8.3.3.2 2. Полиномиальная модель\n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \npoly(length,3)1  14.5038    0.2127    68.18   &lt;2e-16 ***\npoly(length,3)2   3.7209    0.2127    17.49   &lt;2e-16 ***\npoly(length,3)3   0.9526    0.2127     4.48  1.2e-05 ***\n\n\nR² = 0.957\nAIC = -52.80\n\n\n\n\nРис. 1.5: Полиномиальная модель\n\n\n\n\n2.8.3.3.3 3. Степенная модель\n\nParameters:\n   Estimate Std. Error t value Pr(&gt;|t|)    \na 0.000157   0.000028    5.60  6.3e-08 ***\nb 2.920160   0.054102   53.98   &lt;2e-16 ***\n\n\nR² = 0.955\nAIC = -48.43 \n\n\n\n\n2.8.3.4 3. Сравнение моделей\n\n\n\nМодель\nR²\nAIC\n\n\n\n\nЛинейная\n0.894\n148.02\n\n\nПолиномиальная\n0.957\n-52.80\n\n\nСтепенная\n0.955\n-48.43\n\n\n\nВыводы:\n\nПолиномиальная модель демонстрирует наилучшие показатели (максимальный R² и минимальный AIC).\nСтепенная модель близка по качеству, но её параметр b≈2.92 близок к биологически ожидаемому значению 3 (вес пропорционален объёму).\nЛинейная модель существенно уступает по точности.\n\n\n\n2.8.3.5 4. Рекомендации\n\nДля прогнозирования используйте полиномиальную модель, так как она минимизирует ошибку.\nДля биологической интерпретации предпочтительна степенная модель: weight∝length2.92.\nИзбегайте переобучения: Полиномиальные модели высокой степени могут терять интерпретируемость.\n\n\n\n2.8.3.6 5. Визуализация остатков\nОстатки степенной модели распределены равномерно, что подтверждает её адекватность: \n\n\n2.8.3.7 Заключение\nДля анализа зависимости веса от длины северной креветки рекомендуется:\n\nПолиномиальная модель — для задач, требующих максимальной точности.\nСтепенная модель — для интерпретации биологических закономерностей.\n\nСкрипт вышеописанных событий:\n\n# Установка рабочей директории\nsetwd(\"C:/TEXTBOOK/\")\n\n# Загрузка библиотек\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n# Загрузка данных\ndata &lt;- read_csv(\"shrimp_catch.csv\") %&gt;%\n  filter(!id %in% c(10, 50))  # Удаление аномальных наблюдений\n\n# Проверка структуры\nglimpse(data)\n\n# Линейная модель: вес ~ длина\nmodel_linear &lt;- lm(weight ~ length, data = data)\nsummary(model_linear)\n\n# Визуализация\nggplot(data, aes(x = length, y = weight)) +\n  geom_point(color = \"steelblue\", alpha = 0.7) +\n  geom_smooth(method = \"lm\", color = \"#FC4E07\") +\n  labs(title = \"Линейная модель\", x = \"Длина (мм)\", y = \"Вес (г)\")\n\n\n# Полиномиальная модель: вес ~ длина + длина? + длина?\nmodel_poly &lt;- lm(weight ~ poly(length, 3), data = data)\nsummary(model_poly)\n\n# Визуализация\nggplot(data, aes(x = length, y = weight)) +\n  geom_point(color = \"steelblue\", alpha = 0.7) +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 3), color = \"#E7B800\") +\n  labs(title = \"Полиномиальная модель\", x = \"Длина (мм)\", y = \"Вес (г)\")\n\n\n# Степенная модель: вес ~ длина^k (k подбирается)\nmodel_power &lt;- nls(weight ~ a * length^b, \n                   data = data, \n                   start = list(a = 0.001, b = 3))  # Начальные значения\nsummary(model_power)\n\n# Визуализация\ndata$pred_power &lt;- predict(model_power)\nggplot(data, aes(x = length, y = weight)) +\n  geom_point(color = \"steelblue\", alpha = 0.7) +\n  geom_line(aes(y = pred_power), color = \"#00BA38\", linewidth = 1.2) +\n  labs(title = \"Степенная модель\", x = \"Длина (мм)\", y = \"Вес (г)\")\n\n# Расчет AIC\nAIC(model_linear, model_poly, model_power)\n\n# Расчет R?\nr2_linear &lt;- summary(model_linear)$r.squared\nr2_poly &lt;- summary(model_poly)$r.squared\nr2_power &lt;- 1 - sum(residuals(model_power)^2) / sum((data$weight - mean(data$weight))^2)\n\n# Создание таблицы сравнения моделей\ncomparison_table &lt;- data.frame(\n  Модель = c(\"Линейная\", \"Полиномиальная\", \"Степенная\"),\n  R_square = c(r2_linear, r2_poly, r2_power),\n  AIC = c(AIC(model_linear), AIC(model_poly), AIC(model_power))\n)\n\n# Вывод таблицы\nprint(comparison_table)\n\n# Остатки для степенной модели\ndata$residuals &lt;- residuals(model_power)\n\nggplot(data, aes(x = length, y = residuals)) +\n  geom_point(color = \"#FC4E07\", alpha = 0.7) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Остатки степенной модели\", x = \"Длина (мм)\", y = \"Ошибка\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Анализ и визуализация данных улова</span>"
    ]
  },
  {
    "objectID": "chapter2.html",
    "href": "chapter2.html",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "",
    "text": "3.1 Введение\nЭто практическое занятие — про то, как из разрозненных чисел сделать внятную экологическую историю и как перейти от простых регрессий к нейронным сетям, оставаясь честными перед данными. Мы используем R не из эстетики, а из прагматики: он позволяет прозрачно воспроизводить анализ, контролировать каждую трансформацию и быстро проверять гипотезы. В основе занятия — логика и примеры из статьи Андрея Викторовича Коросова «Нейронные сети в экологии: введение» (Принципы экологии, 2023, №3, 76–96). Там хорошо показан путь от классических линейных моделей к нелинейным конструкциям и дальше — к искусственным нейронным сетям, способным решать задачи классификации и прогнозирования. Мы пойдём тем же маршрутом, но с учебной расстановкой акцентов: сначала поймём, как работает «молоток» (регрессия), прежде чем брать в руки «многофункциональный инструмент» (сеть).\nЗадача занятия двоякая. Во‑первых, усвоить минимально достаточный набор статистических практик, чтобы не путать «эффект» с «удачным совпадением»: проверка предпосылок, визуальная диагностика, простые и понятные метрики качества, раздельные обучающие и тестовые выборки. Во‑вторых, увидеть, как усложнение модели должно быть мотивировано данными и биологией, а не нашей любовью к сложным методам. Если более простая модель объясняет всё, что вам нужно для решения прикладной задачи, смело берите её — мозг склонен влюбляться в красивое, но нам нужна работающая гипотеза.\nСтруктура занятия отражает эволюцию инструментов. Начнём с линейной регрессии на предельно понятном примере: связь массы и длины. Здесь важны не только коэффициенты и p‑значения, но и остатки, проверка линейности, гомоскедастичность, доверительные интервалы. Затем познакомимся с численной оптимизацией: когда аналитического решения нет, мы используем итерационные алгоритмы (nls) и учимся задавать стартовые значения, контролировать сходимость и чувствительность. Далее — множественная регрессия и вопрос интерпретации: что реально добавляет предиктор, а что «ездит зайцем» на коллинеарности. Оттуда естественно перейти к нелинейным зависимостям: аллометрия, линеаризация через логарифмы, сопоставление качества моделей не только по R², но и по AIC, и — что особенно важно — по поведению остатков. Логистическая регрессия вводит нас в мир пороговых процессов и бинарных исходов: S‑кривая, L50, ROC/AUC, калибровка вероятностей — всё это работает одинаково хорошо для токсичности дафний и для созревания по длине.\nКогда базовые кирпичики стоят, делаем шаг к нейронным сетям. Сначала показываем, что сеть без скрытых слоёв фактически воспроизводит линейную модель. Затем добавляем один скрытый нейрон и видим, как появляется возможность описывать нелинейности и пороговые эффекты. Дальше — классификация по нескольким признакам и небольшие архитектуры: оцениваем точность, избегаем утечки информации, фиксируем случайные зерна, обязательно сравниваем с простыми бэйзлайнами, чтобы не путать «мощнее» с «лучше». В финале — пример пространственного моделирования численности по биотопам: разделение на train/test, прогноз на новых условиях, разговор о переносимости моделей и ограничениях, без которых любые «красивые карты» остаются просто эстетикой.\nОрганизация работы предельно проста. Даны три версии скрипта: KOROSOV.R — максимально близко к оригиналу; KOROSOV_updated.R — тот же код с подробными комментариями и пояснениями (основной учебный вариант); KOROSOV_visual.R — дополненный продвинутой визуализацией и небольшой аналитикой качества. Для запуска понадобятся данные vipkar.csv и kihzsdat.csv, корректная рабочая директория в setwd() и набор пакетов (как минимум neuralnet и ggplot2). Мы сознательно держим зависимости минимальными, чтобы главный фокус был на методе и интерпретации, а не на обвязке.\nЧему вы научитесь и на что обращать внимание. Во‑первых, всегда проверять, что модель решает именно ваш вопрос: чёткая формулировка задачи до выбора алгоритма экономит половину времени. Во‑вторых, всегда показывать эффект и неопределённость: коэффициенты с интервалами, калибровка вероятностей, ошибки прогноза на независимых данных. В‑третьих, всегда сравнивать с простым бэйзлайном: если «сеть» не лучше честной регрессии на чистых признаках, значит, проблема не в архитектуре, а в данных или постановке. И да, старайтесь говорить языком биологии: «параметр b близок к 3» — это про объём, «L50 сдвинулся» — про созревание, «AUC высок, но калибровка плывёт» — про надёжность решений на уровне индивидуальных вероятностей.\nНаконец, про дисциплину и воспроизводимость. Фиксируйте seed, документируйте версии пакетов и исходные предположения, храните все промежуточные шаги в скриптах. Это скучно минуту, но экономит дни. И даже когда вы дойдёте до «сетей», помните: сложная модель — это не билет в истину, а всего лишь более гибкий аппроксиматор. Хорошая практика — держать рядом простой, интерпретируемый аналог и объяснять расхождения между ними. Тогда ваши результаты будут не просто «работать», а выдерживать обсуждение с биологами, инженерами и управленцами — то есть приносить пользу за пределами экрана.\nДля работы скрипта:\n# ЗАГРУЗКА БИБЛИОТЕК И НАСТРОЙКА СРЕДЫ ================================\nlibrary(neuralnet)   # Для построения нейронных сетей\nlibrary(ggplot2)     # Для продвинутой визуализации (в данном скрипте не используется напрямую)\n\n# Установите свою рабочую директорию (где лежат файлы данных)\n# setwd(\"C:/ВАША_ДИРЕКТОРИЯ/\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter2.html#введение",
    "href": "chapter2.html#введение",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "",
    "text": "Скачайте файлы данных (vipkar.csv и kihzsdat.csv)\nУстановите рабочую директорию в setwd()\nУстановите необходимые пакеты : install.packages(c(\"neuralnet\", \"ggplot2\"))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter2.html#линейная-регрессия",
    "href": "chapter2.html#линейная-регрессия",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.2 ЛИНЕЙНАЯ РЕГРЕССИЯ",
    "text": "3.2 ЛИНЕЙНАЯ РЕГРЕССИЯ\nВ этом разделе мы изучим основы экологического моделирования на примере зависимости массы тела гадюки от ее длины. Вы построите простую линейную регрессионную модель, визуализируете данные и линию регрессии, а также интерпретируете результаты с помощью функции summary().\nЗагружаем данные\n\n# Данные: масса (w) и длина тела (lt) гадюк (в см и граммах)\nw &lt;- c(85, 90, 85, 95, 95, 135, 165, 135, 140)\nlt &lt;- c(51, 51, 52, 54, 54, 59, 59, 60, 62)\n\nСтроим и запускаем модель \\[\nw_t = a_0 + a_1 \\cdot l_t\n\\]\nгде: - \\(w_t\\) — зависимая переменная, - \\(a_0\\) — свободный член, - \\(a_1\\) — коэффициент регрессии, - \\(l_t\\) — независимая переменная.\n\n# Построение линейной модели: w = a0 + a1*lt\nlreg &lt;- lm(w ~ lt)\n\nВыведем результаты модели\n\n# Просмотр результатов модели:\nsummary(lreg)  # Обратите внимание на коэффициенты и p-значения\n\nНа экране появится:\n\nCall:\nlm(formula = w ~ lt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.452  -7.585  -4.868   1.490  30.623 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -240.766     64.457  -3.735 0.007308 ** \nlt             6.358      1.153   5.516 0.000891 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 13.81 on 7 degrees of freedom\nMultiple R-squared:  0.813,     Adjusted R-squared:  0.7863 \nF-statistic: 30.43 on 1 and 7 DF,  p-value: 0.0008911\n\nМы получили результаты линейной регрессии, где зависимая переменная — масса тела гадюки (w), а независимая переменная — длина тела (lt). Разберем каждый параметр:\n1. **Call (Вызов модели):**\n`lm(formula = w ~ lt)`\nЭто просто напоминание, какая модель была построена. Здесь указано, что мы моделировали зависимость массы (w) от длины тела (lt) с помощью линейной регрессии.\n2. **Residuals (Остатки):**\nОстатки — это разница между наблюдаемыми значениями массы и предсказанными моделью значениями. Они показывают, насколько хорошо модель описывает данные.\n\n`Min`: минимальный остаток = -13.452 (наибольшее недооцененное значение)\n`1Q`: первый квартиль = -7.585 (25% остатков меньше этого значения)\n`Median`: медиана остатков = -4.868 (середина распределения остатков)\n`3Q`: третий квартиль = 1.490 (75% остатков меньше этого значения)\n`Max`: максимальный остаток = 30.623 (наибольшее переоцененное значение)\n\nРаспределение остатков: медиана немного смещена влево (отрицательное значение), а размах между 1Q и 3Q составляет примерно 9 единиц. Это может указывать на легкую асимметрию, но выборка мала.\n3. **Coefficients (Коэффициенты):**\n\n`(Intercept)`: свободный член (a0) = -240.766. Это предсказанное значение массы при длине тела, равной нулю. Биологически это не имеет смысла (длина не может быть нулевой), но это математическая особенность модели.\n`lt`: коэффициент регрессии (a1) = 6.358. Это означает, что при увеличении длины тела на 1 см масса тела увеличивается в среднем на 6.358 г.\n\nДля каждого коэффициента приведены:\n\n`Estimate`: точечная оценка коэффициента.\n`Std. Error`: стандартная ошибка оценки коэффициента. Для intercept = 64.457, для lt = 1.153. Это мера изменчивости оценки.\n`t value`: t-статистика. Рассчитывается как Estimate / Std.Error. Для intercept: -240.766 / 64.457 ≈ -3.735; для lt: 6.358 / 1.153 ≈ 5.516.\n`Pr(&gt;|t|)`: p-значение для проверки гипотезы о равенстве коэффициента нулю.\nДля intercept: p=0.007308 (значим на уровне α=0.01, т.е. intercept статистически значимо отличается от нуля).\nДля lt: p=0.000891 (значим на уровне α=0.001). Это означает, что длина тела значимо влияет на массу.\n\nЗначимость кодов: три звездочки (`***`) означают, что коэффициент значим на уровне 0.001.\n4. **Residual standard error (Стандартная ошибка остатков):** 13.81 на 7 степенях свободы. Это мера разброса остатков. В среднем, предсказания модели отклоняются от реальных значений на ±13.81 г. Степени свободы (df) = n - 2 = 9 - 2 = 7 (n — количество наблюдений).\n5. **Multiple R-squared (Коэффициент детерминации R²):** 0.813. Это означает, что 81.3% вариации массы тела объясняется длиной тела. Остальные 18.7% — это неучтенные факторы и случайная изменчивость.\n6. **Adjusted R-squared (Скорректированный R²):** 0.7863. Этот показатель корректирует R² с учетом числа предикторов. Он полезен при сравнении моделей с разным числом предикторов. Здесь он немного меньше R², так как учитывает, что в модели один предиктор.\n7. **F-statistic (F-статистика):** 30.43 на 1 и 7 степенях свободы. Проверяет гипотезу о том, что все коэффициенты (кроме intercept) равны нулю (т.е. модель не лучше, чем модель только с константой).\n\np-value: 0.0008911 (крайне значимый), что означает, что модель в целом адекватна.\n\n**Выводы:**\n- Уравнение модели: `w = -240.77 + 6.36 * lt`\n- Длина тела значимо влияет на массу (p&lt;0.001).\n- Модель объясняет 81.3% вариации массы.\n- На каждый сантиметр длины тела масса увеличивается примерно на 6.36 г.\n- Остатки модели показывают, что есть несколько точек, которые модель предсказывает с заметной ошибкой (особенно максимальный остаток в 30.6 г). Возможно, для более точного прогноза нужна нелинейная модель или учет дополнительных факторов.\n**Рекомендации:**\n- Проверить допущения линейной регрессии (нормальность остатков, гомоскедастичность) с помощью диагностических графиков.\n- Рассмотреть возможность включения других переменных (например, возраста, пола) в модель.\n- Убедиться, что в данных нет выбросов, которые могут влиять на коэффициенты.\n\n# Визуализация зависимости\nplot(lt, w, \n     main = \"Зависимость массы от длины тела гадюки\", \n     xlab = \"Длина тела (см)\", \n     ylab = \"Масса (г)\", \n     pch = 19,        # Кружки вместо стандартных точек\n     col = \"darkgreen\")\nabline(lreg, col = \"red\", lwd = 2)  # Добавляем линию регрессии\n\n\n\n\nРис. 1.: Пример линейной регрессии",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter2.html#численная-оптимизация",
    "href": "chapter2.html#численная-оптимизация",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.3 ЧИСЛЕННАЯ ОПТИМИЗАЦИЯ",
    "text": "3.3 ЧИСЛЕННАЯ ОПТИМИЗАЦИЯ\nЗдесь вы познакомитесь с численными методами оптимизации параметров моделей, которые применяются, когда аналитическое решение невозможно. На примере той же зависимости массы от длины вы подгоните параметры модели с помощью функции nls() и сравните результаты с аналитическим решением.\nАналитические методы дают точное решение в виде математической формулы, используя алгебраические преобразования и теоремы математического анализа. Они идеальны для простых моделей, где существуют явные решения, обеспечивая прозрачную интерпретацию параметров. В экологии такие методы применимы для базовых зависимостей типа линейной регрессии. Численные методы используются, когда аналитическое решение невозможно, и работают через последовательные приближения, начиная со стартовых значений и итеративно улучшая параметры модели. Они незаменимы для сложных экологических моделей с нелинейными зависимостями, взаимодействиями факторов и “шумными” полевыми данными, позволяя решать задачи, недоступные для аналитических подходов.\n\n# Подгонка параметров через оптимизацию\nnls_model &lt;- nls(w ~ a0 + a1 * lt, start = list(a0 = 1, a1 = 1))\nsummary(nls_model)\n\nНа экране появится:\n\nFormula: w ~ a0 + a1 * lt\n\nParameters:\n   Estimate Std. Error t value Pr(&gt;|t|)    \na0 -240.766     64.457  -3.735 0.007308 ** \na1    6.358      1.153   5.516 0.000891 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 13.81 on 7 degrees of freedom\n\nNumber of iterations to convergence: 1 \nAchieved convergence tolerance: 3.247e-08\n\n\n3.3.1 Интерпретация результатов модели\nМы построили линейную модель зависимости массы гадюки (w) от длины её тела (lt) по формуле:\nw = a0 + a1 * lt\nКлючевые параметры модели:\n\na0 (свободный член): -240.8 г\nЭто теоретическая масса при нулевой длине тела. Отрицательное значение указывает, что модель не подходит для очень молодых особей.\na1 (коэффициент при lt): 6.36 г/см\nКаждый дополнительный сантиметр длины тела увеличивает массу в среднем на 6.36 г.\n\nТочность и значимость:\n\nОба коэффициента высоко значимы (p &lt; 0.01), что подтверждает реальность зависимости.\nСтандартная ошибка для a1 составляет 1.15 г/см - это значит, что реальное значение, вероятно, находится между 5.2 и 7.5 г/см.\nМодель хорошо сошлась за 1 шаг (итерацию), что говорит об удачном подборе параметров.\n\nОшибка прогноза:\nСреднее отклонение предсказаний от реальных значений - 13.8 г (стандартная ошибка остатков). Для особи массой 100 г это означает возможную ошибку прогноза около 14%.\n\nБиологический смысл: Модель подтверждает сильную аллометрию - крупные гадюки имеют относительно большую массу тела. Каждый сантиметр длины добавляет около 6.4 г массы. Для особи длиной 55 см прогнозируемая масса составит: -240.8 + 6.36*55 ≈ 109 г.\n\n##МНОЖЕСТВЕННАЯ РЕГРЕССИЯ\nВ этом разделе мы расширим модель, включив несколько факторов. Вы построите множественную регрессию, учитывающую одновременно длину тела и длину хвоста гадюки, и научитесь интерпретировать влияние нескольких предикторов на зависимую переменную.\n\n# Добавляем новый признак - длину хвоста (lc)\nw &lt;- c(40, 156, 105, 85, 80, 50, 75, 48, 75, 67)\nlt &lt;- c(44, 59, 49, 50, 54, 43, 49, 42, 47, 47)\nlc &lt;- c(70, 78, 66, 90, 83, 70, 62, 75, 40, 80)\n\nИспользуя glm-функцию, построим модель с двумя предикторами: \\[\nw = a_0 + a_1 \\cdot l_t + a_2 \\cdot l_c\n\\]\nгде: - \\(w\\) — масса гадюки, - \\(l_t\\) — длина тела гадюки, - \\(l_c\\) — длина хвоста гадюки, - \\(a_0\\) — свободный член (константа), - \\(a_1\\) — коэффициент регрессии при длине тела, - \\(a_2\\) — коэффициент регрессии при длине хвоста.\n\n# Множественная регрессия: w = a0 + a1*lt + a2*lc\nmulti_reg &lt;- glm(w ~ lt + lc)\nsummary(multi_reg)\n\nНа экране появится:\n\nCall:\nglm(formula = w ~ lt + lc)\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -191.2982    53.6908  -3.563 0.009183 ** \nlt             6.0308     1.1051   5.457 0.000949 ***\nlc            -0.3150     0.4133  -0.762 0.470913    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n(Dispersion parameter for gaussian family taken to be 270.9752)\n\n    Null deviance: 10132.9  on 9  degrees of freedom\nResidual deviance:  1896.8  on 7  degrees of freedom\nAIC: 88.832\n\nNumber of Fisher Scoring iterations: 2\n\n\n\n3.3.2 Интерпретация результатов множественной регрессии\nМы исследовали зависимость массы гадюки (w) от длины тела (lt) и длины хвоста (lc) с помощью модели:\nw = b0 + b1*lt + b2*lc\nКлючевые выводы модели:\n\nДлина тела (lt) сильно влияет на массу:\n\nКоэффициент: +6.03 г/см\nКаждый сантиметр длины тела увеличивает массу на ~6 г\nВысокая значимость (p = 0.00095)\n\nДлина хвоста (lc) не влияет значимо на массу:\n\nКоэффициент: -0.315 г/см (незначимый)\np-значение 0.47 &gt; 0.05 - статистически недостоверно\nПосле учета длины тела, длина хвоста не добавляет информации\n\nСвободный член (b0): -191.3 г\nОтрицательное значение подтверждает нелинейность роста у молодых особей\n\nКачество модели:\n\nМодель объясняет значительную часть вариации:\nОбщая вариация (Null deviance) = 10132.9\nОстаточная вариация (Residual deviance) = 1896.8 → Объяснено 81% вариации\nAIC = 88.8 (ниже, чем у модели без lc - 92.1, что указывает на лучшее качество)\nМодель быстро сошлась за 2 итерации\n\nБиологическая интерпретация:\n\nМасса тела определяется в основном длиной туловища, а не хвоста\nДля прогноза массы достаточно учитывать только длину тела\nПример прогноза для особи (lt=50 см, lc=70 см):\n-191.3 + 6.03*50 - 0.315*70 ≈ 111 г\n\n\nРекомендация: При изучении массы гадюк можно исключить длину хвоста из модели, так как она не вносит значимого вклада в предсказание. Основным морфометрическим показателем остается длина тела.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter2.html#нелинейные-зависимости",
    "href": "chapter2.html#нелинейные-зависимости",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.4 НЕЛИНЕЙНЫЕ ЗАВИСИМОСТИ",
    "text": "3.4 НЕЛИНЕЙНЫЕ ЗАВИСИМОСТИ\nЭкологические данные часто имеют нелинейный характер. Здесь вы смоделируете степенную зависимость (аллометрию) между массой и длиной тела, используя линеаризацию через логарифмирование, а затем визуализируете кривую модели.\n\n# Часто в экологии связи имеют степенной характер: w = a0 * lt^a1\n# Линеаризация через логарифмирование\nlog_model &lt;- lm(log(w) ~ log(lt))\n\n# Преобразование коэффициентов обратно\na0 &lt;- exp(coef(log_model)[1])  # Переход от логарифмов\na1 &lt;- coef(log_model)[2]       # Показатель степени\n\n# Визуализация степенной зависимости\nplot(lt, w, \n     main = \"Степенная зависимость массы от длины\", \n     xlab = \"Длина тела (см)\", \n     ylab = \"Масса (г)\",\n     pch = 17,\n     col = \"blue\")\ncurve(a0 * x^a1, add = TRUE, col = \"red\", lwd = 2)  # Кривая модели\n\n\n\n\nРис. 2.: Расчет степенной функции",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter2.html#логистическая-регрессия",
    "href": "chapter2.html#логистическая-регрессия",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.5 ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ",
    "text": "3.5 ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ\nВы изучите моделирование пороговых эффектов в экологии на примере смертности дафний в зависимости от концентрации токсиканта. Построив логистическую регрессию, вы получите S-образную кривую, характерную для таких процессов.\n\n# Пример: смертность дафний при разных концентрациях токсиканта\n# Данные:\nK &lt;- c(100, 126, 158, 200, 251, 316, 398, 501, 631, 794, 1000)\np &lt;- c(0, 0, 0, 0, 0, 0.5, 0.5, 1, 1, 1, 1)  # Доля погибших\nd &lt;- data.frame(K, p)\n\n# Построение логистической модели\nlogit_model &lt;- glm(p ~ K, family = binomial(), data = d)\n\n# Визуализация S-образной кривой\nplot(d$K, d$p, \n     xlab = \"Концентрация токсиканта (мг/л)\", \n     ylab = \"Доля погибших\", \n     main = \"Токсическое воздействие на дафний\",\n     pch = 19,\n     col = \"red\")\nlines(d$K, predict(logit_model, type = \"response\"), \n      col = \"blue\", lwd = 2, lty = 1)\n\n\n\n\nРис. 3.: Расчет логистической регрессии гибели дафний в токсиканте",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter2.html#переход-к-сетям",
    "href": "chapter2.html#переход-к-сетям",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.6 ПЕРЕХОД К СЕТЯМ",
    "text": "3.6 ПЕРЕХОД К СЕТЯМ\nСделаем первый шаг к нейронным сетям, построив простейшую сеть без скрытых слоев (аналог линейной регрессии) для модели токсичности. Вы визуализируете структуру сети и убедитесь, что она дает результат, аналогичный линейной модели.\n\n# Простейшая нейросеть (аналог линейной регрессии)\nnn_simple &lt;- neuralnet(p ~ K, data = d, hidden = 0)\n\n# Визуализация структуры сети\nplot(nn_simple, rep = \"best\")\n\n\n\n\nРис. 4.: Схема нейрона",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter2.html#нейроны-как-нелинейные-преобразователи",
    "href": "chapter2.html#нейроны-как-нелинейные-преобразователи",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.7 НЕЙРОНЫ КАК НЕЛИНЕЙНЫЕ ПРЕОБРАЗОВАТЕЛИ",
    "text": "3.7 НЕЙРОНЫ КАК НЕЛИНЕЙНЫЕ ПРЕОБРАЗОВАТЕЛИ\nЗдесь вы добавите в нейронную сеть скрытый слой с одним нейроном, что позволит моделировать нелинейные зависимости. Вы сравните результат работы такой сети с логистической регрессией и увидите, как нейронная сеть имитирует пороговый эффект.\n\n# Сеть с одним скрытым нейроном (имитирует логистическую регрессию)\nnn_1hidden &lt;- neuralnet(p ~ K, data = d, hidden = 1)\n\n# Сравнение с логистической регрессией\nplot(d$K, predict(logit_model, type = \"response\"), \n     type = \"l\", \n     col = \"darkgreen\", \n     lwd = 2,\n     xlab = \"Концентрация\", \n     ylab = \"Смертность\",\n     main = \"Сравнение моделей\")\nlines(d$K, predict(nn_1hidden, d), col = \"blue\", lty = 2, lwd = 2)\nlegend(\"bottomright\", \n       legend = c(\"Логистическая регрессия\", \"Нейронная сеть (1 нейрон)\"),\n       col = c(\"darkgreen\", \"blue\"), \n       lty = 1:2,\n       lwd = 2)\n\n\n\n\nРис. 5.: Сравнение работы",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter2.html#классификация-в-экологии",
    "href": "chapter2.html#классификация-в-экологии",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.8 КЛАССИФИКАЦИЯ В ЭКОЛОГИИ",
    "text": "3.8 КЛАССИФИКАЦИЯ В ЭКОЛОГИИ\nВы примените нейронные сети для решения задачи классификации - определения пола гадюк по морфометрическим признакам. Построив и сравнив несколько архитектур сетей (без скрытых нейронов, с одним и тремя нейронами), вы оцените их точность.\n\n# Загрузка данных по гадюкам (пол, длина тела, длина хвоста, масса)\nv &lt;- read.csv(\"vipkar.csv\")\nhead(v, 3)  # Просмотр первых строк данных\n\nМодель без скрытых нейронов (аналог линейной регрессии)\n\nnv0 &lt;- neuralnet(ns ~ lc, data = v, hidden = 0)\nplot(nv0)  # Визуализация простейшей сети\n\n\n\n\nРис. 6.: Визуализация простейшей сети\n\n\nМодель с одним скрытым нейроном\n\nnv1 &lt;- neuralnet(ns ~ lc, data = v, hidden = 1)\nplot(nv1)  # Схема сети с одним нейроном\n\n\n\n\nРис. 7.: Схема сети с одним нейроном\n\n\nМодель с тремя скрытыми нейронами (полноценная нейросеть)\n\nnv3 &lt;- neuralnet(ns ~ lc + lt + w, data = v, hidden = 3)\nplot(nv3)  # Визуализация сложной сети\n\n\n\n\nРис. 8.: Модель с тремя скрытыми нейронами\n\n\nОценка точности классификации\n\npredictions &lt;- predict(nv3, v)\npredicted_sex &lt;- round(predictions)\naccuracy &lt;- mean(v$ns == predicted_sex)\ncat(\"Точность классификации:\", round(accuracy*100, 1), \"%\\n\")\n\nСравнение разных архитектур нейронных сетей (см. срипт KOROSOV_visual.R)\n\n\n\nРис. 9.: Точность определения пола гадюк",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  },
  {
    "objectID": "chapter2.html#пространственное-моделирование",
    "href": "chapter2.html#пространственное-моделирование",
    "title": "3  Нейронные сети в экологии: практическое введение",
    "section": "3.9 ПРОСТРАНСТВЕННОЕ МОДЕЛИРОВАНИЕ",
    "text": "3.9 ПРОСТРАНСТВЕННОЕ МОДЕЛИРОВАНИЕ\nВ завершение вы построите нейронную сеть для прогнозирования численности гадюк на островах по характеристикам биотопов. Вы разделите данные на обучающую и тестовую выборки, оцените точность модели и используете ее для прогноза в новых условиях.\n\n# Данные по островам Кижского архипелага\nv &lt;- read.csv(\"kihzsdat.csv\")\nhead(v, 3)  # Структура данных: площадь, биотопы, численность видов\n\n# Случайное разделение данных на обучающую и тестовую выборки\nset.seed(123)  # Для воспроизводимости\ntrain_indices &lt;- sample(1:nrow(v), 12)\ntrain_data &lt;- v[train_indices, ]\ntest_data &lt;- v[-train_indices, ]\n\n# Построение нейросети с 5 нейронами в скрытом слое\nmodel &lt;- neuralnet(vb ~ fo + me + bo, data = train_data, hidden = 5)\n\n# Прогнозирование на обучающей выборке\ntrain_pred &lt;- predict(model, train_data)\ntrain_accuracy &lt;- mean(round(train_pred) == train_data$vb)\ncat(\"Точность на обучающей выборке:\", round(train_accuracy*100, 1), \"%\\n\")\n\n# Прогнозирование на тестовой выборке\ntest_pred &lt;- predict(model, test_data)\ntest_accuracy &lt;- mean(round(test_pred) == test_data$vb)\ncat(\"Точность на тестовой выборке:\", round(test_accuracy*100, 1), \"%\\n\")\n\n# Прогноз для новых условий (пример)\nnew_conditions &lt;- data.frame(\n  fo = c(57.9, 35.3, 83.0),  # Площадь лесов (%)\n  me = c(4.1, 0.0, 7.3),     # Площадь лугов (%)\n  bo = c(3.4, 7.9, 11.5)     # Площадь болот (%)\n)\n\nfuture_pred &lt;- predict(model, new_conditions)\ncat(\"Прогнозируемая численность гадюк:\", round(future_pred), \"\\n\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Нейронные сети в экологии: практическое введение</span>"
    ]
  }
]

# ==============================================================================
# 1) ВЫБОР ПРЕДИКТОРОВ
# ------------------------------------------------------------------------------
# Цель блока: привести данные к числовому виду, обработать пропуски, сократить
# мультиколлинеарность (сильные корреляции), а затем автоматически выделить
# кандидатов-предикторов двумя методами (Boruta, LASSO). В конце сформируем
# финальный пул признаков и проверим их значимость в простой LM.
# ==============================================================================

# Установка и подключение необходимых библиотек
# Для автоматического отбора предикторов нам понадобятся дополнительные пакеты
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
  readxl, tidyverse, caret, corrplot, mgcv, randomForest, xgboost,
  Boruta,GGally, FactoMineR, glmnet, recipes, rsample  # Новые библиотеки для автоматического отбора
)

# Очистка среды и установка рабочей директории
# Совет: rm(list=ls()) очищает все объекты в памяти R; setwd задаёт папку,
# где искать/сохранять файлы. Убедитесь, что путь корректен на вашей машине.
rm(list = ls())
setwd("C:/RECRUITMENT/")

# Пакеты для расширенного отбора предикторов
# Boruta — обёртка над Random Forest для отбора признаков;
# glmnet — регуляризация (LASSO/ElasticNet) для отбора/усиления обобщающей способности;
# FactoMineR — PCA и другие многомерные методы (используем как утилиту).
library(Boruta)   # Алгоритм обертки для отбора признаков
library(glmnet)   # LASSO-регрессия
library(FactoMineR) # PCA анализ


# Загрузка и первичная обработка данных
# Шаги: фильтруем годы, приводим типы к числовому, заменяем строковые "NA" на NA.
DATA <- readxl::read_excel("RECRUITMENT.xlsx", sheet = "RECRUITMENT") %>%
  filter(YEAR > 1989 & YEAR < 2022) %>%
  # Преобразуем необходимые столбцы в числовой формат
  mutate(
    across(starts_with("T"), as.numeric),
    across(starts_with("I"), as.numeric),
    across(starts_with("O"), as.numeric),
  ) %>%
  # Обработка пропущенных значений (заменяем строку "NA" на NA)
  mutate(across(where(is.character), ~na_if(., "NA")))

# 1. Подготовка данных -------------------------------------------------------
# Выделим все возможные предикторы, включая географию и индексы трески
# Примечание: оставляем только числовые переменные, т.к. большинство моделей
# требует числовой вход без категориальных уровней.
predictors <- DATA %>% 
  select(-YEAR, -R3haddock) %>% 
  select_if(is.numeric) # Только числовые переменные

# Целевая переменная
response <- DATA$R3haddock

# В статистическом анализе мы различаем:
# - Отклик (response/target variable) - то, что мы пытаемся предсказать (в нашем случае R3haddock)
# - Предикторы (predictors/features) - переменные, которые могут объяснять изменения отклика
# Для корректного анализа важно, чтобы предикторы были числовыми или преобразованы в числовой формат.

# 2. Обработка пропусков -----------------------------------------------------
# Заполнение медианными значениями — простой и устойчивый способ справиться с NA.
# Альтернативы: множественная иммутация (mice), KNN-impute и др.
predictors_filled <- predictors %>%
  mutate(across(everything(), ~ifelse(is.na(.), median(., na.rm = TRUE), .)))

# Заполнение медианой - простой и устойчивый метод обработки пропусков для числовых переменных.
# Медиана предпочтительнее среднего, так как менее чувствительна к выбросам.

# 3. Предварительный анализ корреляций ---------------------------------------
# Зачем: высокие корреляции затрудняют интерпретацию и могут вредить ряду моделей.
cor_matrix <- cor(predictors_filled, use = "complete.obs")
corrplot(cor_matrix, method = "circle", type = "upper", tl.cex = 0.7)


# Удаляем высокоскоррелированные предикторы (r > 0.8)
# Это механическое сокращение мультиколлинеарности до этапа отбора.
high_cor <- findCorrelation(cor_matrix, cutoff = 0.8)
predictors_filtered <- predictors_filled[, -high_cor]

# Высокая корреляция между предикторами (мультиколлинеарность) может привести к нестабильности моделей.
# Например, если два предиктора почти идентичны, модель может неустойчиво распределять их влияние на отклик.
# Удаление сильно коррелированных переменных (r > 0.8) помогает улучшить интерпретируемость и стабильность моделей.


# 4. Автоматизированный отбор Boruta (обертка Random Forest) -----------------
# Идея: определить признаки, которые важнее, чем случайный шум (shadow features).
set.seed(123)
boruta_output <- Boruta(
  x = predictors_filtered, 
  y = response,
  maxRuns = 100,
  doTrace = 2
)

# Визуализация результатов
plot(boruta_output, cex.axis = 0.7, las = 2)
boruta_stats <- attStats(boruta_output)
selected_vars <- getSelectedAttributes(boruta_output, withTentative = TRUE)

# Boruta - это алгоритм отбора признаков, основанный на методе случайного леса.
# Он сравнивает важность реальных переменных с "теневыми" переменными (случайными копиями),
# чтобы определить, действительно ли переменная информативна. [[6]]
# Результаты Boruta показывают: 
#   - Confirmed (зеленые) - значимые предикторы
#   - Tentative (желтые) - предикторы, близкие к порогу значимости
#   - Rejected (красные) - незначимые предикторы


# 5. LASSO с более строгим критерием ------------------------------------------
# Идея: L1-регуляризация зануляет коэффициенты «слабых» предикторов.
# Выбор lambda.1se вместо lambda.min — более консервативный (простая модель).
x <- as.matrix(predictors_filtered)
y <- response

# LASSO (Least Absolute Shrinkage and Selection Operator) - метод регрессии с L1-регуляризацией,
# который одновременно выполняет отбор признаков и оценку коэффициентов. [[8]]
# Параметр lambda контролирует силу регуляризации:
#   - lambda.min дает наименьшую ошибку, но может включать шумовые переменные
#   - lambda.1se (на 1 стандартную ошибку больше) дает более простую модель с меньшим риском переобучения
# Для прогнозирования мы предпочитаем более строгий критерий (lambda.1se), чтобы модель была устойчивее. [[1]]

# Кросс-валидация
cv_fit <- cv.glmnet(x, y, alpha = 1, nfolds = 10)
plot(cv_fit)

# ИСПОЛЬЗУЕМ lambda.1se вместо lambda.min — СТРОЖЕ!
lasso_coef <- coef(cv_fit, s = "lambda.1se")  # <-- Ключевое изменение!
lasso_vars <- rownames(lasso_coef)[lasso_coef[,1] != 0][-1]  # исключаем (Intercept)


# 6. Сравнение отобранных предикторов ----------------------------------------
# Полезно видеть, какие признаки отмечают оба метода (устойчивые кандидаты).
cat("Boruta selected:", length(selected_vars), "variables\n")
print(selected_vars)

cat("\nLASSO selected:", length(lasso_vars), "variables\n")
print(lasso_vars)

# 7. Финальный набор предикторов (объединение результатов) -------------------
# Логика: объединяем списки, добавляем биологически важные переменные вручную.
final_vars <- union(selected_vars, lasso_vars) 

# Добавляем обязательные переменные по биологической логике
mandatory <- c("haddock68")
final_vars <- union(final_vars, mandatory) %>% unique()

# Мы объединяем результаты двух методов отбора признаков для большей надежности.
# Также добавляем переменную haddock68 (нерестовый запас), так как биологически 
# логично, что пополнение запаса напрямую зависит от численности производителей. 
# Это пример интеграции экспертных знаний в статистический анализ - важный принцип 
# при работе с данными в биологических науках.

# 8. Проверка значимости -----------------------------------------------------
# Быстрая оценка значимости с LM: не как окончательный вывод, а как sanity-check.
final_model <- lm(response ~ as.matrix(predictors_filled[, final_vars]))
summary(final_model)

# 9. Формирование финального датасета ----------------------------------------
# Собираем набор с откликом и выбранными предикторами; удалим строки с NA.
model_data <- DATA %>%
  select(R3haddock, all_of(final_vars)) %>%
  drop_na()

# Просмотр структуры финальных данных
glimpse(model_data)

# Визуализация важности переменных
# Внимание: важности от RF — относительные; сопоставляйте с предметной логикой.
var_importance <- randomForest(R3haddock ~ ., data = model_data, importance = TRUE)
varImpPlot(var_importance, main = "Важность предикторов")

# Перед окончательным выбором модели мы проверяем значимость предикторов с помощью линейной регрессии.
# Функция summary() показывает p-значения коэффициентов - если p < 0.05, переменная считается статистически значимой. 
# Визуализация важности переменных с помощью случайного леса дает дополнительную перспективу,
# показывая, какие переменные наиболее информативны для предсказания без предположений о линейности.

# ==============================================================================
#  ПОДГОТОВКА ДАННЫХ
# Создаём NAOspring, фиксируем финальный набор признаков, сохраняем CSV.
# ------------------------------------------------------------------------------
# Цель блока: стандартизировать набор признаков для дальнейшего сравнения
# моделей и обеспечить воспроизводимость (фиксированный CSV с нужными полями).
# ==============================================================================

# 1.1 Пакеты и окружение
# Примечание: блок повторяет базовую инициализацию для автономного запуска.
if (!require("pacman")) install.packages("pacman")
pacman::p_load(readxl, tidyverse, caret, corrplot)

rm(list = ls())
set.seed(123)
setwd("C:/RECRUITMENT/")

# 1.2 Загрузка исходных данных и приведение типов
DATA <- readxl::read_excel("RECRUITMENT.xlsx", sheet = "RECRUITMENT") %>%
  filter(YEAR > 1989 & YEAR < 2022) %>%
  mutate(
    across(starts_with("T"), as.numeric),
    across(starts_with("I"), as.numeric),
    across(starts_with("O"), as.numeric),
    across(where(is.character), ~na_if(., "NA"))
  )

# 1.3 Создаём NAOspring (если есть NAO3, NAO4, NAO5)
# Идея: агрегируем весенний индекс NAO как среднее за месяцы 3–5.
if (all(c("NAO3","NAO4","NAO5") %in% names(DATA))) {
  DATA <- DATA %>%
    mutate(NAOspring = rowMeans(pick(NAO3, NAO4, NAO5), na.rm = TRUE)) %>%
    select(-NAO3, -NAO4, -NAO5)
}

# NAO (North Atlantic Oscillation) - важный климатический индекс, влияющий описывающий изменения атмосферного давления
# над Северной Атлантикой. В частности, он отражает разницу в атмосферном давлении между Исландской депрессией и
# Азорским максимумом. NAO влияет на силу и направление западных ветров, а также на траектории штормов в Северной Атлантике. 
# Мы создаем NAOspring как среднее значение за весенние месяцы (марта, апреля, мая),
# так как именно в этот период происходят ключевые процессы, влияющие на нерест трески. 
# Создание составных переменных на основе экспертных знаний часто улучшает качество моделей.

# 1.4 Финальный учебный набор предикторов (фиксируем)
# Важно: проверяем присутствие нужных колонок и формируем компактный датасет.
needed <- c("codTSB", "T12", "I5", "NAOspring", "haddock68")
stopifnot(all(needed %in% names(DATA)))

# Сохраняем YEAR в CSV (ниже он будет отброшен при обучении, но нужен для графика)
model_data <- DATA %>%
  select(YEAR, all_of(needed), R3haddock) %>%
  drop_na()

write.csv(model_data, "selected_predictors_dataset.csv", row.names = FALSE)
glimpse(model_data)


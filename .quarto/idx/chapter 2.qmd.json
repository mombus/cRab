{"title":"Нейронные сети в экологии: практическое введение","markdown":{"yaml":{"title":"Нейронные сети в экологии: практическое введение","format":"html"},"headingText":"Введение","containsRefs":false,"markdown":"\n\n\nЭто практическое занятие — про то, как из разрозненных чисел сделать внятную экологическую историю и как перейти от простых регрессий к нейронным сетям, оставаясь честными перед данными. Мы используем R не из эстетики, а из прагматики: он позволяет прозрачно воспроизводить анализ, контролировать каждую трансформацию и быстро проверять гипотезы. В основе занятия — логика и примеры из статьи Андрея Викторовича Коросова «[Нейронные сети в экологии: введение](https://ecopri.ru/journal/article.php?id=14002)» (Принципы экологии, 2023, №3, 76–96). Там хорошо показан путь от классических линейных моделей к нелинейным конструкциям и дальше — к искусственным нейронным сетям, способным решать задачи классификации и прогнозирования. Мы пойдём тем же маршрутом, но с учебной расстановкой акцентов: сначала поймём, как работает «молоток» (регрессия), прежде чем брать в руки «многофункциональный инструмент» (сеть).\n\nЗадача занятия двоякая. Во‑первых, усвоить минимально достаточный набор статистических практик, чтобы не путать «эффект» с «удачным совпадением»: проверка предпосылок, визуальная диагностика, простые и понятные метрики качества, раздельные обучающие и тестовые выборки. Во‑вторых, увидеть, как усложнение модели должно быть мотивировано данными и биологией, а не нашей любовью к сложным методам. Если более простая модель объясняет всё, что вам нужно для решения прикладной задачи, смело берите её — мозг склонен влюбляться в красивое, но нам нужна работающая гипотеза.\n\nСтруктура занятия отражает эволюцию инструментов. Начнём с линейной регрессии на предельно понятном примере: связь массы и длины. Здесь важны не только коэффициенты и p‑значения, но и остатки, проверка линейности, гомоскедастичность, доверительные интервалы. Затем познакомимся с численной оптимизацией: когда аналитического решения нет, мы используем итерационные алгоритмы (nls) и учимся задавать стартовые значения, контролировать сходимость и чувствительность. Далее — множественная регрессия и вопрос интерпретации: что реально добавляет предиктор, а что «ездит зайцем» на коллинеарности. Оттуда естественно перейти к нелинейным зависимостям: аллометрия, линеаризация через логарифмы, сопоставление качества моделей не только по R², но и по AIC, и — что особенно важно — по поведению остатков. Логистическая регрессия вводит нас в мир пороговых процессов и бинарных исходов: S‑кривая, L50, ROC/AUC, калибровка вероятностей — всё это работает одинаково хорошо для токсичности дафний и для созревания по длине.\n\nКогда базовые кирпичики стоят, делаем шаг к нейронным сетям. Сначала показываем, что сеть без скрытых слоёв фактически воспроизводит линейную модель. Затем добавляем один скрытый нейрон и видим, как появляется возможность описывать нелинейности и пороговые эффекты. Дальше — классификация по нескольким признакам и небольшие архитектуры: оцениваем точность, избегаем утечки информации, фиксируем случайные зерна, обязательно сравниваем с простыми бейзлайнами, чтобы не путать «мощнее» с «лучше». В финале — пример пространственного моделирования численности по биотопам: разделение на train/test, прогноз на новых условиях, разговор о переносимости моделей и ограничениях, без которых любые «красивые карты» остаются просто эстетикой.\n\nОрганизация работы предельно проста. Даны три версии скрипта: [KOROSOV.R](https://mombus.github.io/cRab/data/KOROSOV.R) — максимально близко к оригиналу; [KOROSOV_updated.R](https://mombus.github.io/cRab/data/KOROSOV_updated.R) — тот же код с подробными комментариями и пояснениями (основной учебный вариант); [KOROSOV_visual.R](https://mombus.github.io/cRab/data/KOROSOV_visual.R) — дополненный продвинутой визуализацией и небольшой аналитикой качества. Для запуска понадобятся данные [vipkar.csv](https://mombus.github.io/cRab/data/vipkar.csv) и [kihzsdat.csv](https://mombus.github.io/cRab/data/kihzsdat.csv), корректная рабочая директория в setwd() и набор пакетов (как минимум neuralnet и ggplot2). Мы сознательно держим зависимости минимальными, чтобы главный фокус был на методе и интерпретации, а не на обвязке.\n\nЧему вы научитесь и на что обращать внимание. Во‑первых, всегда проверять, что модель решает именно ваш вопрос: чёткая формулировка задачи до выбора алгоритма экономит половину времени. Во‑вторых, всегда показывать эффект и неопределённость: коэффициенты с интервалами, калибровка вероятностей, ошибки прогноза на независимых данных. В‑третьих, всегда сравнивать с простым бейзлайном: если «сеть» не лучше честной регрессии на чистых признаках, значит, проблема не в архитектуре, а в данных или постановке. И да, старайтесь говорить языком биологии: «параметр b близок к 3» — это про объём, «L50 сдвинулся» — про созревание, «AUC высок, но калибровка плывёт» — про надёжность решений на уровне индивидуальных вероятностей.\n\nНаконец, про дисциплину и воспроизводимость. Фиксируйте seed, документируйте версии пакетов и исходные предположения, храните все промежуточные шаги в скриптах. Это скучно минуту, но экономит дни. И даже когда вы дойдёте до «сетей», помните: сложная модель — это не билет в истину, а всего лишь более гибкий аппроксиматор. Хорошая практика — держать рядом простой, интерпретируемый аналог и объяснять расхождения между ними. Тогда ваши результаты будут не просто «работать», а выдерживать обсуждение с биологами, инженерами и управленцами — то есть приносить пользу за пределами экрана.\n\n#### **Для работы скрипта:**\n\n1.  Скачайте файлы данных ([vipkar.csv](https://mombus.github.io/cRab/data/vipkar.csv) и [kihzsdat.csv](https://mombus.github.io/cRab/data/kihzsdat.csv))\n\n2.  Установите рабочую директорию в setwd()\n\n3.  Установите необходимые пакеты : **`install.packages(c(\"neuralnet\", \"ggplot2\"))`**\n\n```{r}\n#| output: false\n#| eval: false\n# ЗАГРУЗКА БИБЛИОТЕК И НАСТРОЙКА СРЕДЫ ================================\nlibrary(neuralnet)   # Для построения нейронных сетей\nlibrary(ggplot2)     # Для продвинутой визуализации (в данном скрипте не используется напрямую)\n\n# Установите свою рабочую директорию (где лежат файлы данных)\n# setwd(\"C:/ВАША_ДИРЕКТОРИЯ/\")\n\n```\n\n## ЛИНЕЙНАЯ РЕГРЕССИЯ\n\nВ этом разделе мы изучим основы экологического моделирования на примере зависимости массы тела гадюки от ее длины. Вы построите простую линейную регрессионную модель, визуализируете данные и линию регрессии, а также интерпретируете результаты с помощью функции `summary()`.\n\nЗагружаем данные\n\n```{r}\n#| output: false\n#| eval: false\n# Данные: масса (w) и длина тела (lt) гадюк (в см и граммах)\nw <- c(85, 90, 85, 95, 95, 135, 165, 135, 140)\nlt <- c(51, 51, 52, 54, 54, 59, 59, 60, 62)\n```\n\nСтроим и запускаем модель $$\nw_t = a_0 + a_1 \\cdot l_t\n$$\n\nгде: - $w_t$ — зависимая переменная, - $a_0$ — свободный член, - $a_1$ — коэффициент регрессии, - $l_t$ — независимая переменная.\n\n```{r}\n#| output: false\n#| eval: false\n# Построение линейной модели: w = a0 + a1*lt\nlreg <- lm(w ~ lt)\n```\n\nВыведем результаты модели\n\n```{r}\n#| output: false\n#| eval: false\n# Просмотр результатов модели:\nsummary(lreg)  # Обратите внимание на коэффициенты и p-значения\n```\n\nНа экране появится:\n\n```{r}\n#| output: false\n#| eval: false\nCall:\nlm(formula = w ~ lt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.452  -7.585  -4.868   1.490  30.623 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -240.766     64.457  -3.735 0.007308 ** \nlt             6.358      1.153   5.516 0.000891 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 13.81 on 7 degrees of freedom\nMultiple R-squared:  0.813,     Adjusted R-squared:  0.7863 \nF-statistic: 30.43 on 1 and 7 DF,  p-value: 0.0008911\n```\n\nМы получили результаты линейной регрессии, где зависимая переменная — масса тела гадюки (w), а независимая переменная — длина тела (lt). Разберем каждый параметр:\n\n1\\. \\*\\*Call (Вызов модели):\\*\\*\n\n\\`lm(formula = w \\~ lt)\\`\n\nЭто просто напоминание, какая модель была построена. Здесь указано, что мы моделировали зависимость массы (w) от длины тела (lt) с помощью линейной регрессии.\n\n2\\. \\*\\*Residuals (Остатки):\\*\\*\n\nОстатки — это разница между наблюдаемыми значениями массы и предсказанными моделью значениями. Они показывают, насколько хорошо модель описывает данные.\n\n-   \\`Min\\`: минимальный остаток = -13.452 (наибольшее недооцененное значение)\n\n-   \\`1Q\\`: первый квартиль = -7.585 (25% остатков меньше этого значения)\n\n-   \\`Median\\`: медиана остатков = -4.868 (середина распределения остатков)\n\n-   \\`3Q\\`: третий квартиль = 1.490 (75% остатков меньше этого значения)\n\n-   \\`Max\\`: максимальный остаток = 30.623 (наибольшее переоцененное значение)\n\nРаспределение остатков: медиана немного смещена влево (отрицательное значение), а размах между 1Q и 3Q составляет примерно 9 единиц. Это может указывать на легкую асимметрию, но выборка мала.\n\n3\\. \\*\\*Coefficients (Коэффициенты):\\*\\*\n\n-   \\`(Intercept)\\`: свободный член (a0) = -240.766. Это предсказанное значение массы при длине тела, равной нулю. Биологически это не имеет смысла (длина не может быть нулевой), но это математическая особенность модели.\n\n-   \\`lt\\`: коэффициент регрессии (a1) = 6.358. Это означает, что при увеличении длины тела на 1 см масса тела увеличивается в среднем на 6.358 г.\n\nДля каждого коэффициента приведены:\n\n-   \\`Estimate\\`: точечная оценка коэффициента.\n\n-   \\`Std. Error\\`: стандартная ошибка оценки коэффициента. Для intercept = 64.457, для lt = 1.153. Это мера изменчивости оценки.\n\n-   \\`t value\\`: t-статистика. Рассчитывается как Estimate / Std.Error. Для intercept: -240.766 / 64.457 ≈ -3.735; для lt: 6.358 / 1.153 ≈ 5.516.\n\n-   \\`Pr(\\>\\|t\\|)\\`: p-значение для проверки гипотезы о равенстве коэффициента нулю.\n\n-   Для intercept: p=0.007308 (значим на уровне α=0.01, т.е. intercept статистически значимо отличается от нуля).\n\n-   Для lt: p=0.000891 (значим на уровне α=0.001). Это означает, что длина тела значимо влияет на массу.\n\nЗначимость кодов: три звездочки (\\`\\*\\*\\*\\`) означают, что коэффициент значим на уровне 0.001.\n\n4\\. \\*\\*Residual standard error (Стандартная ошибка остатков):\\*\\* 13.81 на 7 степенях свободы. Это мера разброса остатков. В среднем, предсказания модели отклоняются от реальных значений на ±13.81 г. Степени свободы (df) = n - 2 = 9 - 2 = 7 (n — количество наблюдений).\n\n5\\. \\*\\*Multiple R-squared (Коэффициент детерминации R²):\\*\\* 0.813. Это означает, что 81.3% вариации массы тела объясняется длиной тела. Остальные 18.7% — это неучтенные факторы и случайная изменчивость.\n\n6\\. \\*\\*Adjusted R-squared (Скорректированный R²):\\*\\* 0.7863. Этот показатель корректирует R² с учетом числа предикторов. Он полезен при сравнении моделей с разным числом предикторов. Здесь он немного меньше R², так как учитывает, что в модели один предиктор.\n\n7\\. \\*\\*F-statistic (F-статистика):\\*\\* 30.43 на 1 и 7 степенях свободы. Проверяет гипотезу о том, что все коэффициенты (кроме intercept) равны нулю (т.е. модель не лучше, чем модель только с константой).\n\n-   p-value: 0.0008911 (крайне значимый), что означает, что модель в целом адекватна.\n\n\\*\\*Выводы:\\*\\*\n\n\\- Уравнение модели: \\`w = -240.77 + 6.36 \\* lt\\`\n\n\\- Длина тела значимо влияет на массу (p\\<0.001).\n\n\\- Модель объясняет 81.3% вариации массы.\n\n\\- На каждый сантиметр длины тела масса увеличивается примерно на 6.36 г.\n\n\\- Остатки модели показывают, что есть несколько точек, которые модель предсказывает с заметной ошибкой (особенно максимальный остаток в 30.6 г). Возможно, для более точного прогноза нужна нелинейная модель или учет дополнительных факторов.\n\n\\*\\*Рекомендации:\\*\\*\n\n\\- Проверить допущения линейной регрессии (нормальность остатков, гомоскедастичность) с помощью диагностических графиков.\n\n\\- Рассмотреть возможность включения других переменных (например, возраста, пола) в модель.\n\n\\- Убедиться, что в данных нет выбросов, которые могут влиять на коэффициенты.\n\n```{r}\n#| output: false\n#| eval: false\n# Визуализация зависимости\nplot(lt, w, \n     main = \"Зависимость массы от длины тела гадюки\", \n     xlab = \"Длина тела (см)\", \n     ylab = \"Масса (г)\", \n     pch = 19,        # Кружки вместо стандартных точек\n     col = \"darkgreen\")\nabline(lreg, col = \"red\", lwd = 2)  # Добавляем линию регрессии\n```\n\n![Рис. 1.: Пример линейной регрессии](images/KOROSOV1.PNG){fig-align=\"center\" width=\"60%\"}\n\n## ЧИСЛЕННАЯ ОПТИМИЗАЦИЯ\n\nЗдесь вы познакомитесь с численными методами оптимизации параметров моделей, которые применяются, когда аналитическое решение невозможно. На примере той же зависимости массы от длины вы подгоните параметры модели с помощью функции `nls()` и сравните результаты с аналитическим решением.\n\nАналитические методы дают точное решение в виде математической формулы, используя алгебраические преобразования и теоремы математического анализа. Они идеальны для простых моделей, где существуют явные решения, обеспечивая прозрачную интерпретацию параметров. В экологии такие методы применимы для базовых зависимостей типа линейной регрессии. Численные методы используются, когда аналитическое решение невозможно, и работают через последовательные приближения, начиная со стартовых значений и итеративно улучшая параметры модели. Они незаменимы для сложных экологических моделей с нелинейными зависимостями, взаимодействиями факторов и \"шумными\" полевыми данными, позволяя решать задачи, недоступные для аналитических подходов.\n\n```{r}\n#| output: false\n#| eval: false\n# Подгонка параметров через оптимизацию\nnls_model <- nls(w ~ a0 + a1 * lt, start = list(a0 = 1, a1 = 1))\nsummary(nls_model)\n```\n\nНа экране появится:\n\n```{r}\n#| output: false\n#| eval: false\nFormula: w ~ a0 + a1 * lt\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \na0 -240.766     64.457  -3.735 0.007308 ** \na1    6.358      1.153   5.516 0.000891 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 13.81 on 7 degrees of freedom\n\nNumber of iterations to convergence: 1 \nAchieved convergence tolerance: 3.247e-08\n```\n\n### **Интерпретация результатов модели**\n\nМы построили линейную модель зависимости массы гадюки (w) от длины её тела (lt) по формуле:\\\n**`w = a0 + a1 * lt`**\n\n**Ключевые параметры модели:**\n\n-   **a0 (свободный член)**: -240.8 г\\\n    Это теоретическая масса при нулевой длине тела. Отрицательное значение указывает, что модель не подходит для очень молодых особей.\n\n-   **a1 (коэффициент при lt)**: 6.36 г/см\\\n    Каждый дополнительный сантиметр длины тела увеличивает массу в среднем на 6.36 г.\n\n**Точность и значимость:**\n\n-   Оба коэффициента **высоко значимы** (p \\< 0.01), что подтверждает реальность зависимости.\n\n-   Стандартная ошибка для a1 составляет 1.15 г/см - это значит, что реальное значение, вероятно, находится между 5.2 и 7.5 г/см.\n\n-   Модель хорошо сошлась за 1 шаг (итерацию), что говорит об удачном подборе параметров.\n\n**Ошибка прогноза:**\\\nСреднее отклонение предсказаний от реальных значений - 13.8 г (стандартная ошибка остатков). Для особи массой 100 г это означает возможную ошибку прогноза около 14%.\n\n> **Биологический смысл:** Модель подтверждает сильную аллометрию - крупные гадюки имеют относительно большую массу тела. Каждый сантиметр длины добавляет около 6.4 г массы. Для особи длиной 55 см прогнозируемая масса составит: -240.8 + 6.36\\*55 ≈ 109 г.\n\n##МНОЖЕСТВЕННАЯ РЕГРЕССИЯ\n\nВ этом разделе мы расширим модель, включив несколько факторов. Вы построите множественную регрессию, учитывающую одновременно длину тела и длину хвоста гадюки, и научитесь интерпретировать влияние нескольких предикторов на зависимую переменную.\n\n```{r}\n#| output: false\n#| eval: false\n# Добавляем новый признак - длину хвоста (lc)\nw <- c(40, 156, 105, 85, 80, 50, 75, 48, 75, 67)\nlt <- c(44, 59, 49, 50, 54, 43, 49, 42, 47, 47)\nlc <- c(70, 78, 66, 90, 83, 70, 62, 75, 40, 80)\n```\n\nИспользуя glm-функцию, построим модель с двумя предикторами: $$\nw = a_0 + a_1 \\cdot l_t + a_2 \\cdot l_c\n$$\n\nгде: - $w$ — масса гадюки, - $l_t$ — длина тела гадюки, - $l_c$ — длина хвоста гадюки, - $a_0$ — свободный член (константа), - $a_1$ — коэффициент регрессии при длине тела, - $a_2$ — коэффициент регрессии при длине хвоста.\n\n```{r}\n#| output: false\n#| eval: false\n# Множественная регрессия: w = a0 + a1*lt + a2*lc\nmulti_reg <- glm(w ~ lt + lc)\nsummary(multi_reg)\n```\n\nНа экране появится:\n\n```{r}\n#| output: false\n#| eval: false\nCall:\nglm(formula = w ~ lt + lc)\n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -191.2982    53.6908  -3.563 0.009183 ** \nlt             6.0308     1.1051   5.457 0.000949 ***\nlc            -0.3150     0.4133  -0.762 0.470913    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n(Dispersion parameter for gaussian family taken to be 270.9752)\n\n    Null deviance: 10132.9  on 9  degrees of freedom\nResidual deviance:  1896.8  on 7  degrees of freedom\nAIC: 88.832\n\nNumber of Fisher Scoring iterations: 2\n```\n\n### **Интерпретация результатов множественной регрессии**\n\nМы исследовали зависимость массы гадюки (w) от длины тела (lt) и длины хвоста (lc) с помощью модели:\\\n**`w = b0 + b1*lt + b2*lc`**\n\n**Ключевые выводы модели:**\n\n1.  **Длина тела (lt) сильно влияет на массу**:\n\n    -   Коэффициент: +6.03 г/см\n\n    -   Каждый сантиметр длины тела увеличивает массу на \\~6 г\n\n    -   Высокая значимость (p = 0.00095)\n\n2.  **Длина хвоста (lc) не влияет значимо на массу**:\n\n    -   Коэффициент: -0.315 г/см (незначимый)\n\n    -   p-значение 0.47 \\> 0.05 - статистически недостоверно\n\n    -   После учета длины тела, длина хвоста не добавляет информации\n\n3.  **Свободный член (b0)**: -191.3 г\\\n    Отрицательное значение подтверждает нелинейность роста у молодых особей\n\n**Качество модели:**\n\n-   Модель объясняет значительную часть вариации:\\\n    Общая вариация (Null deviance) = 10132.9\\\n    Остаточная вариация (Residual deviance) = 1896.8 → **Объяснено 81% вариации**\n\n-   AIC = 88.8 (ниже, чем у модели без lc - 92.1, что указывает на лучшее качество)\n\n-   Модель быстро сошлась за 2 итерации\n\n**Биологическая интерпретация:**\n\n1.  Масса тела определяется в основном длиной туловища, а не хвоста\n\n2.  Для прогноза массы достаточно учитывать только длину тела\n\n3.  Пример прогноза для особи (lt=50 см, lc=70 см):\\\n    **`-191.3 + 6.03*50 - 0.315*70 ≈ 111 г`**\n\n> **Рекомендация**: При изучении массы гадюк можно исключить длину хвоста из модели, так как она не вносит значимого вклада в предсказание. Основным морфометрическим показателем остается длина тела.\n\n## НЕЛИНЕЙНЫЕ ЗАВИСИМОСТИ\n\nЭкологические данные часто имеют нелинейный характер. Здесь вы смоделируете степенную зависимость (аллометрию) между массой и длиной тела, используя линеаризацию через логарифмирование, а затем визуализируете кривую модели.\n\n```{r}\n#| output: false\n#| eval: false\n# Часто в экологии связи имеют степенной характер: w = a0 * lt^a1\n# Линеаризация через логарифмирование\nlog_model <- lm(log(w) ~ log(lt))\n\n# Преобразование коэффициентов обратно\na0 <- exp(coef(log_model)[1])  # Переход от логарифмов\na1 <- coef(log_model)[2]       # Показатель степени\n\n# Визуализация степенной зависимости\nplot(lt, w, \n     main = \"Степенная зависимость массы от длины\", \n     xlab = \"Длина тела (см)\", \n     ylab = \"Масса (г)\",\n     pch = 17,\n     col = \"blue\")\ncurve(a0 * x^a1, add = TRUE, col = \"red\", lwd = 2)  # Кривая модели\n```\n\n![Рис. 2.: Расчет степенной функции](images/KOROSOV2.PNG){fig-align=\"center\" width=\"60%\"}\n\n## ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ\n\nВы изучите моделирование пороговых эффектов в экологии на примере смертности дафний в зависимости от концентрации токсиканта. Построив логистическую регрессию, вы получите S-образную кривую, характерную для таких процессов.\n\n```{r}\n#| output: false\n#| eval: false\n# Пример: смертность дафний при разных концентрациях токсиканта\n# Данные:\nK <- c(100, 126, 158, 200, 251, 316, 398, 501, 631, 794, 1000)\np <- c(0, 0, 0, 0, 0, 0.5, 0.5, 1, 1, 1, 1)  # Доля погибших\nd <- data.frame(K, p)\n\n# Построение логистической модели\nlogit_model <- glm(p ~ K, family = binomial(), data = d)\n\n# Визуализация S-образной кривой\nplot(d$K, d$p, \n     xlab = \"Концентрация токсиканта (мг/л)\", \n     ylab = \"Доля погибших\", \n     main = \"Токсическое воздействие на дафний\",\n     pch = 19,\n     col = \"red\")\nlines(d$K, predict(logit_model, type = \"response\"), \n      col = \"blue\", lwd = 2, lty = 1)\n```\n\n![Рис. 3.: Расчет логистической регрессии гибели дафний в токсиканте](images/KOROSOV3.PNG){fig-align=\"center\" width=\"60%\"}\n\n## ПЕРЕХОД К СЕТЯМ\n\nСделаем первый шаг к нейронным сетям, построив простейшую сеть без скрытых слоев (аналог линейной регрессии) для модели токсичности. Вы визуализируете структуру сети и убедитесь, что она дает результат, аналогичный линейной модели.\n\n```{r}\n#| output: false\n#| eval: false\n# Простейшая нейросеть (аналог линейной регрессии)\nnn_simple <- neuralnet(p ~ K, data = d, hidden = 0)\n\n# Визуализация структуры сети\nplot(nn_simple, rep = \"best\")\n```\n\n![Рис. 4.: Схема нейрона](images/KOROSOV4.PNG){fig-align=\"center\" width=\"40%\"}\n\n## НЕЙРОНЫ КАК НЕЛИНЕЙНЫЕ ПРЕОБРАЗОВАТЕЛИ\n\nЗдесь вы добавите в нейронную сеть скрытый слой с одним нейроном, что позволит моделировать нелинейные зависимости. Вы сравните результат работы такой сети с логистической регрессией и увидите, как нейронная сеть имитирует пороговый эффект.\n\n```{r}\n#| output: false\n#| eval: false\n# Сеть с одним скрытым нейроном (имитирует логистическую регрессию)\nnn_1hidden <- neuralnet(p ~ K, data = d, hidden = 1)\n\n# Сравнение с логистической регрессией\nplot(d$K, predict(logit_model, type = \"response\"), \n     type = \"l\", \n     col = \"darkgreen\", \n     lwd = 2,\n     xlab = \"Концентрация\", \n     ylab = \"Смертность\",\n     main = \"Сравнение моделей\")\nlines(d$K, predict(nn_1hidden, d), col = \"blue\", lty = 2, lwd = 2)\nlegend(\"bottomright\", \n       legend = c(\"Логистическая регрессия\", \"Нейронная сеть (1 нейрон)\"),\n       col = c(\"darkgreen\", \"blue\"), \n       lty = 1:2,\n       lwd = 2)\n```\n\n![Рис. 5.: Сравнение работы](images/KOROSOV5.PNG){fig-align=\"center\" width=\"40%\"}\n\n## КЛАССИФИКАЦИЯ В ЭКОЛОГИИ\n\nВы примените нейронные сети для решения задачи классификации - определения пола гадюк по морфометрическим признакам. Построив и сравнив несколько архитектур сетей (без скрытых нейронов, с одним и тремя нейронами), вы оцените их точность.\n\n```{r}\n#| output: false\n#| eval: false\n# Загрузка данных по гадюкам (пол, длина тела, длина хвоста, масса)\nv <- read.csv(\"vipkar.csv\")\nhead(v, 3)  # Просмотр первых строк данных\n```\n\nМодель без скрытых нейронов (аналог линейной регрессии)\n\n```{r}\n#| output: false\n#| eval: false\nnv0 <- neuralnet(ns ~ lc, data = v, hidden = 0)\nplot(nv0)  # Визуализация простейшей сети\n```\n\n![Рис. 6.: Визуализация простейшей сети](images/KOROSOV6.PNG){fig-align=\"center\" width=\"40%\"}\n\nМодель с одним скрытым нейроном\n\n```{r}\n#| output: false\n#| eval: false\nnv1 <- neuralnet(ns ~ lc, data = v, hidden = 1)\nplot(nv1)  # Схема сети с одним нейроном\n```\n\n![Рис. 7.: Схема сети с одним нейроном](images/KOROSOV7.PNG){fig-align=\"center\" width=\"40%\"}\n\nМодель с тремя скрытыми нейронами (полноценная нейросеть)\n\n```{r}\n#| output: false\n#| eval: false\nnv3 <- neuralnet(ns ~ lc + lt + w, data = v, hidden = 3)\nplot(nv3)  # Визуализация сложной сети\n```\n\n![Рис. 8.: Модель с тремя скрытыми нейронами](images/KOROSOV8.PNG){fig-align=\"center\" width=\"40%\"}\n\nОценка точности классификации\n\n```{r}\n#| output: false\n#| eval: false\npredictions <- predict(nv3, v)\npredicted_sex <- round(predictions)\naccuracy <- mean(v$ns == predicted_sex)\ncat(\"Точность классификации:\", round(accuracy*100, 1), \"%\\n\")\n```\n\nСравнение разных архитектур нейронных сетей (см. срипт [KOROSOV_visual.R](https://mombus.github.io/cRab/data/KOROSOV_visual.R))\n\n![Рис. 9.: Точность определения пола гадюк](images/KOROSOV9.PNG){fig-align=\"center\" width=\"60%\"}\n\n## ПРОСТРАНСТВЕННОЕ МОДЕЛИРОВАНИЕ\n\nВ завершение вы построите нейронную сеть для прогнозирования численности гадюк на островах по характеристикам биотопов. Вы разделите данные на обучающую и тестовую выборки, оцените точность модели и используете ее для прогноза в новых условиях.\n\n```{r}\n#| output: false\n#| eval: false\n# Данные по островам Кижского архипелага\nv <- read.csv(\"kihzsdat.csv\")\nhead(v, 3)  # Структура данных: площадь, биотопы, численность видов\n\n# Случайное разделение данных на обучающую и тестовую выборки\nset.seed(123)  # Для воспроизводимости\ntrain_indices <- sample(1:nrow(v), 12)\ntrain_data <- v[train_indices, ]\ntest_data <- v[-train_indices, ]\n\n# Построение нейросети с 5 нейронами в скрытом слое\nmodel <- neuralnet(vb ~ fo + me + bo, data = train_data, hidden = 5)\n\n# Прогнозирование на обучающей выборке\ntrain_pred <- predict(model, train_data)\ntrain_accuracy <- mean(round(train_pred) == train_data$vb)\ncat(\"Точность на обучающей выборке:\", round(train_accuracy*100, 1), \"%\\n\")\n\n# Прогнозирование на тестовой выборке\ntest_pred <- predict(model, test_data)\ntest_accuracy <- mean(round(test_pred) == test_data$vb)\ncat(\"Точность на тестовой выборке:\", round(test_accuracy*100, 1), \"%\\n\")\n\n# Прогноз для новых условий (пример)\nnew_conditions <- data.frame(\n  fo = c(57.9, 35.3, 83.0),  # Площадь лесов (%)\n  me = c(4.1, 0.0, 7.3),     # Площадь лугов (%)\n  bo = c(3.4, 7.9, 11.5)     # Площадь болот (%)\n)\n\nfuture_pred <- predict(model, new_conditions)\ncat(\"Прогнозируемая численность гадюк:\", round(future_pred), \"\\n\")\n```\n","srcMarkdownNoYaml":"\n\n## Введение\n\nЭто практическое занятие — про то, как из разрозненных чисел сделать внятную экологическую историю и как перейти от простых регрессий к нейронным сетям, оставаясь честными перед данными. Мы используем R не из эстетики, а из прагматики: он позволяет прозрачно воспроизводить анализ, контролировать каждую трансформацию и быстро проверять гипотезы. В основе занятия — логика и примеры из статьи Андрея Викторовича Коросова «[Нейронные сети в экологии: введение](https://ecopri.ru/journal/article.php?id=14002)» (Принципы экологии, 2023, №3, 76–96). Там хорошо показан путь от классических линейных моделей к нелинейным конструкциям и дальше — к искусственным нейронным сетям, способным решать задачи классификации и прогнозирования. Мы пойдём тем же маршрутом, но с учебной расстановкой акцентов: сначала поймём, как работает «молоток» (регрессия), прежде чем брать в руки «многофункциональный инструмент» (сеть).\n\nЗадача занятия двоякая. Во‑первых, усвоить минимально достаточный набор статистических практик, чтобы не путать «эффект» с «удачным совпадением»: проверка предпосылок, визуальная диагностика, простые и понятные метрики качества, раздельные обучающие и тестовые выборки. Во‑вторых, увидеть, как усложнение модели должно быть мотивировано данными и биологией, а не нашей любовью к сложным методам. Если более простая модель объясняет всё, что вам нужно для решения прикладной задачи, смело берите её — мозг склонен влюбляться в красивое, но нам нужна работающая гипотеза.\n\nСтруктура занятия отражает эволюцию инструментов. Начнём с линейной регрессии на предельно понятном примере: связь массы и длины. Здесь важны не только коэффициенты и p‑значения, но и остатки, проверка линейности, гомоскедастичность, доверительные интервалы. Затем познакомимся с численной оптимизацией: когда аналитического решения нет, мы используем итерационные алгоритмы (nls) и учимся задавать стартовые значения, контролировать сходимость и чувствительность. Далее — множественная регрессия и вопрос интерпретации: что реально добавляет предиктор, а что «ездит зайцем» на коллинеарности. Оттуда естественно перейти к нелинейным зависимостям: аллометрия, линеаризация через логарифмы, сопоставление качества моделей не только по R², но и по AIC, и — что особенно важно — по поведению остатков. Логистическая регрессия вводит нас в мир пороговых процессов и бинарных исходов: S‑кривая, L50, ROC/AUC, калибровка вероятностей — всё это работает одинаково хорошо для токсичности дафний и для созревания по длине.\n\nКогда базовые кирпичики стоят, делаем шаг к нейронным сетям. Сначала показываем, что сеть без скрытых слоёв фактически воспроизводит линейную модель. Затем добавляем один скрытый нейрон и видим, как появляется возможность описывать нелинейности и пороговые эффекты. Дальше — классификация по нескольким признакам и небольшие архитектуры: оцениваем точность, избегаем утечки информации, фиксируем случайные зерна, обязательно сравниваем с простыми бейзлайнами, чтобы не путать «мощнее» с «лучше». В финале — пример пространственного моделирования численности по биотопам: разделение на train/test, прогноз на новых условиях, разговор о переносимости моделей и ограничениях, без которых любые «красивые карты» остаются просто эстетикой.\n\nОрганизация работы предельно проста. Даны три версии скрипта: [KOROSOV.R](https://mombus.github.io/cRab/data/KOROSOV.R) — максимально близко к оригиналу; [KOROSOV_updated.R](https://mombus.github.io/cRab/data/KOROSOV_updated.R) — тот же код с подробными комментариями и пояснениями (основной учебный вариант); [KOROSOV_visual.R](https://mombus.github.io/cRab/data/KOROSOV_visual.R) — дополненный продвинутой визуализацией и небольшой аналитикой качества. Для запуска понадобятся данные [vipkar.csv](https://mombus.github.io/cRab/data/vipkar.csv) и [kihzsdat.csv](https://mombus.github.io/cRab/data/kihzsdat.csv), корректная рабочая директория в setwd() и набор пакетов (как минимум neuralnet и ggplot2). Мы сознательно держим зависимости минимальными, чтобы главный фокус был на методе и интерпретации, а не на обвязке.\n\nЧему вы научитесь и на что обращать внимание. Во‑первых, всегда проверять, что модель решает именно ваш вопрос: чёткая формулировка задачи до выбора алгоритма экономит половину времени. Во‑вторых, всегда показывать эффект и неопределённость: коэффициенты с интервалами, калибровка вероятностей, ошибки прогноза на независимых данных. В‑третьих, всегда сравнивать с простым бейзлайном: если «сеть» не лучше честной регрессии на чистых признаках, значит, проблема не в архитектуре, а в данных или постановке. И да, старайтесь говорить языком биологии: «параметр b близок к 3» — это про объём, «L50 сдвинулся» — про созревание, «AUC высок, но калибровка плывёт» — про надёжность решений на уровне индивидуальных вероятностей.\n\nНаконец, про дисциплину и воспроизводимость. Фиксируйте seed, документируйте версии пакетов и исходные предположения, храните все промежуточные шаги в скриптах. Это скучно минуту, но экономит дни. И даже когда вы дойдёте до «сетей», помните: сложная модель — это не билет в истину, а всего лишь более гибкий аппроксиматор. Хорошая практика — держать рядом простой, интерпретируемый аналог и объяснять расхождения между ними. Тогда ваши результаты будут не просто «работать», а выдерживать обсуждение с биологами, инженерами и управленцами — то есть приносить пользу за пределами экрана.\n\n#### **Для работы скрипта:**\n\n1.  Скачайте файлы данных ([vipkar.csv](https://mombus.github.io/cRab/data/vipkar.csv) и [kihzsdat.csv](https://mombus.github.io/cRab/data/kihzsdat.csv))\n\n2.  Установите рабочую директорию в setwd()\n\n3.  Установите необходимые пакеты : **`install.packages(c(\"neuralnet\", \"ggplot2\"))`**\n\n```{r}\n#| output: false\n#| eval: false\n# ЗАГРУЗКА БИБЛИОТЕК И НАСТРОЙКА СРЕДЫ ================================\nlibrary(neuralnet)   # Для построения нейронных сетей\nlibrary(ggplot2)     # Для продвинутой визуализации (в данном скрипте не используется напрямую)\n\n# Установите свою рабочую директорию (где лежат файлы данных)\n# setwd(\"C:/ВАША_ДИРЕКТОРИЯ/\")\n\n```\n\n## ЛИНЕЙНАЯ РЕГРЕССИЯ\n\nВ этом разделе мы изучим основы экологического моделирования на примере зависимости массы тела гадюки от ее длины. Вы построите простую линейную регрессионную модель, визуализируете данные и линию регрессии, а также интерпретируете результаты с помощью функции `summary()`.\n\nЗагружаем данные\n\n```{r}\n#| output: false\n#| eval: false\n# Данные: масса (w) и длина тела (lt) гадюк (в см и граммах)\nw <- c(85, 90, 85, 95, 95, 135, 165, 135, 140)\nlt <- c(51, 51, 52, 54, 54, 59, 59, 60, 62)\n```\n\nСтроим и запускаем модель $$\nw_t = a_0 + a_1 \\cdot l_t\n$$\n\nгде: - $w_t$ — зависимая переменная, - $a_0$ — свободный член, - $a_1$ — коэффициент регрессии, - $l_t$ — независимая переменная.\n\n```{r}\n#| output: false\n#| eval: false\n# Построение линейной модели: w = a0 + a1*lt\nlreg <- lm(w ~ lt)\n```\n\nВыведем результаты модели\n\n```{r}\n#| output: false\n#| eval: false\n# Просмотр результатов модели:\nsummary(lreg)  # Обратите внимание на коэффициенты и p-значения\n```\n\nНа экране появится:\n\n```{r}\n#| output: false\n#| eval: false\nCall:\nlm(formula = w ~ lt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.452  -7.585  -4.868   1.490  30.623 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -240.766     64.457  -3.735 0.007308 ** \nlt             6.358      1.153   5.516 0.000891 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 13.81 on 7 degrees of freedom\nMultiple R-squared:  0.813,     Adjusted R-squared:  0.7863 \nF-statistic: 30.43 on 1 and 7 DF,  p-value: 0.0008911\n```\n\nМы получили результаты линейной регрессии, где зависимая переменная — масса тела гадюки (w), а независимая переменная — длина тела (lt). Разберем каждый параметр:\n\n1\\. \\*\\*Call (Вызов модели):\\*\\*\n\n\\`lm(formula = w \\~ lt)\\`\n\nЭто просто напоминание, какая модель была построена. Здесь указано, что мы моделировали зависимость массы (w) от длины тела (lt) с помощью линейной регрессии.\n\n2\\. \\*\\*Residuals (Остатки):\\*\\*\n\nОстатки — это разница между наблюдаемыми значениями массы и предсказанными моделью значениями. Они показывают, насколько хорошо модель описывает данные.\n\n-   \\`Min\\`: минимальный остаток = -13.452 (наибольшее недооцененное значение)\n\n-   \\`1Q\\`: первый квартиль = -7.585 (25% остатков меньше этого значения)\n\n-   \\`Median\\`: медиана остатков = -4.868 (середина распределения остатков)\n\n-   \\`3Q\\`: третий квартиль = 1.490 (75% остатков меньше этого значения)\n\n-   \\`Max\\`: максимальный остаток = 30.623 (наибольшее переоцененное значение)\n\nРаспределение остатков: медиана немного смещена влево (отрицательное значение), а размах между 1Q и 3Q составляет примерно 9 единиц. Это может указывать на легкую асимметрию, но выборка мала.\n\n3\\. \\*\\*Coefficients (Коэффициенты):\\*\\*\n\n-   \\`(Intercept)\\`: свободный член (a0) = -240.766. Это предсказанное значение массы при длине тела, равной нулю. Биологически это не имеет смысла (длина не может быть нулевой), но это математическая особенность модели.\n\n-   \\`lt\\`: коэффициент регрессии (a1) = 6.358. Это означает, что при увеличении длины тела на 1 см масса тела увеличивается в среднем на 6.358 г.\n\nДля каждого коэффициента приведены:\n\n-   \\`Estimate\\`: точечная оценка коэффициента.\n\n-   \\`Std. Error\\`: стандартная ошибка оценки коэффициента. Для intercept = 64.457, для lt = 1.153. Это мера изменчивости оценки.\n\n-   \\`t value\\`: t-статистика. Рассчитывается как Estimate / Std.Error. Для intercept: -240.766 / 64.457 ≈ -3.735; для lt: 6.358 / 1.153 ≈ 5.516.\n\n-   \\`Pr(\\>\\|t\\|)\\`: p-значение для проверки гипотезы о равенстве коэффициента нулю.\n\n-   Для intercept: p=0.007308 (значим на уровне α=0.01, т.е. intercept статистически значимо отличается от нуля).\n\n-   Для lt: p=0.000891 (значим на уровне α=0.001). Это означает, что длина тела значимо влияет на массу.\n\nЗначимость кодов: три звездочки (\\`\\*\\*\\*\\`) означают, что коэффициент значим на уровне 0.001.\n\n4\\. \\*\\*Residual standard error (Стандартная ошибка остатков):\\*\\* 13.81 на 7 степенях свободы. Это мера разброса остатков. В среднем, предсказания модели отклоняются от реальных значений на ±13.81 г. Степени свободы (df) = n - 2 = 9 - 2 = 7 (n — количество наблюдений).\n\n5\\. \\*\\*Multiple R-squared (Коэффициент детерминации R²):\\*\\* 0.813. Это означает, что 81.3% вариации массы тела объясняется длиной тела. Остальные 18.7% — это неучтенные факторы и случайная изменчивость.\n\n6\\. \\*\\*Adjusted R-squared (Скорректированный R²):\\*\\* 0.7863. Этот показатель корректирует R² с учетом числа предикторов. Он полезен при сравнении моделей с разным числом предикторов. Здесь он немного меньше R², так как учитывает, что в модели один предиктор.\n\n7\\. \\*\\*F-statistic (F-статистика):\\*\\* 30.43 на 1 и 7 степенях свободы. Проверяет гипотезу о том, что все коэффициенты (кроме intercept) равны нулю (т.е. модель не лучше, чем модель только с константой).\n\n-   p-value: 0.0008911 (крайне значимый), что означает, что модель в целом адекватна.\n\n\\*\\*Выводы:\\*\\*\n\n\\- Уравнение модели: \\`w = -240.77 + 6.36 \\* lt\\`\n\n\\- Длина тела значимо влияет на массу (p\\<0.001).\n\n\\- Модель объясняет 81.3% вариации массы.\n\n\\- На каждый сантиметр длины тела масса увеличивается примерно на 6.36 г.\n\n\\- Остатки модели показывают, что есть несколько точек, которые модель предсказывает с заметной ошибкой (особенно максимальный остаток в 30.6 г). Возможно, для более точного прогноза нужна нелинейная модель или учет дополнительных факторов.\n\n\\*\\*Рекомендации:\\*\\*\n\n\\- Проверить допущения линейной регрессии (нормальность остатков, гомоскедастичность) с помощью диагностических графиков.\n\n\\- Рассмотреть возможность включения других переменных (например, возраста, пола) в модель.\n\n\\- Убедиться, что в данных нет выбросов, которые могут влиять на коэффициенты.\n\n```{r}\n#| output: false\n#| eval: false\n# Визуализация зависимости\nplot(lt, w, \n     main = \"Зависимость массы от длины тела гадюки\", \n     xlab = \"Длина тела (см)\", \n     ylab = \"Масса (г)\", \n     pch = 19,        # Кружки вместо стандартных точек\n     col = \"darkgreen\")\nabline(lreg, col = \"red\", lwd = 2)  # Добавляем линию регрессии\n```\n\n![Рис. 1.: Пример линейной регрессии](images/KOROSOV1.PNG){fig-align=\"center\" width=\"60%\"}\n\n## ЧИСЛЕННАЯ ОПТИМИЗАЦИЯ\n\nЗдесь вы познакомитесь с численными методами оптимизации параметров моделей, которые применяются, когда аналитическое решение невозможно. На примере той же зависимости массы от длины вы подгоните параметры модели с помощью функции `nls()` и сравните результаты с аналитическим решением.\n\nАналитические методы дают точное решение в виде математической формулы, используя алгебраические преобразования и теоремы математического анализа. Они идеальны для простых моделей, где существуют явные решения, обеспечивая прозрачную интерпретацию параметров. В экологии такие методы применимы для базовых зависимостей типа линейной регрессии. Численные методы используются, когда аналитическое решение невозможно, и работают через последовательные приближения, начиная со стартовых значений и итеративно улучшая параметры модели. Они незаменимы для сложных экологических моделей с нелинейными зависимостями, взаимодействиями факторов и \"шумными\" полевыми данными, позволяя решать задачи, недоступные для аналитических подходов.\n\n```{r}\n#| output: false\n#| eval: false\n# Подгонка параметров через оптимизацию\nnls_model <- nls(w ~ a0 + a1 * lt, start = list(a0 = 1, a1 = 1))\nsummary(nls_model)\n```\n\nНа экране появится:\n\n```{r}\n#| output: false\n#| eval: false\nFormula: w ~ a0 + a1 * lt\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \na0 -240.766     64.457  -3.735 0.007308 ** \na1    6.358      1.153   5.516 0.000891 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 13.81 on 7 degrees of freedom\n\nNumber of iterations to convergence: 1 \nAchieved convergence tolerance: 3.247e-08\n```\n\n### **Интерпретация результатов модели**\n\nМы построили линейную модель зависимости массы гадюки (w) от длины её тела (lt) по формуле:\\\n**`w = a0 + a1 * lt`**\n\n**Ключевые параметры модели:**\n\n-   **a0 (свободный член)**: -240.8 г\\\n    Это теоретическая масса при нулевой длине тела. Отрицательное значение указывает, что модель не подходит для очень молодых особей.\n\n-   **a1 (коэффициент при lt)**: 6.36 г/см\\\n    Каждый дополнительный сантиметр длины тела увеличивает массу в среднем на 6.36 г.\n\n**Точность и значимость:**\n\n-   Оба коэффициента **высоко значимы** (p \\< 0.01), что подтверждает реальность зависимости.\n\n-   Стандартная ошибка для a1 составляет 1.15 г/см - это значит, что реальное значение, вероятно, находится между 5.2 и 7.5 г/см.\n\n-   Модель хорошо сошлась за 1 шаг (итерацию), что говорит об удачном подборе параметров.\n\n**Ошибка прогноза:**\\\nСреднее отклонение предсказаний от реальных значений - 13.8 г (стандартная ошибка остатков). Для особи массой 100 г это означает возможную ошибку прогноза около 14%.\n\n> **Биологический смысл:** Модель подтверждает сильную аллометрию - крупные гадюки имеют относительно большую массу тела. Каждый сантиметр длины добавляет около 6.4 г массы. Для особи длиной 55 см прогнозируемая масса составит: -240.8 + 6.36\\*55 ≈ 109 г.\n\n##МНОЖЕСТВЕННАЯ РЕГРЕССИЯ\n\nВ этом разделе мы расширим модель, включив несколько факторов. Вы построите множественную регрессию, учитывающую одновременно длину тела и длину хвоста гадюки, и научитесь интерпретировать влияние нескольких предикторов на зависимую переменную.\n\n```{r}\n#| output: false\n#| eval: false\n# Добавляем новый признак - длину хвоста (lc)\nw <- c(40, 156, 105, 85, 80, 50, 75, 48, 75, 67)\nlt <- c(44, 59, 49, 50, 54, 43, 49, 42, 47, 47)\nlc <- c(70, 78, 66, 90, 83, 70, 62, 75, 40, 80)\n```\n\nИспользуя glm-функцию, построим модель с двумя предикторами: $$\nw = a_0 + a_1 \\cdot l_t + a_2 \\cdot l_c\n$$\n\nгде: - $w$ — масса гадюки, - $l_t$ — длина тела гадюки, - $l_c$ — длина хвоста гадюки, - $a_0$ — свободный член (константа), - $a_1$ — коэффициент регрессии при длине тела, - $a_2$ — коэффициент регрессии при длине хвоста.\n\n```{r}\n#| output: false\n#| eval: false\n# Множественная регрессия: w = a0 + a1*lt + a2*lc\nmulti_reg <- glm(w ~ lt + lc)\nsummary(multi_reg)\n```\n\nНа экране появится:\n\n```{r}\n#| output: false\n#| eval: false\nCall:\nglm(formula = w ~ lt + lc)\n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -191.2982    53.6908  -3.563 0.009183 ** \nlt             6.0308     1.1051   5.457 0.000949 ***\nlc            -0.3150     0.4133  -0.762 0.470913    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\n(Dispersion parameter for gaussian family taken to be 270.9752)\n\n    Null deviance: 10132.9  on 9  degrees of freedom\nResidual deviance:  1896.8  on 7  degrees of freedom\nAIC: 88.832\n\nNumber of Fisher Scoring iterations: 2\n```\n\n### **Интерпретация результатов множественной регрессии**\n\nМы исследовали зависимость массы гадюки (w) от длины тела (lt) и длины хвоста (lc) с помощью модели:\\\n**`w = b0 + b1*lt + b2*lc`**\n\n**Ключевые выводы модели:**\n\n1.  **Длина тела (lt) сильно влияет на массу**:\n\n    -   Коэффициент: +6.03 г/см\n\n    -   Каждый сантиметр длины тела увеличивает массу на \\~6 г\n\n    -   Высокая значимость (p = 0.00095)\n\n2.  **Длина хвоста (lc) не влияет значимо на массу**:\n\n    -   Коэффициент: -0.315 г/см (незначимый)\n\n    -   p-значение 0.47 \\> 0.05 - статистически недостоверно\n\n    -   После учета длины тела, длина хвоста не добавляет информации\n\n3.  **Свободный член (b0)**: -191.3 г\\\n    Отрицательное значение подтверждает нелинейность роста у молодых особей\n\n**Качество модели:**\n\n-   Модель объясняет значительную часть вариации:\\\n    Общая вариация (Null deviance) = 10132.9\\\n    Остаточная вариация (Residual deviance) = 1896.8 → **Объяснено 81% вариации**\n\n-   AIC = 88.8 (ниже, чем у модели без lc - 92.1, что указывает на лучшее качество)\n\n-   Модель быстро сошлась за 2 итерации\n\n**Биологическая интерпретация:**\n\n1.  Масса тела определяется в основном длиной туловища, а не хвоста\n\n2.  Для прогноза массы достаточно учитывать только длину тела\n\n3.  Пример прогноза для особи (lt=50 см, lc=70 см):\\\n    **`-191.3 + 6.03*50 - 0.315*70 ≈ 111 г`**\n\n> **Рекомендация**: При изучении массы гадюк можно исключить длину хвоста из модели, так как она не вносит значимого вклада в предсказание. Основным морфометрическим показателем остается длина тела.\n\n## НЕЛИНЕЙНЫЕ ЗАВИСИМОСТИ\n\nЭкологические данные часто имеют нелинейный характер. Здесь вы смоделируете степенную зависимость (аллометрию) между массой и длиной тела, используя линеаризацию через логарифмирование, а затем визуализируете кривую модели.\n\n```{r}\n#| output: false\n#| eval: false\n# Часто в экологии связи имеют степенной характер: w = a0 * lt^a1\n# Линеаризация через логарифмирование\nlog_model <- lm(log(w) ~ log(lt))\n\n# Преобразование коэффициентов обратно\na0 <- exp(coef(log_model)[1])  # Переход от логарифмов\na1 <- coef(log_model)[2]       # Показатель степени\n\n# Визуализация степенной зависимости\nplot(lt, w, \n     main = \"Степенная зависимость массы от длины\", \n     xlab = \"Длина тела (см)\", \n     ylab = \"Масса (г)\",\n     pch = 17,\n     col = \"blue\")\ncurve(a0 * x^a1, add = TRUE, col = \"red\", lwd = 2)  # Кривая модели\n```\n\n![Рис. 2.: Расчет степенной функции](images/KOROSOV2.PNG){fig-align=\"center\" width=\"60%\"}\n\n## ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ\n\nВы изучите моделирование пороговых эффектов в экологии на примере смертности дафний в зависимости от концентрации токсиканта. Построив логистическую регрессию, вы получите S-образную кривую, характерную для таких процессов.\n\n```{r}\n#| output: false\n#| eval: false\n# Пример: смертность дафний при разных концентрациях токсиканта\n# Данные:\nK <- c(100, 126, 158, 200, 251, 316, 398, 501, 631, 794, 1000)\np <- c(0, 0, 0, 0, 0, 0.5, 0.5, 1, 1, 1, 1)  # Доля погибших\nd <- data.frame(K, p)\n\n# Построение логистической модели\nlogit_model <- glm(p ~ K, family = binomial(), data = d)\n\n# Визуализация S-образной кривой\nplot(d$K, d$p, \n     xlab = \"Концентрация токсиканта (мг/л)\", \n     ylab = \"Доля погибших\", \n     main = \"Токсическое воздействие на дафний\",\n     pch = 19,\n     col = \"red\")\nlines(d$K, predict(logit_model, type = \"response\"), \n      col = \"blue\", lwd = 2, lty = 1)\n```\n\n![Рис. 3.: Расчет логистической регрессии гибели дафний в токсиканте](images/KOROSOV3.PNG){fig-align=\"center\" width=\"60%\"}\n\n## ПЕРЕХОД К СЕТЯМ\n\nСделаем первый шаг к нейронным сетям, построив простейшую сеть без скрытых слоев (аналог линейной регрессии) для модели токсичности. Вы визуализируете структуру сети и убедитесь, что она дает результат, аналогичный линейной модели.\n\n```{r}\n#| output: false\n#| eval: false\n# Простейшая нейросеть (аналог линейной регрессии)\nnn_simple <- neuralnet(p ~ K, data = d, hidden = 0)\n\n# Визуализация структуры сети\nplot(nn_simple, rep = \"best\")\n```\n\n![Рис. 4.: Схема нейрона](images/KOROSOV4.PNG){fig-align=\"center\" width=\"40%\"}\n\n## НЕЙРОНЫ КАК НЕЛИНЕЙНЫЕ ПРЕОБРАЗОВАТЕЛИ\n\nЗдесь вы добавите в нейронную сеть скрытый слой с одним нейроном, что позволит моделировать нелинейные зависимости. Вы сравните результат работы такой сети с логистической регрессией и увидите, как нейронная сеть имитирует пороговый эффект.\n\n```{r}\n#| output: false\n#| eval: false\n# Сеть с одним скрытым нейроном (имитирует логистическую регрессию)\nnn_1hidden <- neuralnet(p ~ K, data = d, hidden = 1)\n\n# Сравнение с логистической регрессией\nplot(d$K, predict(logit_model, type = \"response\"), \n     type = \"l\", \n     col = \"darkgreen\", \n     lwd = 2,\n     xlab = \"Концентрация\", \n     ylab = \"Смертность\",\n     main = \"Сравнение моделей\")\nlines(d$K, predict(nn_1hidden, d), col = \"blue\", lty = 2, lwd = 2)\nlegend(\"bottomright\", \n       legend = c(\"Логистическая регрессия\", \"Нейронная сеть (1 нейрон)\"),\n       col = c(\"darkgreen\", \"blue\"), \n       lty = 1:2,\n       lwd = 2)\n```\n\n![Рис. 5.: Сравнение работы](images/KOROSOV5.PNG){fig-align=\"center\" width=\"40%\"}\n\n## КЛАССИФИКАЦИЯ В ЭКОЛОГИИ\n\nВы примените нейронные сети для решения задачи классификации - определения пола гадюк по морфометрическим признакам. Построив и сравнив несколько архитектур сетей (без скрытых нейронов, с одним и тремя нейронами), вы оцените их точность.\n\n```{r}\n#| output: false\n#| eval: false\n# Загрузка данных по гадюкам (пол, длина тела, длина хвоста, масса)\nv <- read.csv(\"vipkar.csv\")\nhead(v, 3)  # Просмотр первых строк данных\n```\n\nМодель без скрытых нейронов (аналог линейной регрессии)\n\n```{r}\n#| output: false\n#| eval: false\nnv0 <- neuralnet(ns ~ lc, data = v, hidden = 0)\nplot(nv0)  # Визуализация простейшей сети\n```\n\n![Рис. 6.: Визуализация простейшей сети](images/KOROSOV6.PNG){fig-align=\"center\" width=\"40%\"}\n\nМодель с одним скрытым нейроном\n\n```{r}\n#| output: false\n#| eval: false\nnv1 <- neuralnet(ns ~ lc, data = v, hidden = 1)\nplot(nv1)  # Схема сети с одним нейроном\n```\n\n![Рис. 7.: Схема сети с одним нейроном](images/KOROSOV7.PNG){fig-align=\"center\" width=\"40%\"}\n\nМодель с тремя скрытыми нейронами (полноценная нейросеть)\n\n```{r}\n#| output: false\n#| eval: false\nnv3 <- neuralnet(ns ~ lc + lt + w, data = v, hidden = 3)\nplot(nv3)  # Визуализация сложной сети\n```\n\n![Рис. 8.: Модель с тремя скрытыми нейронами](images/KOROSOV8.PNG){fig-align=\"center\" width=\"40%\"}\n\nОценка точности классификации\n\n```{r}\n#| output: false\n#| eval: false\npredictions <- predict(nv3, v)\npredicted_sex <- round(predictions)\naccuracy <- mean(v$ns == predicted_sex)\ncat(\"Точность классификации:\", round(accuracy*100, 1), \"%\\n\")\n```\n\nСравнение разных архитектур нейронных сетей (см. срипт [KOROSOV_visual.R](https://mombus.github.io/cRab/data/KOROSOV_visual.R))\n\n![Рис. 9.: Точность определения пола гадюк](images/KOROSOV9.PNG){fig-align=\"center\" width=\"60%\"}\n\n## ПРОСТРАНСТВЕННОЕ МОДЕЛИРОВАНИЕ\n\nВ завершение вы построите нейронную сеть для прогнозирования численности гадюк на островах по характеристикам биотопов. Вы разделите данные на обучающую и тестовую выборки, оцените точность модели и используете ее для прогноза в новых условиях.\n\n```{r}\n#| output: false\n#| eval: false\n# Данные по островам Кижского архипелага\nv <- read.csv(\"kihzsdat.csv\")\nhead(v, 3)  # Структура данных: площадь, биотопы, численность видов\n\n# Случайное разделение данных на обучающую и тестовую выборки\nset.seed(123)  # Для воспроизводимости\ntrain_indices <- sample(1:nrow(v), 12)\ntrain_data <- v[train_indices, ]\ntest_data <- v[-train_indices, ]\n\n# Построение нейросети с 5 нейронами в скрытом слое\nmodel <- neuralnet(vb ~ fo + me + bo, data = train_data, hidden = 5)\n\n# Прогнозирование на обучающей выборке\ntrain_pred <- predict(model, train_data)\ntrain_accuracy <- mean(round(train_pred) == train_data$vb)\ncat(\"Точность на обучающей выборке:\", round(train_accuracy*100, 1), \"%\\n\")\n\n# Прогнозирование на тестовой выборке\ntest_pred <- predict(model, test_data)\ntest_accuracy <- mean(round(test_pred) == test_data$vb)\ncat(\"Точность на тестовой выборке:\", round(test_accuracy*100, 1), \"%\\n\")\n\n# Прогноз для новых условий (пример)\nnew_conditions <- data.frame(\n  fo = c(57.9, 35.3, 83.0),  # Площадь лесов (%)\n  me = c(4.1, 0.0, 7.3),     # Площадь лугов (%)\n  bo = c(3.4, 7.9, 11.5)     # Площадь болот (%)\n)\n\nfuture_pred <- predict(model, new_conditions)\ncat(\"Прогнозируемая численность гадюк:\", round(future_pred), \"\\n\")\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"chapter 2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.29","bibliography":["references.bib"],"editor":"visual","theme":["cosmo","brand"],"title":"Нейронные сети в экологии: практическое введение"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"chapter 2.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"block-headings":true,"bibliography":["references.bib"],"editor":"visual","documentclass":"scrreprt","title":"Нейронные сети в экологии: практическое введение"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}